Title,Abstract,Authors,Last Author,Published Date
"Hyperspectral Unmixing of Agricultural Images taken from UAV Using
  Adapted U-Net Architecture","  The hyperspectral unmixing method is an algorithm that extracts material
(usually called endmember) data from hyperspectral data cube pixels along with
their abundances. Due to a lower spatial resolution of hyperspectral sensors
data in each of the pixels may contain mixed information from multiple
endmembers. In this paper we create a hyperspectral unmixing dataset, created
from blueberry field data gathered by a hyperspectral camera mounted on a UAV.
We also propose a hyperspectral unmixing algorithm based on U-Net network
architecture to achieve more accurate unmixing results on existing and newly
created hyperspectral unmixing datasets.
","Vytautas Paura, Virginijus Marcinkevičius",Virginijus Marcinkevičius,2024-09-29T13:24:48Z
"HyperKon: A Self-Supervised Contrastive Network for Hyperspectral Image
  Analysis","  The exceptional spectral resolution of hyperspectral imagery enables material
insights that are not possible with RGB or multispectral images. Yet, the full
potential of this data is often underutilized by deep learning techniques due
to the scarcity of hyperspectral-native CNN backbones. To bridge this gap, we
introduce HyperKon, a self-supervised contrastive learning network designed and
trained on hyperspectral data from the EnMAP Hyperspectral
Satellite\cite{kaufmann2012environmental}. HyperKon uniquely leverages the high
spectral continuity, range, and resolution of hyperspectral data through a
spectral attention mechanism and specialized convolutional layers. We also
perform a thorough ablation study on different kinds of layers, showing their
performance in understanding hyperspectral layers. It achieves an outstanding
98% Top-1 retrieval accuracy and outperforms traditional RGB-trained backbones
in hyperspectral pan-sharpening tasks. Additionally, in hyperspectral image
classification, HyperKon surpasses state-of-the-art methods, indicating a
paradigm shift in hyperspectral image analysis and underscoring the importance
of hyperspectral-native backbones.
","Daniel L Ayuba, Belen Marti-Cardona, Jean-Yves Guillemaut, Oscar Mendez Maldonado",Oscar Mendez Maldonado,2023-11-26T23:50:05Z
"Hyperspectral Imaging and Analysis for Sparse Reconstruction and
  Recognition","  This thesis proposes spatio-spectral techniques for hyperspectral image
analysis. Adaptive spatio-spectral support and variable exposure hyperspectral
imaging is demonstrated to improve spectral reflectance recovery from
hyperspectral images. Novel spectral dimensionality reduction techniques have
been proposed from the perspective of spectral only and spatio-spectral
information preservation. It was found that the joint sparse and joint group
sparse hyperspectral image models achieve lower reconstruction error and higher
recognition accuracy using only a small subset of bands. Hyperspectral image
databases have been developed and made publicly available for further research
in compressed hyperspectral imaging, forensic document analysis and spectral
reflectance recovery.
",Zohaib Khan,Zohaib Khan,2014-07-29T10:29:28Z
"Image-level Classification in Hyperspectral Images using Feature
  Descriptors, with Application to Face Recognition","  In this paper, we proposed a novel pipeline for image-level classification in
the hyperspectral images. By doing this, we show that the discriminative
spectral information at image-level features lead to significantly improved
performance in a face recognition task. We also explored the potential of
traditional feature descriptors in the hyperspectral images. From our
evaluations, we observe that SIFT features outperform the state-of-the-art
hyperspectral face recognition methods, and also the other descriptors. With
the increasing deployment of hyperspectral sensors in a multitude of
applications, we believe that our approach can effectively exploit the spectral
information in hyperspectral images, thus beneficial to more accurate
classification.
","Vivek Sharma, Luc Van Gool",Luc Van Gool,2016-05-11T13:18:22Z
"Multispectral and Hyperspectral Image Fusion Using a 3-D-Convolutional
  Neural Network","  In this paper, we propose a method using a three dimensional convolutional
neural network (3-D-CNN) to fuse together multispectral (MS) and hyperspectral
(HS) images to obtain a high resolution hyperspectral image. Dimensionality
reduction of the hyperspectral image is performed prior to fusion in order to
significantly reduce the computational time and make the method more robust to
noise. Experiments are performed on a data set simulated using a real
hyperspectral image. The results obtained show that the proposed approach is
very promising when compared to conventional methods. This is especially true
when the hyperspectral image is corrupted by additive noise.
","Frosti Palsson, Johannes R. Sveinsson, Magnus O. Ulfarsson",Magnus O. Ulfarsson,2017-06-16T12:38:44Z
"High-Resolution Hyperspectral Video Imaging Using A Hexagonal Camera
  Array","  Retrieving the reflectance spectrum from objects is an essential task for
many classification and detection problems, since many materials and processes
have a unique spectral behaviour. In many cases, it is highly desirable to
capture hyperspectral images due to the high spectral flexibility. Often, it is
even necessary to capture hyperspectral videos or at least to be able to record
a hyperspectral image at once, also called snapshot hyperspectral imaging, to
avoid spectral smearing. For this task, a high-resolution snapshot
hyperspectral camera array using a hexagonal shape is introduced.The hexagonal
array for hyperspectral imaging uses off-the-shelf hardware, which enables high
flexibility regarding employed cameras, lenses and filters. Hence, the spectral
range can be easily varied by mounting a different set of filters. Moreover,
the concept of using off-the-shelf hardware enables low prices in comparison to
other approaches with highly specialized hardware. Since classical industrial
cameras are used in this hyperspectral camera array, the spatial and temporal
resolution is very high, while recording 37 hyperspectral channels in the range
from 400 nm to 760 nm in 10 nm steps. A registration process is required for
near-field imaging, which maps the peripheral camera views to the center view.
It is shown that this combination using a hyperspectral camera array and the
corresponding image registration pipeline is superior in comparison to other
popular snapshot approaches. For this evaluation, a synthetic hyperspectral
database is rendered. On the synthetic data, the novel approach outperforms its
best competitor by more than 3 dB in reconstruction quality. This synthetic
data is also used to show the superiority of the hexagonal shape in comparison
to an orthogonal-spaced one. Moreover, a real-world high resolution
hyperspectral video database is provided.
","Frank Sippel, Jürgen Seiler, André Kaup",André Kaup,2024-07-12T07:00:28Z
"Deep Hyperspectral-Depth Reconstruction Using Single Color-Dot
  Projection","  Depth reconstruction and hyperspectral reflectance reconstruction are two
active research topics in computer vision and image processing. Conventionally,
these two topics have been studied separately using independent imaging setups
and there is no existing method which can acquire depth and spectral
reflectance simultaneously in one shot without using special hardware. In this
paper, we propose a novel single-shot hyperspectral-depth reconstruction method
using an off-the-shelf RGB camera and projector. Our method is based on a
single color-dot projection, which simultaneously acts as structured light for
depth reconstruction and spatially-varying color illuminations for
hyperspectral reflectance reconstruction. To jointly reconstruct the depth and
the hyperspectral reflectance from a single color-dot image, we propose a novel
end-to-end network architecture that effectively incorporates a geometric
color-dot pattern loss and a photometric hyperspectral reflectance loss.
Through the experiments, we demonstrate that our hyperspectral-depth
reconstruction method outperforms the combination of an existing
state-of-the-art single-shot hyperspectral reflectance reconstruction method
and depth reconstruction method.
","Chunyu Li, Yusuke Monno, Masatoshi Okutomi",Masatoshi Okutomi,2022-04-08T08:46:27Z
"End-to-end joint optimization of metasurface and image processing for
  compact snapshot hyperspectral imaging","  Traditional snapshot hyperspectral imaging systems generally require multiple
refractive-optics-based elements to modulate light, resulting in bulky
framework. In pursuit of a more compact form factor, a metasurface-based
snapshot hyperspectral imaging system, which achieves joint optimization of
metasurface and image processing, is proposed in this paper. The unprecedented
light manipulation capabilities of metasurfaces are used in conjunction with
neural networks to encode and decode light fields for better hyperspectral
imaging. Specifically, the extremely strong dispersion of metasurfaces is
exploited to distinguish spectral information, and a neural network based on
spectral priors is applied for hyperspectral image reconstruction. By
constructing a fully differentiable model of metasurface-based hyperspectral
imaging, the front-end metasurface phase distribution and the back-end recovery
network parameters can be jointly optimized. This method achieves high-quality
hyperspectral reconstruction results numerically, outperforming separation
optimization methods. The proposed system holds great potential for
miniaturization and portability of hyperspectral imaging systems.
","Qiangbo Zhang, Zeqing Yu, Xinyu Liu, Chang Wang, Zhenrong Zheng",Zhenrong Zheng,2022-10-14T10:21:27Z
"Synthetic Hyperspectral Array Video Database with Applications to
  Cross-Spectral Reconstruction and Hyperspectral Video Coding","  In this paper, a synthetic hyperspectral video database is introduced. Since
it is impossible to record ground truth hyperspectral videos, this database
offers the possibility to leverage the evaluation of algorithms in diverse
applications. For all scenes, depth maps are provided as well to yield the
position of a pixel in all spatial dimensions as well as the reflectance in
spectral dimension. Two novel algorithms for two different applications are
proposed to prove the diversity of applications that can be addressed by this
novel database. First, a cross-spectral image reconstruction algorithm is
extended to exploit the temporal correlation between two consecutive frames.
The evaluation using this hyperspectral database shows an increase in PSNR of
up to 5.6 dB dependent on the scene. Second, a hyperspectral video coder is
introduced which extends an existing hyperspectral image coder by exploiting
temporal correlation. The evaluation shows rate savings of up to 10% depending
on the scene. The novel hyperspectral video database and source code is
available at https:// github.com/ FAU-LMS/ HyViD for use by the research
community.
","Frank Sippel, Jürgen Seiler, André Kaup",André Kaup,2023-01-18T14:11:59Z
HHTrack: Hyperspectral Object Tracking Using Hybrid Attention,"  Hyperspectral imagery provides abundant spectral information beyond the
visible RGB bands, offering rich discriminative details about objects in a
scene. Leveraging such data has the potential to enhance visual tracking
performance. In this paper, we propose a hyperspectral object tracker based on
hybrid attention (HHTrack). The core of HHTrack is a hyperspectral hybrid
attention (HHA) module that unifies feature extraction and fusion within one
component through token interactions. A hyperspectral bands fusion (HBF) module
is also introduced to selectively aggregate spatial and spectral signatures
from the full hyperspectral input. Extensive experiments demonstrate the
state-of-the-art performance of HHTrack on benchmark Near Infrared (NIR), Red
Near Infrared (Red-NIR), and Visible (VIS) hyperspectral tracking datasets. Our
work provides new insights into harnessing the strengths of transformers and
hyperspectral fusion to advance robust object tracking.
",Yuedong Tan,Yuedong Tan,2023-08-14T09:04:06Z
"High Spectral Spatial Resolution Synthetic HyperSpectral Dataset form
  multi-source fusion","  This research paper introduces a synthetic hyperspectral dataset that
combines high spectral and spatial resolution imaging to achieve a
comprehensive, accurate, and detailed representation of observed scenes or
objects. Obtaining such desirable qualities is challenging when relying on a
single camera. The proposed dataset addresses this limitation by leveraging
three modalities: RGB, push-broom visible hyperspectral camera, and snapshot
infrared hyperspectral camera, each offering distinct spatial and spectral
resolutions. Different camera systems exhibit varying photometric properties,
resulting in a trade-off between spatial and spectral resolution. RGB cameras
typically offer high spatial resolution but limited spectral resolution, while
hyperspectral cameras possess high spectral resolution at the expense of
spatial resolution. Moreover, hyperspectral cameras themselves employ different
capturing techniques and spectral ranges, further complicating the acquisition
of comprehensive data. By integrating the photometric properties of these
modalities, a single synthetic hyperspectral image can be generated,
facilitating the exploration of broader spectral-spatial relationships for
improved analysis, monitoring, and decision-making across various fields. This
paper emphasizes the importance of multi-modal fusion in producing a
high-quality synthetic hyperspectral dataset with consistent spectral intervals
between bands.
","Yajie Sun, Ali Zia, Jun Zhou",Jun Zhou,2023-06-25T11:17:12Z
Unmixing of Hyperspectral Data Using Robust Statistics-based NMF,"  Mixed pixels are presented in hyperspectral images due to low spatial
resolution of hyperspectral sensors. Spectral unmixing decomposes mixed pixels
spectra into endmembers spectra and abundance fractions. In this paper using of
robust statistics-based nonnegative matrix factorization (RNMF) for spectral
unmixing of hyperspectral data is investigated. RNMF uses a robust cost
function and iterative updating procedure, so is not sensitive to outliers.
This method has been applied to simulated data using USGS spectral library,
AVIRIS and ROSIS datasets. Unmixing results are compared to traditional NMF
method based on SAD and AAD measures. Results demonstrate that this method can
be used efficiently for hyperspectral unmixing purposes.
","Roozbeh Rajabi, Hassan Ghassemian",Hassan Ghassemian,2012-12-04T21:59:35Z
"An approximate message passing approach for compressive hyperspectral
  imaging using a simultaneous low-rank and joint-sparsity prior","  This paper considers a compressive sensing (CS) approach for hyperspectral
data acquisition, which results in a practical compression ratio substantially
higher than the state-of-the-art. Applying simultaneous low-rank and
joint-sparse (L&S) model to the hyperspectral data, we propose a novel
algorithm to joint reconstruction of hyperspectral data based on loopy belief
propagation that enables the exploitation of both structured sparsity and
amplitude correlations in the data. Experimental results with real
hyperspectral datasets demonstrate that the proposed algorithm outperforms the
state-of-the-art CS-based solutions with substantial reductions in
reconstruction error.
","Yangqing Li, Saurabh Prasad, Wei Chen, Changchuan Yin, Zhu Han",Zhu Han,2016-07-12T14:49:05Z
"Map-guided Hyperspectral Image Superpixel Segmentation Using Proportion
  Maps","  A map-guided superpixel segmentation method for hyperspectral imagery is
developed and introduced. The proposed approach develops a
hyperspectral-appropriate version of the SLIC superpixel segmentation
algorithm, leverages map information to guide segmentation, and incorporates
the semi-supervised Partial Membership Latent Dirichlet Allocation (sPM-LDA) to
obtain a final superpixel segmentation. The proposed method is applied to two
real hyperspectral data sets and quantitative cluster validity metrics indicate
that the proposed approach outperforms existing hyperspectral superpixel
segmentation methods.
","Hao Sun, Alina Zare",Alina Zare,2017-01-06T19:52:10Z
"TDiffDe: A Truncated Diffusion Model for Remote Sensing Hyperspectral
  Image Denoising","  Hyperspectral images play a crucial role in precision agriculture,
environmental monitoring or ecological analysis. However, due to sensor
equipment and the imaging environment, the observed hyperspectral images are
often inevitably corrupted by various noise. In this study, we proposed a
truncated diffusion model, called TDiffDe, to recover the useful information in
hyperspectral images gradually. Rather than starting from a pure noise, the
input data contains image information in hyperspectral image denoising. Thus,
we cut the trained diffusion model from small steps to avoid the destroy of
valid information.
","Jiang He, Yajie Li, Jie L, Qiangqiang Yuan",Qiangqiang Yuan,2023-11-22T08:49:08Z
"Learning Spatial-Spectral Prior for Super-Resolution of Hyperspectral
  Imagery","  Recently, single gray/RGB image super-resolution reconstruction task has been
extensively studied and made significant progress by leveraging the advanced
machine learning techniques based on deep convolutional neural networks
(DCNNs). However, there has been limited technical development focusing on
single hyperspectral image super-resolution due to the high-dimensional and
complex spectral patterns in hyperspectral image. In this paper, we make a step
forward by investigating how to adapt state-of-the-art residual learning based
single gray/RGB image super-resolution approaches for computationally efficient
single hyperspectral image super-resolution, referred as SSPSR. Specifically,
we introduce a spatial-spectral prior network (SSPN) to fully exploit the
spatial information and the correlation between the spectra of the
hyperspectral data. Considering that the hyperspectral training samples are
scarce and the spectral dimension of hyperspectral image data is very high, it
is nontrivial to train a stable and effective deep network. Therefore, a group
convolution (with shared network parameters) and progressive upsampling
framework is proposed. This will not only alleviate the difficulty in feature
extraction due to high-dimension of the hyperspectral data, but also make the
training process more stable. To exploit the spatial and spectral prior, we
design a spatial-spectral block (SSB), which consists of a spatial residual
module and a spectral attention residual module. Experimental results on some
hyperspectral images demonstrate that the proposed SSPSR method enhances the
details of the recovered high-resolution hyperspectral images, and outperforms
state-of-the-arts. The source code is available at
\url{https://github.com/junjun-jiang/SSPSR
","Junjun Jiang, He Sun, Xianming Liu, Jiayi Ma",Jiayi Ma,2020-05-18T14:25:50Z
"Hyper-Skin: A Hyperspectral Dataset for Reconstructing Facial
  Skin-Spectra from RGB Images","  We introduce Hyper-Skin, a hyperspectral dataset covering wide range of
wavelengths from visible (VIS) spectrum (400nm - 700nm) to near-infrared (NIR)
spectrum (700nm - 1000nm), uniquely designed to facilitate research on facial
skin-spectra reconstruction. By reconstructing skin spectra from RGB images,
our dataset enables the study of hyperspectral skin analysis, such as melanin
and hemoglobin concentrations, directly on the consumer device. Overcoming
limitations of existing datasets, Hyper-Skin consists of diverse facial skin
data collected with a pushbroom hyperspectral camera. With 330 hyperspectral
cubes from 51 subjects, the dataset covers the facial skin from different
angles and facial poses. Each hyperspectral cube has dimensions of
1024$\times$1024$\times$448, resulting in millions of spectra vectors per
image. The dataset, carefully curated in adherence to ethical guidelines,
includes paired hyperspectral images and synthetic RGB images generated using
real camera responses. We demonstrate the efficacy of our dataset by showcasing
skin spectra reconstruction using state-of-the-art models on 31 bands of
hyperspectral data resampled in the VIS and NIR spectrum. This Hyper-Skin
dataset would be a valuable resource to NeurIPS community, encouraging the
development of novel algorithms for skin spectral reconstruction while
fostering interdisciplinary collaboration in hyperspectral skin analysis
related to cosmetology and skin's well-being. Instructions to request the data
and the related benchmarking codes are publicly available at:
\url{https://github.com/hyperspectral-skin/Hyper-Skin-2023}.
","Pai Chet Ng, Zhixiang Chi, Yannick Verdie, Juwei Lu, Konstantinos N. Plataniotis",Konstantinos N. Plataniotis,2023-10-27T06:10:35Z
Hyperspectral Neural Radiance Fields,"  Hyperspectral Imagery (HSI) has been used in many applications to
non-destructively determine the material and/or chemical compositions of
samples. There is growing interest in creating 3D hyperspectral
reconstructions, which could provide both spatial and spectral information
while also mitigating common HSI challenges such as non-Lambertian surfaces and
translucent objects. However, traditional 3D reconstruction with HSI is
difficult due to technological limitations of hyperspectral cameras. In recent
years, Neural Radiance Fields (NeRFs) have seen widespread success in creating
high quality volumetric 3D representations of scenes captured by a variety of
camera models. Leveraging recent advances in NeRFs, we propose computing a
hyperspectral 3D reconstruction in which every point in space and view
direction is characterized by wavelength-dependent radiance and transmittance
spectra. To evaluate our approach, a dataset containing nearly 2000
hyperspectral images across 8 scenes and 2 cameras was collected. We perform
comparisons against traditional RGB NeRF baselines and apply ablation testing
with alternative spectra representations. Finally, we demonstrate the potential
of hyperspectral NeRFs for hyperspectral super-resolution and imaging sensor
simulation. We show that our hyperspectral NeRF approach enables creating fast,
accurate volumetric 3D hyperspectral scenes and enables several new
applications and areas for future study.
","Gerry Chen, Sunil Kumar Narayanan, Thomas Gautier Ottou, Benjamin Missaoui, Harsh Muriki, Cédric Pradalier, Yongsheng Chen",Yongsheng Chen,2024-03-21T21:18:08Z
Fast and robust pushbroom hyperspectral imaging via DMD-based scanning,"  We describe a new pushbroom hyperspectral imaging device that has no macro
moving part. The main components of the proposed hyperspectral imager are a
digital micromirror device (DMD), a CMOS image sensor with no filter as the
spectral sensor, a CMOS color (RGB) image sensor as the auxiliary image sensor,
and a diffraction grating. Using the image sensor pair, the device can
simultaneously capture hyperspectral data as well as RGB images of the scene.
The RGB images captured by the auxiliary image sensor can facilitate geometric
co-registration of the hyperspectral image slices captured by the spectral
sensor. In addition, the information discernible from the RGB images can lead
to capturing the spectral data of only the regions of interest within the
scene. The proposed hyperspectral imaging architecture is cost-effective, fast,
and robust. It also enables a trade-off between resolution and speed. We have
built an initial prototype based on the proposed design. The prototype can
capture a hyperspectral image datacube with a spatial resolution of 192x192
pixels and a spectral resolution of 500 bands in less than thirty seconds.
","Reza Arablouei, Ethan Goan, Stephen Gensemer, Branislav Kusy",Branislav Kusy,2016-08-01T09:18:38Z
Hyperspectral Data Analysis in R: the hsdar Package,"  Hyperspectral remote sensing is a promising tool for a variety of
applications including ecology, geology, analytical chemistry and medical
research. This article presents the new \hsdar package for R statistical
software, which performs a variety of analysis steps taken during a typical
hyperspectral remote sensing approach. The package introduces a new class for
efficiently storing large hyperspectral datasets such as hyperspectral cubes
within R. The package includes several important hyperspectral analysis tools
such as continuum removal, normalized ratio indices and integrates two widely
used radiation transfer models. In addition, the package provides methods to
directly use the functionality of the caret package for machine learning tasks.
Two case studies demonstrate the package's range of functionality: First, plant
leaf chlorophyll content is estimated and second, cancer in the human larynx is
detected from hyperspectral data.
","Lukas W. Lehnert, Hanna Meyer, Wolfgang A. Obermeier, Brenner Silva, Bianca Regeling, Jörg Bendix",Jörg Bendix,2018-05-14T09:57:25Z
"Aerial Vehicle Tracking by Adaptive Fusion of Hyperspectral Likelihood
  Maps","  Hyperspectral cameras can provide unique spectral signatures for consistently
distinguishing materials that can be used to solve surveillance tasks. In this
paper, we propose a novel real-time hyperspectral likelihood maps-aided
tracking method (HLT) inspired by an adaptive hyperspectral sensor. A moving
object tracking system generally consists of registration, object detection,
and tracking modules. We focus on the target detection part and remove the
necessity to build any offline classifiers and tune a large amount of
hyperparameters, instead learning a generative target model in an online manner
for hyperspectral channels ranging from visible to infrared wavelengths. The
key idea is that, our adaptive fusion method can combine likelihood maps from
multiple bands of hyperspectral imagery into one single more distinctive
representation increasing the margin between mean value of foreground and
background pixels in the fused map. Experimental results show that the HLT not
only outperforms all established fusion methods but is on par with the current
state-of-the-art hyperspectral target tracking frameworks.
","Burak Uzkent, Aneesh Rangnekar, M. J. Hoffman",M. J. Hoffman,2017-07-12T05:55:54Z
"WHU-Hi: UAV-borne hyperspectral with high spatial resolution (H2)
  benchmark datasets for hyperspectral image classification","  Classification is an important aspect of hyperspectral images processing and
application. At present, the researchers mostly use the classic airborne
hyperspectral imagery as the benchmark dataset. However, existing datasets
suffer from three bottlenecks: (1) low spatial resolution; (2) low labeled
pixels proportion; (3) low degree of subclasses distinction. In this paper, a
new benchmark dataset named the Wuhan UAV-borne hyperspectral image (WHU-Hi)
dataset was built for hyperspectral image classification. The WHU-Hi dataset
with a high spectral resolution (nm level) and a very high spatial resolution
(cm level), which we refer to here as H2 imager. Besides, the WHU-Hi dataset
has a higher pixel labeling ratio and finer subclasses. Some start-of-art
hyperspectral image classification methods benchmarked the WHU-Hi dataset, and
the experimental results show that WHU-Hi is a challenging dataset. We hope
WHU-Hi dataset can become a strong benchmark to accelerate future research.
","Xin Hu, Yanfei Zhong, Chang Luo, Xinyu Wang",Xinyu Wang,2020-12-27T11:28:37Z
Hyperspectral 3D Mapping of Underwater Environments,"  Hyperspectral imaging has been increasingly used for underwater survey
applications over the past years. As many hyperspectral cameras work as
push-broom scanners, their use is usually limited to the creation of
photo-mosaics based on a flat surface approximation and by interpolating the
camera pose from dead-reckoning navigation. Yet, because of drift in the
navigation and the mostly wrong flat surface assumption, the quality of the
obtained photo-mosaics is often too low to support adequate analysis.In this
paper we present an initial method for creating hyperspectral 3D
reconstructions of underwater environments. By fusing the data gathered by a
classical RGB camera, an inertial navigation system and a hyperspectral
push-broom camera, we show that the proposed method creates highly accurate 3D
reconstructions with hyperspectral textures. We propose to combine techniques
from simultaneous localization and mapping, structure-from-motion and 3D
reconstruction and advantageously use them to create 3D models with
hyperspectral texture, allowing us to overcome the flat surface assumption and
the classical limitation of dead-reckoning navigation.
","Maxime Ferrera, Aurélien Arnaubec, Klemen Istenic, Nuno Gracias, Touria Bajjouk",Touria Bajjouk,2021-10-13T08:37:22Z
"HyperDID: Hyperspectral Intrinsic Image Decomposition with Deep Feature
  Embedding","  The dissection of hyperspectral images into intrinsic components through
hyperspectral intrinsic image decomposition (HIID) enhances the
interpretability of hyperspectral data, providing a foundation for more
accurate classification outcomes. However, the classification performance of
HIID is constrained by the model's representational ability. To address this
limitation, this study rethinks hyperspectral intrinsic image decomposition for
classification tasks by introducing deep feature embedding. The proposed
framework, HyperDID, incorporates the Environmental Feature Module (EFM) and
Categorical Feature Module (CFM) to extract intrinsic features. Additionally, a
Feature Discrimination Module (FDM) is introduced to separate
environment-related and category-related features. Experimental results across
three commonly used datasets validate the effectiveness of HyperDID in
improving hyperspectral image classification performance. This novel approach
holds promise for advancing the capabilities of hyperspectral image analysis by
leveraging deep feature embedding principles. The implementation of the
proposed method could be accessed soon at https://github.com/shendu-sw/HyperDID
for the sake of reproducibility.
","Zhiqiang Gong, Xian Zhou, Wen Yao, Xiaohu Zheng, Ping Zhong",Ping Zhong,2023-11-25T02:05:10Z
"Deep learning-based hyperspectral image reconstruction for quality
  assessment of agro-product","  Hyperspectral imaging (HSI) has recently emerged as a promising tool for many
agricultural applications; however, the technology cannot be directly used in a
real-time system due to the extensive time needed to process large volumes of
data. Consequently, the development of a simple, compact, and cost-effective
imaging system is not possible with the current HSI systems. Therefore, the
overall goal of this study was to reconstruct hyperspectral images from RGB
images through deep learning for agricultural applications. Specifically, this
study used Hyperspectral Convolutional Neural Network - Dense (HSCNN-D) to
reconstruct hyperspectral images from RGB images for predicting soluble solid
content (SSC) in sweet potatoes. The algorithm accurately reconstructed the
hyperspectral images from RGB images, with the resulting spectra closely
matching the ground-truth. The partial least squares regression (PLSR) model
based on reconstructed spectra outperformed the model using the full spectral
range, demonstrating its potential for SSC prediction in sweet potatoes. These
findings highlight the potential of deep learning-based hyperspectral image
reconstruction as a low-cost, efficient tool for various agricultural uses.
","Md. Toukir Ahmed, Ocean Monjur, Mohammed Kamruzzaman",Mohammed Kamruzzaman,2024-05-20T18:15:20Z
"Online Unmixing of Multitemporal Hyperspectral Images accounting for
  Spectral Variability","  Hyperspectral unmixing is aimed at identifying the reference spectral
signatures composing an hyperspectral image and their relative abundance
fractions in each pixel. In practice, the identified signatures may vary
spectrally from an image to another due to varying acquisition conditions, thus
inducing possibly significant estimation errors. Against this background,
hyperspectral unmixing of several images acquired over the same area is of
considerable interest. Indeed, such an analysis enables the endmembers of the
scene to be tracked and the corresponding endmember variability to be
characterized. Sequential endmember estimation from a set of hyperspectral
images is expected to provide improved performance when compared to methods
analyzing the images independently. However, the significant size of
hyperspectral data precludes the use of batch procedures to jointly estimate
the mixture parameters of a sequence of hyperspectral images. Provided that
each elementary component is present in at least one image of the sequence, we
propose to perform an online hyperspectral unmixing accounting for temporal
endmember variability. The online hyperspectral unmixing is formulated as a
two-stage stochastic program, which can be solved using a stochastic
approximation. The performance of the proposed method is evaluated on synthetic
and real data. A comparison with independent unmixing algorithms finally
illustrates the interest of the proposed strategy.
","Pierre-Antoine Thouvenin, Nicolas Dobigeon, Jean-Yves Tourneret",Jean-Yves Tourneret,2015-10-20T13:47:24Z
Validating Hyperspectral Image Segmentation,"  Hyperspectral satellite imaging attracts enormous research attention in the
remote sensing community, hence automated approaches for precise segmentation
of such imagery are being rapidly developed. In this letter, we share our
observations on the strategy for validating hyperspectral image segmentation
algorithms currently followed in the literature, and show that it can lead to
over-optimistic experimental insights. We introduce a new routine for
generating segmentation benchmarks, and use it to elaborate ready-to-use
hyperspectral training-test data partitions. They can be utilized for fair
validation of new and existing algorithms without any training-test data
leakage.
","Jakub Nalepa, Michal Myller, Michal Kawulok",Michal Kawulok,2018-11-08T22:59:40Z
"Hyperspectral Unmixing with Endmember Variability using Semi-supervised
  Partial Membership Latent Dirichlet Allocation","  A semi-supervised Partial Membership Latent Dirichlet Allocation approach is
developed for hyperspectral unmixing and endmember estimation while accounting
for spectral variability and spatial information. Partial Membership Latent
Dirichlet Allocation is an effective approach for spectral unmixing while
representing spectral variability and leveraging spatial information. In this
work, we extend Partial Membership Latent Dirichlet Allocation to incorporate
any available (imprecise) label information to help guide unmixing.
Experimental results on two hyperspectral datasets show that the proposed
semi-supervised PM-LDA can yield improved hyperspectral unmixing and endmember
estimation results.
","Sheng Zou, Hao Sun, Alina Zare",Alina Zare,2017-03-17T18:13:59Z
"Fast Hyperspectral Image Denoising and Inpainting Based on Low-Rank and
  Sparse Representations","  This paper introduces two very fast and competitive hyperspectral image (HSI)
restoration algorithms: fast hyperspectral denoising (FastHyDe), a denoising
algorithm able to cope with Gaussian and Poissonian noise, and fast
hyperspectral inpainting (FastHyIn), an inpainting algorithm to restore HSIs
where some observations from known pixels in some known bands are missing.
FastHyDe and FastHyIn fully exploit extremely compact and sparse HSI
representations linked with their low-rank and self-similarity characteristics.
In a series of experiments with simulated and real data, the newly introduced
FastHyDe and FastHyIn compete with the state-of-the-art methods, with much
lower computational complexity.
","Lina Zhuang, Jose M. Bioucas-Dias",Jose M. Bioucas-Dias,2021-03-11T18:12:29Z
"Cross-View-Prediction: Exploring Contrastive Feature for Hyperspectral
  Image Classification","  This paper presents a self-supervised feature learning method for
hyperspectral image classification. Our method tries to construct two different
views of the raw hyperspectral image through a cross-representation learning
method. And then to learn semantically consistent representation over the
created views by contrastive learning method. Specifically, four
cross-channel-prediction based augmentation methods are naturally designed to
utilize the high dimension characteristic of hyperspectral data for the view
construction. And the better representative features are learned by maximizing
mutual information and minimizing conditional entropy across different views
from our contrastive network. This 'Cross-View-Predicton' style is
straightforward and gets the state-of-the-art performance of unsupervised
classification with a simple SVM classifier.
","Haotian Wu, Anyu Zhang, Zeyu Cao",Zeyu Cao,2022-03-14T11:07:33Z
"mHealth hyperspectral learning for instantaneous spatiospectral imaging
  of hemodynamics","  Hyperspectral imaging acquires data in both the spatial and frequency domains
to offer abundant physical or biological information. However, conventional
hyperspectral imaging has intrinsic limitations of bulky instruments, slow data
acquisition rate, and spatiospectral tradeoff. Here we introduce hyperspectral
learning for snapshot hyperspectral imaging in which sampled hyperspectral data
in a small subarea are incorporated into a learning algorithm to recover the
hypercube. Hyperspectral learning exploits the idea that a photograph is more
than merely a picture and contains detailed spectral information. A small
sampling of hyperspectral data enables spectrally informed learning to recover
a hypercube from an RGB image. Hyperspectral learning is capable of recovering
full spectroscopic resolution in the hypercube, comparable to high spectral
resolutions of scientific spectrometers. Hyperspectral learning also enables
ultrafast dynamic imaging, leveraging ultraslow video recording in an
off-the-shelf smartphone, given that a video comprises a time series of
multiple RGB images. To demonstrate its versatility, an experimental model of
vascular development is used to extract hemodynamic parameters via statistical
and deep-learning approaches. Subsequently, the hemodynamics of peripheral
microcirculation is assessed at an ultrafast temporal resolution up to a
millisecond, using a conventional smartphone camera. This spectrally informed
learning method is analogous to compressed sensing; however, it further allows
for reliable hypercube recovery and key feature extractions with a transparent
learning algorithm. This learning-powered snapshot hyperspectral imaging method
yields high spectral and temporal resolutions and eliminates the spatiospectral
tradeoff, offering simple hardware requirements and potential applications of
various machine-learning techniques.
","Yuhyun Ji, Sang Mok Park, Semin Kwon, Jung Woo Leem, Vidhya Vijayakrishnan Nair, Yunjie Tong, Young L. Kim",Young L. Kim,2023-03-27T15:12:10Z
"Deep Learning Approach for Hyperspectral Image Demosaicking, Spectral
  Correction and High-resolution RGB Reconstruction","  Hyperspectral imaging is one of the most promising techniques for
intraoperative tissue characterisation. Snapshot mosaic cameras, which can
capture hyperspectral data in a single exposure, have the potential to make a
real-time hyperspectral imaging system for surgical decision-making possible.
However, optimal exploitation of the captured data requires solving an
ill-posed demosaicking problem and applying additional spectral corrections to
recover spatial and spectral information of the image. In this work, we propose
a deep learning-based image demosaicking algorithm for snapshot hyperspectral
images using supervised learning methods. Due to the lack of publicly available
medical images acquired with snapshot mosaic cameras, a synthetic image
generation approach is proposed to simulate snapshot images from existing
medical image datasets captured by high-resolution, but slow, hyperspectral
imaging devices. Image reconstruction is achieved using convolutional neural
networks for hyperspectral image super-resolution, followed by cross-talk and
leakage correction using a sensor-specific calibration matrix. The resulting
demosaicked images are evaluated both quantitatively and qualitatively, showing
clear improvements in image quality compared to a baseline demosaicking method
using linear interpolation. Moreover, the fast processing time of~45\,ms of our
algorithm to obtain super-resolved RGB or oxygenation saturation maps per image
frame for a state-of-the-art snapshot mosaic camera demonstrates the potential
for its seamless integration into real-time surgical hyperspectral imaging
applications.
","Peichao Li, Michael Ebner, Philip Noonan, Conor Horgan, Anisha Bahl, Sebastien Ourselin, Jonathan Shapey, Tom Vercauteren",Tom Vercauteren,2021-09-03T09:50:03Z
"High-Order Coupled Fully-Connected Tensor Network Decomposition for
  Hyperspectral Image Super-Resolution","  Hyperspectral image super-resolution addresses the problem of fusing a
low-resolution hyperspectral image (LR-HSI) and a high-resolution multispectral
image (HR-MSI) to produce a high-resolution hyperspectral image (HR-HSI).
Tensor analysis has been proven to be an efficient method for hyperspectral
image processing. However, the existing tensor-based methods of hyperspectral
image super-resolution like the tensor train and tensor ring decomposition only
establish an operation between adjacent two factors and are highly sensitive to
the permutation of tensor modes, leading to an inadequate and inflexible
representation. In this paper, we propose a novel method for hyperspectral
image super-resolution by utilizing the specific properties of high-order
tensors in fully-connected tensor network decomposition. The proposed method
first tensorizes the target HR-HSI into a high-order tensor that has multiscale
spatial structures. Then, a coupled fully-connected tensor network
decomposition model is proposed to fuse the corresponding high-order tensors of
LR-HSI and HR-MSI. Moreover, a weighted-graph regularization is imposed on the
spectral core tensors to preserve spectral information. In the proposed model,
the superiorities of the fully-connected tensor network decomposition lie in
the outstanding capability for characterizing adequately the intrinsic
correlations between any two modes of tensors and the essential invariance for
transposition. Experimental results on three data sets show the effectiveness
of the proposed approach as compared to other hyperspectral image
super-resolution methods.
","Diyi Jin, Jianjun Liu, Jinlong Yang, Zebin Wu",Zebin Wu,2022-07-11T12:24:28Z
"HySpecNet-11k: A Large-Scale Hyperspectral Dataset for Benchmarking
  Learning-Based Hyperspectral Image Compression Methods","  The development of learning-based hyperspectral image compression methods has
recently attracted great attention in remote sensing. Such methods require a
high number of hyperspectral images to be used during training to optimize all
parameters and reach a high compression performance. However, existing
hyperspectral datasets are not sufficient to train and evaluate learning-based
compression methods, which hinders the research in this field. To address this
problem, in this paper we present HySpecNet-11k that is a large-scale
hyperspectral benchmark dataset made up of 11,483 nonoverlapping image patches.
Each patch is a portion of 128 $\times$ 128 pixels with 224 spectral bands and
a ground sample distance of 30 m. We exploit HySpecNet-11k to benchmark the
current state of the art in learning-based hyperspectral image compression by
focussing our attention on various 1D, 2D and 3D convolutional autoencoder
architectures. Nevertheless, HySpecNet-11k can be used for any unsupervised
learning task in the framework of hyperspectral image analysis. The dataset,
our code and the pre-trained weights are publicly available at
https://hyspecnet.rsim.berlin
","Martin Hermann Paul Fuchs, Begüm Demir",Begüm Demir,2023-06-01T06:34:14Z
"MatSpectNet: Material Segmentation Network with Domain-Aware and
  Physically-Constrained Hyperspectral Reconstruction","  Achieving accurate material segmentation for 3-channel RGB images is
challenging due to the considerable variation in a material's appearance.
Hyperspectral images, which are sets of spectral measurements sampled at
multiple wavelengths, theoretically offer distinct information for material
identification, as variations in intensity of electromagnetic radiation
reflected by a surface depend on the material composition of a scene. However,
existing hyperspectral datasets are impoverished regarding the number of images
and material categories for the dense material segmentation task, and
collecting and annotating hyperspectral images with a spectral camera is
prohibitively expensive. To address this, we propose a new model, the
MatSpectNet to segment materials with recovered hyperspectral images from RGB
images. The network leverages the principles of colour perception in modern
cameras to constrain the reconstructed hyperspectral images and employs the
domain adaptation method to generalise the hyperspectral reconstruction
capability from a spectral recovery dataset to material segmentation datasets.
The reconstructed hyperspectral images are further filtered using learned
response curves and enhanced with human perception. The performance of
MatSpectNet is evaluated on the LMD dataset as well as the OpenSurfaces
dataset. Our experiments demonstrate that MatSpectNet attains a 1.60% increase
in average pixel accuracy and a 3.42% improvement in mean class accuracy
compared with the most recent publication. The project code is attached to the
supplementary material and will be published on GitHub.
","Yuwen Heng, Yihong Wu, Jiawen Chen, Srinandan Dasmahapatra, Hansung Kim",Hansung Kim,2023-07-21T10:02:02Z
"Hy-Tracker: A Novel Framework for Enhancing Efficiency and Accuracy of
  Object Tracking in Hyperspectral Videos","  Hyperspectral object tracking has recently emerged as a topic of great
interest in the remote sensing community. The hyperspectral image, with its
many bands, provides a rich source of material information of an object that
can be effectively used for object tracking. While most hyperspectral trackers
are based on detection-based techniques, no one has yet attempted to employ
YOLO for detecting and tracking the object. This is due to the presence of
multiple spectral bands, the scarcity of annotated hyperspectral videos, and
YOLO's performance limitation in managing occlusions, and distinguishing object
in cluttered backgrounds. Therefore, in this paper, we propose a novel
framework called Hy-Tracker, which aims to bridge the gap between hyperspectral
data and state-of-the-art object detection methods to leverage the strengths of
YOLOv7 for object tracking in hyperspectral videos. Hy-Tracker not only
introduces YOLOv7 but also innovatively incorporates a refined tracking module
on top of YOLOv7. The tracker refines the initial detections produced by
YOLOv7, leading to improved object-tracking performance. Furthermore, we
incorporate Kalman-Filter into the tracker, which addresses the challenges
posed by scale variation and occlusion. The experimental results on
hyperspectral benchmark datasets demonstrate the effectiveness of Hy-Tracker in
accurately tracking objects across frames.
","Mohammad Aminul Islam, Wangzhi Xing, Jun Zhou, Yongsheng Gao, Kuldip K. Paliwal",Kuldip K. Paliwal,2023-11-30T02:38:45Z
"SpecDETR: A Transformer-based Hyperspectral Point Object Detection
  Network","  Hyperspectral target detection (HTD) aims to identify specific materials
based on spectral information in hyperspectral imagery and can detect point
targets, some of which occupy a smaller than one-pixel area. However, existing
HTD methods are developed based on per-pixel binary classification, which
limits the feature representation capability for point targets. In this paper,
we rethink the hyperspectral point target detection from the object detection
perspective, and focus more on the object-level prediction capability rather
than the pixel classification capability. Inspired by the token-based
processing flow of Detection Transformer (DETR), we propose the first
specialized network for hyperspectral multi-class point object detection,
SpecDETR. Without the backbone part of the current object detection framework,
SpecDETR treats the spectral features of each pixel in hyperspectral images as
a token and utilizes a multi-layer Transformer encoder with local and global
coordination attention modules to extract deep spatial-spectral joint features.
SpecDETR regards point object detection as a one-to-many set prediction
problem, thereby achieving a concise and efficient DETR decoder that surpasses
the current state-of-the-art DETR decoder in terms of parameters and accuracy
in point object detection. We develop a simulated hyperSpectral Point Object
Detection benchmark termed SPOD, and for the first time, evaluate and compare
the performance of current object detection networks and HTD methods on
hyperspectral multi-class point object detection. SpecDETR demonstrates
superior performance as compared to current object detection networks and HTD
methods on the SPOD dataset. Additionally, we validate on a public HTD dataset
that by using data simulation instead of manual annotation, SpecDETR can detect
real-world single-spectral point objects directly.
","Zhaoxu Li, Wei An, Gaowei Guo, Longguang Wang, Yingqian Wang, Zaiping Lin",Zaiping Lin,2024-05-16T14:45:06Z
"Hyperspectral Dataset and Deep Learning methods for Waste from Electric
  and Electronic Equipment Identification (WEEE)","  Hyperspectral imaging, a rapidly evolving field, has witnessed the ascendancy
of deep learning techniques, supplanting classical feature extraction and
classification methods in various applications. However, many researchers
employ arbitrary architectures for hyperspectral image processing, often
without rigorous analysis of the interplay between spectral and spatial
information. This oversight neglects the implications of combining these two
modalities on model performance.
  In this paper, we evaluate the performance of diverse deep learning
architectures for hyperspectral image segmentation. Our analysis disentangles
the impact of different architectures, spanning various spectral and spatial
granularities. Specifically, we investigate the effects of spectral resolution
(capturing spectral information) and spatial texture (conveying spatial
details) on segmentation outcomes. Additionally, we explore the transferability
of knowledge from large pre-trained image foundation models, originally
designed for RGB images, to the hyperspectral domain.
  Results show that incorporating spatial information alongside spectral data
leads to improved segmentation results, and that it is essential to further
work on novel architectures comprising spectral and spatial information and on
the adaption of RGB foundation models into the hyperspectral domain.
  Furthermore, we contribute to the field by cleaning and publicly releasing
the Tecnalia WEEE Hyperspectral dataset. This dataset contains different
non-ferrous fractions of Waste Electrical and Electronic Equipment (WEEE),
including Copper, Brass, Aluminum, Stainless Steel, and White Copper, spanning
the range of 400 to 1000 nm.
  We expect these conclusions can guide novel researchers in the field of
hyperspectral imaging.
","Artzai Picon, Pablo Galan, Arantza Bereciartua-Perez, Leire Benito-del-Valle",Leire Benito-del-Valle,2024-07-05T13:45:11Z
Further results on dissimilarity spaces for hyperspectral images RF-CBIR,"  Content-Based Image Retrieval (CBIR) systems are powerful search tools in
image databases that have been little applied to hyperspectral images.
Relevance feedback (RF) is an iterative process that uses machine learning
techniques and user's feedback to improve the CBIR systems performance. We
pursued to expand previous research in hyperspectral CBIR systems built on
dissimilarity functions defined either on spectral and spatial features
extracted by spectral unmixing techniques, or on dictionaries extracted by
dictionary-based compressors. These dissimilarity functions were not suitable
for direct application in common machine learning techniques. We propose to use
a RF general approach based on dissimilarity spaces which is more appropriate
for the application of machine learning algorithms to the hyperspectral
RF-CBIR. We validate the proposed RF method for hyperspectral CBIR systems over
a real hyperspectral dataset.
","Miguel Angel Veganzones, Mihai Datcu, Manuel Graña",Manuel Graña,2013-07-04T11:58:04Z
Spatial-Aware Dictionary Learning for Hyperspectral Image Classification,"  This paper presents a structured dictionary-based model for hyperspectral
data that incorporates both spectral and contextual characteristics of a
spectral sample, with the goal of hyperspectral image classification. The idea
is to partition the pixels of a hyperspectral image into a number of spatial
neighborhoods called contextual groups and to model each pixel with a linear
combination of a few dictionary elements learned from the data. Since pixels
inside a contextual group are often made up of the same materials, their linear
combinations are constrained to use common elements from the dictionary. To
this end, dictionary learning is carried out with a joint sparse regularizer to
induce a common sparsity pattern in the sparse coefficients of each contextual
group. The sparse coefficients are then used for classification using a linear
SVM. Experimental results on a number of real hyperspectral images confirm the
effectiveness of the proposed representation for hyperspectral image
classification. Moreover, experiments with simulated multispectral data show
that the proposed model is capable of finding representations that may
effectively be used for classification of multispectral-resolution samples.
","Ali Soltani-Farani, Hamid R. Rabiee, Seyyed Abbas Hosseini",Seyyed Abbas Hosseini,2013-08-06T05:57:08Z
"Fusion of Hyperspectral and Panchromatic Images using Spectral Uumixing
  Results","  Hyperspectral imaging, due to providing high spectral resolution images, is
one of the most important tools in the remote sensing field. Because of
technological restrictions hyperspectral sensors has a limited spatial
resolution. On the other hand panchromatic image has a better spatial
resolution. Combining this information together can provide a better
understanding of the target scene. Spectral unmixing of mixed pixels in
hyperspectral images results in spectral signature and abundance fractions of
endmembers but gives no information about their location in a mixed pixel. In
this paper we have used spectral unmixing results of hyperspectral images and
segmentation results of panchromatic image for data fusion. The proposed method
has been applied on simulated data using AVRIS Indian Pines datasets. Results
show that this method can effectively combine information in hyperspectral and
panchromatic images.
","Roozbeh Rajabi, Hassan Ghassemian",Hassan Ghassemian,2013-10-22T15:44:51Z
"Super-resolution reconstruction of hyperspectral images via low rank
  tensor modeling and total variation regularization","  In this paper, we propose a novel approach to hyperspectral image
super-resolution by modeling the global spatial-and-spectral correlation and
local smoothness properties over hyperspectral images. Specifically, we utilize
the tensor nuclear norm and tensor folded-concave penalty functions to describe
the global spatial-and-spectral correlation hidden in hyperspectral images, and
3D total variation (TV) to characterize the local spatial-and-spectral
smoothness across all hyperspectral bands. Then, we develop an efficient
algorithm for solving the resulting optimization problem by combing the local
linear approximation (LLA) strategy and alternative direction method of
multipliers (ADMM). Experimental results on one hyperspectral image dataset
illustrate the merits of the proposed approach.
","Shiying He, Haiwei Zhou, Yao Wang, Wenfei Cao, Zhi Han",Zhi Han,2016-01-23T07:07:16Z
"Wavelet-Based Semantic Features for Hyperspectral Signature
  Discrimination","  Hyperspectral signature classification is a quantitative analysis approach
for hyperspectral imagery which performs detection and classification of the
constituent materials at the pixel level in the scene. The classification
procedure can be operated directly on hyperspectral data or performed by using
some features extracted from the corresponding hyperspectral signatures
containing information like the signature's energy or shape. In this paper, we
describe a technique that applies non-homogeneous hidden Markov chain (NHMC)
models to hyperspectral signature classification. The basic idea is to use
statistical models (such as NHMC) to characterize wavelet coefficients which
capture the spectrum semantics (i.e., structural information) at multiple
levels. Experimental results show that the approach based on NHMC models can
outperform existing approaches relevant in classification tasks.
","Siwei Feng, Yuki Itoh, Mario Parente, Marco F. Duarte",Marco F. Duarte,2016-02-11T21:25:36Z
Hyperspectral Subspace Identification Using SURE,"  Remote sensing hyperspectral sensors collect large volumes of high
dimensional spectral and spatial data. However, due to spectral and spatial
redundancy the true hyperspectral signal lies on a subspace of much lower
dimension than the original data. The identification of the signal subspace is
a very important first step for most hyperspectral algorithms. In this paper we
investigate the important problem of identifying the hyperspectral signal
subspace by minimizing the mean squared error (MSE) between the true signal and
an estimate of the signal. Since the MSE is uncomputable in practice, due to
its dependency on the true signal, we propose a method based on the Stein's
unbiased risk estimator (SURE) that provides an unbiased estimate of the MSE.
The resulting method is simple and fully automatic and we evaluate it using
both simulated and real hyperspectral data sets. Experimental results shows
that our proposed method compares well to recent state-of-the-art subspace
identification methods.
","Behnood Rasti, Magnus O. Ulfarsson, Johannes R. Sveinsson",Johannes R. Sveinsson,2016-06-01T11:01:54Z
"Person Re-identification with Hyperspectral Multi-Camera Systems --- A
  Pilot Study","  Person re-identification in a multi-camera environment is an important part
of modern surveillance systems. Person re-identification from color images has
been the focus of much active research, due to the numerous challenges posed
with such analysis tasks, such as variations in illumination, pose and
viewpoints. In this paper, we suggest that hyperspectral imagery has the
potential to provide unique information that is expected to be beneficial for
the re-identification task. Specifically, we assert that by accurately
characterizing the unique spectral signature for each person's skin,
hyperspectral imagery can provide very useful descriptors (e.g. spectral
signatures from skin pixels) for re-identification. Towards this end, we
acquired proof-of-concept hyperspectral re-identification data under
challenging (practical) conditions from 15 people. Our results indicate that
hyperspectral data result in a substantially enhanced re-identification
performance compared to color (RGB) images, when using spectral signatures over
skin as the feature descriptor.
","Saurabh Prasad, Tanu Priya, Minshan Cui, Shishir Shah",Shishir Shah,2016-07-15T18:38:38Z
"A Dual Symmetric Gauss-Seidel Alternating Direction Method of
  Multipliers for Hyperspectral Sparse Unmixing","  Since sparse unmixing has emerged as a promising approach to hyperspectral
unmixing, some spatial-contextual information in the hyperspectral images has
been exploited to improve the performance of the unmixing recently. The total
variation (TV) has been widely used to promote the spatial homogeneity as well
as the smoothness between adjacent pixels. However, the computation task for
hyperspectral sparse unmixing with a TV regularization term is heavy. Besides,
the convergence of the primal alternating direction method of multipliers
(ADMM) for the hyperspectral sparse unmixing with a TV regularization term has
not been explained in details. In this paper, we design an efficient and
convergent dual symmetric Gauss-Seidel ADMM (sGS-ADMM) for hyperspectral sparse
unmixing with a TV regularization term. We also present the global convergence
and local linear convergence rate analysis for this algorithm. As demonstrated
in numerical experiments, our algorithm can obviously improve the efficiency of
the unmixing compared with the state-of-the-art algorithm. More importantly, we
can obtain images with higher quality.
","Longfei Ren, Chengjing Wang, Peipei Tang, Zheng Ma",Zheng Ma,2019-02-25T08:28:01Z
"Salient object detection on hyperspectral images using features learned
  from unsupervised segmentation task","  Various saliency detection algorithms from color images have been proposed to
mimic eye fixation or attentive object detection response of human observers
for the same scenes. However, developments on hyperspectral imaging systems
enable us to obtain redundant spectral information of the observed scenes from
the reflected light source from objects. A few studies using low-level features
on hyperspectral images demonstrated that salient object detection can be
achieved. In this work, we proposed a salient object detection model on
hyperspectral images by applying manifold ranking (MR) on self-supervised
Convolutional Neural Network (CNN) features (high-level features) from
unsupervised image segmentation task. Self-supervision of CNN continues until
clustering loss or saliency maps converges to a defined error between each
iteration. Finally, saliency estimations is done as the saliency map at last
iteration when the self-supervision procedure terminates with convergence.
Experimental evaluations demonstrated that proposed saliency detection
algorithm on hyperspectral images is outperforming state-of-the-arts
hyperspectral saliency models including the original MR based saliency model.
","Nevrez Imamoglu, Guanqun Ding, Yuming Fang, Asako Kanezaki, Toru Kouyama, Ryosuke Nakamura",Ryosuke Nakamura,2019-02-28T10:23:00Z
"Deep Clustering With Intra-class Distance Constraint for Hyperspectral
  Images","  The high dimensionality of hyperspectral images often results in the
degradation of clustering performance. Due to the powerful ability of deep
feature extraction and non-linear feature representation, the clustering
algorithm based on deep learning has become a hot research topic in the field
of hyperspectral remote sensing. However, most deep clustering algorithms for
hyperspectral images utilize deep neural networks as feature extractor without
considering prior knowledge constraints that are suitable for clustering. To
solve this problem, we propose an intra-class distance constrained deep
clustering algorithm for high-dimensional hyperspectral images. The proposed
algorithm constrains the feature mapping procedure of the auto-encoder network
by intra-class distance so that raw images are transformed from the original
high-dimensional space to the low-dimensional feature space that is more
conducive to clustering. Furthermore, the related learning process is treated
as a joint optimization problem of deep feature extraction and clustering.
Experimental results demonstrate the intense competitiveness of the proposed
algorithm in comparison with state-of-the-art clustering methods of
hyperspectral images.
","Jinguang Sun, Wanli Wang, Xian Wei, Li Fang, Xiaoliang Tang, Yusheng Xu, Hui Yu, Wei Yao",Wei Yao,2019-04-01T04:42:18Z
"Transfer Learning for Segmenting Dimensionally-Reduced Hyperspectral
  Images","  Deep learning has established the state of the art in multiple fields,
including hyperspectral image analysis. However, training large-capacity
learners to segment such imagery requires representative training sets.
Acquiring such data is human-dependent and time-consuming, especially in Earth
observation scenarios, where the hyperspectral data transfer is very costly and
time-constrained. In this letter, we show how to effectively deal with a
limited number and size of available hyperspectral ground-truth sets, and apply
transfer learning for building deep feature extractors. Also, we exploit
spectral dimensionality reduction to make our technique applicable over
hyperspectral data acquired using different sensors, which may capture
different numbers of hyperspectral bands. The experiments, performed over
several benchmarks and backed up with statistical tests, indicated that our
approach allows us to effectively train well-generalizing deep convolutional
neural nets even using significantly reduced data.
","Jakub Nalepa, Michal Myller, Michal Kawulok",Michal Kawulok,2019-06-23T19:11:26Z
Trends in deep learning for medical hyperspectral image analysis,"  Deep learning algorithms have seen acute growth of interest in their
applications throughout several fields of interest in the last decade, with
medical hyperspectral imaging being a particularly promising domain. So far, to
the best of our knowledge, there is no review paper that discusses the
implementation of deep learning for medical hyperspectral imaging, which is
what this review paper aims to accomplish by examining publications that
currently utilize deep learning to perform effective analysis of medical
hyperspectral imagery. This paper discusses deep learning concepts that are
relevant and applicable to medical hyperspectral imaging analysis, several of
which have been implemented since the boom in deep learning. This will comprise
of reviewing the use of deep learning for classification, segmentation, and
detection in order to investigate the analysis of medical hyperspectral
imaging. Lastly, we discuss the current and future challenges pertaining to
this discipline and the possible efforts to overcome such trials.
","Uzair Khan, Paheding Sidike, Colin Elkin, Vijay Devabhaktuni",Vijay Devabhaktuni,2020-11-27T19:42:06Z
"Learning Hyperspectral Feature Extraction and Classification with
  ResNeXt Network","  The Hyperspectral image (HSI) classification is a standard remote sensing
task, in which each image pixel is given a label indicating the physical
land-cover on the earth's surface. The achievements of image semantic
segmentation and deep learning approaches on ordinary images have accelerated
the research on hyperspectral image classification. Moreover, the utilization
of both the spectral and spatial cues in hyperspectral images has shown
improved classification accuracy in hyperspectral image classification. The use
of only 3D Convolutional Neural Networks (3D-CNN) to extract both spatial and
spectral cues from Hyperspectral images results in an explosion of parameters
hence high computational cost. We propose network architecture called the
MixedSN that utilizes the 3D convolutions to modeling spectral-spatial
information in the early layers of the architecture and the 2D convolutions at
the top layers which majorly deal with semantic abstraction. We constrain our
architecture to ResNeXt block because of their performance and simplicity. Our
model drastically reduced the number of parameters and achieved comparable
classification performance with state-of-the-art methods on Indian Pine (IP)
scene dataset, Pavia University scene (PU) dataset, Salinas (SA) Scene dataset,
and Botswana (BW) dataset.
","Divinah Nyasaka, Jing Wang, Haron Tinega",Haron Tinega,2020-02-07T01:54:15Z
"Spectral DiffuserCam: lensless snapshot hyperspectral imaging with a
  spectral filter array","  Hyperspectral imaging is useful for applications ranging from medical
diagnostics to agricultural crop monitoring; however, traditional scanning
hyperspectral imagers are prohibitively slow and expensive for widespread
adoption. Snapshot techniques exist but are often confined to bulky benchtop
setups or have low spatio-spectral resolution. In this paper, we propose a
novel, compact, and inexpensive computational camera for snapshot hyperspectral
imaging. Our system consists of a tiled spectral filter array placed directly
on the image sensor and a diffuser placed close to the sensor. Each point in
the world maps to a unique pseudorandom pattern on the spectral filter array,
which encodes multiplexed spatio-spectral information. By solving a
sparsity-constrained inverse problem, we recover the hyperspectral volume with
sub-super-pixel resolution. Our hyperspectral imaging framework is flexible and
can be designed with contiguous or non-contiguous spectral filters that can be
chosen for a given application. We provide theory for system design,
demonstrate a prototype device, and present experimental results with high
spatio-spectral resolution.
","Kristina Monakhova, Kyrollos Yanny, Neerja Aggarwal, Laura Waller",Laura Waller,2020-06-15T17:31:17Z
"Forgery Detection in a Questioned Hyperspectral Document Image using
  K-means Clustering","  Hyperspectral imaging allows for analysis of images in several hundred of
spectral bands depending on the spectral resolution of the imaging sensor.
Hyperspectral document image is the one which has been captured by a
hyperspectral camera so that the document can be observed in the different
bands on the basis of their unique spectral signatures. To detect the forgery
in a document various Ink mismatch detection techniques based on hyperspectral
imaging have presented vast potential in differentiating visually similar inks.
Inks of different materials exhibit different spectral signature even if they
have the same color. Hyperspectral analysis of document images allows
identification and discrimination of visually similar inks. Based on this
analysis forensic experts can identify the authenticity of the document. In
this paper an extensive ink mismatch detection technique is presented which
uses KMean Clustering to identify different inks on the basis of their unique
spectral response and separates them into different clusters.
","Maria Yaseen, Rammal Aftab Ahmed, Rimsha Mahrukh",Rimsha Mahrukh,2020-06-29T13:51:24Z
A Dataset for Evaluating Blood Detection in Hyperspectral Images,"  The sensitivity of imaging spectroscopy to haemoglobin derivatives makes it a
promising tool for detecting blood. However, due to complexity and high
dimensionality of hyperspectral images, the development of hyperspectral blood
detection algorithms is challenging. To facilitate their development, we
present a new hyperspectral blood detection dataset. This dataset, published in
accordance to open access mandate, consist of multiple detection scenarios with
varying levels of complexity. It allows to test the performance of Machine
Learning methods in relation to different acquisition environments, types of
background, age of blood and presence of other blood-like substances. We
explored the dataset with blood detection experiments. We used hyperspectral
target detection algorithm based on the well-known Matched Filter detector. Our
results and their discussion highlight the challenges of blood detection in
hyperspectral data and form a reference for further works.
","Michał Romaszewski, Przemysław Głomb, Arkadiusz Sochan, Michał Cholewa",Michał Cholewa,2020-08-24T08:38:00Z
SASSI -- Super-Pixelated Adaptive Spatio-Spectral Imaging,"  We introduce a novel video-rate hyperspectral imager with high spatial, and
temporal resolutions. Our key hypothesis is that spectral profiles of pixels in
a super-pixel of an oversegmented image tend to be very similar. Hence, a
scene-adaptive spatial sampling of an hyperspectral scene, guided by its
super-pixel segmented image, is capable of obtaining high-quality
reconstructions. To achieve this, we acquire an RGB image of the scene, compute
its super-pixels, from which we generate a spatial mask of locations where we
measure high-resolution spectrum. The hyperspectral image is subsequently
estimated by fusing the RGB image and the spectral measurements using a
learnable guided filtering approach. Due to low computational complexity of the
superpixel estimation step, our setup can capture hyperspectral images of the
scenes with little overhead over traditional snapshot hyperspectral cameras,
but with significantly higher spatial and spectral resolutions. We validate the
proposed technique with extensive simulations as well as a lab prototype that
measures hyperspectral video at a spatial resolution of $600 \times 900$
pixels, at a spectral resolution of 10 nm over visible wavebands, and achieving
a frame rate at $18$fps.
","Vishwanath Saragadam, Michael DeZeeuw, Richard Baraniuk, Ashok Veeraraghavan, Aswin Sankaranarayanan",Aswin Sankaranarayanan,2020-12-28T21:34:18Z
"Class-Wise Principal Component Analysis for hyperspectral image feature
  extraction","  This paper introduces the Class-wise Principal Component Analysis, a
supervised feature extraction method for hyperspectral data. Hyperspectral
Imaging (HSI) has appeared in various fields in recent years, including Remote
Sensing. Realizing that information extraction tasks for hyperspectral images
are burdened by data-specific issues, we identify and address two major
problems. Those are the Curse of Dimensionality which occurs due to the
high-volume of the data cube and the class imbalance problem which is common in
hyperspectral datasets. Dimensionality reduction is an essential preprocessing
step to complement a hyperspectral image classification task. Therefore, we
propose a feature extraction algorithm for dimensionality reduction, based on
Principal Component Analysis (PCA). Evaluations are carried out on the Indian
Pines dataset to demonstrate that significant improvements are achieved when
using the reduced data in a classification task.
","Dimitra Koumoutsou, Eleni Charou, Georgios Siolas, Giorgos Stamou",Giorgos Stamou,2021-04-09T17:25:11Z
"Self-supervised Contrastive Learning for Cross-domain Hyperspectral
  Image Representation","  Recently, self-supervised learning has attracted attention due to its
remarkable ability to acquire meaningful representations for classification
tasks without using semantic labels. This paper introduces a self-supervised
learning framework suitable for hyperspectral images that are inherently
challenging to annotate. The proposed framework architecture leverages
cross-domain CNN, allowing for learning representations from different
hyperspectral images with varying spectral characteristics and no pixel-level
annotation. In the framework, cross-domain representations are learned via
contrastive learning where neighboring spectral vectors in the same image are
clustered together in a common representation space encompassing multiple
hyperspectral images. In contrast, spectral vectors in different hyperspectral
images are separated into distinct clusters in the space. To verify that the
learned representation through contrastive learning is effectively transferred
into a downstream task, we perform a classification task on hyperspectral
images. The experimental results demonstrate the advantage of the proposed
self-supervised representation over models trained from scratch or other
transfer learning methods.
","Hyungtae Lee, Heesung Kwon",Heesung Kwon,2022-02-08T16:16:45Z
"A distribution-dependent Mumford-Shah model for unsupervised
  hyperspectral image segmentation","  Hyperspectral images provide a rich representation of the underlying spectrum
for each pixel, allowing for a pixel-wise classification/segmentation into
different classes. As the acquisition of labeled training data is very
time-consuming, unsupervised methods become crucial in hyperspectral image
analysis. The spectral variability and noise in hyperspectral data make this
task very challenging and define special requirements for such methods.
  Here, we present a novel unsupervised hyperspectral segmentation framework.
It starts with a denoising and dimensionality reduction step by the
well-established Minimum Noise Fraction (MNF) transform. Then, the Mumford-Shah
(MS) segmentation functional is applied to segment the data. We equipped the MS
functional with a novel robust distribution-dependent indicator function
designed to handle the characteristic challenges of hyperspectral data. To
optimize our objective function with respect to the parameters for which no
closed form solution is available, we propose an efficient fixed point
iteration scheme. Numerical experiments on four public benchmark datasets show
that our method produces competitive results, which outperform three
state-of-the-art methods substantially on three of these datasets.
","Jan-Christopher Cohrs, Chandrajit Bajaj, Benjamin Berkels",Benjamin Berkels,2022-03-28T19:57:14Z
Dispersed Structured Light for Hyperspectral 3D Imaging,"  Hyperspectral 3D imaging aims to acquire both depth and spectral information
of a scene. However, existing methods are either prohibitively expensive and
bulky or compromise on spectral and depth accuracy. In this work, we present
Dispersed Structured Light (DSL), a cost-effective and compact method for
accurate hyperspectral 3D imaging. DSL modifies a traditional projector-camera
system by placing a sub-millimeter thick diffraction grating film front of the
projector. The grating disperses structured light based on light wavelength. To
utilize the dispersed structured light, we devise a model for dispersive
projection image formation and a per-pixel hyperspectral 3D reconstruction
method. We validate DSL by instantiating a compact experimental prototype. DSL
achieves spectral accuracy of 18.8nm full-width half-maximum (FWHM) and depth
error of 1mm. We demonstrate that DSL outperforms prior work on practical
hyperspectral 3D imaging. DSL promises accurate and practical hyperspectral 3D
imaging for diverse application domains, including computer vision and
graphics, cultural heritage, geology, and biology.
","Suhyun Shin, Seokjun Choi, Felix Heide, Seung-Hwan Baek",Seung-Hwan Baek,2023-11-30T06:45:52Z
"HyperColorization: Propagating spatially sparse noisy spectral clues for
  reconstructing hyperspectral images","  Hyperspectral cameras face challenging spatial-spectral resolution trade-offs
and are more affected by shot noise than RGB photos taken over the same total
exposure time. Here, we present a colorization algorithm to reconstruct
hyperspectral images from a grayscale guide image and spatially sparse spectral
clues. We demonstrate that our algorithm generalizes to varying spectral
dimensions for hyperspectral images, and show that colorizing in a low-rank
space reduces compute time and the impact of shot noise. To enhance robustness,
we incorporate guided sampling, edge-aware filtering, and dimensionality
estimation techniques. Our method surpasses previous algorithms in various
performance metrics, including SSIM, PSNR, GFC, and EMD, which we analyze as
metrics for characterizing hyperspectral image quality. Collectively, these
findings provide a promising avenue for overcoming the time-space-wavelength
resolution trade-off by reconstructing a dense hyperspectral image from samples
obtained by whisk or push broom scanners, as well as hybrid spatial-spectral
computational imaging systems.
","M. Kerem Aydin, Qi Guo, Emma Alexander",Emma Alexander,2024-03-18T16:33:43Z
Transformer for Multitemporal Hyperspectral Image Unmixing,"  Multitemporal hyperspectral image unmixing (MTHU) holds significant
importance in monitoring and analyzing the dynamic changes of surface. However,
compared to single-temporal unmixing, the multitemporal approach demands
comprehensive consideration of information across different phases, rendering
it a greater challenge. To address this challenge, we propose the Multitemporal
Hyperspectral Image Unmixing Transformer (MUFormer), an end-to-end unsupervised
deep learning model. To effectively perform multitemporal hyperspectral image
unmixing, we introduce two key modules: the Global Awareness Module (GAM) and
the Change Enhancement Module (CEM). The Global Awareness Module computes
self-attention across all phases, facilitating global weight allocation. On the
other hand, the Change Enhancement Module dynamically learns local temporal
changes by comparing endmember changes between adjacent phases. The synergy
between these modules allows for capturing semantic information regarding
endmember and abundance changes, thereby enhancing the effectiveness of
multitemporal hyperspectral image unmixing. We conducted experiments on one
real dataset and two synthetic datasets, demonstrating that our model
significantly enhances the effect of multitemporal hyperspectral image
unmixing.
","Hang Li, Qiankun Dong, Xueshuo Xie, Xia Xu, Tao Li, Zhenwei Shi",Zhenwei Shi,2024-07-15T04:02:01Z
Fast Hyperspectral Neutron Tomography,"  Hyperspectral neutron computed tomography is a tomographic imaging technique
in which thousands of wavelength-specific neutron radiographs are typically
measured for each tomographic view. In conventional hyperspectral
reconstruction, data from each neutron wavelength bin is reconstructed
separately, which is extremely time-consuming. These reconstructions often
suffer from poor quality due to low signal-to-noise ratio. Consequently,
material decomposition based on these reconstructions tends to lead to both
inaccurate estimates of the material spectra and inaccurate volumetric material
separation.
  In this paper, we present two novel algorithms for processing hyperspectral
neutron data: fast hyperspectral reconstruction and fast material
decomposition. Both algorithms rely on a subspace decomposition procedure that
transforms hyperspectral views into low-dimensional projection views within an
intermediate subspace, where tomographic reconstruction is performed. The use
of subspace decomposition dramatically reduces reconstruction time while
reducing both noise and reconstruction artifacts. We apply our algorithms to
both simulated and measured neutron data and demonstrate that they reduce
computation and improve the quality of the results relative to conventional
methods.
","Mohammad Samin Nur Chowdhury, Diyu Yang, Shimin Tang, Singanallur V. Venkatakrishnan, Hassina Z. Bilheux, Gregery T. Buzzard, Charles A. Bouman",Charles A. Bouman,2024-10-29T19:43:02Z
"Hyperspectral Unmixing: Ground Truth Labeling, Datasets, Benchmark
  Performances and Survey","  Hyperspectral unmixing (HU) is a very useful and increasingly popular
preprocessing step for a wide range of hyperspectral applications. However, the
HU research has been constrained a lot by three factors: (a) the number of
hyperspectral images (especially the ones with ground truths) are very limited;
(b) the ground truths of most hyperspectral images are not shared on the web,
which may cause lots of unnecessary troubles for researchers to evaluate their
algorithms; (c) the codes of most state-of-the-art methods are not shared,
which may also delay the testing of new methods.
  Accordingly, this paper deals with the above issues from the following three
perspectives: (1) as a profound contribution, we provide a general labeling
method for the HU. With it, we labeled up to 15 hyperspectral images, providing
18 versions of ground truths. To the best of our knowledge, this is the first
paper to summarize and share up to 15 hyperspectral images and their 18
versions of ground truths for the HU. Observing that the hyperspectral
classification (HyC) has much more standard datasets (whose ground truths are
generally publicly shared) than the HU, we propose an interesting method to
transform the HyC datasets for the HU research. (2) To further facilitate the
evaluation of HU methods under different conditions, we reviewed and
implemented the algorithm to generate a complex synthetic hyperspectral image.
By tuning the hyper-parameters in the code, we may verify the HU methods from
four perspectives. The code would also be shared on the web. (3) To provide a
standard comparison, we reviewed up to 10 state-of-the-art HU algorithms, then
selected the 5 most benchmark HU algorithms, and compared them on the 15 real
hyperspectral datasets. The experiment results are surely reproducible; the
implemented codes would be shared on the web.
",Feiyun Zhu,Feiyun Zhu,2017-08-17T03:35:02Z
"In-Vivo Hyperspectral Human Brain Image Database for Brain Cancer
  Detection","  The use of hyperspectral imaging for medical applications is becoming more
common in recent years. One of the main obstacles that researchers find when
developing hyperspectral algorithms for medical applications is the lack of
specific, publicly available, and hyperspectral medical data. The work
described in this paper was developed within the framework of the European
project HELICoiD (HypErspectraL Imaging Cancer Detection), which had as a main
goal the application of hyperspectral imaging to the delineation of brain
tumors in real-time during neurosurgical operations. In this paper, the
methodology followed to generate the first hyperspectral database of in-vivo
human brain tissues is presented. Data was acquired employing a customized
hyperspectral acquisition system capable of capturing information in the Visual
and Near InfraRed (VNIR) range from 400 to 1000 nm. Repeatability was assessed
for the cases where two images of the same scene were captured consecutively.
The analysis reveals that the system works more efficiently in the spectral
range between 450 and 900 nm. A total of 36 hyperspectral images from 22
different patients were obtained. From these data, more than 300 000 spectral
signatures were labeled employing a semi-automatic methodology based on the
spectral angle mapper algorithm. Four different classes were defined: normal
tissue, tumor tissue, blood vessel, and background elements. All the
hyperspectral data has been made available in a public repository.
","H. Fabelo, S. Ortega, A. Szolna, D. Bulters, J. F. Pineiro, S. Kabwama, A. Shanahan, H. Bulstrode, S. Bisshopp, B. R. Kiran, D. Ravi, R. Lazcano, D. Madronal, C. Sosa, C. Espino, M. Marquez, M. De la Luz Plaza, R. Camacho, D. Carrera, M. Hernandez, G. M. Callico, J. Morera, B. Stanciulescu, G. Z. Yang, R. Salvador, E. Juarez, C. Sanz, R. Sarmiento",R. Sarmiento,2024-02-16T15:58:45Z
AeroRIT: A New Scene for Hyperspectral Image Analysis,"  We investigate applying convolutional neural network (CNN) architecture to
facilitate aerial hyperspectral scene understanding and present a new
hyperspectral dataset-AeroRIT-that is large enough for CNN training. To date
the majority of hyperspectral airborne have been confined to various
sub-categories of vegetation and roads and this scene introduces two new
categories: buildings and cars. To the best of our knowledge, this is the first
comprehensive large-scale hyperspectral scene with nearly seven million pixel
annotations for identifying cars, roads, and buildings. We compare the
performance of three popular architectures - SegNet, U-Net, and Res-U-Net, for
scene understanding and object identification via the task of dense semantic
segmentation to establish a benchmark for the scene. To further strengthen the
network, we add squeeze and excitation blocks for better channel interactions
and use self-supervised learning for better encoder initialization. Aerial
hyperspectral image analysis has been restricted to small datasets with limited
train/test splits capabilities and we believe that AeroRIT will help advance
the research in the field with a more complex object distribution to perform
well on. The full dataset, with flight lines in radiance and reflectance
domain, is available for download at https://github.com/aneesh3108/AeroRIT.
This dataset is the first step towards developing robust algorithms for
hyperspectral airborne sensing that can robustly perform advanced tasks like
vehicle tracking and occlusion handling.
","Aneesh Rangnekar, Nilay Mokashi, Emmett Ientilucci, Christopher Kanan, Matthew J. Hoffman",Matthew J. Hoffman,2019-12-17T18:31:56Z
"Tracking in Aerial Hyperspectral Videos using Deep Kernelized
  Correlation Filters","  Hyperspectral imaging holds enormous potential to improve the
state-of-the-art in aerial vehicle tracking with low spatial and temporal
resolutions. Recently, adaptive multi-modal hyperspectral sensors have
attracted growing interest due to their ability to record extended data quickly
from aerial platforms. In this study, we apply popular concepts from
traditional object tracking, namely (1) Kernelized Correlation Filters (KCF)
and (2) Deep Convolutional Neural Network (CNN) features to aerial tracking in
hyperspectral domain. We propose the Deep Hyperspectral Kernelized Correlation
Filter based tracker (DeepHKCF) to efficiently track aerial vehicles using an
adaptive multi-modal hyperspectral sensor. We address low temporal resolution
by designing a single KCF-in-multiple Regions-of-Interest (ROIs) approach to
cover a reasonably large area. To increase the speed of deep convolutional
features extraction from multiple ROIs, we design an effective ROI mapping
strategy. The proposed tracker also provides flexibility to couple with the
more advanced correlation filter trackers. The DeepHKCF tracker performs
exceptionally well with deep features set up in a synthetic hyperspectral video
generated by the Digital Imaging and Remote Sensing Image Generation (DIRSIG)
software. Additionally, we generate a large, synthetic, single-channel dataset
using DIRSIG to perform vehicle classification in the Wide Area Motion Imagery
(WAMI) platform. This way, the high-fidelity of the DIRSIG software is proved
and a large scale aerial vehicle classification dataset is released to support
studies on vehicle detection and tracking in the WAMI platform.
","Burak Uzkent, Aneesh Rangnekar, Matthew J. Hoffman",Matthew J. Hoffman,2017-11-20T10:06:07Z
Machine learning based hyperspectral image analysis: A survey,"  Hyperspectral sensors enable the study of the chemical properties of scene
materials remotely for the purpose of identification, detection, and chemical
composition analysis of objects in the environment. Hence, hyperspectral images
captured from earth observing satellites and aircraft have been increasingly
important in agriculture, environmental monitoring, urban planning, mining, and
defense. Machine learning algorithms due to their outstanding predictive power
have become a key tool for modern hyperspectral image analysis. Therefore, a
solid understanding of machine learning techniques have become essential for
remote sensing researchers and practitioners. This paper reviews and compares
recent machine learning-based hyperspectral image analysis methods published in
literature. We organize the methods by the image analysis task and by the type
of machine learning algorithm, and present a two-way mapping between the image
analysis tasks and the types of machine learning algorithms that can be applied
to them. The paper is comprehensive in coverage of both hyperspectral image
analysis tasks and machine learning algorithms. The image analysis tasks
considered are land cover classification, target detection, unmixing, and
physical parameter estimation. The machine learning algorithms covered are
Gaussian models, linear regression, logistic regression, support vector
machines, Gaussian mixture model, latent linear models, sparse linear models,
Gaussian mixture models, ensemble learning, directed graphical models,
undirected graphical models, clustering, Gaussian processes, Dirichlet
processes, and deep learning. We also discuss the open challenges in the field
of hyperspectral image analysis and explore possible future directions.
","Utsav B. Gewali, Sildomar T. Monteiro, Eli Saber",Eli Saber,2018-02-23T19:11:25Z
Hyperspectral Image Dataset for Benchmarking on Salient Object Detection,"  Many works have been done on salient object detection using supervised or
unsupervised approaches on colour images. Recently, a few studies demonstrated
that efficient salient object detection can also be implemented by using
spectral features in visible spectrum of hyperspectral images from natural
scenes. However, these models on hyperspectral salient object detection were
tested with a very few number of data selected from various online public
dataset, which are not specifically created for object detection purposes.
Therefore, here, we aim to contribute to the field by releasing a hyperspectral
salient object detection dataset with a collection of 60 hyperspectral images
with their respective ground-truth binary images and representative rendered
colour images (sRGB). We took several aspects in consideration during the data
collection such as variation in object size, number of objects,
foreground-background contrast, object position on the image, and etc. Then, we
prepared ground truth binary images for each hyperspectral data, where salient
objects are labelled on the images. Finally, we did performance evaluation
using Area Under Curve (AUC) metric on some existing hyperspectral saliency
detection models in literature.
","Nevrez Imamoglu, Yu Oishi, Xiaoqiang Zhang, Guanqun Ding, Yuming Fang, Toru Kouyama, Ryosuke Nakamura",Ryosuke Nakamura,2018-06-29T09:31:56Z
Spatial-Spectral Manifold Embedding of Hyperspectral Data,"  In recent years, hyperspectral imaging, also known as imaging spectroscopy,
has been paid an increasing interest in geoscience and remote sensing
community. Hyperspectral imagery is characterized by very rich spectral
information, which enables us to recognize the materials of interest lying on
the surface of the Earth more easier. We have to admit, however, that high
spectral dimension inevitably brings some drawbacks, such as expensive data
storage and transmission, information redundancy, etc. Therefore, to reduce the
spectral dimensionality effectively and learn more discriminative spectral
low-dimensional embedding, in this paper we propose a novel hyperspectral
embedding approach by simultaneously considering spatial and spectral
information, called spatial-spectral manifold embedding (SSME). Beyond the
pixel-wise spectral embedding approaches, SSME models the spatial and spectral
information jointly in a patch-based fashion. SSME not only learns the spectral
embedding by using the adjacency matrix obtained by similarity measurement
between spectral signatures, but also models the spatial neighbours of a target
pixel in hyperspectral scene by sharing the same weights (or edges) in the
process of learning embedding. Classification is explored as a potential
strategy to quantitatively evaluate the performance of learned embedding
representations. Classification is explored as a potential application for
quantitatively evaluating the performance of these hyperspectral embedding
algorithms. Extensive experiments conducted on the widely-used hyperspectral
datasets demonstrate the superiority and effectiveness of the proposed SSME as
compared to several state-of-the-art embedding methods.
","Danfeng Hong, Jing Yao, Xin Wu, Jocelyn Chanussot, Xiao Xiang Zhu",Xiao Xiang Zhu,2020-07-17T05:40:27Z
"From Less to More: Spectral Splitting and Aggregation Network for
  Hyperspectral Face Super-Resolution","  High-resolution (HR) hyperspectral face image plays an important role in face
related computer vision tasks under uncontrolled conditions, such as low-light
environment and spoofing attacks. However, the dense spectral bands of
hyperspectral face images come at the cost of limited amount of photons reached
a narrow spectral window on average, which greatly reduces the spatial
resolution of hyperspectral face images. In this paper, we investigate how to
adapt the deep learning techniques to hyperspectral face image super-resolution
(HFSR), especially when the training samples are very limited. Benefiting from
the amount of spectral bands, in which each band can be seen as an image, we
present a spectral splitting and aggregation network (SSANet) for HFSR with
limited training samples. In the shallow layers, we split the hyperspectral
image into different spectral groups. Then, we gradually aggregate the neighbor
bands at deeper layers to exploit spectral correlations. By this spectral
splitting and aggregation strategy (SSAS), we can divide the original
hyperspectral image into multiple samples (\emph{from less to more}) to support
the efficient training of the network and effectively exploit the spectral
correlations among spectrum. To cope with the challenge of small training
sample size (S3) problem, we propose to expand the training samples by a
self-representation model and symmetry-induced augmentation. Experiments show
that SSANet can well model the joint correlations of spatial and spectral
information. By expanding the training samples, SSANet can effectively
alleviate the S3 problem.
","Junjun Jiang, Chenyang Wang, Xianming Liu, Kui Jiang, Jiayi Ma",Jiayi Ma,2021-08-31T02:13:00Z
"Classification of Hyperspectral Images by Using Spectral Data and Fully
  Connected Neural Network","  It is observed that high classification performance is achieved for one- and
two-dimensional signals by using deep learning methods. In this context, most
researchers have tried to classify hyperspectral images by using deep learning
methods and classification success over 90% has been achieved for these images.
Deep neural networks (DNN) actually consist of two parts: i) Convolutional
neural network (CNN) and ii) fully connected neural network (FCNN). While CNN
determines the features, FCNN is used in classification. In classification of
the hyperspectral images, it is observed that almost all of the researchers
used 2D or 3D convolution filters on the spatial data beside spectral data
(features). It is convenient to use convolution filters on images or time
signals. In hyperspectral images, each pixel is represented by a signature
vector which consists of individual features that are independent of each
other. Since the order of the features in the vector can be changed, it doesn't
make sense to use convolution filters on these features as on time signals. At
the same time, since the hyperspectral images do not have a textural structure,
there is no need to use spatial data besides spectral data. In this study,
hyperspectral images of Indian pines, Salinas, Pavia centre, Pavia university
and Botswana are classified by using only fully connected neural network and
the spectral data with one dimensional. An average accuracy of 97.5% is
achieved for the test sets of all hyperspectral images.
","Zumray Dokur, Tamer Olmez",Tamer Olmez,2022-01-08T12:45:48Z
"HyperNet: Self-Supervised Hyperspectral Spatial-Spectral Feature
  Understanding Network for Hyperspectral Change Detection","  The fast development of self-supervised learning lowers the bar learning
feature representation from massive unlabeled data and has triggered a series
of research on change detection of remote sensing images. Challenges in
adapting self-supervised learning from natural images classification to remote
sensing images change detection arise from difference between the two tasks.
The learned patch-level feature representations are not satisfying for the
pixel-level precise change detection. In this paper, we proposed a novel
pixel-level self-supervised hyperspectral spatial-spectral understanding
network (HyperNet) to accomplish pixel-wise feature representation for
effective hyperspectral change detection. Concretely, not patches but the whole
images are fed into the network and the multi-temporal spatial-spectral
features are compared pixel by pixel. Instead of processing the two-dimensional
imaging space and spectral response dimension in hybrid style, a powerful
spatial-spectral attention module is put forward to explore the spatial
correlation and discriminative spectral features of multi-temporal
hyperspectral images (HSIs), separately. Only the positive samples at the same
location of bi-temporal HSIs are created and forced to be aligned, aiming at
learning the spectral difference-invariant features. Moreover, a new similarity
loss function named focal cosine is proposed to solve the problem of imbalanced
easy and hard positive samples comparison, where the weights of those hard
samples are enlarged and highlighted to promote the network training. Six
hyperspectral datasets have been adopted to test the validity and
generalization of proposed HyperNet. The extensive experiments demonstrate the
superiority of HyperNet over the state-of-the-art algorithms on downstream
hyperspectral change detection tasks.
","Meiqi Hu, Chen Wu, Liangpei Zhang",Liangpei Zhang,2022-07-20T03:26:03Z
"A novel information gain-based approach for classification and
  dimensionality reduction of hyperspectral images","  Recently, the hyperspectral sensors have improved our ability to monitor the
earth surface with high spectral resolution. However, the high dimensionality
of spectral data brings challenges for the image processing. Consequently, the
dimensionality reduction is a necessary step in order to reduce the
computational complexity and increase the classification accuracy. In this
paper, we propose a new filter approach based on information gain for
dimensionality reduction and classification of hyperspectral images. A special
strategy based on hyperspectral bands selection is adopted to pick the most
informative bands and discard the irrelevant and noisy ones. The algorithm
evaluates the relevancy of the bands based on the information gain function
with the support vector machine classifier. The proposed method is compared
using two benchmark hyperspectral datasets (Indiana, Pavia) with three
competing methods. The comparison results showed that the information gain
filter approach outperforms the other methods on the tested datasets and could
significantly reduce the computation cost while improving the classification
accuracy. Keywords: Hyperspectral images; dimensionality reduction; information
gain; classification accuracy.
  Keywords: Hyperspectral images; dimensionality reduction; information gain;
classification accuracy.
","Asma Elmaizi, Hasna Nhaila, Elkebir Sarhrouni, Ahmed Hammouch, Chafik Nacir",Chafik Nacir,2022-10-26T20:59:57Z
"Object Detection in Hyperspectral Image via Unified Spectral-Spatial
  Feature Aggregation","  Deep learning-based hyperspectral image (HSI) classification and object
detection techniques have gained significant attention due to their vital role
in image content analysis, interpretation, and wider HSI applications. However,
current hyperspectral object detection approaches predominantly emphasize
either spectral or spatial information, overlooking the valuable complementary
relationship between these two aspects. In this study, we present a novel
\textbf{S}pectral-\textbf{S}patial \textbf{A}ggregation (S2ADet) object
detector that effectively harnesses the rich spectral and spatial complementary
information inherent in hyperspectral images. S2ADet comprises a hyperspectral
information decoupling (HID) module, a two-stream feature extraction network,
and a one-stage detection head. The HID module processes hyperspectral images
by aggregating spectral and spatial information via band selection and
principal components analysis, consequently reducing redundancy. Based on the
acquired spatial and spectral aggregation information, we propose a feature
aggregation two-stream network for interacting spectral-spatial features.
Furthermore, to address the limitations of existing databases, we annotate an
extensive dataset, designated as HOD3K, containing 3,242 hyperspectral images
captured across diverse real-world scenes and encompassing three object
classes. These images possess a resolution of 512x256 pixels and cover 16 bands
ranging from 470 nm to 620 nm. Comprehensive experiments on two datasets
demonstrate that S2ADet surpasses existing state-of-the-art methods, achieving
robust and reliable results. The demo code and dataset of this work are
publicly available at \url{https://github.com/hexiao-cs/S2ADet}.
","Xiao He, Chang Tang, Xinwang Liu, Wei Zhang, Kun Sun, Jiangfeng Xu",Jiangfeng Xu,2023-06-14T09:01:50Z
"Embedded Hyperspectral Band Selection with Adaptive Optimization for
  Image Semantic Segmentation","  Hyperspectral band selection plays a pivotal role in remote sensing and image
analysis, aiming to identify the most informative spectral bands while
minimizing computational overhead. In this paper, we introduce a pioneering
approach for hyperspectral band selection that offers an embedded solution,
making it well-suited for resource-constrained or real-time applications. Our
proposed method, embedded Hyperspectral Band Selection (EHBS), excels in
selecting the best bands without the need for prior processing, seamlessly
integrating with the downstream task model. This is achieved through the
adaptation of the Stochastic Gates (STG) algorithm, originally designed for
feature selection, for hyperspectral band selection in the context of image
semantic segmentation and the integration of a dynamic optimizer, DoG, which
removes the need for the required tuning the learning rate. To assess the
performance of our method, we introduce a novel metric for evaluating band
selection methods across different target numbers of selected bands quantified
by the Area Under the Curve (AUC). We conduct experiments on two distinct
semantic-segmentation hyperspectral benchmark datasets, demonstrating its
superiority in terms of its resulting accuracy and its ease of use compared to
many common and state-of-the-art methods. Furthermore, our contributions extend
beyond the realm of hyperspectral band selection. The adaptability of our
approach to other tasks, especially those involving grouped features, opens up
promising avenues for broader applications within the realm of deep learning,
such as feature selection for feature groups. The demonstrated success on the
tested datasets and the potential for application to a variety of tasks
underscore the value of our method as a substantial addition to the field of
computer vision.
","Yaniv Zimmer, Oren Glickman",Oren Glickman,2024-01-21T07:48:39Z
"Unveiling the Power of Wavelets: A Wavelet-based Kolmogorov-Arnold
  Network for Hyperspectral Image Classification","  Hyperspectral image classification is a crucial but challenging task due to
the high dimensionality and complex spatial-spectral correlations inherent in
hyperspectral data. This paper employs Wavelet-based Kolmogorov-Arnold Network
(wav-kan) architecture tailored for efficient modeling of these intricate
dependencies. Inspired by the Kolmogorov-Arnold representation theorem, Wav-KAN
incorporates wavelet functions as learnable activation functions, enabling
non-linear mapping of the input spectral signatures. The wavelet-based
activation allows Wav-KAN to effectively capture multi-scale spatial and
spectral patterns through dilations and translations. Experimental evaluation
on three benchmark hyperspectral datasets (Salinas, Pavia, Indian Pines)
demonstrates the superior performance of Wav-KAN compared to traditional
multilayer perceptrons (MLPs) and the recently proposed Spline-based KAN
(Spline-KAN) model. In this work we are: (1) conducting more experiments on
additional hyperspectral datasets (Pavia University, WHU-Hi, and Urban
Hyperspectral Image) to further validate the generalizability of Wav-KAN; (2)
developing a multiresolution Wav-KAN architecture to capture scale-invariant
features; (3) analyzing the effect of dimensional reduction techniques on
classification performance; (4) exploring optimization methods for tuning the
hyperparameters of KAN models; and (5) comparing Wav-KAN with other
state-of-the-art models in hyperspectral image classification.
","Seyd Teymoor Seydi, Zavareh Bozorgasl, Hao Chen",Hao Chen,2024-06-12T04:52:40Z
"HS3-Bench: A Benchmark and Strong Baseline for Hyperspectral Semantic
  Segmentation in Driving Scenarios","  Semantic segmentation is an essential step for many vision applications in
order to understand a scene and the objects within. Recent progress in
hyperspectral imaging technology enables the application in driving scenarios
and the hope is that the devices perceptive abilities provide an advantage over
RGB-cameras. Even though some datasets exist, there is no standard benchmark
available to systematically measure progress on this task and evaluate the
benefit of hyperspectral data. In this paper, we work towards closing this gap
by providing the HyperSpectral Semantic Segmentation benchmark (HS3-Bench). It
combines annotated hyperspectral images from three driving scenario datasets
and provides standardized metrics, implementations, and evaluation protocols.
We use the benchmark to derive two strong baseline models that surpass the
previous state-of-the-art performances with and without pre-training on the
individual datasets. Further, our results indicate that the existing
learning-based methods benefit more from leveraging additional RGB training
data than from leveraging the additional hyperspectral channels. This poses
important questions for future research on hyperspectral imaging for semantic
segmentation in driving scenarios. Code to run the benchmark and the strong
baseline approaches are available under
https://github.com/nickstheisen/hyperseg.
","Nick Theisen, Robin Bartsch, Dietrich Paulus, Peer Neubert",Peer Neubert,2024-09-17T14:00:49Z
"PUNCH: Positive UNlabelled Classification based information retrieval in
  Hyperspectral images","  Hyperspectral images of land-cover captured by airborne or satellite-mounted
sensors provide a rich source of information about the chemical composition of
the materials present in a given place. This makes hyperspectral imaging an
important tool for earth sciences, land-cover studies, and military and
strategic applications. However, the scarcity of labeled training examples and
spatial variability of spectral signature are two of the biggest challenges
faced by hyperspectral image classification. In order to address these issues,
we aim to develop a framework for material-agnostic information retrieval in
hyperspectral images based on Positive-Unlabelled (PU) classification. Given a
hyperspectral scene, the user labels some positive samples of a material he/she
is looking for and our goal is to retrieve all the remaining instances of the
query material in the scene. Additionally, we require the system to work
equally well for any material in any scene without the user having to disclose
the identity of the query material. This material-agnostic nature of the
framework provides it with superior generalization abilities. We explore two
alternative approaches to solve the hyperspectral image classification problem
within this framework. The first approach is an adaptation of non-negative risk
estimation based PU learning for hyperspectral data. The second approach is
based on one-versus-all positive-negative classification where the negative
class is approximately sampled using a novel spectral-spatial retrieval model.
We propose two annotator models - uniform and blob - that represent the
labelling patterns of a human annotator. We compare the performances of the
proposed algorithms for each annotator model on three benchmark hyperspectral
image datasets - Indian Pines, Pavia University and Salinas.
","Anirban Santara, Jayeeta Datta, Sourav Sarkar, Ankur Garg, Kirti Padia, Pabitra Mitra",Pabitra Mitra,2019-04-09T09:00:28Z
"Spatial gradient consistency for unsupervised learning of hyperspectral
  demosaicking: Application to surgical imaging","  Hyperspectral imaging has the potential to improve intraoperative decision
making if tissue characterisation is performed in real-time and with
high-resolution. Hyperspectral snapshot mosaic sensors offer a promising
approach due to their fast acquisition speed and compact size. However, a
demosaicking algorithm is required to fully recover the spatial and spectral
information of the snapshot images. Most state-of-the-art demosaicking
algorithms require ground-truth training data with paired snapshot and
high-resolution hyperspectral images, but such imagery pairs with the exact
same scene are physically impossible to acquire in intraoperative settings. In
this work, we present a fully unsupervised hyperspectral image demosaicking
algorithm which only requires exemplar snapshot images for training purposes.
We regard hyperspectral demosaicking as an ill-posed linear inverse problem
which we solve using a deep neural network. We take advantage of the spectral
correlation occurring in natural scenes to design a novel inter spectral band
regularisation term based on spatial gradient consistency. By combining our
proposed term with standard regularisation techniques and exploiting a standard
data fidelity term, we obtain an unsupervised loss function for training deep
neural networks, which allows us to achieve real-time hyperspectral image
demosaicking. Quantitative results on hyperspetral image datasets show that our
unsupervised demosaicking approach can achieve similar performance to its
supervised counter-part, and significantly outperform linear demosaicking. A
qualitative user study on real snapshot hyperspectral surgical images confirms
the results from the quantitative analysis. Our results suggest that the
proposed unsupervised algorithm can achieve promising hyperspectral
demosaicking in real-time thus advancing the suitability of the modality for
intraoperative use.
","Peichao Li, Muhammad Asad, Conor Horgan, Oscar MacCormac, Jonathan Shapey, Tom Vercauteren",Tom Vercauteren,2023-02-21T18:07:14Z
Hierarchical Markovian models for hyperspectral image segmentation,"  Hyperspectral images can be represented either as a set of images or as a set
of spectra. Spectral classification and segmentation and data reduction are the
main problems in hyperspectral image analysis. In this paper we propose a
Bayesian estimation approach with an appropriate hiearchical model with hidden
markovian variables which gives the possibility to jointly do data reduction,
spectral classification and image segmentation. In the proposed model, the
desired independent components are piecewise homogeneous images which share the
same common hidden segmentation variable. Thus, the joint Bayesian estimation
of this hidden variable as well as the sources and the mixing matrix of the
source separation problem gives a solution for all the three problems of
dimensionality reduction, spectra classification and segmentation of
hyperspectral images. A few simulation results illustrate the performances of
the proposed method compared to other classical methods usually used in
hyperspectral image processing.
","Ali Mohammad-Djafari, Adel Mohammadpoor, Nadia Bali",Nadia Bali,2007-05-17T00:35:36Z
Robust Hyperspectral Unmixing with Correntropy based Metric,"  Hyperspectral unmixing is one of the crucial steps for many hyperspectral
applications. The problem of hyperspectral unmixing has proven to be a
difficult task in unsupervised work settings where the endmembers and
abundances are both unknown. What is more, this task becomes more challenging
in the case that the spectral bands are degraded with noise. This paper
presents a robust model for unsupervised hyperspectral unmixing. Specifically,
our model is developed with the correntropy based metric where the non-negative
constraints on both endmembers and abundances are imposed to keep physical
significance. In addition, a sparsity prior is explicitly formulated to
constrain the distribution of the abundances of each endmember. To solve our
model, a half-quadratic optimization technique is developed to convert the
original complex optimization problem into an iteratively re-weighted NMF with
sparsity constraints. As a result, the optimization of our model can adaptively
assign small weights to noisy bands and give more emphasis on noise-free bands.
In addition, with sparsity constraints, our model can naturally generate sparse
abundances. Experiments on synthetic and real data demonstrate the
effectiveness of our model in comparison to the related state-of-the-art
unmixing models.
","Ying Wang, Chunhong Pan, Shiming Xiang, Feiyun Zhu",Feiyun Zhu,2013-05-31T06:43:31Z
Spectral Curve Fitting for Automatic Hyperspectral Data Analysis,"  Automatic discovery and curve fitting of absorption bands in hyperspectral
data can enable the analyst to identify materials present in a scene by
comparison with library spectra. This procedure is common in laboratory
spectra, but is challenging for sparse hyperspectral data. A procedure for
robust discovery of overlapping bands in hyperspectral data is described in
this paper. The method is capable of automatically discovering and fitting
symmetric absorption bands, can separate overlapping absorption bands in a
stable manner, and has relatively low sensitivity to noise. A comparison with
techniques already available in the literature is presented using simulated
spectra. An application is demonstrated utilizing the shortwave infrared
(2.0-2.5 micron or 5000-4000 cm-1) region. A small hyperspectral scene is
processed to demonstrate the ability of the method to detect small shifts in
absorption wavelength caused by varying white mica chemistry in a natural
setting.
",Adrian J. Brown,Adrian J. Brown,2014-01-22T06:03:06Z
Structured Sparse Method for Hyperspectral Unmixing,"  Hyperspectral Unmixing (HU) has received increasing attention in the past
decades due to its ability of unveiling information latent in hyperspectral
data. Unfortunately, most existing methods fail to take advantage of the
spatial information in data. To overcome this limitation, we propose a
Structured Sparse regularized Nonnegative Matrix Factorization (SS-NMF) method
from the following two aspects. First, we incorporate a graph Laplacian to
encode the manifold structures embedded in the hyperspectral data space. In
this way, the highly similar neighboring pixels can be grouped together.
Second, the lasso penalty is employed in SS-NMF for the fact that pixels in the
same manifold structure are sparsely mixed by a common set of relevant bases.
These two factors act as a new structured sparse constraint. With this
constraint, our method can learn a compact space, where highly similar pixels
are grouped to share correlated sparse representations. Experiments on real
hyperspectral data sets with different noise levels demonstrate that our method
outperforms the state-of-the-art methods significantly.
","Feiyun Zhu, Ying Wang, Shiming Xiang, Bin Fan, Chunhong Pan",Chunhong Pan,2014-03-19T03:23:30Z
Robust hyperspectral image classification with rejection fields,"  In this paper we present a novel method for robust hyperspectral image
classification using context and rejection. Hyperspectral image classification
is generally an ill-posed image problem where pixels may belong to unknown
classes, and obtaining representative and complete training sets is costly.
Furthermore, the need for high classification accuracies is frequently greater
than the need to classify the entire image.
  We approach this problem with a robust classification method that combines
classification with context with classification with rejection. A rejection
field that will guide the rejection is derived from the classification with
contextual information obtained by using the SegSALSA algorithm. We validate
our method in real hyperspectral data and show that the performance gains
obtained from the rejection fields are equivalent to an increase the dimension
of the training sets.
","Filipe Condessa, Jose Bioucas-Dias, Jelena Kovacevic",Jelena Kovacevic,2015-04-29T16:30:45Z
Hyperspectral Image Recovery via Hybrid Regularization,"  Natural images tend to mostly consist of smooth regions with individual
pixels having highly correlated spectra. This information can be exploited to
recover hyperspectral images of natural scenes from their incomplete and noisy
measurements. To perform the recovery while taking full advantage of the prior
knowledge, we formulate a composite cost function containing a square-error
data-fitting term and two distinct regularization terms pertaining to spatial
and spectral domains. The regularization for the spatial domain is the sum of
total-variation of the image frames corresponding to all spectral bands. The
regularization for the spectral domain is the l1-norm of the coefficient matrix
obtained by applying a suitable sparsifying transform to the spectra of the
pixels. We use an accelerated proximal-subgradient method to minimize the
formulated cost function. We analyze the performance of the proposed algorithm
and prove its convergence. Numerical simulations using real hyperspectral
images exhibit that the proposed algorithm offers an excellent recovery
performance with a number of measurements that is only a small fraction of the
hyperspectral image data size. Simulation results also show that the proposed
algorithm significantly outperforms an accelerated proximal-gradient algorithm
that solves the classical basis-pursuit denoising problem to recover the
hyperspectral image.
","Reza Arablouei, Frank de Hoog",Frank de Hoog,2015-11-09T23:31:31Z
"Scalable low dimensional manifold model in the reconstruction of noisy
  and incomplete hyperspectral images","  We present a scalable low dimensional manifold model for the reconstruction
of noisy and incomplete hyperspectral images. The model is based on the
observation that the spatial-spectral blocks of a hyperspectral image typically
lie close to a collection of low dimensional manifolds. To emphasize this, the
dimension of the manifold is directly used as a regularizer in a variational
functional, which is solved efficiently by alternating direction of
minimization and weighted nonlocal Laplacian. Unlike general 3D images, the
same similarity matrix can be shared across all spectral bands for a
hyperspectral image, therefore the resulting algorithm is much more scalable
than that for general 3D data. Numerical experiments on the reconstruction of
hyperspectral images from sparse and noisy sampling demonstrate the superiority
of our proposed algorithm in terms of both speed and accuracy.
","Wei Zhu, Zuoqiang Shi, Stanley Osher",Stanley Osher,2016-05-18T16:47:53Z
Hyperspectral Unmixing Based on Clustered Multitask Networks,"  Hyperspectral remote sensing is a prominent research topic in data
processing. Most of the spectral unmixing algorithms are developed by adopting
the linear mixing models. Nonnegative matrix factorization (NMF) and its
developments are used widely for estimation of signatures and fractional
abundances in the SU problem. Sparsity constraints was added to NMF, and was
regularized by $ L_ {q} $ norm. In this paper, at first hyperspectral images
are clustered by fuzzy c- means method, and then a new algorithm based on
sparsity constrained distributed optimization is used for spectral unmixing. In
the proposed algorithm, a network including clusters is employed. Each pixel in
the hyperspectral images considered as a node in this network. The proposed
algorithm is optimized with diffusion LMS strategy, and then the update
equations for fractional abundance and signature matrices are obtained.
Simulation results based on defined performance metrics illustrate advantage of
the proposed algorithm in spectral unmixing of hyperspectral data compared with
other methods.
","Sara Khoshsokhan, Roozbeh Rajabi, Hadi Zayyani",Hadi Zayyani,2018-12-27T18:31:25Z
Hyperspectral Calibration of Art: Acquisition and Calibration Workflows,"  Hyperspectral imaging has become an increasingly used tool in the analysis of
works of art. However, the quality of the acquired data and the processing of
that data to produce accurate and reproducible spectral image cubes can be a
challenge to many cultural heritage users. The calibration of data that is both
spectrally and spatially accurate is an essential step in order to obtain
useful and relevant results from hyperspectral imaging. Data that is too noisy
or inaccurate will produce sub-optimal results when used for pigment mapping,
the detection of hidden features, change detection or for quantitative spectral
documentation. To help address this, therefore, we will examine the specific
acquisition and calibration workflows necessary for works of art. These
workflows includes the key parameters that must be addressed during acquisition
and the essential steps and issues at each of the stages required during
post-processing in order to fully calibrate hyperspectral data. In addition we
will look in detail at the key issues that affect data quality and propose
practical solutions that can make significant differences to overall
hyperspectral image quality.
","Ruven Pillay, Jon Y Hardeberg, Sony George",Sony George,2019-03-11T23:23:45Z
"Deep Learning for Classification of Hyperspectral Data: A Comparative
  Review","  In recent years, deep learning techniques revolutionized the way remote
sensing data are processed. Classification of hyperspectral data is no
exception to the rule, but has intrinsic specificities which make application
of deep learning less straightforward than with other optical data. This
article presents a state of the art of previous machine learning approaches,
reviews the various deep learning approaches currently proposed for
hyperspectral classification, and identifies the problems and difficulties
which arise to implement deep neural networks for this task. In particular, the
issues of spatial and spectral resolution, data volume, and transfer of models
from multimedia images to hyperspectral data are addressed. Additionally, a
comparative study of various families of network architectures is provided and
a software toolbox is publicly released to allow experimenting with these
methods. 1 This article is intended for both data scientists with interest in
hyperspectral data and remote sensing experts eager to apply deep learning
techniques to their own dataset.
","Nicolas Audebert, Bertrand Saux, Sébastien Lefèvre",Sébastien Lefèvre,2019-04-24T07:56:37Z
"Self-supervised spectral matching network for hyperspectral target
  detection","  Hyperspectral target detection is a pixel-level recognition problem. Given a
few target samples, it aims to identify the specific target pixels such as
airplane, vehicle, ship, from the entire hyperspectral image. In general, the
background pixels take the majority of the image and complexly distributed. As
a result, the datasets are weak annotated and extremely imbalanced. To address
these problems, a spectral mixing based self-supervised paradigm is designed
for hyperspectral data to obtain an effective feature representation. The model
adopts a spectral similarity based matching network framework. In order to
learn more discriminative features, a pair-based loss is adopted to minimize
the distance between target pixels while maximizing the distances between
target and background. Furthermore, through a background separated step, the
complex unlabeled spectra are downsampled into different sub-categories. The
experimental results on three real hyperspectral datasets demonstrate that the
proposed framework achieves better results compared with the existing
detectors.
","Can Yao, Yuan Yuan, Zhiyu Jiang",Zhiyu Jiang,2021-05-10T02:32:58Z
Deep-learning-based Hyperspectral imaging through a RGB camera,"  Hyperspectral image (HSI) contains both spatial pattern and spectral
information which has been widely used in food safety, remote sensing, and
medical detection. However, the acquisition of hyperspectral images is usually
costly due to the complicated apparatus for the acquisition of optical
spectrum. Recently, it has been reported that HSI can be reconstructed from
single RGB image using convolution neural network (CNN) algorithms. Compared
with the traditional hyperspectral cameras, the method based on CNN algorithms
is simple, portable and low cost. In this study, we focused on the influence of
the RGB camera spectral sensitivity (CSS) on the HSI. A Xenon lamp incorporated
with a monochromator were used as the standard light source to calibrate the
CSS. And the experimental results show that the CSS plays a significant role in
the reconstruction accuracy of an HSI. In addition, we proposed a new HSI
reconstruction network where the dimensional structure of the original
hyperspectral datacube was modified by 3D matrix transpose to improve the
reconstruction accuracy.
","Xinyu Gao, Tianlang Wang, Jing Yang, Jinchao Tao, Yanqing Qiu, Yanlong Meng, Banging Mao, Pengwei Zhou, Yi Li",Yi Li,2021-07-12T04:23:25Z
"Hyperspectral image unmixing with LiDAR data-aided spatial
  regularization","  Spectral unmixing methods incorporating spatial regularizations have
demonstrated increasing interest. Although spatial regularizers which promote
smoothness of the abundance maps have been widely used, they may overly smooth
these maps and, in particular, may not preserve edges present in the
hyperspectral image. Existing unmixing methods usually ignore these edge
structures or use edge information derived from the hyperspectral image itself.
However, this information may be affected by large amounts of noise or
variations in illumination, leading to erroneous spatial information
incorporated into the unmixing procedure. This paper proposes a simple, yet
powerful, spectral unmixing framework which incorporates external data (i.e.
LiDAR data). The LiDAR measurements can be easily exploited to adjust standard
spatial regularizations applied to the unmixing process. The proposed framework
is rigorously evaluated using two simulated datasets and a real hyperspectral
image. It is compared with competing methods that rely on spatial information
derived from a hyperspectral image. The results show that the proposed
framework can provide better abundance estimates and, more specifically, can
significantly improve the abundance estimates for pixels affected by shadows.
","Tatsumi Uezato, Mathieu Fauvel, Nicolas Dobigeon",Nicolas Dobigeon,2017-12-21T10:33:32Z
"Fusion of hyperspectral and ground penetrating radar to estimate soil
  moisture","  In this contribution, we investigate the potential of hyperspectral data
combined with either simulated ground penetrating radar (GPR) or simulated
(sensor-like) soil-moisture data to estimate soil moisture. We propose two
simulation approaches to extend a given multi-sensor dataset which contains
sparse GPR data. In the first approach, simulated GPR data is generated either
by an interpolation along the time axis or by a machine learning model. The
second approach includes the simulation of soil-moisture along the GPR profile.
The soil-moisture estimation is improved significantly by the fusion of
hyperspectral and GPR data. In contrast, the combination of simulated,
sensor-like soil-moisture values and hyperspectral data achieves the worst
regression performance. In conclusion, the estimation of soil moisture with
hyperspectral and GPR data engages further investigations.
","Felix M. Riese, Sina Keller",Sina Keller,2018-04-14T20:51:54Z
"Multitask Deep Learning with Spectral Knowledge for Hyperspectral Image
  Classification","  In this letter, we propose a multitask deep learning method for
classification of multiple hyperspectral data in a single training. Deep
learning models have achieved promising results on hyperspectral image
classification, but their performance highly rely on sufficient labeled
samples, which are scarce on hyperspectral images. However, samples from
multiple data sets might be sufficient to train one deep learning model,
thereby improving its performance. To do so, we trained an identical feature
extractor for all data, and the extracted features were fed into corresponding
Softmax classifiers. Spectral knowledge was introduced to ensure that the
shared features were similar across domains. Four hyperspectral data sets were
used in the experiments. We achieved higher classification accuracies on three
data sets (Pavia University, Pavia Center, and Indian Pines) and competitive
results on the Salinas Valley data compared with the baseline. Spectral
knowledge was useful to prevent the deep network from overfitting when the data
shared similar spectral response. The proposed method tested on two deep CNNs
successfully shows its ability to utilize samples from multiple data sets and
enhance networks' performance.
","Shengjie Liu, Qian Shi",Qian Shi,2019-05-11T14:50:34Z
"HyperFaceNet: A Hyperspectral Face Recognition Method Based on Deep
  Fusion","  Face recognition has already been well studied under the visible light and
the infrared,in both intra-spectral and cross-spectral cases. However, how to
fuse different light bands, i.e., hyperspectral face recognition, is still an
open research problem, which has the advantages of richer information retaining
and all-weather functionality over single band face recognition. Among the very
few works for hyperspectral face recognition, traditional non-deep learning
techniques are largely used. Thus, we in this paper bring deep learning into
the topic of hyperspectral face recognition, and propose a new fusion model
(termed HyperFaceNet) especially for hyperspectral faces. The proposed fusion
model is characterized by residual dense learning, a feedback style encoder and
a recognition-oriented loss function. During the experiments, our method is
proved to be of higher recognition rates than face recognition using either
visible light or the infrared. Moreover, our fusion model is shown to be
superior to other general-purposed image fusion methods including
state-of-the-arts, in terms of both image quality and recognition performance.
","Zhicheng Cao, Xi Cen, Liaojun Pang",Liaojun Pang,2020-08-02T14:59:24Z
"Kernel Extreme Learning Machine Optimized by the Sparrow Search
  Algorithm for Hyperspectral Image Classification","  To improve the classification performance and generalization ability of the
hyperspectral image classification algorithm, this paper uses Multi-Scale Total
Variation (MSTV) to extract the spectral features, local binary pattern (LBP)
to extract spatial features, and feature superposition to obtain the fused
features of hyperspectral images. A new swarm intelligence optimization method
with high convergence and strong global search capability, the Sparrow Search
Algorithm (SSA), is used to optimize the kernel parameters and regularization
coefficients of the Kernel Extreme Learning Machine (KELM). In summary, a
multiscale fusion feature hyperspectral image classification method (MLS-KELM)
is proposed in this paper. The Indian Pines, Pavia University and Houston 2013
datasets were selected to validate the classification performance of MLS-KELM,
and the method was applied to ZY1-02D hyperspectral data. The experimental
results show that MLS-KELM has better classification performance and
generalization ability compared with other popular classification methods, and
MLS-KELM shows its strong robustness in the small sample case.
","Zhixin Yan, Jiawei Huang, Kehua Xiang",Kehua Xiang,2022-04-03T02:46:36Z
Active Deep Learning for Classification of Hyperspectral Images,"  Active deep learning classification of hyperspectral images is considered in
this paper. Deep learning has achieved success in many applications, but
good-quality labeled samples are needed to construct a deep learning network.
It is expensive getting good labeled samples in hyperspectral images for remote
sensing applications. An active learning algorithm based on a weighted
incremental dictionary learning is proposed for such applications. The proposed
algorithm selects training samples that maximize two selection criteria, namely
representative and uncertainty. This algorithm trains a deep network
efficiently by actively selecting training samples at each iteration. The
proposed algorithm is applied for the classification of hyperspectral images,
and compared with other classification algorithms employing active learning. It
is shown that the proposed algorithm is efficient and effective in classifying
hyperspectral images.
","Peng Liu, Hui Zhang, Kie B. Eom",Kie B. Eom,2016-11-30T07:34:46Z
Hyperspectral recovery from RGB images using Gaussian Processes,"  We propose to recover spectral details from RGB images of known spectral
quantization by modeling natural spectra under Gaussian Processes and combining
them with the RGB images. Our technique exploits Process Kernels to model the
relative smoothness of reflectance spectra, and encourages non-negativity in
the resulting signals for better estimation of the reflectance values. The
Gaussian Processes are inferred in sets using clusters of spatio-spectrally
correlated hyperspectral training patches. Each set is transformed to match the
spectral quantization of the test RGB image. We extract overlapping patches
from the RGB image and match them to the hyperspectral training patches by
spectrally transforming the latter. The RGB patches are encoded over the
transformed Gaussian Processes related to those hyperspectral patches and the
resulting image is constructed by combining the codes with the original
Processes. Our approach infers the desired Gaussian Processes under a fully
Bayesian model inspired by Beta-Bernoulli Process, for which we also present
the inference procedure. A thorough evaluation using three hyperspectral
datasets demonstrates the effective extraction of spectral details from RGB
images by the proposed technique.
","Naveed Akhtar, Ajmal Mian",Ajmal Mian,2018-01-15T03:26:09Z
"KRISM --- Krylov Subspace-based Optical Computing of Hyperspectral
  Images","  We present an adaptive imaging technique that optically computes a low-rank
approximation of a scene's hyperspectral image, conceptualized as a matrix.
Central to the proposed technique is the optical implementation of two
measurement operators: a spectrally-coded imager and a spatially-coded
spectrometer. By iterating between the two operators, we show that the top
singular vectors and singular values of a hyperspectral image can be adaptively
and optically computed with only a few iterations. We present an optical design
that uses pupil plane coding for implementing the two operations and show
several compelling results using a lab prototype to demonstrate the
effectiveness of the proposed hyperspectral imager.
","Vishwanath Saragadam, Aswin C. Sankaranarayanan",Aswin C. Sankaranarayanan,2018-01-26T12:10:38Z
"Accurate Spectral Super-resolution from Single RGB Image Using
  Multi-scale CNN","  Different from traditional hyperspectral super-resolution approaches that
focus on improving the spatial resolution, spectral super-resolution aims at
producing a high-resolution hyperspectral image from the RGB observation with
super-resolution in spectral domain. However, it is challenging to accurately
reconstruct a high-dimensional continuous spectrum from three discrete
intensity values at each pixel, since too much information is lost during the
procedure where the latent hyperspectral image is downsampled (e.g., with x10
scaling factor) in spectral domain to produce an RGB observation. To address
this problem, we present a multi-scale deep convolutional neural network (CNN)
to explicitly map the input RGB image into a hyperspectral image. Through
symmetrically downsampling and upsampling the intermediate feature maps in a
cascading paradigm, the local and non-local image information can be jointly
encoded for spectral representation, ultimately improving the spectral
reconstruction accuracy. Extensive experiments on a large hyperspectral dataset
demonstrate the effectiveness of the proposed method.
","Yiqi Yan, Lei Zhang, Jun Li, Wei Wei, Yanning Zhang",Yanning Zhang,2018-06-10T02:32:02Z
"Snapshot hyperspectral imaging via spectral basis multiplexing in
  Fourier domain","  Hyperspectral imaging is an important tool having been applied in various
fields, but still limited in observation of dynamic scenes. In this paper, we
propose a snapshot hyperspectral imaging technique which exploits both spectral
and spatial sparsity of natural scenes. Under the computational imaging scheme,
we conduct spectral dimension reduction and spatial frequency truncation to the
hyperspectral data cube and snapshot it in a low cost manner. Specifically, we
modulate the spectral variations by several broadband spectral filters, and
then map these modulated images into different regions in the Fourier domain.
The encoded image compressed in both spectral and spatial are finally collected
by a monochrome detector. Correspondingly, the reconstruction is essentially a
Fourier domain extraction and spectral dimensional back projection with low
computational load. This Fourier-spectral multiplexing in a 2D sensor
simplifies both the encoding and decoding process, and makes hyperspectral data
captured in a low cost manner. We demonstrate the high performance of our
method by quantitative evaluation on simulation data and build a prototype
system experimentally for further validation.
","Chao Deng, Xuemei Hu, Jinli Suo, Yuanlong Zhang, Zhili Zhang, Qionghai Dai",Qionghai Dai,2018-05-22T03:23:04Z
"Hyperspectral Images Classification Based on Multi-scale Residual
  Network","  Because hyperspectral remote sensing images contain a lot of redundant
information and the data structure is highly non-linear, leading to low
classification accuracy of traditional machine learning methods. The latest
research shows that hyperspectral image classification based on deep
convolutional neural network has high accuracy. However, when a small amount of
data is used for training, the classification accuracy of deep learning methods
is greatly reduced. In order to solve the problem of low classification
accuracy of existing algorithms on small samples of hyperspectral images, a
multi-scale residual network is proposed. The multi-scale extraction and fusion
of spatial and spectral features is realized by adding a branch structure into
the residual block and using convolution kernels of different sizes in the
branch. The spatial and spectral information contained in hyperspectral images
are fully utilized to improve the classification accuracy. In addition, in
order to improve the speed and prevent overfitting, the model uses dynamic
learning rate, BN and Dropout strategies. The experimental results show that
the overall classification accuracy of this method is 99.07% and 99.96%
respectively in the data set of Indian Pines and Pavia University, which is
better than other algorithms.
","Xiangdong Zhang, Tengjun Wang, Yun Yang",Yun Yang,2020-04-26T13:46:52Z
"TPPI-Net: Towards Efficient and Practical Hyperspectral Image
  Classification","  Hyperspectral Image(HSI) classification is the most vibrant field of research
in the hyperspectral community, which aims to assign each pixel in the image to
one certain category based on its spectral-spatial characteristics. Recently,
some spectral-spatial-feature based DCNNs have been proposed and demonstrated
remarkable classification performance. When facing a real HSI, however, these
Networks have to deal with the pixels in the image one by one. The pixel-wise
processing strategy is inefficient since there are numerous repeated
calculations between adjacent pixels. In this paper, firstly, a brand new
Network design mechanism TPPI (training based on pixel and prediction based on
image) is proposed for HSI classification, which makes it possible to provide
efficient and practical HSI classification with the restrictive conditions
attached to the hyperspectral dataset. And then, according to the TPPI
mechanism, TPPI-Net is derived based on the state of the art networks for HSI
classification. Experimental results show that the proposed TPPI-Net can not
only obtain high classification accuracy equivalent to the state of the art
networks for HSI classification, but also greatly reduce the computational
complexity of hyperspectral image prediction.
","Hao Chen, Xiaohua Li, Jiliu Zhou",Jiliu Zhou,2021-03-18T08:35:37Z
"Fusformer: A Transformer-based Fusion Approach for Hyperspectral Image
  Super-resolution","  Hyperspectral image has become increasingly crucial due to its abundant
spectral information. However, It has poor spatial resolution with the
limitation of the current imaging mechanism. Nowadays, many convolutional
neural networks have been proposed for the hyperspectral image super-resolution
problem. However, convolutional neural network (CNN) based methods only
consider the local information instead of the global one with the limited
kernel size of receptive field in the convolution operation. In this paper, we
design a network based on the transformer for fusing the low-resolution
hyperspectral images and high-resolution multispectral images to obtain the
high-resolution hyperspectral images. Thanks to the representing ability of the
transformer, our approach is able to explore the intrinsic relationships of
features globally. Furthermore, considering the LR-HSIs hold the main spectral
structure, the network focuses on the spatial detail estimation releasing from
the burden of reconstructing the whole data. It reduces the mapping space of
the proposed network, which enhances the final performance. Various experiments
and quality indexes show our approach's superiority compared with other
state-of-the-art methods.
","Jin-Fan Hu, Ting-Zhu Huang, Liang-Jian Deng",Liang-Jian Deng,2021-09-05T14:00:34Z
"Hyperspectral Mixed Noise Removal via Subspace Representation and
  Weighted Low-rank Tensor Regularization","  Recently, the low-rank property of different components extracted from the
image has been considered in man hyperspectral image denoising methods.
However, these methods usually unfold the 3D tensor to 2D matrix or 1D vector
to exploit the prior information, such as nonlocal spatial self-similarity
(NSS) and global spectral correlation (GSC), which break the intrinsic
structure correlation of hyperspectral image (HSI) and thus lead to poor
restoration quality. In addition, most of them suffer from heavy computational
burden issues due to the involvement of singular value decomposition operation
on matrix and tensor in the original high-dimensionality space of HSI. We
employ subspace representation and the weighted low-rank tensor regularization
(SWLRTR) into the model to remove the mixed noise in the hyperspectral image.
Specifically, to employ the GSC among spectral bands, the noisy HSI is
projected into a low-dimensional subspace which simplified calculation. After
that, a weighted low-rank tensor regularization term is introduced to
characterize the priors in the reduced image subspace. Moreover, we design an
algorithm based on alternating minimization to solve the nonconvex problem.
Experiments on simulated and real datasets demonstrate that the SWLRTR method
performs better than other hyperspectral denoising methods quantitatively and
visually.
","Hang Zhou, Yanchi Su, Zhanshan Li",Zhanshan Li,2021-11-13T05:30:56Z
Large-Scale Hyperspectral Image Clustering Using Contrastive Learning,"  Clustering of hyperspectral images is a fundamental but challenging task. The
recent development of hyperspectral image clustering has evolved from shallow
models to deep and achieved promising results in many benchmark datasets.
However, their poor scalability, robustness, and generalization ability, mainly
resulting from their offline clustering scenarios, greatly limit their
application to large-scale hyperspectral data. To circumvent these problems, we
present a scalable deep online clustering model, named Spectral-Spatial
Contrastive Clustering (SSCC), based on self-supervised learning. Specifically,
we exploit a symmetric twin neural network comprised of a projection head with
a dimensionality of the cluster number to conduct dual contrastive learning
from a spectral-spatial augmentation pool. We define the objective function by
implicitly encouraging within-cluster similarity and reducing between-cluster
redundancy. The resulting approach is trained in an end-to-end fashion by
batch-wise optimization, making it robust in large-scale data and resulting in
good generalization ability for unseen data. Extensive experiments on three
hyperspectral image benchmarks demonstrate the effectiveness of our approach
and show that we advance the state-of-the-art approaches by large margins.
","Yaoming Cai, Zijia Zhang, Yan Liu, Pedram Ghamisi, Kun Li, Xiaobo Liu, Zhihua Cai",Zhihua Cai,2021-11-15T17:50:06Z
Hyperspectral Imaging for cherry tomato,"  Cherry tomato (Solanum Lycopersicum) is popular with consumers over the world
due to its special flavor. Soluble solids content (SSC) and firmness are two
key metrics for evaluating the product qualities. In this work, we develop
non-destructive testing techniques for SSC and fruit firmness based on
hyperspectral images and a corresponding deep learning regression model.
Hyperspectral reflectance images of over 200 tomato fruits are derived with
spectrum ranging from 400 to 1000 nm. The acquired hyperspectral images are
corrected and the spectral information is extracted. A novel
one-dimensional(1D) convolutional ResNet (Con1dResNet) based regression model
is prosed and compared with the state of art techniques. Experimental results
show that, with a relatively large number of samples our technique is 26.4\%
better than state of art technique for SSC and 33.7\% for firmness. The results
of this study indicate the application potential of hyperspectral imaging
technique in the SSC and firmness detection, which provides a new option for
non-destructive testing of cherry tomato fruit quality in the future.
","Yun Xiang, Qijun Chen, Zhongjin Su, Lu Zhang, Zuohui Chen, Guozhi Zhou, Zhuping Yao, Qi Xuan, Yuan Cheng",Yuan Cheng,2022-03-10T07:21:50Z
"Hyperspectral Unmixing Based on Nonnegative Matrix Factorization: A
  Comprehensive Review","  Hyperspectral unmixing has been an important technique that estimates a set
of endmembers and their corresponding abundances from a hyperspectral image
(HSI). Nonnegative matrix factorization (NMF) plays an increasingly significant
role in solving this problem. In this article, we present a comprehensive
survey of the NMF-based methods proposed for hyperspectral unmixing. Taking the
NMF model as a baseline, we show how to improve NMF by utilizing the main
properties of HSIs (e.g., spectral, spatial, and structural information). We
categorize three important development directions including constrained NMF,
structured NMF, and generalized NMF. Furthermore, several experiments are
conducted to illustrate the effectiveness of associated algorithms. Finally, we
conclude the article with possible future directions with the purposes of
providing guidelines and inspiration to promote the development of
hyperspectral unmixing.
","Xin-Ru Feng, Heng-Chao Li, Rui Wang, Qian Du, Xiuping Jia, Antonio Plaza",Antonio Plaza,2022-05-20T02:48:43Z
Wavelength-aware 2D Convolutions for Hyperspectral Imaging,"  Deep Learning could drastically boost the classification accuracy for
Hyperspectral Imaging (HSI). Still, the training on the mostly small
hyperspectral data sets is not trivial. Two key challenges are the large
channel dimension of the recordings and the incompatibility between cameras of
different manufacturers. By introducing a suitable model bias and continuously
defining the channel dimension, we propose a 2D convolution optimized for these
challenges of Hyperspectral Imaging. We evaluate the method based on two
different hyperspectral applications (inline inspection and remote sensing).
Besides the shown superiority of the model, the modification adds additional
explanatory power. In addition, the model learns the necessary camera filters
in a data-driven manner. Based on these camera filters, an optimal camera can
be designed.
","Leon Amadeus Varga, Martin Messmer, Nuri Benbarka, Andreas Zell",Andreas Zell,2022-09-05T12:19:27Z
"Unsupervised hyperspectral data mining and bioimaging by information
  entropy and self-modeling curve resolution","  Unsupervised estimation of the dimensionality of hyperspectral
microspectroscopy datasets containing pure and mixed spectral features, and
extraction of their representative endmember spectra, remains a challenge in
biochemical data mining. We report a new versatile algorithm building on
semi-nonnegativity constrained self-modeling curve resolution and information
entropy, to estimate the quantity of separable biochemical species from
hyperspectral microspectroscopy, and extraction of their representative
spectra. The algorithm is benchmarked with established methods from satellite
remote sensing, spectral unmixing, and clustering. To demonstrate the
widespread applicability of the developed algorithm, we collected hyperspectral
datasets using spontaneous Raman, Coherent Anti-stokes Raman Scattering and
Fourier Transform IR, of seven reference compounds, an oil-in-water emulsion,
and tissue-engineered extracellular matrices on poly-L-lactic acid and porcine
jejunum-derived small intestine submucosa scaffolds seeded with bovine
chondrocytes. We show the potential of the developed algorithm by consolidating
hyperspectral molecular information with sample microstructure, pertinent to
fields ranging from gastrophysics to regenerative medicine.
","Simon Vilms Pedersen, Anders R. Walther, Anthony Callanan, Molly M. Stevens, Martin A. B. Hedegaard, Eva C. Arnspang",Eva C. Arnspang,2022-10-06T22:25:11Z
"New wrapper method based on normalized mutual information for dimension
  reduction and classification of hyperspectral images","  Feature selection is one of the most important problems in hyperspectral
images classification. It consists to choose the most informative bands from
the entire set of input datasets and discard the noisy, redundant and
irrelevant ones. In this context, we propose a new wrapper method based on
normalized mutual information (NMI) and error probability (PE) using support
vector machine (SVM) to reduce the dimensionality of the used hyperspectral
images and increase the classification efficiency. The experiments have been
performed on two challenging hyperspectral benchmarks datasets captured by the
NASA's Airborne Visible/Infrared Imaging Spectrometer Sensor (AVIRIS). Several
metrics had been calculated to evaluate the performance of the proposed
algorithm. The obtained results prove that our method can increase the
classification performance and provide an accurate thematic map in comparison
with other reproduced algorithms. This method may be improved for more
classification efficiency. Keywords-Feature selection, hyperspectral images,
classification, wrapper, normalized mutual information, support vector machine.
","Hasna Nhaila, Asma Elmaizi, Elkebir Sarhrouni, Ahmed Hammouch",Ahmed Hammouch,2022-10-25T21:17:11Z
"A Survey on Fundamental Concepts and Practical Challenges of
  Hyperspectral images","  The Remote sensing provides a synoptic view of land by detecting the energy
reflected from Earth's surface. The Hyperspectral images (HSI) use perfect
sensors that extract more than a hundred of images, with more detailed
information than using traditional Multispectral data. In this paper, we aim to
study this aspect of communication in the case of passive reception. First, a
brief overview of acquisition process and treatment of Hyperspectral images is
provided. Then, we explain representation spaces and the various analysis
methods of these images. Furthermore, the factors influencing this analysis are
investigated and some applications, in this area, are presented. Finally, we
explain the relationship between Hyperspectral images and Datamining and we
outline the open issues related to this area. So we consider the case study:
HSI AVIRIS 92AV3C. This study serves as map of route for integrating
classification methods in the higher dimensionality data.
  Keywords-component: Hyperspectral images, Passive Sensing,Classification,
Data mining.
","Hasna Nhaila, Elkebir Sarhrouni, Ahmed Hammouch",Ahmed Hammouch,2022-10-25T23:52:14Z
Hyperspectral Image Compression Using Implicit Neural Representation,"  Hyperspectral images, which record the electromagnetic spectrum for a pixel
in the image of a scene, often store hundreds of channels per pixel and contain
an order of magnitude more information than a typical similarly-sized color
image. Consequently, concomitant with the decreasing cost of capturing these
images, there is a need to develop efficient techniques for storing,
transmitting, and analyzing hyperspectral images. This paper develops a method
for hyperspectral image compression using implicit neural representations where
a multilayer perceptron network $\Phi_\theta$ with sinusoidal activation
functions ``learns'' to map pixel locations to pixel intensities for a given
hyperspectral image $I$. $\Phi_\theta$ thus acts as a compressed encoding of
this image. The original image is reconstructed by evaluating $\Phi_\theta$ at
each pixel location. We have evaluated our method on four benchmarks -- Indian
Pines, Cuprite, Pavia University, and Jasper Ridge -- and we show the proposed
method achieves better compression than JPEG, JPEG2000, and PCA-DCT at low
bitrates.
","Shima Rezasoltani, Faisal Z. Qureshi",Faisal Z. Qureshi,2023-02-08T15:27:00Z
"MultiScale Spectral-Spatial Convolutional Transformer for Hyperspectral
  Image Classification","  Due to the powerful ability in capturing the global information, Transformer
has become an alternative architecture of CNNs for hyperspectral image
classification. However, general Transformer mainly considers the global
spectral information while ignores the multiscale spatial information of the
hyperspectral image. In this paper, we propose a multiscale spectral-spatial
convolutional Transformer (MultiscaleFormer) for hyperspectral image
classification. First, the developed method utilizes multiscale spatial patches
as tokens to formulate the spatial Transformer and generates multiscale spatial
representation of each band in each pixel. Second, the spatial representation
of all the bands in a given pixel are utilized as tokens to formulate the
spectral Transformer and generate the multiscale spectral-spatial
representation of each pixel. Besides, a modified spectral-spatial CAF module
is constructed in the MultiFormer to fuse cross-layer spectral and spatial
information. Therefore, the proposed MultiFormer can capture the multiscale
spectral-spatial information and provide better performance than most of other
architectures for hyperspectral image classification. Experiments are conducted
over commonly used real-world datasets and the comparison results show the
superiority of the proposed method.
","Zhiqiang Gong, Xian Zhou, Wen Yao",Wen Yao,2023-10-28T00:41:35Z
"Cross-Scope Spatial-Spectral Information Aggregation for Hyperspectral
  Image Super-Resolution","  Hyperspectral image super-resolution has attained widespread prominence to
enhance the spatial resolution of hyperspectral images. However,
convolution-based methods have encountered challenges in harnessing the global
spatial-spectral information. The prevailing transformer-based methods have not
adequately captured the long-range dependencies in both spectral and spatial
dimensions. To alleviate this issue, we propose a novel cross-scope
spatial-spectral Transformer (CST) to efficiently investigate long-range
spatial and spectral similarities for single hyperspectral image
super-resolution. Specifically, we devise cross-attention mechanisms in spatial
and spectral dimensions to comprehensively model the long-range
spatial-spectral characteristics. By integrating global information into the
rectangle-window self-attention, we first design a cross-scope spatial
self-attention to facilitate long-range spatial interactions. Then, by
leveraging appropriately characteristic spatial-spectral features, we construct
a cross-scope spectral self-attention to effectively capture the intrinsic
correlations among global spectral bands. Finally, we elaborate a concise
feed-forward neural network to enhance the feature representation capacity in
the Transformer structure. Extensive experiments over three hyperspectral
datasets demonstrate that the proposed CST is superior to other
state-of-the-art methods both quantitatively and visually. The code is
available at \url{https://github.com/Tomchenshi/CST.git}.
","Shi Chen, Lefei Zhang, Liangpei Zhang",Liangpei Zhang,2023-11-29T03:38:56Z
"A Comparative Study of Compressive Sensing Algorithms for Hyperspectral
  Imaging Reconstruction","  Hyperspectral Imaging comprises excessive data consequently leading to
significant challenges for data processing, storage and transmission.
Compressive Sensing has been used in the field of Hyperspectral Imaging as a
technique to compress the large amount of data. This work addresses the
recovery of hyperspectral images 2.5x compressed. A comparative study in terms
of the accuracy and the performance of the convex FISTA/ADMM in addition to the
greedy gOMP/BIHT/CoSaMP recovery algorithms is presented. The results indicate
that the algorithms recover successfully the compressed data, yet the gOMP
algorithm achieves superior accuracy and faster recovery in comparison to the
other algorithms at the expense of high dependence on unknown sparsity level of
the data to recover.
","Jon Alvarez Justo, Daniela Lupu, Milica Orlandic, Ion Necoara, Tor Arne Johansen",Tor Arne Johansen,2024-01-26T10:38:39Z
"Randomized Principal Component Analysis for Hyperspectral Image
  Classification","  The high-dimensional feature space of the hyperspectral imagery poses major
challenges to the processing and analysis of the hyperspectral data sets. In
such a case, dimensionality reduction is necessary to decrease the
computational complexity. The random projections open up new ways of
dimensionality reduction, especially for large data sets. In this paper, the
principal component analysis (PCA) and randomized principal component analysis
(R-PCA) for the classification of hyperspectral images using support vector
machines (SVM) and light gradient boosting machines (LightGBM) have been
investigated. In this experimental research, the number of features was reduced
to 20 and 30 for classification of two hyperspectral datasets (Indian Pines and
Pavia University). The experimental results demonstrated that PCA outperformed
R-PCA for SVM for both datasets, but received close accuracy values for
LightGBM. The highest classification accuracies were obtained as 0.9925 and
0.9639 by LightGBM with original features for the Pavia University and Indian
Pines, respectively.
",Mustafa Ustuner,Mustafa Ustuner,2024-03-14T05:40:23Z
Contrastive Learning for Regression on Hyperspectral Data,"  Contrastive learning has demonstrated great effectiveness in representation
learning especially for image classification tasks. However, there is still a
shortage in the studies targeting regression tasks, and more specifically
applications on hyperspectral data. In this paper, we propose a contrastive
learning framework for the regression tasks for hyperspectral data. To this
end, we provide a collection of transformations relevant for augmenting
hyperspectral data, and investigate contrastive learning for regression.
Experiments on synthetic and real hyperspectral datasets show that the proposed
framework and transformations significantly improve the performance of
regression models, achieving better scores than other state-of-the-art
transformations.
","Mohamad Dhaini, Maxime Berar, Paul Honeine, Antonin Van Exem",Antonin Van Exem,2024-02-12T21:33:46Z
Pansharpening of PRISMA products for archaeological prospection,"  Hyperspectral data recorded from satellite platforms are often ill-suited for
geo-archaeological prospection due to low spatial resolution. The established
potential of hyperspectral data from airborne sensors in identifying
archaeological features has, on the other side, generated increased interest in
enhancing hyperspectral data to achieve higher spatial resolution. This
improvement is crucial for detecting traces linked to sub-surface
geo-archaeological features and can make satellite hyperspectral acquisitions
more suitable for archaeological research. This research assesses the usability
of pansharpened PRISMA satellite products in geo-archaeological prospections.
Three pan-sharpening methods (GSA, MTF-GLP and HySure) are compared
quantitatively and qualitatively and tested over the archaeological landscape
of Aquileia (Italy). The results suggest that the application of pansharpening
techniques makes hyperspectral satellite imagery highly suitable, under certain
conditions, to the identification of sub-surface archaeological features of
small and large size.
","Gregory Sech, Giulio Poggi, Marina Ljubenovic, Marco Fiorucci, Arianna Traviglia",Arianna Traviglia,2024-04-08T12:29:46Z
"Onboard Processing of Hyperspectral Imagery: Deep Learning Advancements,
  Methodologies, Challenges, and Emerging Trends","  Recent advancements in deep learning techniques have spurred considerable
interest in their application to hyperspectral imagery processing. This paper
provides a comprehensive review of the latest developments in this field,
focusing on methodologies, challenges, and emerging trends. Deep learning
architectures such as Convolutional Neural Networks (CNNs), Autoencoders, Deep
Belief Networks (DBNs), Generative Adversarial Networks (GANs), and Recurrent
Neural Networks (RNNs) are examined for their suitability in processing
hyperspectral data. Key challenges, including limited training data and
computational constraints, are identified, along with strategies such as data
augmentation and noise reduction using GANs. The paper discusses the efficacy
of different network architectures, highlighting the advantages of lightweight
CNN models and 1D CNNs for onboard processing. Moreover, the potential of
hardware accelerators, particularly Field Programmable Gate Arrays (FPGAs), for
enhancing processing efficiency is explored. The review concludes with insights
into ongoing research trends, including the integration of deep learning
techniques into Earth observation missions such as the CHIME mission, and
emphasizes the need for further exploration and refinement of deep learning
methodologies to address the evolving demands of hyperspectral image
processing.
","Nafiseh Ghasemi, Jon Alvarez Justo, Marco Celesti, Laurent Despoisse, Jens Nieke",Jens Nieke,2024-04-09T14:32:39Z
"Implementing Hottopixx Methods for Endmember Extraction in Hyperspectral
  Images","  Hyperspectral imaging technology has a wide range of applications, including
forest management, mineral resource exploration, and Earth surface monitoring.
Endmember extraction of hyperspectral images is a key step in leveraging this
technology for applications. It aims to identifying the spectral signatures of
materials, i.e., the major components in the observed scenes. Theoretically
speaking, Hottopixx methods should be effective on problems involving
extracting endmembers from hyperspectral images. Yet, these methods are
challenging to perform in practice, due to high computational costs. They
require us to solve LP problems, called Hottopixx models, whose size grows
quadratically with the number of pixels in the image. It is thus still unclear
as to whether they are actually effective or not. This study clarifies this
situation. We propose an efficient and effective implementation of Hottopixx.
Our implementation follows the framework of column generation, which is known
as a classical but powerful means of solving large-scale LPs. We show in
experiments that our implementation is applicable to the endmember extraction
from real hyperspectral images and can provide estimations of endmember
signatures with higher accuracy than the existing methods can.
",Tomohiko Mizutani,Tomohiko Mizutani,2024-04-19T07:28:51Z
"CMTNet: Convolutional Meets Transformer Network for Hyperspectral Images
  Classification","  Hyperspectral remote sensing (HIS) enables the detailed capture of spectral
information from the Earth's surface, facilitating precise classification and
identification of surface crops due to its superior spectral diagnostic
capabilities. However, current convolutional neural networks (CNNs) focus on
local features in hyperspectral data, leading to suboptimal performance when
classifying intricate crop types and addressing imbalanced sample
distributions. In contrast, the Transformer framework excels at extracting
global features from hyperspectral imagery. To leverage the strengths of both
approaches, this research introduces the Convolutional Meet Transformer Network
(CMTNet). This innovative model includes a spectral-spatial feature extraction
module for shallow feature capture, a dual-branch structure combining CNN and
Transformer branches for local and global feature extraction, and a
multi-output constraint module that enhances classification accuracy through
multi-output loss calculations and cross constraints across local,
international, and joint features. Extensive experiments conducted on three
datasets (WHU-Hi-LongKou, WHU-Hi-HanChuan, and WHU-Hi-HongHu) demonstrate that
CTDBNet significantly outperforms other state-of-the-art networks in
classification performance, validating its effectiveness in hyperspectral crop
classification.
","Faxu Guo, Quan Feng, Sen Yang, Wanxia Yang",Wanxia Yang,2024-06-20T07:56:51Z
"Inter and Intra Prior Learning-based Hyperspectral Image Reconstruction
  Using Snapshot SWIR Metasurface","  Shortwave-infrared(SWIR) spectral information, ranging from 1 {\mu}m to
2.5{\mu}m, overcomes the limitations of traditional color cameras in acquiring
scene information. However, conventional SWIR hyperspectral imaging systems
face challenges due to their bulky setups and low acquisition speeds. This work
introduces a snapshot SWIR hyperspectral imaging system based on a metasurface
filter and a corresponding filter selection method to achieve the lowest
correlation coefficient among these filters. This system offers the advantages
of compact size and snapshot imaging. We propose a novel inter and intra prior
learning unfolding framework to achieve high-quality SWIR hyperspectral image
reconstruction, which bridges the gap between prior learning and cross-stage
information interaction. Additionally, We design an adaptive feature transfer
mechanism to adaptively transfer the contextual correlation of multi-scale
encoder features to prevent detailed information loss in the decoder.
Experiment results demonstrate that our method can reconstruct hyperspectral
images with high speed and superior performance over existing methods.
","Linqiang Li, Jinglei Hao, Yongqiang Zhao, Pan Liu, Haofang Yan, Ziqin Zhang, Seong G. Kong",Seong G. Kong,2024-07-10T09:41:36Z
"Investigation of unsupervised and supervised hyperspectral anomaly
  detection","  Hyperspectral sensing is a valuable tool for detecting anomalies and
distinguishing between materials in a scene. Hyperspectral anomaly detection
(HS-AD) helps characterize the captured scenes and separates them into anomaly
and background classes. It is vital in agriculture, environment, and military
applications such as RSTA (reconnaissance, surveillance, and target
acquisition) missions. We previously designed an equal voting ensemble of
hyperspectral unmixing and three unsupervised HS-AD algorithms. We later
utilized a supervised classifier to determine the weights of a voting ensemble,
creating a hybrid of heterogeneous unsupervised HS-AD algorithms with a
supervised classifier in a model stacking, which improved detection accuracy.
However, supervised classification methods usually fail to detect novel or
unknown patterns that substantially deviate from those seen previously. In this
work, we evaluate our technique and other supervised and unsupervised methods
using general hyperspectral data to provide new insights.
","Mazharul Hossain, Aaron Robinson, Lan Wang, Chrysanthe Preza",Chrysanthe Preza,2024-08-13T17:20:14Z
"Cluster-based Random Radial Basis Kernel Function for Hyperspectral Data
  Classification","  Kernel-based classification methods, particularly the support vector machine
(SVM), are among the most common algorithms for hyperspectral data
classification. The Radial Basis function (RBF) kernel has earned great
popularity in hyperspectral data classification due to its superior performance
among other available kernel functions. Nonetheless, the cross-validation
technique usually used for tunning the RBF parameter can be time-consuming and
may result in sub-optimal values for the parameter. This paper proposed the
cluster-based random radial basis function (CRRBF) kernel function as an
alternative to the RBF kernel to achieve similar performance with a more
manageable parameter, which is the number of clusters. The CRRBF kernel
initially clusters the hyperspectral bands and then constructs an RBF kernel
with a randomly assigned value as the kernel parameter from each cluster of
bands. The final CRRBF kernel is constructed by adding up these basis RBF
kernels. We have designed several experiments to evaluate the SVM performance
trained with the CRRBF kernel considering a different number of clusters and
training samples, using three hyperspectral data sets. The obtained results
showed that the CRRBF kernel could provide comparable or better results than
the RBF. The results also showed that the classification performance is pretty
robust to the number of clusters, as the only open parameter of the CRRBF
kernel.
",Saeid Niazmardi,Saeid Niazmardi,2024-09-08T07:47:24Z
"Self-Supervised Elimination of Non-Independent Noise in Hyperspectral
  Imaging","  Hyperspectral imaging has been widely used for spectral and spatial
identification of target molecules, yet often contaminated by sophisticated
noise. Current denoising methods generally rely on independent and identically
distributed noise statistics, showing corrupted performance for non-independent
noise removal. Here, we demonstrate Self-supervised PErmutation Noise2noise
Denoising (SPEND), a deep learning denoising architecture tailor-made for
removing non-independent noise from a single hyperspectral image stack. We
utilize hyperspectral stimulated Raman scattering and mid-infrared photothermal
microscopy as the testbeds, where the noise is spatially correlated and
spectrally varied. Based on single hyperspectral images, SPEND permutates odd
and even spectral frames to generate two stacks with identical noise
properties, and uses the pairs for efficient self-supervised noise-to-noise
training. SPEND achieved an 8-fold signal-to-noise improvement without having
access to the ground truth data. SPEND enabled accurate mapping of low
concentration biomolecules in both fingerprint and silent regions,
demonstrating its robustness in sophisticated cellular environments.
","Guangrui Ding, Chang Liu, Jiaze Yin, Xinyan Teng, Yuying Tan, Hongjian He, Haonan Lin, Lei Tian, Ji-Xin Cheng",Ji-Xin Cheng,2024-09-16T00:48:58Z
"Plugin procedure in segmentation and application to hyperspectral image
  segmentation","  In this article we give our contribution to the problem of segmentation with
plug-in procedures. We give general sufficient conditions under which plug in
procedure are efficient. We also give an algorithm that satisfy these
conditions. We give an application of the used algorithm to hyperspectral
images segmentation. Hyperspectral images are images that have both spatial and
spectral coherence with thousands of spectral bands on each pixel. In the
proposed procedure we combine a reduction dimension technique and a spatial
regularisation technique. This regularisation is based on the mixlet
modelisation of Kolaczyck and Al.
",R. Girard,R. Girard,2010-02-19T13:48:57Z
"Graph Regularized Nonnegative Matrix Factorization for Hyperspectral
  Data Unmixing","  Spectral unmixing is an important tool in hyperspectral data analysis for
estimating endmembers and abundance fractions in a mixed pixel. This paper
examines the applicability of a recently developed algorithm called graph
regularized nonnegative matrix factorization (GNMF) for this aim. The proposed
approach exploits the intrinsic geometrical structure of the data besides
considering positivity and full additivity constraints. Simulated data based on
the measured spectral signatures, is used for evaluating the proposed
algorithm. Results in terms of abundance angle distance (AAD) and spectral
angle distance (SAD) show that this method can effectively unmix hyperspectral
data.
","Roozbeh Rajabi, Mahdi Khodadadzadeh, Hassan Ghassemian",Hassan Ghassemian,2011-11-03T15:46:47Z
"Nonlinear unmixing of hyperspectral images using a semiparametric model
  and spatial regularization","  Incorporating spatial information into hyperspectral unmixing procedures has
been shown to have positive effects, due to the inherent spatial-spectral
duality in hyperspectral scenes. Current research works that consider spatial
information are mainly focused on the linear mixing model. In this paper, we
investigate a variational approach to incorporating spatial correlation into a
nonlinear unmixing procedure. A nonlinear algorithm operating in reproducing
kernel Hilbert spaces, associated with an $\ell_1$ local variation norm as the
spatial regularizer, is derived. Experimental results, with both synthetic and
real data, illustrate the effectiveness of the proposed scheme.
","Jie Chen, Cédric Richard, Alfred O. Hero III",Alfred O. Hero III,2013-10-31T17:40:20Z
On Hyperspectral Classification in the Compressed Domain,"  In this paper, we study the problem of hyperspectral pixel classification
based on the recently proposed architectures for compressive whisk-broom
hyperspectral imagers without the need to reconstruct the complete data cube. A
clear advantage of classification in the compressed domain is its suitability
for real-time on-site processing of the sensed data. Moreover, it is assumed
that the training process also takes place in the compressed domain, thus,
isolating the classification unit from the recovery unit at the receiver's
side. We show that, perhaps surprisingly, using distinct measurement matrices
for different pixels results in more accuracy of the learned classifier and
consistent classification performance, supporting the role of information
diversity in learning.
","Mohammad Aghagolzadeh, Hayder Radha",Hayder Radha,2015-08-02T20:40:21Z
Dynamical spectral unmixing of multitemporal hyperspectral images,"  In this paper, we consider the problem of unmixing a time series of
hyperspectral images. We propose a dynamical model based on linear mixing
processes at each time instant. The spectral signatures and fractional
abundances of the pure materials in the scene are seen as latent variables, and
assumed to follow a general dynamical structure. Based on a simplified version
of this model, we derive an efficient spectral unmixing algorithm to estimate
the latent variables by performing alternating minimizations. The performance
of the proposed approach is demonstrated on synthetic and real multitemporal
hyperspectral images.
","Simon Henrot, Jocelyn Chanussot, Christian Jutten",Christian Jutten,2015-10-14T18:51:51Z
Ladder Networks for Semi-Supervised Hyperspectral Image Classification,"  We used the Ladder Network [Rasmus et al. (2015)] to perform Hyperspectral
Image Classification in a semi-supervised setting. The Ladder Network
distinguishes itself from other semi-supervised methods by jointly optimizing a
supervised and unsupervised cost. In many settings this has proven to be more
successful than other semi-supervised techniques, such as pretraining using
unlabeled data. We furthermore show that the convolutional Ladder Network
outperforms most of the current techniques used in hyperspectral image
classification and achieves new state-of-the-art performance on the Pavia
University dataset given only 5 labeled data points per class.
","Julian Büchel, Okan Ersoy",Okan Ersoy,2018-12-04T05:24:47Z
Morphological segmentation of hyperspectral images,"  The present paper develops a general methodology for the morphological
segmentation of hyperspectral images, i.e., with an important number of
channels. This approach, based on watershed, is composed of a spectral
classification to obtain the markers and a vectorial gradient which gives the
spatial information. Several alternative gradients are adapted to the different
hyperspectral functions. Data reduction is performed either by Factor Analysis
or by model fitting. Image segmentation is done on different spaces: factor
space, parameters space, etc. On all these spaces the spatial/spectral
segmentation approach is applied, leading to relevant results on the image.
","Guillaume Noyel, Jesus Angulo, Dominique Jeulin",Dominique Jeulin,2020-10-02T08:32:52Z
"Deep Learning Hyperspectral Image Classification Using Multiple
  Class-based Denoising Autoencoders, Mixed Pixel Training Augmentation, and
  Morphological Operations","  Herein, we present a system for hyperspectral image segmentation that
utilizes multiple class--based denoising autoencoders which are efficiently
trained. Moreover, we present a novel hyperspectral data augmentation method
for labelled HSI data using linear mixtures of pixels from each class, which
helps the system with edge pixels which are almost always mixed pixels.
Finally, we utilize a deep neural network and morphological hole-filling to
provide robust image classification. Results run on the Salinas dataset verify
the high performance of the proposed algorithm.
","John E. Ball, Pan Wei",Pan Wei,2018-07-11T23:49:30Z
"Hyperspectral holography and spectroscopy: computational features of
  inverse discrete cosine transform","  Broadband hyperspectral digital holography and Fourier transform spectroscopy
are important instruments in various science and application fields. In the
digital hyperspectral holography and spectroscopy the variable of interest are
obtained as inverse discrete cosine transforms of observed diffractive
intensity patterns. In these notes, we provide a variety of algorithms for the
inverse cosine transform with the proofs of perfect spectrum reconstruction, as
well as we discuss and illustrate some nontrivial features of these algorithms.
","Vladimir Katkovnik, Igor Shevkunov, Karen Egiazarian",Karen Egiazarian,2019-10-04T12:15:16Z
Hyperspectral Nanomotion Microscopy,"  We have developed a technique that extends static scanning electron
microscopic imaging to include hyperspectral mapping of fast thermal and
externally-driven movements at up to Megahertz frequencies. It is based on
spectral analysis of the secondary electron flux generated by a focused
electron beam incident on the moving object. We demonstrate detection of
nanowire Brownian motion and hyperspectral mapping of stimulated oscillations
of flea setae with deep sub-nanometer displacement sensitivity.
","Tongjun Liu, Jun-Yu Ou, Kevin F. MacDonald, Nikolay I. Zheludev",Nikolay I. Zheludev,2020-05-11T14:55:17Z
"Deep Deterministic Independent Component Analysis for Hyperspectral
  Unmixing","  We develop a new neural network based independent component analysis (ICA)
method by directly minimizing the dependence amongst all extracted components.
Using the matrix-based R{\'e}nyi's $\alpha$-order entropy functional, our
network can be directly optimized by stochastic gradient descent (SGD), without
any variational approximation or adversarial training. As a solid application,
we evaluate our ICA in the problem of hyperspectral unmixing (HU) and refute a
statement that ""\emph{ICA does not play a role in unmixing hyperspectral
data}"", which was initially suggested by \cite{nascimento2005does}. Code and
additional remarks of our DDICA is available at
https://github.com/hongmingli1995/DDICA.
","Hongming Li, Shujian Yu, Jose C. Principe",Jose C. Principe,2022-02-07T05:26:32Z
A Hyperspectral and RGB Dataset for Building Facade Segmentation,"  Hyperspectral Imaging (HSI) provides detailed spectral information and has
been utilised in many real-world applications. This work introduces an HSI
dataset of building facades in a light industry environment with the aim of
classifying different building materials in a scene. The dataset is called the
Light Industrial Building HSI (LIB-HSI) dataset. This dataset consists of nine
categories and 44 classes. In this study, we investigated deep learning based
semantic segmentation algorithms on RGB and hyperspectral images to classify
various building materials, such as timber, brick and concrete.
","Nariman Habili, Ernest Kwan, Weihao Li, Christfried Webers, Jeremy Oorloff, Mohammad Ali Armin, Lars Petersson",Lars Petersson,2022-12-06T04:38:44Z
"A Hierarchical Bayesian Model Accounting for Endmember Variability and
  Abrupt Spectral Changes to Unmix Multitemporal Hyperspectral Images","  Hyperspectral unmixing is a blind source separation problem which consists in
estimating the reference spectral signatures contained in a hyperspectral
image, as well as their relative contribution to each pixel according to a
given mixture model. In practice, the process is further complexified by the
inherent spectral variability of the observed scene and the possible presence
of outliers. More specifically, multi-temporal hyperspectral images, i.e.,
sequences of hyperspectral images acquired over the same area at different time
instants, are likely to simultaneously exhibit moderate endmember variability
and abrupt spectral changes either due to outliers or to significant time
intervals between consecutive acquisitions. Unless properly accounted for,
these two perturbations can significantly affect the unmixing process. In this
context, we propose a new unmixing model for multitemporal hyperspectral images
accounting for smooth temporal variations, construed as spectral variability,
and abrupt spectral changes interpreted as outliers. The proposed hierarchical
Bayesian model is inferred using a Markov chain Monte-Carlo (MCMC) method
allowing the posterior of interest to be sampled and Bayesian estimators to be
approximated. A comparison with unmixing techniques from the literature on
synthetic and real data allows the interest of the proposed approach to be
appreciated.
","Pierre-Antoine Thouvenin, Nicolas Dobigeon, Jean-Yves Tourneret",Jean-Yves Tourneret,2016-09-25T20:02:25Z
"Unsupervised Clustering and Active Learning of Hyperspectral Images with
  Nonlinear Diffusion","  The problem of unsupervised learning and segmentation of hyperspectral images
is a significant challenge in remote sensing. The high dimensionality of
hyperspectral data, presence of substantial noise, and overlap of classes all
contribute to the difficulty of automatically clustering and segmenting
hyperspectral images. We propose an unsupervised learning technique called
spectral-spatial diffusion learning (DLSS) that combines a geometric estimation
of class modes with a diffusion-inspired labeling that incorporates both
spectral and spatial information. The mode estimation incorporates the geometry
of the hyperspectral data by using diffusion distance to promote learning a
unique mode from each class. These class modes are then used to label all
points by a joint spectral-spatial nonlinear diffusion process. A related
variation of DLSS is also discussed, which enables active learning by
requesting labels for a very small number of well-chosen pixels, dramatically
boosting overall clustering results. Extensive experimental analysis
demonstrates the efficacy of the proposed methods against benchmark and
state-of-the-art hyperspectral analysis techniques on a variety of real
datasets, their robustness to choices of parameters, and their low
computational complexity.
","James M. Murphy, Mauro Maggioni",Mauro Maggioni,2017-04-26T03:11:21Z
"Deep Neural Network Based Hyperspectral Pixel Classification With
  Factorized Spectral-Spatial Feature Representation","  Deep learning has been widely used for hyperspectral pixel classification due
to its ability of generating deep feature representation. However, how to
construct an efficient and powerful network suitable for hyperspectral data is
still under exploration. In this paper, a novel neural network model is
designed for taking full advantage of the spectral-spatial structure of
hyperspectral data. Firstly, we extract pixel-based intrinsic features from
rich yet redundant spectral bands by a subnetwork with supervised pre-training
scheme. Secondly, in order to utilize the local spatial correlation among
pixels, we share the previous subnetwork as a spectral feature extractor for
each pixel in a patch of image, after which the spectral features of all pixels
in a patch are combined and feeded into the subsequent classification
subnetwork. Finally, the whole network is further fine-tuned to improve its
classification performance. Specially, the spectral-spatial factorization
scheme is applied in our model architecture, making the network size and the
number of parameters great less than the existing spectral-spatial deep
networks for hyperspectral image classification. Experiments on the
hyperspectral data sets show that, compared with some state-of-art deep
learning methods, our method achieves better classification results while
having smaller network size and less parameters.
","Jingzhou Chen, Siyu Chen, Peilin Zhou, Yuntao Qian",Yuntao Qian,2019-04-16T04:52:19Z
"Statistical Loss and Analysis for Deep Learning in Hyperspectral Image
  Classification","  Nowadays, deep learning methods, especially the convolutional neural networks
(CNNs), have shown impressive performance on extracting abstract and high-level
features from the hyperspectral image. However, general training process of
CNNs mainly considers the pixel-wise information or the samples' correlation to
formulate the penalization while ignores the statistical properties especially
the spectral variability of each class in the hyperspectral image. These
samples-based penalizations would lead to the uncertainty of the training
process due to the imbalanced and limited number of training samples. To
overcome this problem, this work characterizes each class from the
hyperspectral image as a statistical distribution and further develops a novel
statistical loss with the distributions, not directly with samples for deep
learning. Based on the Fisher discrimination criterion, the loss penalizes the
sample variance of each class distribution to decrease the intra-class variance
of the training samples. Moreover, an additional diversity-promoting condition
is added to enlarge the inter-class variance between different class
distributions and this could better discriminate samples from different classes
in hyperspectral image. Finally, the statistical estimation form of the
statistical loss is developed with the training samples through multi-variant
statistical analysis. Experiments over the real-world hyperspectral images show
the effectiveness of the developed statistical loss for deep learning.
","Zhiqiang Gong, Ping Zhong, Weidong Hu",Weidong Hu,2019-12-28T02:41:49Z
"GETNET: A General End-to-end Two-dimensional CNN Framework for
  Hyperspectral Image Change Detection","  Change detection (CD) is an important application of remote sensing, which
provides timely change information about large-scale Earth surface. With the
emergence of hyperspectral imagery, CD technology has been greatly promoted, as
hyperspectral data with the highspectral resolution are capable of detecting
finer changes than using the traditional multispectral imagery. Nevertheless,
the high dimension of hyperspectral data makes it difficult to implement
traditional CD algorithms. Besides, endmember abundance information at subpixel
level is often not fully utilized. In order to better handle high dimension
problem and explore abundance information, this paper presents a General
End-to-end Two-dimensional CNN (GETNET) framework for hyperspectral image
change detection (HSI-CD). The main contributions of this work are threefold:
1) Mixed-affinity matrix that integrates subpixel representation is introduced
to mine more cross-channel gradient features and fuse multi-source information;
2) 2-D CNN is designed to learn the discriminative features effectively from
multi-source data at a higher level and enhance the generalization ability of
the proposed CD algorithm; 3) A new HSI-CD data set is designed for the
objective comparison of different methods. Experimental results on real
hyperspectral data sets demonstrate the proposed method outperforms most of the
state-of-the-arts.
","Qi Wang, Zhenghang Yuan, Qian Du, Xuelong Li",Xuelong Li,2019-05-05T11:36:53Z
"Frost filtered scale-invariant feature extraction and multilayer
  perceptron for hyperspectral image classification","  Hyperspectral image (HSI) classification plays a significant in the field of
remote sensing due to its ability to provide spatial and spectral information.
Due to the rapid development and increasing of hyperspectral remote sensing
technology, many methods have been developed for HSI classification but still a
lack of achieving the better performance. A Frost Filtered Scale-Invariant
Feature Transformation based MultiLayer Perceptron Classification (FFSIFT-MLPC)
technique is introduced for classifying the hyperspectral image with higher
accuracy and minimum time consumption. The FFSIFT-MLPC technique performs three
major processes, namely preprocessing, feature extraction and classification
using multiple layers. Initially, the hyperspectral image is divided into
number of spectral bands. These bands are given as input in the input layer of
perceptron. Then the Frost filter is used in FFSIFT-MLPC technique for
preprocessing the input bands which helps to remove the noise from
hyper-spectral image at the first hidden layer. After preprocessing task,
texture, color and object features of hyper-spectral image are extracted at
second hidden layer using Gaussian distributive scale-invariant feature
transform. At the third hidden layer, Euclidean distance is measured between
the extracted features and testing features. Finally, feature matching is
carried out at the output layer for hyper-spectral image classification. The
classified outputs are resulted in terms of spectral bands (i.e., different
colors). Experimental analysis is performed with PSNR, classification accuracy,
false positive rate and classification time with number of spectral bands. The
results evident that presented FFSIFT-MLPC technique improves the hyperspectral
image classification accuracy, PSNR and minimizes false positive rate as well
as classification time than the state-of-the-art methods.
","G. Kalaiarasi, S. Maheswari",S. Maheswari,2020-06-18T10:51:04Z
"Real-time Hyperspectral Imaging in Hardware via Trained Metasurface
  Encoders","  Hyperspectral imaging has attracted significant attention to identify
spectral signatures for image classification and automated pattern recognition
in computer vision. State-of-the-art implementations of snapshot hyperspectral
imaging rely on bulky, non-integrated, and expensive optical elements,
including lenses, spectrometers, and filters. These macroscopic components do
not allow fast data processing for, e.g real-time and high-resolution videos.
This work introduces Hyplex, a new integrated architecture addressing the
limitations discussed above. Hyplex is a CMOS-compatible, fast hyperspectral
camera that replaces bulk optics with nanoscale metasurfaces inversely designed
through artificial intelligence. Hyplex does not require spectrometers but
makes use of conventional monochrome cameras, opening up the possibility for
real-time and high-resolution hyperspectral imaging at inexpensive costs.
Hyplex exploits a model-driven optimization, which connects the physical
metasurfaces layer with modern visual computing approaches based on end-to-end
training. We design and implement a prototype version of Hyplex and compare its
performance against the state-of-the-art for typical imaging tasks such as
spectral reconstruction and semantic segmentation. In all benchmarks, Hyplex
reports the smallest reconstruction error. We additionally present what is, to
the best of our knowledge, the largest publicly available labeled hyperspectral
dataset for semantic segmentation.
","Maksim Makarenko, Arturo Burguete-Lopez, Qizhou Wang, Fedor Getman, Silvio Giancola, Bernard Ghanem, Andrea Fratalocchi",Andrea Fratalocchi,2022-04-05T09:52:51Z
"Spectral Unmixing of Hyperspectral Images Based on Block Sparse
  Structure","  Spectral unmixing (SU) of hyperspectral images (HSIs) is one of the important
areas in remote sensing (RS) that needs to be carefully addressed in different
RS applications. Despite the high spectral resolution of the hyperspectral
data, the relatively low spatial resolution of the sensors may lead to mixture
of different pure materials within the image pixels. In this case, the spectrum
of a given pixel recorded by the sensor can be a combination of multiple
spectra each belonging to a unique material in that pixel. Spectral unmixing is
then used as a technique to extract the spectral characteristics of the
different materials within the mixed pixels and to recover the spectrum of each
pure spectral signature, called endmember. Block-sparsity exists in
hyperspectral images as a result of spectral similarity between neighboring
pixels. In block-sparse signals, the nonzero samples occur in clusters and the
pattern of the clusters is often supposed to be unavailable as prior
information. This paper presents an innovative spectral unmixing approach for
HSIs based on block-sparse structure. Hyperspectral unmixing problem is solved
using pattern coupled sparse Bayesian learning strategy (PCSBL). To evaluate
the performance of the proposed SU algorithm, it is tested on both synthetic
and real hyperspectral data and the quantitative results are compared to those
of other state-of-the-art methods in terms of abundance angle distance and mean
squared error. The achieved results show the superiority of the proposed
algorithm over the other competing methods by a significant margin.
","Seyed Hossein Mosavi Azarang, Roozbeh Rajabi, Hadi Zayyani, Amin Zehtabian",Amin Zehtabian,2022-04-10T09:37:41Z
Hyperspectral CNN Classification with Limited Training Samples,"  Hyperspectral imaging sensors are becoming increasingly popular in robotics
applications such as agriculture and mining, and allow per-pixel thematic
classification of materials in a scene based on their unique spectral
signatures. Recently, convolutional neural networks have shown remarkable
performance for classification tasks, but require substantial amounts of
labelled training data. This data must sufficiently cover the variability
expected to be encountered in the environment. For hyperspectral data, one of
the main variations encountered outdoors is due to incident illumination, which
can change in spectral shape and intensity depending on the scene geometry. For
example, regions occluded from the sun have a lower intensity and their
incident irradiance skewed towards shorter wavelengths.
  In this work, a data augmentation strategy based on relighting is used during
training of a hyperspectral convolutional neural network. It allows training to
occur in the outdoor environment given only a small labelled region, which does
not need to sufficiently represent the geometric variability of the entire
scene. This is important for applications where obtaining large amounts of
training data is labourious, hazardous or difficult, such as labelling pixels
within shadows. Radiometric normalisation approaches for pre-processing the
hyperspectral data are analysed and it is shown that methods based on the raw
pixel data are sufficient to be used as input for the classifier. This removes
the need for external hardware such as calibration boards, which can restrict
the application of hyperspectral sensors in robotics applications. Experiments
to evaluate the classification system are carried out on two datasets captured
from a field-based platform.
","Lloyd Windrim, Rishi Ramakrishnan, Arman Melkumyan, Richard Murphy",Richard Murphy,2016-11-28T07:29:29Z
"Unsupervised Spatial-spectral Network Learning for Hyperspectral
  Compressive Snapshot Reconstruction","  Hyperspectral compressive imaging takes advantage of compressive sensing
theory to achieve coded aperture snapshot measurement without temporal
scanning, and the entire three-dimensional spatial-spectral data is captured by
a two-dimensional projection during a single integration period. Its core issue
is how to reconstruct the underlying hyperspectral image using compressive
sensing reconstruction algorithms. Due to the diversity in the spectral
response characteristics and wavelength range of different spectral imaging
devices, previous works are often inadequate to capture complex spectral
variations or lack the adaptive capacity to new hyperspectral imagers. In order
to address these issues, we propose an unsupervised spatial-spectral network to
reconstruct hyperspectral images only from the compressive snapshot
measurement. The proposed network acts as a conditional generative model
conditioned on the snapshot measurement, and it exploits the spatial-spectral
attention module to capture the joint spatial-spectral correlation of
hyperspectral images. The network parameters are optimized to make sure that
the network output can closely match the given snapshot measurement according
to the imaging model, thus the proposed network can adapt to different imaging
settings, which can inherently enhance the applicability of the network.
Extensive experiments upon multiple datasets demonstrate that our network can
achieve better reconstruction results than the state-of-the-art methods.
","Yubao Sun, Ying Yang, Qingshan Liu, Mohan Kankanhalli",Mohan Kankanhalli,2020-12-18T12:29:04Z
"SpecTr: Spectral Transformer for Hyperspectral Pathology Image
  Segmentation","  Hyperspectral imaging (HSI) unlocks the huge potential to a wide variety of
applications relied on high-precision pathology image segmentation, such as
computational pathology and precision medicine. Since hyperspectral pathology
images benefit from the rich and detailed spectral information even beyond the
visible spectrum, the key to achieve high-precision hyperspectral pathology
image segmentation is to felicitously model the context along high-dimensional
spectral bands. Inspired by the strong context modeling ability of
transformers, we hereby, for the first time, formulate the contextual feature
learning across spectral bands for hyperspectral pathology image segmentation
as a sequence-to-sequence prediction procedure by transformers. To assist
spectral context learning procedure, we introduce two important strategies: (1)
a sparsity scheme enforces the learned contextual relationship to be sparse, so
as to eliminates the distraction from the redundant bands; (2) a spectral
normalization, a separate group normalization for each spectral band, mitigates
the nuisance caused by heterogeneous underlying distributions of bands. We name
our method Spectral Transformer (SpecTr), which enjoys two benefits: (1) it has
a strong ability to model long-range dependency among spectral bands, and (2)
it jointly explores the spatial-spectral features of HSI. Experiments show that
SpecTr outperforms other competing methods in a hyperspectral pathology image
segmentation benchmark without the need of pre-training. Code is available at
https://github.com/hfut-xc-yun/SpecTr.
","Boxiang Yun, Yan Wang, Jieneng Chen, Huiyu Wang, Wei Shen, Qingli Li",Qingli Li,2021-03-05T11:12:22Z
"Deep Reinforcement Learning for Band Selection in Hyperspectral Image
  Classification","  Band selection refers to the process of choosing the most relevant bands in a
hyperspectral image. By selecting a limited number of optimal bands, we aim at
speeding up model training, improving accuracy, or both. It reduces redundancy
among spectral bands while trying to preserve the original information of the
image. By now many efforts have been made to develop unsupervised band
selection approaches, of which the majority are heuristic algorithms devised by
trial and error. In this paper, we are interested in training an intelligent
agent that, given a hyperspectral image, is capable of automatically learning
policy to select an optimal band subset without any hand-engineered reasoning.
To this end, we frame the problem of unsupervised band selection as a Markov
decision process, propose an effective method to parameterize it, and finally
solve the problem by deep reinforcement learning. Once the agent is trained, it
learns a band-selection policy that guides the agent to sequentially select
bands by fully exploiting the hyperspectral image and previously picked bands.
Furthermore, we propose two different reward schemes for the environment
simulation of deep reinforcement learning and compare them in experiments.
This, to the best of our knowledge, is the first study that explores a deep
reinforcement learning model for hyperspectral image analysis, thus opening a
new door for future research and showcasing the great potential of deep
reinforcement learning in remote sensing applications. Extensive experiments
are carried out on four hyperspectral data sets, and experimental results
demonstrate the effectiveness of the proposed method.
","Lichao Mou, Sudipan Saha, Yuansheng Hua, Francesca Bovolo, Lorenzo Bruzzone, Xiao Xiang Zhu",Xiao Xiang Zhu,2021-03-15T22:06:15Z
Event-based hyperspectral EELS: towards nanosecond temporal resolution,"  The acquisition of a hyperspectral image is nowadays a standard technique
used in the scanning transmission electron microscope. It relates the spatial
position of the electron probe to the spectral data associated with it. In the
case of electron energy loss spectroscopy (EELS), frame-based hyperspectral
acquisition is much slower than the achievable rastering time of the scan unit
(SU), which sometimes leads to undesirable effects in the sample, such as
electron irradiation damage, that goes unperceived during frame acquisition. In
this work, we have developed an event-based hyperspectral EELS by using a
Timepix3 application-specific integrated circuit detector with two
supplementary time-to-digital (TDC) lines embedded. In such a system, electron
events are characterized by their positional and temporal coordinates, but TDC
events only by temporal ones. By sending reference signals from the SU to the
TDC line, it is possible to reconstruct the entire spectral image with
SU-limited scanning pixel dwell time and thus acquire, with no additional cost,
a hyperspectral image at the same rate as that of a single channel detector,
such as annular dark-field. To exemplify the possibilities behind event-based
hyperspectral EELS, we have studied the decomposition of calcite (CaCO$_3$)
into calcium oxide (CaO) and carbon dioxide (CO$_2$) under the electron beam
irradiation.
","Yves Auad, Michael Walls, Jean-Denis Blazit, Odile Stéphan, Luiz H. G. Tizei, Mathieu Kociak, Francisco De la Peña, Marcel Tencé",Marcel Tencé,2021-10-04T20:36:22Z
"SSCU-Net: Spatial-Spectral Collaborative Unmixing Network for
  Hyperspectral Images","  Linear spectral unmixing is an essential technique in hyperspectral image
processing and interpretation. In recent years, deep learning-based approaches
have shown great promise in hyperspectral unmixing, in particular, unsupervised
unmixing methods based on autoencoder networks are a recent trend. The
autoencoder model, which automatically learns low-dimensional representations
(abundances) and reconstructs data with their corresponding bases (endmembers),
has achieved superior performance in hyperspectral unmixing. In this article,
we explore the effective utilization of spatial and spectral information in
autoencoder-based unmixing networks. Important findings on the use of spatial
and spectral information in the autoencoder framework are discussed. Inspired
by these findings, we propose a spatial-spectral collaborative unmixing
network, called SSCU-Net, which learns a spatial autoencoder network and a
spectral autoencoder network in an end-to-end manner to more effectively
improve the unmixing performance. SSCU-Net is a two-stream deep network and
shares an alternating architecture, where the two autoencoder networks are
efficiently trained in a collaborative way for estimation of endmembers and
abundances. Meanwhile, we propose a new spatial autoencoder network by
introducing a superpixel segmentation method based on abundance information,
which greatly facilitates the employment of spatial information and improves
the accuracy of unmixing network. Moreover, extensive ablation studies are
carried out to investigate the performance gain of SSCU-Net. Experimental
results on both synthetic and real hyperspectral data sets illustrate the
effectiveness and competitiveness of the proposed SSCU-Net compared with
several state-of-the-art hyperspectral unmixing methods.
","Lin Qi, Feng Gao, Junyu Dong, Xinbo Gao, Qian Du",Qian Du,2022-03-12T08:20:44Z
"A CNN with Noise Inclined Module and Denoise Framework for Hyperspectral
  Image Classification","  Deep Neural Networks have been successfully applied in hyperspectral image
classification. However, most of prior works adopt general deep architectures
while ignore the intrinsic structure of the hyperspectral image, such as the
physical noise generation. This would make these deep models unable to generate
discriminative features and provide impressive classification performance. To
leverage such intrinsic information, this work develops a novel deep learning
framework with the noise inclined module and denoise framework for
hyperspectral image classification. First, we model the spectral signature of
hyperspectral image with the physical noise model to describe the high
intraclass variance of each class and great overlapping between different
classes in the image. Then, a noise inclined module is developed to capture the
physical noise within each object and a denoise framework is then followed to
remove such noise from the object. Finally, the CNN with noise inclined module
and the denoise framework is developed to obtain discriminative features and
provides good classification performance of hyperspectral image. Experiments
are conducted over two commonly used real-world datasets and the experimental
results show the effectiveness of the proposed method. The implementation of
the proposed method and other compared methods could be accessed at
https://github.com/shendu-sw/noise-physical-framework.
","Zhiqiang Gong, Ping Zhong, Jiahao Qi, Panhe Hu",Panhe Hu,2022-05-25T03:12:26Z
"Hyperspectral Images Classification and Dimensionality Reduction using
  spectral interaction and SVM classifier","  Over the past decades, the hyperspectral remote sensing technology
development has attracted growing interest among scientists in various domains.
The rich and detailed spectral information provided by the hyperspectral
sensors has improved the monitoring and detection capabilities of the earth
surface substances. However, the high dimensionality of the hyperspectral
images (HSI) is one of the main challenges for the analysis of the collected
data. The existence of noisy, redundant and irrelevant bands increases the
computational complexity, induce the Hughes phenomenon and decrease the
target's classification accuracy. Hence, the dimensionality reduction is an
essential step to face the dimensionality challenges. In this paper, we propose
a novel filter approach based on the maximization of the spectral interaction
measure and the support vector machines for dimensionality reduction and
classification of the HSI. The proposed Max Relevance Max Synergy (MRMS)
algorithm evaluates the relevance of every band through the combination of
spectral synergy, redundancy and relevance measures. Our objective is to select
the optimal subset of synergistic bands providing accurate classification of
the supervised scene materials. Experimental results have been performed using
three different hyperspectral datasets: ""Indiana Pine"", ""Pavia University"" and
""Salinas"" provided by the ""NASA-AVIRIS"" and the ""ROSIS"" spectrometers.
Furthermore, a comparison with the state of the art band selection methods has
been carried out in order to demonstrate the robustness and efficiency of the
proposed approach.
  Keywords: Hyperspectral images, remote sensing, dimensionality reduction,
classification, synergic, correlation, spectral interaction information, mutual
inform
","Asma Elmaizi, Elkebir Sarhrouni, Ahmed Hammouch, Nacir Chafik",Nacir Chafik,2022-10-27T15:37:57Z
"Probabilistic Deep Metric Learning for Hyperspectral Image
  Classification","  This paper proposes a probabilistic deep metric learning (PDML) framework for
hyperspectral image classification, which aims to predict the category of each
pixel for an image captured by hyperspectral sensors. The core problem for
hyperspectral image classification is the spectral variability between
intraclass materials and the spectral similarity between interclass materials,
motivating the further incorporation of spatial information to differentiate a
pixel based on its surrounding patch. However, different pixels and even the
same pixel in one patch might not encode the same material due to the low
spatial resolution of most hyperspectral sensors, leading to an inconsistent
judgment of a specific pixel. To address this issue, we propose a probabilistic
deep metric learning framework to model the categorical uncertainty of the
spectral distribution of an observed pixel. We propose to learn a global
probabilistic distribution for each pixel in the patch and a probabilistic
metric to model the distance between distributions. We treat each pixel in a
patch as a training sample, enabling us to exploit more information from the
patch compared with conventional methods. Our framework can be readily applied
to existing hyperspectral image classification methods with various network
architectures and loss functions. Extensive experiments on four widely used
datasets including IN, UP, KSC, and Houston 2013 datasets demonstrate that our
framework improves the performance of existing methods and further achieves the
state of the art. Code is available at: https://github.com/wzzheng/PDML.
","Chengkun Wang, Wenzhao Zheng, Xian Sun, Jiwen Lu, Jie Zhou",Jie Zhou,2022-11-15T17:57:12Z
"Investigation of Minerals Using Hyperspectral Satellite Imagery in
  Bangladesh","  Mineral identification using remote sensing technologies is becoming more
dominant in this field since it saves time by demonstrating a more effective
way for land resources survey. In such remote sensing technologies,
hyperspectral remote sensing (HSRS) technology has increased gradually for its
efficient manner. This technology is usually used from an airborne platform,
i.e., satellite. Hence, satellite imagery remote sensing technology is now more
capable of providing accuracy in mineral identification, and mapping.
Hyperspectral satellite imagery can identify minerals more accurately compared
to traditional technologies in remote sensing by constructing a complete
reflectance of the spectrum from each pixel with its advanced imaging sensor.
Bangladesh is a developing country with an area of 1,50,000 square kilometers
located in Southeast Asia. Though it is a small country, it is enriched with
several mineral resources through rivers, forests, hills, and the Bay of
Bengal. In this study, hyperspectral imaging technology is employed on some
major identical areas (Maheshkhali, Netrokona, Panchagarh, and Patuakhali) of
Bangladesh to identify minerals there. As there are no studies done in
Bangladesh using hyperspectral imaging yet, it is a good opportunity to explore
the potentiality of HS imagery in this field. In this study, the FLAASH (Fast
Line-of-sight Atmospheric Analysis) module with necessary parameter settings is
used to filter the data, and finally, mineral identification is done by the
spectral matched filtering method. Our investigation resulted in finding some
potential minerals in those areas including Stariolite, Diasphore, Zircon,
Alunite, Quartz, and so on. This indicates that there still is enormous
potential for further exploration of minerals in Bangladesh by Hyperspectral
Satellite Imagery.
","Nazmul Hasan, Kazi Mahmudul Hasan, Md. Tahsinul Islam, Shahnewaz Siddique",Shahnewaz Siddique,2022-12-08T18:41:02Z
"A broadband hyperspectral image sensor with high spatio-temporal
  resolution","  Hyperspectral imaging provides high-dimensional spatial-temporal-spectral
information revealing intrinsic matter characteristics. Here we report an
on-chip computational hyperspectral imaging framework with high spatial and
temporal resolution. By integrating different broadband modulation materials on
the image sensor chip, the target spectral information is non-uniformly and
intrinsically coupled on each pixel with high light throughput. Using
intelligent reconstruction algorithms, multi-channel images can be recovered
from each frame, realizing real-time hyperspectral imaging. Following such a
framework, we for the first time fabricated a broadband VIS-NIR (400-1700 nm)
hyperspectral imaging sensor using photolithography, with an average light
throughput of 74.8% and 96 wavelength channels. The demonstrated resolution is
1,024*1,024 pixels at 124 fps. We demonstrated its wide applications including
chlorophyll and sugar quantification for intelligent agriculture, blood oxygen
and water quality monitoring for human health, textile classification and apple
bruise detection for industrial automation, and remote lunar detection for
astronomy. The integrated hyperspectral image sensor weighs only tens of grams,
and can be assembled on various resource-limited platforms or equipped with
off-the-shelf optical systems. The technique transforms the challenge of
high-dimensional imaging from a high-cost manufacturing and cumbersome system
to one that is solvable through on-chip compression and agile computation.
","Liheng Bian, Zhen Wang, Yuzhe Zhang, Lianjie Li, Yinuo Zhang, Chen Yang, Wen Fang, Jiajun Zhao, Chunli Zhu, Qinghao Meng, Xuan Peng, Jun Zhang",Jun Zhang,2023-06-20T14:56:34Z
"InSPECtor: an end-to-end design framework for compressive pixelated
  hyperspectral instruments","  Classic designs of hyperspectral instrumentation densely sample the spatial
and spectral information of the scene of interest. Data may be compressed after
the acquisition. In this paper we introduce a framework for the design of an
optimized, micro-patterned snapshot hyperspectral imager that acquires an
optimized subset of the spatial and spectral information in the scene. The data
is thereby compressed already at the sensor level, but can be restored to the
full hyperspectral data cube by the jointly optimized reconstructor. This
framework is implemented with TensorFlow and makes use of its automatic
differentiation for the joint optimization of the layout of the micro-patterned
filter array as well as the reconstructor. We explore the achievable
compression ratio for different numbers of filter passbands, number of scanning
frames, and filter layouts using data collected by the Hyperscout instrument.
We show resulting instrument designs that take snapshot measurements without
losing significant information while reducing the data volume, acquisition
time, or detector space by a factor of 40 as compared to classic, dense
sampling. The joint optimization of a compressive hyperspectral imager design
and the accompanying reconstructor provides an avenue to substantially reduce
the data volume from hyperspectral imagers.
","T. A. Stockmans, F. Snik, M. Esposito, C. van Dijk, C. U. Keller",C. U. Keller,2023-09-19T13:12:23Z
"Pixel-to-Abundance Translation: Conditional Generative Adversarial
  Networks Based on Patch Transformer for Hyperspectral Unmixing","  Spectral unmixing is a significant challenge in hyperspectral image
processing. Existing unmixing methods utilize prior knowledge about the
abundance distribution to solve the regularization optimization problem, where
the difficulty lies in choosing appropriate prior knowledge and solving the
complex regularization optimization problem. To solve these problems, we
propose a hyperspectral conditional generative adversarial network (HyperGAN)
method as a generic unmixing framework, based on the following assumption: the
unmixing process from pixel to abundance can be regarded as a transformation of
two modalities with an internal specific relationship. The proposed HyperGAN is
composed of a generator and discriminator, the former completes the modal
conversion from mixed hyperspectral pixel patch to the abundance of
corresponding endmember of the central pixel and the latter is used to
distinguish whether the distribution and structure of generated abundance are
the same as the true ones. We propose hyperspectral image (HSI) Patch
Transformer as the main component of the generator, which utilize adaptive
attention score to capture the internal pixels correlation of the HSI patch and
leverage the spatial-spectral information in a fine-grained way to achieve
optimization of the unmixing process. Experiments on synthetic data and real
hyperspectral data achieve impressive results compared to state-of-the-art
competitors.
","Li Wang, Xiaohua Zhang, Longfei Li, Hongyun Meng, Xianghai Cao",Xianghai Cao,2023-12-20T15:47:21Z
"A consensus-constrained parsimonious Gaussian mixture model for
  clustering hyperspectral images","  The use of hyperspectral imaging to investigate food samples has grown due to
the improved performance and lower cost of spectroscopy instrumentation. Food
engineers use hyperspectral images to classify the type and quality of a food
sample, typically using classification methods. In order to train these
methods, every pixel in each training image needs to be labelled. Typically,
computationally cheap threshold-based approaches are used to label the pixels,
and classification methods are trained based on those labels. However,
threshold-based approaches are subjective and cannot be generalized across
hyperspectral images taken in different conditions and of different foods. Here
a consensus-constrained parsimonious Gaussian mixture model (ccPGMM) is
proposed to label pixels in hyperspectral images using a model-based clustering
approach. The ccPGMM utilizes available information on the labels of a small
number of pixels and the relationship between those pixels and neighbouring
pixels as constraints when clustering the rest of the pixels in the image. A
latent variable model is used to represent the high-dimensional data in terms
of a small number of underlying latent factors. To ensure computational
feasibility, a consensus clustering approach is employed, where the data are
divided into multiple randomly selected subsets of variables and constrained
clustering is applied to each data subset; the clustering results are then
consolidated across all data subsets to provide a consensus clustering
solution. The ccPGMM approach is applied to simulated datasets and real
hyperspectral images of three types of puffed cereal, corn, rice, and wheat.
Improved clustering performance and computational efficiency are demonstrated
when compared to other current state-of-the-art approaches.
","Ganesh Babu, Aoife Gowen, Michael Fop, Isobel Claire Gormley",Isobel Claire Gormley,2024-03-05T22:23:43Z
"Comparative Analysis of Hyperspectral Image Reconstruction Using Deep
  Learning for Agricultural and Biological Applications","  Hyperspectral imaging (HSI) has become a key technology for non-invasive
quality evaluation in various fields, offering detailed insights through
spatial and spectral data. Despite its efficacy, the complexity and high cost
of HSI systems have hindered their widespread adoption. This study addressed
these challenges by exploring deep learning-based hyperspectral image
reconstruction from RGB (Red, Green, Blue) images, particularly for
agricultural products. Specifically, different hyperspectral reconstruction
algorithms, such as Hyperspectral Convolutional Neural Network - Dense
(HSCNN-D), High-Resolution Network (HRNET), and Multi-Scale Transformer Plus
Plus (MST++), were compared to assess the dry matter content of sweet potatoes.
Among the tested reconstruction methods, HRNET demonstrated superior
performance, achieving the lowest mean relative absolute error (MRAE) of 0.07,
root mean square error (RMSE) of 0.03, and the highest peak signal-to-noise
ratio (PSNR) of 32.28 decibels (dB). Some key features were selected using the
genetic algorithm (GA), and their importance was interpreted using explainable
artificial intelligence (XAI). Partial least squares regression (PLSR) models
were developed using the RGB, reconstructed, and ground truth (GT) data. The
visual and spectra quality of these reconstructed methods was compared with GT
data, and predicted maps were generated. The results revealed the prospect of
deep learning-based hyperspectral image reconstruction as a cost-effective and
efficient quality assessment tool for agricultural and biological applications.
","Md. Toukir Ahmed, Arthur Villordon, Mohammed Kamruzzaman",Mohammed Kamruzzaman,2024-05-22T04:20:30Z
Dual Hyperspectral Mamba for Efficient Spectral Compressive Imaging,"  Deep unfolding methods have made impressive progress in restoring 3D
hyperspectral images (HSIs) from 2D measurements through convolution neural
networks or Transformers in spectral compressive imaging. However, they cannot
efficiently capture long-range dependencies using global receptive fields,
which significantly limits their performance in HSI reconstruction. Moreover,
these methods may suffer from local context neglect if we directly utilize
Mamba to unfold a 2D feature map as a 1D sequence for modeling global
long-range dependencies. To address these challenges, we propose a novel Dual
Hyperspectral Mamba (DHM) to explore both global long-range dependencies and
local contexts for efficient HSI reconstruction. After learning informative
parameters to estimate degradation patterns of the CASSI system, we use them to
scale the linear projection and offer noise level for the denoiser (i.e., our
proposed DHM). Specifically, our DHM consists of multiple dual hyperspectral S4
blocks (DHSBs) to restore original HSIs. Particularly, each DHSB contains a
global hyperspectral S4 block (GHSB) to model long-range dependencies across
the entire high-resolution HSIs using global receptive fields, and a local
hyperspectral S4 block (LHSB) to address local context neglect by establishing
structured state-space sequence (S4) models within local windows. Experiments
verify the benefits of our DHM for HSI reconstruction. The source codes and
models will be available at https://github.com/JiahuaDong/DHM.
","Jiahua Dong, Hui Yin, Hongliu Li, Wenbo Li, Yulun Zhang, Salman Khan, Fahad Shahbaz Khan",Fahad Shahbaz Khan,2024-06-01T14:14:40Z
"Unsupervised Hyperspectral and Multispectral Image Blind Fusion Based on
  Deep Tucker Decomposition Network with Spatial-Spectral Manifold Learning","  Hyperspectral and multispectral image fusion aims to generate high spectral
and spatial resolution hyperspectral images (HR-HSI) by fusing high-resolution
multispectral images (HR-MSI) and low-resolution hyperspectral images (LR-HSI).
However, existing fusion methods encounter challenges such as unknown
degradation parameters, incomplete exploitation of the correlation between
high-dimensional structures and deep image features. To overcome these issues,
in this article, an unsupervised blind fusion method for hyperspectral and
multispectral images based on Tucker decomposition and spatial spectral
manifold learning (DTDNML) is proposed. We design a novel deep Tucker
decomposition network that maps LR-HSI and HR-MSI into a consistent feature
space, achieving reconstruction through decoders with shared parameter. To
better exploit and fuse spatial-spectral features in the data, we design a core
tensor fusion network that incorporates a spatial spectral attention mechanism
for aligning and fusing features at different scales. Furthermore, to enhance
the capacity in capturing global information, a Laplacian-based
spatial-spectral manifold constraints is introduced in shared-decoders.
Sufficient experiments have validated that this method enhances the accuracy
and efficiency of hyperspectral and multispectral fusion on different remote
sensing datasets. The source code is available at
https://github.com/Shawn-H-Wang/DTDNML.
","He Wang, Yang Xu, Zebin Wu, Zhihui Wei",Zhihui Wei,2024-09-15T08:58:26Z
"Semisupervised hyperspectral image unmixing using a variational Bayes
  algorithm","  This technical report presents a variational Bayes algorithm for
semisupervised hyperspectral image unmixing. The presented Bayesian model
employs a heavy tailed, nonnegatively truncated Laplace prior over the
abundance coefficients. This prior imposes both the sparsity assumption and the
nonnegativity constraint on the abundance coefficients. Experimental results
conducted on the Aviris Cuprite data set are presented that demonstrate the
effectiveness of the proposed method.
","Konstantinos E. Themelis, Athanasios A. Rontogiannis, Konstantinos D. Koutroumbas",Konstantinos D. Koutroumbas,2014-06-18T13:13:17Z
"Feature Extraction for Hyperspectral Imagery: The Evolution from Shallow
  to Deep (Overview and Toolbox)","  Hyperspectral images provide detailed spectral information through hundreds
of (narrow) spectral channels (also known as dimensionality or bands) with
continuous spectral information that can accurately classify diverse materials
of interest. The increased dimensionality of such data makes it possible to
significantly improve data information content but provides a challenge to the
conventional techniques (the so-called curse of dimensionality) for accurate
analysis of hyperspectral images. Feature extraction, as a vibrant field of
research in the hyperspectral community, evolved through decades of research to
address this issue and extract informative features suitable for data
representation and classification. The advances in feature extraction have been
inspired by two fields of research, including the popularization of image and
signal processing as well as machine (deep) learning, leading to two types of
feature extraction approaches named shallow and deep techniques. This article
outlines the advances in feature extraction approaches for hyperspectral
imagery by providing a technical overview of the state-of-the-art techniques,
providing useful entry points for researchers at different levels, including
students, researchers, and senior researchers, willing to explore novel
investigations on this challenging topic. In more detail, this paper provides a
bird's eye view over shallow (both supervised and unsupervised) and deep
feature extraction approaches specifically dedicated to the topic of
hyperspectral feature extraction and its application on hyperspectral image
classification. Additionally, this paper compares 15 advanced techniques with
an emphasis on their methodological foundations in terms of classification
accuracies. Furthermore, the codes and libraries are shared at
https://github.com/BehnoodRasti/HyFTech-Hyperspectral-Shallow-Deep-Feature-Extraction-Toolbox.
","Behnood Rasti, Danfeng Hong, Renlong Hang, Pedram Ghamisi, Xudong Kang, Jocelyn Chanussot, Jon Atli Benediktsson",Jon Atli Benediktsson,2020-03-05T18:45:22Z
"High-speed hyperspectral four-wave-mixing microscopy with frequency
  combs","  A four-wave-mixing, frequency-comb-based, hyperspectral imaging technique
that is spectrally precise, potentially rapid, and can in principle be applied
to any material, is demonstrated in a near-diffraction-limited microscopy
application.
","Brad C. Smith, Bachana Lomsadze, Steven T. Cundiff",Steven T. Cundiff,2021-04-23T14:04:22Z
"Toulouse Hyperspectral Data Set: a benchmark data set to assess
  semi-supervised spectral representation learning and pixel-wise
  classification techniques","  Airborne hyperspectral images can be used to map the land cover in large
urban areas, thanks to their very high spatial and spectral resolutions on a
wide spectral domain. While the spectral dimension of hyperspectral images is
highly informative of the chemical composition of the land surface, the use of
state-of-the-art machine learning algorithms to map the land cover has been
dramatically limited by the availability of training data. To cope with the
scarcity of annotations, semi-supervised and self-supervised techniques have
lately raised a lot of interest in the community. Yet, the publicly available
hyperspectral data sets commonly used to benchmark machine learning models are
not totally suited to evaluate their generalization performances due to one or
several of the following properties: a limited geographical coverage (which
does not reflect the spectral diversity in metropolitan areas), a small number
of land cover classes and a lack of appropriate standard train / test splits
for semi-supervised and self-supervised learning. Therefore, we release in this
paper the Toulouse Hyperspectral Data Set that stands out from other data sets
in the above-mentioned respects in order to meet key issues in spectral
representation learning and classification over large-scale hyperspectral
images with very few labeled pixels. Besides, we discuss and experiment
self-supervised techniques for spectral representation learning, including the
Masked Autoencoder, and establish a baseline for pixel-wise classification
achieving 85% overall accuracy and 77% F1 score. The Toulouse Hyperspectral
Data Set and our code are publicly available at
https://www.toulouse-hyperspectral-data-set.com and
https://www.github.com/Romain3Ch216/tlse-experiments, respectively.
","Romain Thoreau, Laurent Risser, Véronique Achard, Béatrice Berthelot, Xavier Briottet",Xavier Briottet,2023-11-15T10:49:15Z
"A Variable Splitting Augmented Lagrangian Approach to Linear Spectral
  Unmixing","  This paper presents a new linear hyperspectral unmixing method of the minimum
volume class, termed \emph{simplex identification via split augmented
Lagrangian} (SISAL). Following Craig's seminal ideas, hyperspectral linear
unmixing amounts to finding the minimum volume simplex containing the
hyperspectral vectors. This is a nonconvex optimization problem with convex
constraints. In the proposed approach, the positivity constraints, forcing the
spectral vectors to belong to the convex hull of the endmember signatures, are
replaced by soft constraints. The obtained problem is solved by a sequence of
augmented Lagrangian optimizations. The resulting algorithm is very fast and
able so solve problems far beyond the reach of the current state-of-the art
algorithms. The effectiveness of SISAL is illustrated with simulated data.
",Jose Bioucas-Dias,Jose Bioucas-Dias,2009-04-29T15:31:41Z
"Adaptive band selection snapshot multispectral imaging in the VIS/NIR
  domain","  Hyperspectral imaging has proven its efficiency for target detection
applications but the acquisition mode and the data rate are major issues when
dealing with real-time detection applications. It can be useful to use snapshot
spectral imagers able to acquire all the spectral channels simultaneously on a
single image sensor. Such snapshot spectral imagers suffer from the lack of
spectral resolution. It is then mandatory to carefully select the spectral
content of the acquired image with respect to the proposed application. We
present a novel approach of hyperspectral band selection for target detection
which maximizes the contrast between the background and the target by proper
optimization of positions and linewidths of a limited number of filters. Based
on a set of tunable band-pass filters such as Fabry-Perot filters, the device
should be able to adapt itself to the current scene and the target looked for.
Simulations based on real hyperspectral images show that such snapshot imagers
could compete well against hyperspectral imagers in terms of detection
efficiency while allowing snapshot acquisition, and real-time detection.
","Jean Minet, Jean Taboury, Michel Péalat, Nicolas Roux, Jacques Lonnoy, Yann Ferrec",Yann Ferrec,2010-09-29T09:57:16Z
"Improvement of Anomoly Detection Algorithms in Hyperspectral Images
  using Discrete Wavelet Transform","  Recently anomaly detection (AD) has become an important application for
target detection in hyperspectral remotely sensed images. In many applications,
in addition to high accuracy of detection we need a fast and reliable algorithm
as well. This paper presents a novel method to improve the performance of
current AD algorithms. The proposed method first calculates Discrete Wavelet
Transform (DWT) of every pixel vector of image using Daubechies4 wavelet. Then,
AD algorithm performs on four bands of ""Wavelet transform"" matrix which are the
approximation of main image. In this research some benchmark AD algorithms
including Local RX, DWRX and DWEST have been implemented on Airborne
Visible/Infrared Imaging Spectrometer (AVIRIS) hyperspectral datasets.
Experimental results demonstrate significant improvement of runtime in proposed
method. In addition, this method improves the accuracy of AD algorithms because
of DWT's power in extracting approximation coefficients of signal, which
contain the main behaviour of signal, and abandon the redundant information in
hyperspectral image data.
","Mohsen Zare Baghbidi, Kamal Jamshidi, Ahmad Reza Naghsh Nilchi, Saeid Homayouni",Saeid Homayouni,2012-01-10T11:29:02Z
"Dimensionality Reduction and Classification Feature Using Mutual
  Information Applied to Hyperspectral Images: A Wrapper Strategy Algorithm
  Based on Minimizing the Error Probability Using the Inequality of Fano","  In the feature classification domain, the choice of data affects widely the
results. For the Hyperspectral image, the bands dont all contain the
information; some bands are irrelevant like those affected by various
atmospheric effects, see Figure.4, and decrease the classification accuracy.
And there exist redundant bands to complicate the learning system and product
incorrect prediction [14]. Even the bands contain enough information about the
scene they may can't predict the classes correctly if the dimension of space
images, see Figure.3, is so large that needs many cases to detect the
relationship between the bands and the scene (Hughes phenomenon) [10]. We can
reduce the dimensionality of hyperspectral images by selecting only the
relevant bands (feature selection or subset selection methodology), or
extracting, from the original bands, new bands containing the maximal
information about the classes, using any functions, logical or numerical
(feature extraction methodology) [11][9]. Here we focus on the feature
selection using mutual information. Hyperspectral images have three advantages
regarding the multispectral images [6],
","Elkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine",Driss Aboutajdine,2012-10-31T23:30:59Z
Hyperspectral Data Unmixing Using GNMF Method and Sparseness Constraint,"  Hyperspectral images contain mixed pixels due to low spatial resolution of
hyperspectral sensors. Mixed pixels are pixels containing more than one
distinct material called endmembers. The presence percentages of endmembers in
mixed pixels are called abundance fractions. Spectral unmixing problem refers
to decomposing these pixels into a set of endmembers and abundance fractions.
Due to nonnegativity constraint on abundance fractions, nonnegative matrix
factorization methods (NMF) have been widely used for solving spectral unmixing
problem. In this paper we have used graph regularized (GNMF) method with
sparseness constraint to unmix hyperspectral data. This method applied on
simulated data using AVIRIS Indian Pines dataset and USGS library and results
are quantified based on AAD and SAD measures. Results in comparison with other
methods show that the proposed method can unmix data more effectively.
","Roozbeh Rajabi, Hassan Ghassemian",Hassan Ghassemian,2013-06-29T16:57:44Z
"Advances in Hyperspectral Image Classification: Earth monitoring with
  statistical learning methods","  Hyperspectral images show similar statistical properties to natural grayscale
or color photographic images. However, the classification of hyperspectral
images is more challenging because of the very high dimensionality of the
pixels and the small number of labeled examples typically available for
learning. These peculiarities lead to particular signal processing problems,
mainly characterized by indetermination and complex manifolds. The framework of
statistical learning has gained popularity in the last decade. New methods have
been presented to account for the spatial homogeneity of images, to include
user's interaction via active learning, to take advantage of the manifold
structure with semisupervised learning, to extract and encode invariances, or
to adapt classifiers and image representations to unseen yet similar scenes.
This tutuorial reviews the main advances for hyperspectral remote sensing image
classification through illustrative examples.
","Gustavo Camps-Valls, Devis Tuia, Lorenzo Bruzzone, Jón Atli Benediktsson",Jón Atli Benediktsson,2013-10-18T17:49:45Z
"Hyperspectral pan-sharpening: a variational convex constrained
  formulation to impose parallel level lines, solved with ADMM","  In this paper, we address the issue of hyperspectral pan-sharpening, which
consists in fusing a (low spatial resolution) hyperspectral image HX and a
(high spatial resolution) panchromatic image P to obtain a high spatial
resolution hyperspectral image. The problem is addressed under a variational
convex constrained formulation. The objective favors high resolution spectral
bands with level lines parallel to those of the panchromatic image. This term
is balanced with a total variation term as regularizer. Fit-to-P data and
fit-to-HX data constraints are effectively considered as mathematical
constraints, which depend on the statistics of the data noise measurements. The
developed Alternating Direction Method of Multipliers (ADMM) optimization
scheme enables us to solve this problem efficiently despite the non
differentiabilities and the huge number of unknowns.
","Alexis Huck, François de Vieilleville, Pierre Weiss, Manuel Grizonnet",Manuel Grizonnet,2014-05-10T07:38:19Z
Spectral Unmixing of Hyperspectral Imagery using Multilayer NMF,"  Hyperspectral images contain mixed pixels due to low spatial resolution of
hyperspectral sensors. Spectral unmixing problem refers to decomposing mixed
pixels into a set of endmembers and abundance fractions. Due to nonnegativity
constraint on abundance fractions, nonnegative matrix factorization (NMF)
methods have been widely used for solving spectral unmixing problem. In this
letter we proposed using multilayer NMF (MLNMF) for the purpose of
hyperspectral unmixing. In this approach, spectral signature matrix can be
modeled as a product of sparse matrices. In fact MLNMF decomposes the
observation matrix iteratively in a number of layers. In each layer, we applied
sparseness constraint on spectral signature matrix as well as on abundance
fractions matrix. In this way signatures matrix can be sparsely decomposed
despite the fact that it is not generally a sparse matrix. The proposed
algorithm is applied on synthetic and real datasets. Synthetic data is
generated based on endmembers from USGS spectral library. AVIRIS Cuprite
dataset has been used as a real dataset for evaluation of proposed method.
Results of experiments are quantified based on SAD and AAD measures. Results in
comparison with previously proposed methods show that the multilayer approach
can unmix data more effectively.
","Roozbeh Rajabi, Hassan Ghassemian",Hassan Ghassemian,2014-08-12T19:07:23Z
A graph Laplacian regularization for hyperspectral data unmixing,"  This paper introduces a graph Laplacian regularization in the hyperspectral
unmixing formulation. The proposed regularization relies upon the construction
of a graph representation of the hyperspectral image. Each node in the graph
represents a pixel's spectrum, and edges connect spectrally and spatially
similar pixels. The proposed graph framework promotes smoothness in the
estimated abundance maps and collaborative estimation between homogeneous areas
of the image. The resulting convex optimization problem is solved using the
Alternating Direction Method of Multipliers (ADMM). A special attention is
given to the computational complexity of the algorithm, and Graph-cut methods
are proposed in order to reduce the computational burden. Finally, simulations
conducted on synthetic data illustrate the effectiveness of the graph Laplacian
regularization with respect to other classical regularizations for
hyperspectral unmixing.
","Rita Ammanouil, André Ferrari, Cédric Richard",Cédric Richard,2014-10-14T14:11:43Z
Compressive Hyperspectral Imaging with Side Information,"  A blind compressive sensing algorithm is proposed to reconstruct
hyperspectral images from spectrally-compressed measurements.The
wavelength-dependent data are coded and then superposed, mapping the
three-dimensional hyperspectral datacube to a two-dimensional image. The
inversion algorithm learns a dictionary {\em in situ} from the measurements via
global-local shrinkage priors. By using RGB images as side information of the
compressive sensing system, the proposed approach is extended to learn a
coupled dictionary from the joint dataset of the compressed measurements and
the corresponding RGB images, to improve reconstruction quality. A prototype
camera is built using a liquid-crystal-on-silicon modulator. Experimental
reconstructions of hyperspectral datacubes from both simulated and real
compressed measurements demonstrate the efficacy of the proposed inversion
algorithm, the feasibility of the camera and the benefit of side information.
","Xin Yuan, Tsung-Han Tsai, Ruoyu Zhu, Patrick Llull, David Brady, Lawrence Carin",Lawrence Carin,2015-02-22T19:10:31Z
"SegSALSA-STR: A convex formulation to supervised hyperspectral image
  segmentation using hidden fields and structure tensor regularization","  We present a supervised hyperspectral image segmentation algorithm based on a
convex formulation of a marginal maximum a posteriori segmentation with hidden
fields and structure tensor regularization: Segmentation via the Constraint
Split Augmented Lagrangian Shrinkage by Structure Tensor Regularization
(SegSALSA-STR). This formulation avoids the generally discrete nature of
segmentation problems and the inherent NP-hardness of the integer optimization
associated.
  We extend the Segmentation via the Constraint Split Augmented Lagrangian
Shrinkage (SegSALSA) algorithm by generalizing the vectorial total variation
prior using a structure tensor prior constructed from a patch-based Jacobian.
The resulting algorithm is convex, time-efficient and highly parallelizable.
This shows the potential of combining hidden fields with convex optimization
through the inclusion of different regularizers. The SegSALSA-STR algorithm is
validated in the segmentation of real hyperspectral images.
","Filipe Condessa, Jose Bioucas-Dias, Jelena Kovacevic",Jelena Kovacevic,2015-04-27T11:08:53Z
Multilayer Structured NMF for Spectral Unmixing of Hyperspectral Images,"  One of the challenges in hyperspectral data analysis is the presence of mixed
pixels. Mixed pixels are the result of low spatial resolution of hyperspectral
sensors. Spectral unmixing methods decompose a mixed pixel into a set of
endmembers and abundance fractions. Due to nonnegativity constraint on
abundance fraction values, NMF based methods are well suited to this problem.
In this paper multilayer NMF has been used to improve the results of NMF
methods for spectral unmixing of hyperspectral data under the linear mixing
framework. Sparseness constraint on both spectral signatures and abundance
fractions matrices are used in this paper. Evaluation of the proposed algorithm
is done using synthetic and real datasets in terms of spectral angle and
abundance angle distances. Results show that the proposed algorithm outperforms
other previously proposed methods.
","Roozbeh Rajabi, Hassan Ghassemian",Hassan Ghassemian,2015-06-04T13:53:33Z
"Correntropy Maximization via ADMM - Application to Robust Hyperspectral
  Unmixing","  In hyperspectral images, some spectral bands suffer from low signal-to-noise
ratio due to noisy acquisition and atmospheric effects, thus requiring robust
techniques for the unmixing problem. This paper presents a robust supervised
spectral unmixing approach for hyperspectral images. The robustness is achieved
by writing the unmixing problem as the maximization of the correntropy
criterion subject to the most commonly used constraints. Two unmixing problems
are derived: the first problem considers the fully-constrained unmixing, with
both the non-negativity and sum-to-one constraints, while the second one deals
with the non-negativity and the sparsity-promoting of the abundances. The
corresponding optimization problems are solved efficiently using an alternating
direction method of multipliers (ADMM) approach. Experiments on synthetic and
real hyperspectral images validate the performance of the proposed algorithms
for different scenarios, demonstrating that the correntropy-based unmixing is
robust to outlier bands.
","Fei Zhu, Abderrahim Halimi, Paul Honeine, Badong Chen, Nanning Zheng",Nanning Zheng,2016-02-04T16:21:09Z
Going Deeper with Contextual CNN for Hyperspectral Image Classification,"  In this paper, we describe a novel deep convolutional neural network (CNN)
that is deeper and wider than other existing deep networks for hyperspectral
image classification. Unlike current state-of-the-art approaches in CNN-based
hyperspectral image classification, the proposed network, called contextual
deep CNN, can optimally explore local contextual interactions by jointly
exploiting local spatio-spectral relationships of neighboring individual pixel
vectors. The joint exploitation of the spatio-spectral information is achieved
by a multi-scale convolutional filter bank used as an initial component of the
proposed CNN pipeline. The initial spatial and spectral feature maps obtained
from the multi-scale filter bank are then combined together to form a joint
spatio-spectral feature map. The joint feature map representing rich spectral
and spatial properties of the hyperspectral image is then fed through a fully
convolutional network that eventually predicts the corresponding label of each
pixel vector. The proposed approach is tested on three benchmark datasets: the
Indian Pines dataset, the Salinas dataset and the University of Pavia dataset.
Performance comparison shows enhanced classification performance of the
proposed approach over the current state-of-the-art on the three datasets.
","Hyungtae Lee, Heesung Kwon",Heesung Kwon,2016-04-12T18:44:34Z
"Combining multiscale features for classification of hyperspectral
  images: a sequence based kernel approach","  Nowadays, hyperspectral image classification widely copes with spatial
information to improve accuracy. One of the most popular way to integrate such
information is to extract hierarchical features from a multiscale segmentation.
In the classification context, the extracted features are commonly concatenated
into a long vector (also called stacked vector), on which is applied a
conventional vector-based machine learning technique (e.g. SVM with Gaussian
kernel). In this paper, we rather propose to use a sequence structured kernel:
the spectrum kernel. We show that the conventional stacked vector-based kernel
is actually a special case of this kernel. Experiments conducted on various
publicly available hyperspectral datasets illustrate the improvement of the
proposed kernel w.r.t. conventional ones using the same hierarchical spatial
features.
","Yanwei Cui, Laetitia Chapel, Sébastien Lefèvre",Sébastien Lefèvre,2016-06-15T21:19:54Z
"Spatial Context based Angular Information Preserving Projection for
  Hyperspectral Image Classification","  Dimensionality reduction is a crucial preprocessing for hyperspectral data
analysis - finding an appropriate subspace is often required for subsequent
image classification. In recent work, we proposed supervised angular
information based dimensionality reduction methods to find effective subspaces.
Since unlabeled data are often more readily available compared to labeled data,
we propose an unsupervised projection that finds a lower dimensional subspace
where local angular information is preserved. To exploit spatial information
from the hyperspectral images, we further extend our unsupervised projection to
incorporate spatial contextual information around each pixel in the image.
Additionally, we also propose a sparse representation based classifier which is
optimized to exploit spatial information during classification - we hence
assert that our proposed projection is particularly suitable for classifiers
where local similarity and spatial context are both important. Experimental
results with two real-world hyperspectral datasets demonstrate that our
proposed methods provide a robust classification performance.
","Minshan Cui, Saurabh Prasad",Saurabh Prasad,2016-07-15T17:38:34Z
"Hyperspectral Unmixing with Endmember Variability using Partial
  Membership Latent Dirichlet Allocation","  The application of Partial Membership Latent Dirichlet Allocation(PM-LDA) for
hyperspectral endmember estimation and spectral unmixing is presented. PM-LDA
provides a model for a hyperspectral image analysis that accounts for spectral
variability and incorporates spatial information through the use of
superpixel-based 'documents.' In our application of PM-LDA, we employ the
Normal Compositional Model in which endmembers are represented as Normal
distributions to account for spectral variability and proportion vectors are
modeled as random variables governed by a Dirichlet distribution. The use of
the Dirichlet distribution enforces positivity and sum-to-one constraints on
the proportion values. Algorithm results on real hyperspectral data indicate
that PM-LDA produces endmember distributions that represent the ground truth
classes and their associated variability.
","Sheng Zou, Alina Zare",Alina Zare,2016-09-12T17:32:41Z
"Scan-less hyperspectral dual-comb single-pixel-imaging in both amplitude
  and phase","  We have developed a hyperspectral imaging scheme that involves a combination
of dual-comb spectroscopy and Hadamard-transform-based single-pixel imaging.
The scheme enables us to obtain 12,000 hyperspectral images of amplitude and
phase at a spatial resolution of 46 um without mechanical scanning. The
spectral resolution is 20 MHz, as determined by the linewidth of a single comb
mode, and the spectral interval is 100 MHz over a spectral range of 1.2 THz
centred at 191.5 THz. As an initial demonstration of our scheme, we obtained
spectroscopic images of a standard test chart through an etalon plate. The
thickness of an absorptive chromium-coated layer on a float-glass substrate was
determined to be 70 nm from the hyperspectral phase images in the near-infrared
wavelength region.
","Kyuki Shibuya, Takeo Minamikawa, Yasuhiro Mizutani, Hirotsugu Yamamoto, Kaoru Minoshima, Takeshi Yasui, Tetsuo Iwata",Tetsuo Iwata,2017-05-06T02:01:58Z
Endoscopic Depth Measurement and Super-Spectral-Resolution Imaging,"  Intra-operative measurements of tissue shape and multi/ hyperspectral
information have the potential to provide surgical guidance and decision making
support. We report an optical probe based system to combine sparse
hyperspectral measurements and spectrally-encoded structured lighting (SL) for
surface measurements. The system provides informative signals for navigation
with a surgical interface. By rapidly switching between SL and white light (WL)
modes, SL information is combined with structure-from-motion (SfM) from white
light images, based on SURF feature detection and Lucas-Kanade (LK) optical
flow to provide quasi-dense surface shape reconstruction with known scale in
real-time. Furthermore, ""super-spectral-resolution"" was realized, whereby the
RGB images and sparse hyperspectral data were integrated to recover dense
pixel-level hyperspectral stacks, by using convolutional neural networks to
upscale the wavelength dimension. Validation and demonstration of this system
is reported on ex vivo/in vivo animal/ human experiments.
","Jianyu Lin, Neil T. Clancy, Yang Hu, Ji Qi, Taran Tatla, Danail Stoyanov, Lena Maier-Hein, Daniel S. Elson",Daniel S. Elson,2017-06-19T17:49:20Z
"Machine learning regression on hyperspectral data to estimate multiple
  water parameters","  In this paper, we present a regression framework involving several machine
learning models to estimate water parameters based on hyperspectral data.
Measurements from a multi-sensor field campaign, conducted on the River Elbe,
Germany, represent the benchmark dataset. It contains hyperspectral data and
the five water parameters chlorophyll a, green algae, diatoms, CDOM and
turbidity. We apply a PCA for the high-dimensional data as a possible
preprocessing step. Then, we evaluate the performance of the regression
framework with and without this preprocessing step. The regression results of
the framework clearly reveal the potential of estimating water parameters based
on hyperspectral data with machine learning. The proposed framework provides
the basis for further investigations, such as adapting the framework to
estimate water parameters of different inland waters.
","Philipp M. Maier, Sina Keller",Sina Keller,2018-05-03T15:13:02Z
"Object Tracking in Hyperspectral Videos with Convolutional Features and
  Kernelized Correlation Filter","  Target tracking in hyperspectral videos is a new research topic. In this
paper, a novel method based on convolutional network and Kernelized Correlation
Filter (KCF) framework is presented for tracking objects of interest in
hyperspectral videos. We extract a set of normalized three-dimensional cubes
from the target region as fixed convolution filters which contain spectral
information surrounding a target. The feature maps generated by convolutional
operations are combined to form a three-dimensional representation of an
object, thereby providing effective encoding of local spectral-spatial
information. We show that a simple two-layer convolutional networks is
sufficient to learn robust representations without the need of offline training
with a large dataset. In the tracking step, KCF is adopted to distinguish
targets from neighboring environment. Experimental results demonstrate that the
proposed method performs well on sample hyperspectral videos, and outperforms
several state-of-the-art methods tested on grayscale and color videos in the
same scene.
","Kun Qian, Jun Zhou, Fengchao Xiong, Huixin Zhou, Juan Du",Juan Du,2018-10-28T14:35:26Z
Multispectral and Hyperspectral Image Fusion by MS/HS Fusion Net,"  Hyperspectral imaging can help better understand the characteristics of
different materials, compared with traditional image systems. However, only
high-resolution multispectral (HrMS) and low-resolution hyperspectral (LrHS)
images can generally be captured at video rate in practice. In this paper, we
propose a model-based deep learning approach for merging an HrMS and LrHS
images to generate a high-resolution hyperspectral (HrHS) image. In specific,
we construct a novel MS/HS fusion model which takes the observation models of
low-resolution images and the low-rankness knowledge along the spectral mode of
HrHS image into consideration. Then we design an iterative algorithm to solve
the model by exploiting the proximal gradient method. And then, by unfolding
the designed algorithm, we construct a deep network, called MS/HS Fusion Net,
with learning the proximal operators and model parameters by convolutional
neural networks. Experimental results on simulated and real data substantiate
the superiority of our method both visually and quantitatively as compared with
state-of-the-art methods along this line of research.
","Qi Xie, Minghao Zhou, Qian Zhao, Deyu Meng, Wangmeng Zuo, Zongben Xu",Zongben Xu,2019-01-10T17:16:59Z
Sparsity Constrained Distributed Unmixing of Hyperspectral Data,"  Spectral unmixing (SU) is a technique to characterize mixed pixels in
hyperspectral images measured by remote sensors. Most of the spectral unmixing
algorithms are developed using the linear mixing models. To estimate endmembers
and fractional abundance matrices in a blind problem, nonnegative matrix
factorization (NMF) and its developments are widely used in the SU problem. One
of the constraints which was added to NMF is sparsity, that was regularized by
Lq norm. In this paper, a new algorithm based on distributed optimization is
suggested for spectral unmixing. In the proposed algorithm, a network including
single-node clusters is employed. Each pixel in the hyperspectral images is
considered as a node in this network. The sparsity constrained distributed
unmixing is optimized with diffusion least mean p-power (LMP) strategy, and
then the update equations for fractional abundance and signature matrices are
obtained. Afterwards the proposed algorithm is analyzed for different values of
LMP power and Lq norms. Simulation results based on defined performance metrics
illustrate the advantage of the proposed algorithm in spectral unmixing of
hyperspectral data compared with other methods.
","Sara Khoshsokhan, Roozbeh Rajabi, Hadi Zayyani",Hadi Zayyani,2019-02-20T15:16:06Z
Hyperspectral Data Augmentation,"  Data augmentation is a popular technique which helps improve generalization
capabilities of deep neural networks. It plays a pivotal role in remote-sensing
scenarios in which the amount of high-quality ground truth data is limited, and
acquiring new examples is costly or impossible. This is a common problem in
hyperspectral imaging, where manual annotation of image data is difficult,
expensive, and prone to human bias. In this letter, we propose online data
augmentation of hyperspectral data which is executed during the inference
rather than before the training of deep networks. This is in contrast to all
other state-of-the-art hyperspectral augmentation algorithms which increase the
size (and representativeness) of training sets. Additionally, we introduce a
new principal component analysis based augmentation. The experiments revealed
that our data augmentation algorithms improve generalization of deep networks,
work in real-time, and the online approach can be effectively combined with
offline techniques to enhance the classification accuracy.
","Jakub Nalepa, Michal Myller, Michal Kawulok",Michal Kawulok,2019-03-13T16:27:38Z
"Self-supervised Hyperspectral Image Restoration using Separable Image
  Prior","  Supervised learning with a convolutional neural network is recognized as a
powerful means of image restoration. However, most such methods have been
designed for application to grayscale and/or color images; therefore, they have
limited success when applied to hyperspectral image restoration. This is
partially owing to large datasets being difficult to collect, and also the
heavy computational load associated with the restoration of an image with many
spectral bands. To address this difficulty, we propose a novel self-supervised
learning strategy for application to hyperspectral image restoration. Our
method automatically creates a training dataset from a single degraded image
and trains a denoising network without any clear images. Another notable
feature of our method is the use of a separable convolutional layer. We
undertake experiments to prove that the use of a separable network allows us to
acquire the prior of a hyperspectral image and to realize efficient
restoration. We demonstrate the validity of our method through extensive
experiments and show that our method has better characteristics than those that
are currently regarded as state-of-the-art.
","Ryuji Imamura, Tatsuki Itasaka, Masahiro Okuda",Masahiro Okuda,2019-07-01T10:51:57Z
"Unsupervised Segmentation of Hyperspectral Images Using 3D Convolutional
  Autoencoders","  Hyperspectral image analysis has become an important topic widely researched
by the remote sensing community. Classification and segmentation of such
imagery help understand the underlying materials within a scanned scene, since
hyperspectral images convey a detailed information captured in a number of
spectral bands. Although deep learning has established the state of the art in
the field, it still remains challenging to train well-generalizing models due
to the lack of ground-truth data. In this letter, we tackle this problem and
propose an end-to-end approach to segment hyperspectral images in a fully
unsupervised way. We introduce a new deep architecture which couples 3D
convolutional autoencoders with clustering. Our multi-faceted experimental
study---performed over benchmark and real-life data---revealed that our
approach delivers high-quality segmentation without any prior class labels.
","Jakub Nalepa, Michal Myller, Yasuteru Imai, Ken-ichi Honda, Tomomi Takeda, Marek Antoniak",Marek Antoniak,2019-07-20T22:17:10Z
"3D CNN with Localized Residual Connections for Hyperspectral Image
  Classification","  In this paper we propose a novel 3D CNN network with localized residual
connections for hyperspectral image classification. Our work chalks a
comparative study with the existing methods employed for abstracting deeper
features and propose a model which incorporates residual features from multiple
stages in the network. The proposed architecture processes individual
spatiospectral feature rich cubes from hyperspectral images through 3D
convolutional layers. The residual connections result in improved performance
due to assimilation of both low-level and high-level features. We conduct
experiments over Pavia University and Pavia Center dataset for performance
analysis. We compare our method with two recent state-of-the-art methods for
hyperspectral image classification method. The proposed network outperforms the
existing approaches by a good margin.
","Shivangi Dwivedi, Murari Mandal, Shekhar Yadav, Santosh Kumar Vipparthi",Santosh Kumar Vipparthi,2019-12-06T06:46:01Z
"Discriminative Robust Deep Dictionary Learning for Hyperspectral Image
  Classification","  This work proposes a new framework for deep learning that has been
particularly tailored for hyperspectral image classification. We learn multiple
levels of dictionaries in a robust fashion. The last layer is discriminative
that learns a linear classifier. The training proceeds greedily, at a time a
single level of dictionary is learnt and the coefficients used to train the
next level. The coefficients from the final level are used for classification.
Robustness is incorporated by minimizing the absolute deviations instead of the
more popular Euclidean norm. The inbuilt robustness helps combat mixed noise
(Gaussian and sparse) present in hyperspectral images. Results show that our
proposed techniques outperforms all other deep learning methods Deep Belief
Network (DBN), Stacked Autoencoder (SAE) and Convolutional Neural Network
(CNN). The experiments have been carried out on benchmark hyperspectral imaging
datasets.
","Vanika Singhal, Hemant K. Aggarwal, Snigdha Tariyal, Angshul Majumdar",Angshul Majumdar,2019-12-11T10:59:25Z
"Row-Sparse Discriminative Deep Dictionary Learning for Hyperspectral
  Image Classification","  In recent studies in hyperspectral imaging, biometrics and energy analytics,
the framework of deep dictionary learning has shown promise. Deep dictionary
learning outperforms other traditional deep learning tools when training data
is limited; therefore hyperspectral imaging is one such example that benefits
from this framework. Most of the prior studies were based on the unsupervised
formulation; and in all cases, the training algorithm was greedy and hence
sub-optimal. This is the first work that shows how to learn the deep dictionary
learning problem in a joint fashion. Moreover, we propose a new discriminative
penalty to the said framework. The third contribution of this work is showing
how to incorporate stochastic regularization techniques into the deep
dictionary learning framework. Experimental results on hyperspectral image
classification shows that the proposed technique excels over all
state-of-the-art deep and shallow (traditional) learning based methods
published in recent times.
","Vanika Singhal, Angshul Majumdar",Angshul Majumdar,2019-12-11T10:00:31Z
Deep Manifold Embedding for Hyperspectral Image Classification,"  Deep learning methods have played a more and more important role in
hyperspectral image classification. However, the general deep learning methods
mainly take advantage of the information of sample itself or the pairwise
information between samples while ignore the intrinsic data structure within
the whole data. To tackle this problem, this work develops a novel deep
manifold embedding method(DMEM) for hyperspectral image classification. First,
each class in the image is modelled as a specific nonlinear manifold and the
geodesic distance is used to measure the correlation between the samples. Then,
based on the hierarchical clustering, the manifold structure of the data can be
captured and each nonlinear data manifold can be divided into several
sub-classes. Finally, considering the distribution of each sub-class and the
correlation between different subclasses, the DMEM is constructed to preserve
the estimated geodesic distances on the data manifold between the learned low
dimensional features of different samples. Experiments over three real-world
hyperspectral image datasets have demonstrated the effectiveness of the
proposed method.
","Zhiqiang Gong, Weidong Hu, Xiaoyong Du, Ping Zhong, Panhe Hu",Panhe Hu,2019-12-24T09:41:56Z
Hyperspectral-Multispectral Image Fusion with Weighted LASSO,"  Spectral imaging enables spatially-resolved identification of materials in
remote sensing, biomedicine, and astronomy. However, acquisition times require
balancing spectral and spatial resolution with signal-to-noise. Hyperspectral
imaging provides superior material specificity, while multispectral images are
faster to collect at greater fidelity. We propose an approach for fusing
hyperspectral and multispectral images to provide high-quality hyperspectral
output. The proposed optimization leverages the least absolute shrinkage and
selection operator (LASSO) to perform variable selection and regularization.
Computational time is reduced by applying the alternating direction method of
multipliers (ADMM), as well as initializing the fusion image by estimating it
using maximum a posteriori (MAP) based on Hardie's method. We demonstrate that
the proposed sparse fusion and reconstruction provides quantitatively superior
results when compared to existing methods on publicly available images.
Finally, we show how the proposed method can be practically applied in
biomedical infrared spectroscopic microscopy.
","Nguyen Tran, Rupali Mankar, David Mayerich, Zhu Han",Zhu Han,2020-03-15T23:07:56Z
"Compressive spectral image classification using 3D coded convolutional
  neural network","  Hyperspectral image classification (HIC) is an active research topic in
remote sensing. Hyperspectral images typically generate large data cubes posing
big challenges in data acquisition, storage, transmission and processing. To
overcome these limitations, this paper develops a novel deep learning HIC
approach based on compressive measurements of coded-aperture snapshot spectral
imagers (CASSI), without reconstructing the complete hyperspectral data cube. A
new kind of deep learning strategy, namely 3D coded convolutional neural
network (3D-CCNN) is proposed to efficiently solve for the classification
problem, where the hardware-based coded aperture is regarded as a pixel-wise
connected network layer. An end-to-end training method is developed to jointly
optimize the network parameters and the coded apertures with periodic
structures. The accuracy of classification is effectively improved by
exploiting the synergy between the deep learning network and coded apertures.
The superiority of the proposed method is assessed over the state-of-the-art
HIC methods on several hyperspectral datasets.
","Hao Zhang, Xu Ma, Xianhong Zhao, Gonzalo R. Arce",Gonzalo R. Arce,2020-09-23T15:05:57Z
"Weighted Hierarchical Sparse Representation for Hyperspectral Target
  Detection","  Hyperspectral target detection has been widely studied in the field of remote
sensing. However, background dictionary building issue and the correlation
analysis of target and background dictionary issue have not been well studied.
To tackle these issues, a \emph{Weighted Hierarchical Sparse Representation}
for hyperspectral target detection is proposed. The main contributions of this
work are listed as follows. 1) Considering the insufficient representation of
the traditional background dictionary building by dual concentric window
structure, a hierarchical background dictionary is built considering the local
and global spectral information simultaneously. 2) To reduce the impureness
impact of background dictionary, target scores from target dictionary and
background dictionary are weighted considered according to the dictionary
quality. Three hyperspectral target detection data sets are utilized to verify
the effectiveness of the proposed method. And the experimental results show a
better performance when compared with the state-of-the-arts.
","Chenlu Wei, Zhiyu Jiang, Yuan Yuan",Yuan Yuan,2021-05-11T12:50:16Z
"Exploring the Intrinsic Probability Distribution for Hyperspectral
  Anomaly Detection","  In recent years, neural network-based anomaly detection methods have
attracted considerable attention in the hyperspectral remote sensing domain due
to the powerful reconstruction ability compared with traditional methods.
However, actual probability distribution statistics hidden in the latent space
are not discovered by exploiting the reconstruction error because the
probability distribution of anomalies is not explicitly modeled. To address the
issue, we propose a novel probability distribution representation detector
(PDRD) that explores the intrinsic distribution of both the background and the
anomalies in original data for hyperspectral anomaly detection in this paper.
First, we represent the hyperspectral data with multivariate Gaussian
distributions from a probabilistic perspective. Then, we combine the local
statistics with the obtained distributions to leverage the spatial information.
Finally, the difference between the corresponding distributions of the test
pixel and the average expectation of the pixels in the Chebyshev neighborhood
is measured by computing the modified Wasserstein distance to acquire the
detection map. We conduct the experiments on four real data sets to evaluate
the performance of our proposed method. Experimental results demonstrate the
accuracy and efficiency of our proposed method compared to the state-of-the-art
detection methods.
","Shaoqi Yu, Xiaorun Li, Shuhan Chen, Liaoying Zhao",Liaoying Zhao,2021-05-14T11:42:09Z
"A survey on computational spectral reconstruction methods from RGB to
  hyperspectral imaging","  Hyperspectral imaging enables versatile applications due to its competence in
capturing abundant spatial and spectral information, which are crucial for
identifying substances. However, the devices for acquiring hyperspectral images
are expensive and complicated. Therefore, many alternative spectral imaging
methods have been proposed by directly reconstructing the hyperspectral
information from lower-cost, more available RGB images. We present a thorough
investigation of these state-of-the-art spectral reconstruction methods from
the widespread RGB images. A systematic study and comparison of more than 25
methods has revealed that most of the data-driven deep learning methods are
superior to prior-based methods in terms of reconstruction accuracy and quality
despite lower speeds. This comprehensive review can serve as a fruitful
reference source for peer researchers, thus further inspiring future
development directions in related domains.
","Jingang Zhang, Runmu Su, Wenqi Ren, Qiang Fu, Felix Heide, Yunfeng Nie",Yunfeng Nie,2021-06-30T09:52:41Z
Distributed Unmixing of Hyperspectral Data With Sparsity Constraint,"  Spectral unmixing (SU) is a data processing problem in hyperspectral remote
sensing. The significant challenge in the SU problem is how to identify
endmembers and their weights, accurately. For estimation of signature and
fractional abundance matrices in a blind problem, nonnegative matrix
factorization (NMF) and its developments are used widely in the SU problem. One
of the constraints which was added to NMF is sparsity constraint that was
regularized by L 1/2 norm. In this paper, a new algorithm based on distributed
optimization has been used for spectral unmixing. In the proposed algorithm, a
network including single-node clusters has been employed. Each pixel in
hyperspectral images considered as a node in this network. The distributed
unmixing with sparsity constraint has been optimized with diffusion LMS
strategy, and then the update equations for fractional abundance and signature
matrices are obtained. Simulation results based on defined performance metrics,
illustrate advantage of the proposed algorithm in spectral unmixing of
hyperspectral data compared with other methods. The results show that the AAD
and SAD of the proposed approach are improved respectively about 6 and 27
percent toward distributed unmixing in SNR=25dB.
","Sara Khoshsokhan, Roozbeh Rajabi, Hadi Zayyani",Hadi Zayyani,2017-11-03T17:23:49Z
"GMM-Based Synthetic Samples for Classification of Hyperspectral Images
  With Limited Training Data","  The amount of training data that is required to train a classifier scales
with the dimensionality of the feature data. In hyperspectral remote sensing,
feature data can potentially become very high dimensional. However, the amount
of training data is oftentimes limited. Thus, one of the core challenges in
hyperspectral remote sensing is how to perform multi-class classification using
only relatively few training data points.
  In this work, we address this issue by enriching the feature matrix with
synthetically generated sample points. This synthetic data is sampled from a
GMM fitted to each class of the limited training data. Although, the true
distribution of features may not be perfectly modeled by the fitted GMM, we
demonstrate that a moderate augmentation by these synthetic samples can
effectively replace a part of the missing training samples. We show the
efficacy of the proposed approach on two hyperspectral datasets. The median
gain in classification performance is $5\%$. It is also encouraging that this
performance gain is remarkably stable for large variations in the number of
added samples, which makes it much easier to apply this method to real-world
applications.
","AmirAbbas Davari, Erchan Aptoula, Berrin Yanikoglu, Andreas Maier, Christian Riess",Christian Riess,2017-12-13T14:12:06Z
Cross-domain CNN for Hyperspectral Image Classification,"  In this paper, we address the dataset scarcity issue with the hyperspectral
image classification. As only a few thousands of pixels are available for
training, it is difficult to effectively learn high-capacity Convolutional
Neural Networks (CNNs). To cope with this problem, we propose a novel
cross-domain CNN containing the shared parameters which can co-learn across
multiple hyperspectral datasets. The network also contains the non-shared
portions designed to handle the dataset specific spectral characteristics and
the associated classification tasks. Our approach is the first attempt to learn
a CNN for multiple hyperspectral datasets, in an end-to-end fashion. Moreover,
we have experimentally shown that the proposed network trained on three of the
widely used datasets outperform all the baseline networks which are trained on
single dataset.
","Hyungtae Lee, Sungmin Eum, Heesung Kwon",Heesung Kwon,2018-01-31T23:02:08Z
"Generative Adversarial Networks and Probabilistic Graph Models for
  Hyperspectral Image Classification","  High spectral dimensionality and the shortage of annotations make
hyperspectral image (HSI) classification a challenging problem. Recent studies
suggest that convolutional neural networks can learn discriminative spatial
features, which play a paramount role in HSI interpretation. However, most of
these methods ignore the distinctive spectral-spatial characteristic of
hyperspectral data. In addition, a large amount of unlabeled data remains an
unexploited gold mine for efficient data use. Therefore, we proposed an
integration of generative adversarial networks (GANs) and probabilistic
graphical models for HSI classification. Specifically, we used a
spectral-spatial generator and a discriminator to identify land cover
categories of hyperspectral cubes. Moreover, to take advantage of a large
amount of unlabeled data, we adopted a conditional random field to refine the
preliminary classification results generated by GANs. Experimental results
obtained using two commonly studied datasets demonstrate that the proposed
framework achieved encouraging classification accuracy using a small number of
data for training.
","Zilong Zhong, Jonathan Li",Jonathan Li,2018-02-10T01:33:52Z
"Hyperspectral unmixing with spectral variability using adaptive bundles
  and double sparsity","  Spectral variability is one of the major issue when conducting hyperspectral
unmixing. Within a given image composed of some elementary materials (herein
referred to as endmember classes), the spectral signature characterizing these
classes may spatially vary due to intrinsic component fluctuations or external
factors (illumination). These redundant multiple endmember spectra within each
class adversely affect the performance of unmixing methods. This paper proposes
a mixing model that explicitly incorporates a hierarchical structure of
redundant multiple spectra representing each class. The proposed method is
designed to promote sparsity on the selection of both spectra and classes
within each pixel. The resulting unmixing algorithm is able to adaptively
recover several bundles of endmember spectra associated with each class and
robustly estimate abundances. In addition, its flexibility allows a variable
number of classes to be present within each pixel of the hyperspectral image to
be unmixed. The proposed method is compared with other state-of-the-art
unmixing methods that incorporate sparsity using both simulated and real
hyperspectral data. The results show that the proposed method can successfully
determine the variable number of classes present within each class and estimate
the corresponding class abundances.
","Tatsumi Uezato, Mathieu Fauvel, Nicolas Dobigeon",Nicolas Dobigeon,2018-04-30T11:49:37Z
Segmentation-Aware Hyperspectral Image Classification,"  In this paper, we propose an unified hyperspectral image classification
method which takes three-dimensional hyperspectral data cube as an input and
produces a classification map. In the proposed method, a deep neural network
which uses spectral and spatial information together with residual connections,
and pixel affinity network based segmentation-aware superpixels are used
together. In the architecture, segmentation-aware superpixels run on the
initial classification map of deep residual network, and apply majority voting
on obtained results. Experimental results show that our propoped method yields
state-of-the-art results in two benchmark datasets. Moreover, we also show that
the segmentation-aware superpixels have great contribution to the success of
hyperspectral image classification methods in cases where training data is
insufficient.
","Berkan Demirel, Omer Ozdil, Yunus Emre Esin, Safak Ozturk",Safak Ozturk,2019-05-22T16:03:01Z
"LEt-SNE: A Hybrid Approach To Data Embedding and Visualization of
  Hyperspectral Imagery","  Hyperspectral Imagery (and Remote Sensing in general) captured from UAVs or
satellites are highly voluminous in nature due to the large spatial extent and
wavelengths captured by them. Since analyzing these images requires a huge
amount of computational time and power, various dimensionality reduction
techniques have been used for feature reduction. Some popular techniques among
these falter when applied to Hyperspectral Imagery due to the famed curse of
dimensionality. In this paper, we propose a novel approach, LEt-SNE, which
combines graph based algorithms like t-SNE and Laplacian Eigenmaps into a model
parameterized by a shallow feed forward network. We introduce a new term,
Compression Factor, that enables our method to combat the curse of
dimensionality. The proposed algorithm is suitable for manifold visualization
and sample clustering with labelled or unlabelled data. We demonstrate that our
method is competitive with current state-of-the-art methods on hyperspectral
remote sensing datasets in public domain.
","Megh Shukla, Biplab Banerjee, Krishna Mohan Buddhiraju",Krishna Mohan Buddhiraju,2019-10-19T15:45:15Z
"Hyperspectral Image Classification Based on Sparse Modeling of Spectral
  Blocks","  Hyperspectral images provide abundant spatial and spectral information that
is very valuable for material detection in diverse areas of practical science.
The high-dimensions of data lead to many processing challenges that can be
addressed via existent spatial and spectral redundancies. In this paper, a
sparse modeling framework is proposed for hyperspectral image classification.
Spectral blocks are introduced to be used along with spatial groups to jointly
exploit spectral and spatial redundancies. To reduce the computational
complexity of sparse modeling, spectral blocks are used to break the
high-dimensional optimization problems into small-size sub-problems that are
faster to solve. Furthermore, the proposed sparse structure enables to extract
the most discriminative spectral blocks and further reduce the computational
burden. Experiments on three benchmark datasets, i.e., Pavia University Image
and Indian Pines Image verify that the proposed method leads to a robust sparse
modeling of hyperspectral images and improves the classification accuracy
compared to several state-of-the-art methods. Moreover, the experiments
demonstrate that the proposed method requires less processing time.
","Saeideh Ghanbari Azar, Saeed Meshgini, Tohid Yousefi Rezaii, Soosan Beheshti",Soosan Beheshti,2020-05-17T08:18:13Z
Dual-Comb Real-Time Molecular Fingerprint Imaging,"  Hyperspectral imaging provides spatially resolved spectral information.
Utilising dual frequency combs as active illumination sources, hyperspectral
imaging with ultra-high spectral resolution can be implemented in a scan-free
manner when a detector array is used for heterodyne detection. However, relying
on low-noise detector arrays, this approach is currently limited to the
near-infrared regime. Here, we show that dual-comb hyperspectral imaging can be
performed with an uncooled near-to-mid-infrared detector by exploiting the
detector array's high frame-rate and the combs' high-mutual coherence. The
system simultaneously acquires hyperspectral data in 30~spectral channels
across 16'384 pixel, from which molecule-specific gas concentration images can
be derived. Artificial intelligence enables rapid data reduction and real-time
image reconstruction. Owing to the detector array's sensitivity from 1~$\mu$m
to 5~$\mu$m wavelength, this demonstration lays the foundation for versatile
imaging of molecular fingerprint signatures across the infrared
wavelength-regime in real-time.
","T. Voumard, T. Wildi, V. Brasch, R. Gutiérrez Álvarez, G. Vergara Ogando, T. Herr",T. Herr,2020-06-03T09:13:32Z
Dual-Stage Approach Toward Hyperspectral Image Super-Resolution,"  Hyperspectral image produces high spectral resolution at the sacrifice of
spatial resolution. Without reducing the spectral resolution, improving the
resolution in the spatial domain is a very challenging problem. Motivated by
the discovery that hyperspectral image exhibits high similarity between
adjacent bands in a large spectral range, in this paper, we explore a new
structure for hyperspectral image super-resolution (DualSR), leading to a
dual-stage design, i.e., coarse stage and fine stage. In coarse stage, five
bands with high similarity in a certain spectral range are divided into three
groups, and the current band is guided to study the potential knowledge. Under
the action of alternative spectral fusion mechanism, the coarse SR image is
super-resolved in band-by-band. In order to build model from a global
perspective, an enhanced back-projection method via spectral angle constraint
is developed in fine stage to learn the content of spatial-spectral
consistency, dramatically improving the performance gain. Extensive experiments
demonstrate the effectiveness of the proposed coarse stage and fine stage.
Besides, our network produces state-of-the-art results against existing works
in terms of spatial reconstruction and spectral fidelity.
","Qiang Li, Yuan Yuan, Xiuping Jia, Qi Wang",Qi Wang,2022-04-09T04:36:44Z
"Active Diffusion and VCA-Assisted Image Segmentation of Hyperspectral
  Images","  Hyperspectral images encode rich structure that can be exploited for material
discrimination by machine learning algorithms. This article introduces the
Active Diffusion and VCA-Assisted Image Segmentation (ADVIS) for active
material discrimination. ADVIS selects high-purity, high-density pixels that
are far in diffusion distance (a data-dependent metric) from other high-purity,
high-density pixels in the hyperspectral image. The ground truth labels of
these pixels are queried and propagated to the rest of the image. The ADVIS
active learning algorithm is shown to strongly outperform its fully
unsupervised clustering algorithm counterpart, suggesting that the
incorporation of a very small number of carefully-selected ground truth labels
can result in substantially superior material discrimination in hyperspectral
images.
","Sam L. Polk, Kangning Cui, Robert J. Plemmons, James M. Murphy",James M. Murphy,2022-04-13T11:00:52Z
"Multiple Instance Hybrid Estimator for Hyperspectral Target
  Characterization and Sub-pixel Target Detection","  The Multiple Instance Hybrid Estimator for discriminative target
characterization from imprecisely labeled hyperspectral data is presented. In
many hyperspectral target detection problems, acquiring accurately labeled
training data is difficult. Furthermore, each pixel containing target is likely
to be a mixture of both target and non-target signatures (i.e., sub-pixel
targets), making extracting a pure prototype signature for the target class
from the data extremely difficult. The proposed approach addresses these
problems by introducing a data mixing model and optimizing the response of the
hybrid sub-pixel detector within a multiple instance learning framework. The
proposed approach iterates between estimating a set of discriminative target
and non-target signatures and solving a sparse unmixing problem. After learning
target signatures, a signature based detector can then be applied on test data.
Both simulated and real hyperspectral target detection experiments show the
proposed algorithm is effective at learning discriminative target signatures
and achieves superior performance over state-of-the-art comparison algorithms.
","Changzhe Jiao, Chao Chen, Ronald G. McGarvey, Stephanie Bohlman, Licheng Jiao, Alina Zare",Alina Zare,2017-10-31T17:19:57Z
"Hyper-Hue and EMAP on Hyperspectral Images for Supervised Layer
  Decomposition of Old Master Drawings","  Old master drawings were mostly created step by step in several layers using
different materials. To art historians and restorers, examination of these
layers brings various insights into the artistic work process and helps to
answer questions about the object, its attribution and its authenticity.
However, these layers typically overlap and are oftentimes difficult to
differentiate with the unaided eye. For example, a common layer combination is
red chalk under ink.
  In this work, we propose an image processing pipeline that operates on
hyperspectral images to separate such layers. Using this pipeline, we show that
hyperspectral images enable better layer separation than RGB images, and that
spectral focus stacking aids the layer separation. In particular, we propose to
use two descriptors in hyperspectral historical document analysis, namely
hyper-hue and extended multi-attribute profile (EMAP). Our comparative results
with other features underline the efficacy of the three proposed improvements.
","AmirAbbas Davari, Nikolaos Sakaltras, Armin Haeberle, Sulaiman Vesal, Vincent Christlein, Andreas Maier, Christian Riess",Christian Riess,2018-01-29T12:29:44Z
"A two-stage method for spectral-spatial classification of hyperspectral
  images","  This paper proposes a novel two-stage method for the classification of
hyperspectral images. Pixel-wise classifiers, such as the classical support
vector machine (SVM), consider spectral information only; therefore they would
generate noisy classification results as spatial information is not utilized.
Many existing methods, such as morphological profiles, superpixel segmentation,
and composite kernels, exploit the spatial information too. In this paper, we
propose a two-stage approach to incorporate the spatial information. In the
first stage, an SVM is used to estimate the class probability for each pixel.
The resulting probability map for each class will be noisy. In the second
stage, a variational denoising method is used to restore these noisy
probability maps to get a good classification map. Our proposed method
effectively utilizes both spectral and spatial information of the hyperspectral
data sets. Experimental results on three widely used real hyperspectral data
sets indicate that our method is very competitive when compared with current
state-of-the-art methods, especially when the inter-class spectra are similar
or the percentage of the training pixels is high.
","Raymond H. Chan, Kelvin K. Kan, Mila Nikolova, Robert J. Plemmons",Robert J. Plemmons,2018-06-03T17:20:15Z
"LiteDenseNet: A Lightweight Network for Hyperspectral Image
  Classification","  Hyperspectral Image (HSI) classification based on deep learning has been an
attractive area in recent years. However, as a kind of data-driven algorithm,
deep learning method usually requires numerous computational resources and
high-quality labelled dataset, while the cost of high-performance computing and
data annotation is expensive. In this paper, to reduce dependence on massive
calculation and labelled samples, we propose a lightweight network architecture
(LiteDenseNet) based on DenseNet for Hyperspectral Image Classification.
Inspired by GoogLeNet and PeleeNet, we design a 3D two-way dense layer to
capture the local and global features of the input. As convolution is a
computationally intensive operation, we introduce group convolution to decrease
calculation cost and parameter size further. Thus, the number of parameters and
the consumptions of calculation are observably less than contrapositive deep
learning methods, which means LiteDenseNet owns simpler architecture and higher
efficiency. A series of quantitative experiences on 6 widely used hyperspectral
datasets show that the proposed LiteDenseNet obtains the state-of-the-art
performance, even though when the absence of labelled samples is severe.
","Rui Li, Chenxi Duan",Chenxi Duan,2020-04-17T08:38:52Z
GAN-based Hyperspectral Anomaly Detection,"  In this paper, we propose a generative adversarial network (GAN)-based
hyperspectral anomaly detection algorithm. In the proposed algorithm, we train
a GAN model to generate a synthetic background image which is close to the
original background image as much as possible. By subtracting the synthetic
image from the original one, we are able to remove the background from the
hyperspectral image. Anomaly detection is performed by applying Reed-Xiaoli
(RX) anomaly detector (AD) on the spectral difference image. In the
experimental part, we compare our proposed method with the classical RX,
Weighted-RX (WRX) and support vector data description (SVDD)-based anomaly
detectors and deep autoencoder anomaly detection (DAEAD) method on synthetic
and real hyperspectral images. The detection results show that our proposed
algorithm outperforms the other methods in the benchmark.
","Sertac Arisoy, Nasser M. Nasrabadi, Koray Kayabol",Koray Kayabol,2020-07-05T20:31:50Z
"Unsupervised Pixel-wise Hyperspectral Anomaly Detection via Autoencoding
  Adversarial Networks","  We propose a completely unsupervised pixel-wise anomaly detection method for
hyperspectral images. The proposed method consists of three steps called data
preparation, reconstruction, and detection. In the data preparation step, we
apply a background purification to train the deep network in an unsupervised
manner. In the reconstruction step, we propose to use three different deep
autoencoding adversarial network (AEAN) models including 1D-AEAN, 2D-AEAN, and
3D-AEAN which are developed for working on spectral, spatial, and joint
spectral-spatial domains, respectively. The goal of the AEAN models is to
generate synthesized hyperspectral images (HSIs) which are close to real ones.
A reconstruction error map (REM) is calculated between the original and the
synthesized image pixels. In the detection step, we propose to use a WRX-based
detector in which the pixel weights are obtained according to REM. We compare
our proposed method with the classical RX, WRX, support vector data
description-based (SVDD), collaborative representation-based detector (CRD),
adaptive weight deep belief network (AW-DBN) detector and deep autoencoder
anomaly detection (DAEAD) method on real hyperspectral datasets. The
experimental results show that the proposed approach outperforms other
detectors in the benchmark.
","Sertac Arisoy, Nasser M. Nasrabadi, Koray Kayabol",Koray Kayabol,2021-01-21T19:52:18Z
"Snapshot Hyperspectral Imaging Based on Weighted High-order Singular
  Value Regularization","  Snapshot hyperspectral imaging can capture the 3D hyperspectral image (HSI)
with a single 2D measurement and has attracted increasing attention recently.
Recovering the underlying HSI from the compressive measurement is an ill-posed
problem and exploiting the image prior is essential for solving this ill-posed
problem. However, existing reconstruction methods always start from modeling
image prior with the 1D vector or 2D matrix and cannot fully exploit the
structurally spectral-spatial nature in 3D HSI, thus leading to a poor
fidelity. In this paper, we propose an effective high-order tensor optimization
based method to boost the reconstruction fidelity for snapshot hyperspectral
imaging. We first build high-order tensors by exploiting the spatial-spectral
correlation in HSI. Then, we propose a weight high-order singular value
regularization (WHOSVR) based low-rank tensor recovery model to characterize
the structure prior of HSI. By integrating the structure prior in WHOSVR with
the system imaging process, we develop an optimization framework for HSI
reconstruction, which is finally solved via the alternating minimization
algorithm. Extensive experiments implemented on two representative systems
demonstrate that our method outperforms state-of-the-art methods.
","Niankai Cheng, Hua Huang, Lei Zhang, Lizhi Wang",Lizhi Wang,2021-01-22T02:54:55Z
"Hyperspectral Image Classification: Artifacts of Dimension Reduction on
  Hybrid CNN","  Convolutional Neural Networks (CNN) has been extensively studied for
Hyperspectral Image Classification (HSIC) more specifically, 2D and 3D CNN
models have proved highly efficient in exploiting the spatial and spectral
information of Hyperspectral Images. However, 2D CNN only considers the spatial
information and ignores the spectral information whereas 3D CNN jointly
exploits spatial-spectral information at a high computational cost. Therefore,
this work proposed a lightweight CNN (3D followed by 2D-CNN) model which
significantly reduces the computational cost by distributing spatial-spectral
feature extraction across a lighter model alongside a preprocessing that has
been carried out to improve the classification results. Five benchmark
Hyperspectral datasets (i.e., SalinasA, Salinas, Indian Pines, Pavia
University, Pavia Center, and Botswana) are used for experimental evaluation.
The experimental results show that the proposed pipeline outperformed in terms
of generalization performance, statistical significance, and computational
complexity, as compared to the state-of-the-art 2D/3D CNN models except
commonly used computationally expensive design choices.
","Muhammad Ahmad, Sidrah Shabbir, Rana Aamir Raza, Manuel Mazzara, Salvatore Distefano, Adil Mehmood Khan",Adil Mehmood Khan,2021-01-25T18:43:57Z
"Multiscale Clustering of Hyperspectral Images Through Spectral-Spatial
  Diffusion Geometry","  Clustering algorithms partition a dataset into groups of similar points. The
primary contribution of this article is the Multiscale Spatially-Regularized
Diffusion Learning (M-SRDL) clustering algorithm, which uses
spatially-regularized diffusion distances to efficiently and accurately learn
multiple scales of latent structure in hyperspectral images. The M-SRDL
clustering algorithm extracts clusterings at many scales from a hyperspectral
image and outputs these clusterings' variation of information-barycenter as an
exemplar for all underlying cluster structure. We show that incorporating
spatial regularization into a multiscale clustering framework results in
smoother and more coherent clusters when applied to hyperspectral data,
yielding more accurate clustering labels.
","Sam L. Polk, James M. Murphy",James M. Murphy,2021-03-29T17:24:28Z
"Unsupervised Hyperspectral Stimulated Raman Microscopy Image
  Enhancement: Denoising and Segmentation via One-Shot Deep Learning","  Hyperspectral stimulated Raman scattering (SRS) microscopy is a label-free
technique for biomedical and mineralogical imaging which can suffer from low
signal to noise ratios. Here we demonstrate the use of an unsupervised deep
learning neural network for rapid and automatic denoising of SRS images: UHRED
(Unsupervised Hyperspectral Resolution Enhancement and Denoising). UHRED is
capable of one-shot learning; only one hyperspectral image is needed, with no
requirements for training on previously labelled datasets or images.
Furthermore, by applying a k-means clustering algorithm to the processed data,
we demonstrate automatic, unsupervised image segmentation, yielding, without
prior knowledge of the sample, intuitive chemical species maps, as shown here
for a lithium ore sample.
","Pedram Abdolghader, Andrew Ridsdale, Tassos Grammatikopoulos, Gavin Resch, Francois Legare, Albert Stolow, Adrian F. Pegoraro, Isaac Tamblyn",Isaac Tamblyn,2021-04-14T22:36:24Z
Domain Adaptor Networks for Hyperspectral Image Recognition,"  We consider the problem of adapting a network trained on three-channel color
images to a hyperspectral domain with a large number of channels. To this end,
we propose domain adaptor networks that map the input to be compatible with a
network trained on large-scale color image datasets such as ImageNet. Adaptors
enable learning on small hyperspectral datasets where training a network from
scratch may not be effective. We investigate architectures and strategies for
training adaptors and evaluate them on a benchmark consisting of multiple
hyperspectral datasets. We find that simple schemes such as linear projection
or subset selection are often the most effective, but can lead to a loss in
performance in some cases. We also propose a novel multi-view adaptor where of
the inputs are combined in an intermediate layer of the network in an order
invariant manner that provides further improvements. We present extensive
experiments by varying the number of training examples in the benchmark to
characterize the accuracy and computational trade-offs offered by these
adaptors.
","Gustavo Perez, Subhransu Maji",Subhransu Maji,2021-08-03T15:06:39Z
"A Joint Morphological Profiles and Patch Tensor Change Detection for
  Hyperspectral Imagery","  Multi-temporal hyperspectral images can be used to detect changed
information, which has gradually attracted researchers' attention. However,
traditional change detection algorithms have not deeply explored the relevance
of spatial and spectral changed features, which leads to low detection
accuracy. To better excavate both spectral and spatial information of changed
features, a joint morphology and patch-tensor change detection (JMPT) method is
proposed. Initially, a patch-based tensor strategy is adopted to exploit
similar property of spatial structure, where the non-overlapping local patch
image is reshaped into a new tensor cube, and then three-order Tucker
decompositon and image reconstruction strategies are adopted to obtain more
robust multi-temporal hyperspectral datasets. Meanwhile, multiple morphological
profiles including max-tree and min-tree are applied to extract different
attributes of multi-temporal images. Finally, these results are fused to
general a final change detection map. Experiments conducted on two real
hyperspectral datasets demonstrate that the proposed detector achieves better
detection performance.
","Zengfu Hou, Wei Li",Wei Li,2022-01-20T07:34:17Z
Dictionary learning for clustering on hyperspectral images,"  Dictionary learning and sparse coding have been widely studied as mechanisms
for unsupervised feature learning. Unsupervised learning could bring enormous
benefit to the processing of hyperspectral images and to other remote sensing
data analysis because labelled data are often scarce in this field. We propose
a method for clustering the pixels of hyperspectral images using sparse
coefficients computed from a representative dictionary as features. We show
empirically that the proposed method works more effectively than clustering on
the original pixels. We also demonstrate that our approach, in certain
circumstances, outperforms the clustering results of features extracted using
principal component analysis and non-negative matrix factorisation.
Furthermore, our method is suitable for applications in repetitively clustering
an ever-growing amount of high-dimensional data, which is the case when working
with hyperspectral satellite imagery.
","Joshua Bruton, Hairong Wang",Hairong Wang,2022-02-02T12:22:33Z
Toward Efficient Hyperspectral Image Processing inside Camera Pixels,"  Hyperspectral cameras generate a large amount of data due to the presence of
hundreds of spectral bands as opposed to only three channels (red, green, and
blue) in traditional cameras. This requires a significant amount of data
transmission between the hyperspectral image sensor and a processor used to
classify/detect/track the images, frame by frame, expending high energy and
causing bandwidth and security bottlenecks. To mitigate this problem, we
propose a form of processing-in-pixel (PIP) that leverages advanced CMOS
technologies to enable the pixel array to perform a wide range of complex
operations required by the modern convolutional neural networks (CNN) for
hyperspectral image recognition (HSI). Consequently, our PIP-optimized custom
CNN layers effectively compress the input data, significantly reducing the
bandwidth required to transmit the data downstream to the HSI processing unit.
This reduces the average energy consumption associated with pixel array of
cameras and the CNN processing unit by 25.06x and 3.90x respectively, compared
to existing hardware implementations. Our custom models yield average test
accuracies within 0.56% of the baseline models for the standard HSI benchmarks.
","Gourav Datta, Zihan Yin, Ajey Jacob, Akhilesh R. Jaiswal, Peter A. Beerel",Peter A. Beerel,2022-03-11T01:06:02Z
"Multi-Temporal Spatial-Spectral Comparison Network for Hyperspectral
  Anomalous Change Detection","  Hyperspectral anomalous change detection has been a challenging task for its
emphasis on the dynamics of small and rare objects against the prevalent
changes. In this paper, we have proposed a Multi-Temporal spatial-spectral
Comparison Network for hyperspectral anomalous change detection (MTC-NET). The
whole model is a deep siamese network, aiming at learning the prevalent
spectral difference resulting from the complex imaging conditions from the
hyperspectral images by contrastive learning. A three-dimensional spatial
spectral attention module is designed to effectively extract the spatial
semantic information and the key spectral differences. Then the gaps between
the multi-temporal features are minimized, boosting the alignment of the
semantic and spectral features and the suppression of the multi-temporal
background spectral difference. The experiments on the ""Viareggio 2013""
datasets demonstrate the effectiveness of proposed MTC-NET.
","Meiqi Hu, Chen Wu, Bo Du",Bo Du,2022-05-23T15:41:27Z
"Bio-inspired Compact, High-resolution Snapshot Hyperspectral Imaging
  System with 3D Printed Glass Lightguide Array","  To address the major challenges to obtain high spatial resolution in snapshot
hyperspectral imaging, 3D printed glass lightguide array has been developed to
sample the intermediate image in high spatial resolution and redistribute the
pixels in the output end to achieve high spectral resolution. Curved 3D printed
lightguide array can significantly simplify the snapshot hyperspectral imaging
system, achieve better imaging performance, and reduce the system complexity
and cost. We have developed two-photon polymerization process to print glass
lightguide array, and demonstrated the system performance with biological
samples. This new snapshot technology will catalyze new hyperspectral imaging
system development and open doors for new applications from UV to IR.
","Zhihan Hong, Yuanyuan Sun, Piaoran Ye, Douglas A. Loy, Rongguang Liang",Rongguang Liang,2022-09-16T08:09:14Z
Entropic Descent Archetypal Analysis for Blind Hyperspectral Unmixing,"  In this paper, we introduce a new algorithm based on archetypal analysis for
blind hyperspectral unmixing, assuming linear mixing of endmembers. Archetypal
analysis is a natural formulation for this task. This method does not require
the presence of pure pixels (i.e., pixels containing a single material) but
instead represents endmembers as convex combinations of a few pixels present in
the original hyperspectral image. Our approach leverages an entropic gradient
descent strategy, which (i) provides better solutions for hyperspectral
unmixing than traditional archetypal analysis algorithms, and (ii) leads to
efficient GPU implementations. Since running a single instance of our algorithm
is fast, we also propose an ensembling mechanism along with an appropriate
model selection procedure that make our method robust to hyper-parameter
choices while keeping the computational complexity reasonable. By using six
standard real datasets, we show that our approach outperforms state-of-the-art
matrix factorization and recent deep learning methods. We also provide an
open-source PyTorch implementation: https://github.com/inria-thoth/EDAA.
","Alexandre Zouaoui, Gedeon Muhawenayo, Behnood Rasti, Jocelyn Chanussot, Julien Mairal",Julien Mairal,2022-09-22T13:34:21Z
"Sketched Multi-view Subspace Learning for Hyperspectral Anomalous Change
  Detection","  In recent years, multi-view subspace learning has been garnering increasing
attention. It aims to capture the inner relationships of the data that are
collected from multiple sources by learning a unified representation. In this
way, comprehensive information from multiple views is shared and preserved for
the generalization processes. As a special branch of temporal series
hyperspectral image (HSI) processing, the anomalous change detection task
focuses on detecting very small changes among different temporal images.
However, when the volume of datasets is very large or the classes are
relatively comprehensive, existing methods may fail to find those changes
between the scenes, and end up with terrible detection results. In this paper,
inspired by the sketched representation and multi-view subspace learning, a
sketched multi-view subspace learning (SMSL) model is proposed for HSI
anomalous change detection. The proposed model preserves major information from
the image pairs and improves computational complexity by using a sketched
representation matrix. Furthermore, the differences between scenes are
extracted by utilizing the specific regularizer of the self-representation
matrices. To evaluate the detection effectiveness of the proposed SMSL model,
experiments are conducted on a benchmark hyperspectral remote sensing dataset
and a natural hyperspectral dataset, and compared with other state-of-the art
approaches.
","Shizhen Chang, Michael Kopp, Pedram Ghamisi",Pedram Ghamisi,2022-10-09T14:08:17Z
"Hybridization of filter and wrapper approaches for the dimensionality
  reduction and classification of hyperspectral images","  The high dimensionality of hyperspectral images often imposes a heavy
computational burden for image processing. Therefore, dimensionality reduction
is often an essential step in order to remove the irrelevant, noisy and
redundant bands. And consequently, increase the classification accuracy.
However, identification of useful bands from hundreds or even thousands of
related bands is a nontrivial task. This paper aims at identifying a small set
of bands, for improving computational speed and prediction accuracy. Hence, we
have proposed a hybrid algorithm through band selection for dimensionality
reduction of hyperspectral images. The proposed approach combines mutual
information gain (MIG), Minimum Redundancy Maximum Relevance (mRMR) and Error
probability of Fano with Support Vector Machine Bands Elimination (SVM-PF). The
proposed approach is compared to an effective reproduced filters approach based
on mutual information. Experimental results on HSI AVIRIS 92AV3C have shown
that the proposed approach outperforms the reproduced filters.
  Keywords - Hyperspectral images, Classification, band Selection, filter,
wrapper, mutual information, information gain.
","Asma Elmaizi, Maria Merzouqi, Elkebir Sarhrouni, Ahmed hammouch, Chafik Nacir",Chafik Nacir,2022-10-29T05:25:10Z
"A new filter for dimensionality reduction and classification of
  hyperspectral images using GLCM features and mutual information","  Dimensionality reduction is an important preprocessing step of the
hyperspectral images classification (HSI), it is inevitable task. Some methods
use feature selection or extraction algorithms based on spectral and spatial
information. In this paper, we introduce a new methodology for dimensionality
reduction and classification of HSI taking into account both spectral and
spatial information based on mutual information. We characterise the spatial
information by the texture features extracted from the grey level cooccurrence
matrix (GLCM); we use Homogeneity, Contrast, Correlation and Energy. For
classification, we use support vector machine (SVM). The experiments are
performed on three well-known hyperspectral benchmark datasets. The proposed
algorithm is compared with the state of the art methods. The obtained results
of this fusion show that our method outperforms the other approaches by
increasing the classification accuracy in a good timing. This method may be
improved for more performance
  Keywords: hyperspectral images; classification; spectral and spatial
features; grey level cooccurrence matrix; GLCM; mutual information; support
vector machine; SVM.
","Hasna Nhaila, Elkebir Sarhrouni, Ahmed Hammouch",Ahmed Hammouch,2022-11-01T13:19:08Z
"Autonomous Polycrystalline Material Decomposition for Hyperspectral
  Neutron Tomography","  Hyperspectral neutron tomography is an effective method for analyzing
crystalline material samples with complex compositions in a non-destructive
manner. Since the counts in the hyperspectral neutron radiographs directly
depend on the neutron cross-sections, materials may exhibit contrasting neutron
responses across wavelengths. Therefore, it is possible to extract the unique
signatures associated with each material and use them to separate the
crystalline phases simultaneously.
  We introduce an autonomous material decomposition (AMD) algorithm to
automatically characterize and localize polycrystalline structures using Bragg
edges with contrasting neutron responses from hyperspectral data. The algorithm
estimates the linear attenuation coefficient spectra from the measured
radiographs and then uses these spectra to perform polycrystalline material
decomposition and reconstructs 3D material volumes to localize materials in the
spatial domain. Our results demonstrate that the method can accurately estimate
both the linear attenuation coefficient spectra and associated reconstructions
on both simulated and experimental neutron data.
","Mohammad Samin Nur Chowdhury, Diyu Yang, Shimin Tang, Singanallur V. Venkatakrishnan, Hassina Z. Bilheux, Gregery T. Buzzard, Charles A. Bouman",Charles A. Bouman,2023-02-27T16:16:39Z
"EMS-Net: Efficient Multi-Temporal Self-Attention For Hyperspectral
  Change Detection","  Hyperspectral change detection plays an essential role of monitoring the
dynamic urban development and detecting precise fine object evolution and
alteration. In this paper, we have proposed an original Efficient
Multi-temporal Self-attention Network (EMS-Net) for hyperspectral change
detection. The designed EMS module cuts redundancy of those similar and
containing-no-changes feature maps, computing efficient multi-temporal change
information for precise binary change map. Besides, to explore the clustering
characteristics of the change detection, a novel supervised contrastive loss is
provided to enhance the compactness of the unchanged. Experiments implemented
on two hyperspectral change detection datasets manifests the out-standing
performance and validity of proposed method.
","Meiqi Hu, Chen Wu, Bo Du",Bo Du,2023-03-24T02:11:22Z
"SAWU-Net: Spatial Attention Weighted Unmixing Network for Hyperspectral
  Images","  Hyperspectral unmixing is a critical yet challenging task in hyperspectral
image interpretation. Recently, great efforts have been made to solve the
hyperspectral unmixing task via deep autoencoders. However, existing networks
mainly focus on extracting spectral features from mixed pixels, and the
employment of spatial feature prior knowledge is still insufficient. To this
end, we put forward a spatial attention weighted unmixing network, dubbed as
SAWU-Net, which learns a spatial attention network and a weighted unmixing
network in an end-to-end manner for better spatial feature exploitation. In
particular, we design a spatial attention module, which consists of a pixel
attention block and a window attention block to efficiently model pixel-based
spectral information and patch-based spatial information, respectively. While
in the weighted unmixing framework, the central pixel abundance is dynamically
weighted by the coarse-grained abundances of surrounding pixels. In addition,
SAWU-Net generates dynamically adaptive spatial weights through the spatial
attention mechanism, so as to dynamically integrate surrounding pixels more
effectively. Experimental results on real and synthetic datasets demonstrate
the better accuracy and superiority of SAWU-Net, which reflects the
effectiveness of the proposed spatial attention mechanism.
","Lin Qi, Xuewen Qin, Feng Gao, Junyu Dong, Xinbo Gao",Xinbo Gao,2023-04-22T05:22:50Z
"Quantitative Ink Analysis: Estimating the Number of Inks in Documents
  through Hyperspectral Imaging","  In the field of document forensics, ink analysis plays a crucial role in
determining the authenticity of legal and historic documents and detecting
forgery. Visual examination alone is insufficient for distinguishing visually
similar inks, necessitating the use of advanced scientific techniques. This
paper proposes an ink analysis technique based on hyperspectral imaging, which
enables the examination of documents in hundreds of narrowly spaced spectral
bands, revealing hidden details. The main objective of this study is to
identify the number of distinct inks used in a document. Three clustering
algorithms, namely k-means, Agglomerative, and c-means, are employed to
estimate the number of inks present. The methodology involves data extraction,
ink pixel segmentation, and ink number determination. The results demonstrate
the effectiveness of the proposed technique in identifying ink clusters and
distinguishing between different inks. The analysis of a hyperspectral cube
dataset reveals variations in spectral reflectance across different bands and
distinct spectral responses among the 12 lines, indicating the presence of
multiple inks. The clustering algorithms successfully identify ink clusters,
with k-means clustering showing superior classification performance. These
findings contribute to the development of reliable methodologies for ink
analysis using hyperspectral imaging, enhancing the
","Aneeqa Abrar, Hamza Iqbal",Hamza Iqbal,2023-06-09T09:55:20Z
Deep Learning Hyperspectral Pansharpening on large scale PRISMA dataset,"  In this work, we assess several deep learning strategies for hyperspectral
pansharpening. First, we present a new dataset with a greater extent than any
other in the state of the art. This dataset, collected using the ASI PRISMA
satellite, covers about 262200 km2, and its heterogeneity is granted by
randomly sampling the Earth's soil. Second, we adapted several state of the art
approaches based on deep learning to fit PRISMA hyperspectral data and then
assessed, quantitatively and qualitatively, the performance in this new
scenario. The investigation has included two settings: Reduced Resolution (RR)
to evaluate the techniques in a supervised environment and Full Resolution (FR)
for a real-world evaluation. The main purpose is the evaluation of the
reconstruction fidelity of the considered methods. In both scenarios, for the
sake of completeness, we also included machine-learning-free approaches. From
this extensive analysis has emerged that data-driven neural network methods
outperform machine-learning-free approaches and adapt better to the task of
hyperspectral pansharpening, both in RR and FR protocols.
","Simone Zini, Mirko Paolo Barbato, Flavio Piccoli, Paolo Napoletano",Paolo Napoletano,2023-07-21T16:10:22Z
"Hyper-Drive: Visible-Short Wave Infrared Hyperspectral Imaging Datasets
  for Robots in Unstructured Environments","  Hyperspectral sensors have enjoyed widespread use in the realm of remote
sensing; however, they must be adapted to a format in which they can be
operated onboard mobile robots. In this work, we introduce a first-of-its-kind
system architecture with snapshot hyperspectral cameras and point spectrometers
to efficiently generate composite datacubes from a robotic base. Our system
collects and registers datacubes spanning the visible to shortwave infrared
(660-1700 nm) spectrum while simultaneously capturing the ambient solar
spectrum reflected off a white reference tile. We collect and disseminate a
large dataset of more than 500 labeled datacubes from on-road and off-road
terrain compliant with the ATLAS ontology to further the integration and
demonstration of hyperspectral imaging (HSI) as beneficial in terrain class
separability. Our analysis of this data demonstrates that HSI is a significant
opportunity to increase understanding of scene composition from a robot-centric
context. All code and data are open source online:
https://river-lab.github.io/hyper_drive_data
","Nathaniel Hanson, Benjamin Pyatski, Samuel Hibbard, Charles DiMarzio, Taşkın Padır",Taşkın Padır,2023-08-15T22:01:00Z
"An Open Hyperspectral Dataset with Sea-Land-Cloud Ground-Truth from the
  HYPSO-1 Satellite","  Hyperspectral Imaging, employed in satellites for space remote sensing, like
HYPSO-1, faces constraints due to few labeled data sets, affecting the training
of AI models demanding these ground-truth annotations. In this work, we
introduce The HYPSO-1 Sea-Land-Cloud-Labeled Dataset, an open dataset with 200
diverse hyperspectral images from the HYPSO-1 mission, available in both raw
and calibrated forms for scientific research in Earth observation. Moreover, 38
of these images from different countries include ground-truth labels at
pixel-level totaling about 25 million spectral signatures labeled for
sea/land/cloud categories. To demonstrate the potential of the dataset and its
labeled subset, we have additionally optimized a deep learning model (1D Fully
Convolutional Network), achieving superior performance to the current state of
the art. The complete dataset, ground-truth labels, deep learning model, and
software code are openly accessible for download at the website
https://ntnu-smallsat-lab.github.io/hypso1_sea_land_clouds_dataset/ .
","Jon A. Justo, Joseph Garrett, Dennis D. Langer, Marie B. Henriksen, Radu T. Ionescu, Tor A. Johansen",Tor A. Johansen,2023-08-25T21:35:22Z
Locality-Aware Hyperspectral Classification,"  Hyperspectral image classification is gaining popularity for high-precision
vision tasks in remote sensing, thanks to their ability to capture visual
information available in a wide continuum of spectra. Researchers have been
working on automating Hyperspectral image classification, with recent efforts
leveraging Vision-Transformers. However, most research models only spectra
information and lacks attention to the locality (i.e., neighboring pixels),
which may be not sufficiently discriminative, resulting in performance
limitations. To address this, we present three contributions: i) We introduce
the Hyperspectral Locality-aware Image TransformEr (HyLITE), a vision
transformer that models both local and spectral information, ii) A novel
regularization function that promotes the integration of local-to-global
information, and iii) Our proposed approach outperforms competing baselines by
a significant margin, achieving up to 10% gains in accuracy. The trained models
and the code are available at HyLITE.
","Fangqin Zhou, Mert Kilickaya, Joaquin Vanschoren",Joaquin Vanschoren,2023-09-04T12:29:32Z
"MultiHU-TD: Multifeature Hyperspectral Unmixing Based on Tensor
  Decomposition","  Hyperspectral unmixing allows representing mixed pixels as a set of pure
materials weighted by their abundances. Spectral features alone are often
insufficient, so it is common to rely on other features of the scene. Matrix
models become insufficient when the hyperspectral image (HSI) is represented as
a high-order tensor with additional features in a multimodal, multifeature
framework. Tensor models such as canonical polyadic decomposition allow for
this kind of unmixing but lack a general framework and interpretability of the
results. In this article, we propose an interpretable methodological framework
for low-rank multifeature hyperspectral unmixing based on tensor decomposition
(MultiHU-TD) that incorporates the abundance sum-to-one constraint in the
alternating optimization alternating direction method of multipliers (ADMM)
algorithm and provide in-depth mathematical, physical, and graphical
interpretation and connections with the extended linear mixing model. As
additional features, we propose to incorporate mathematical morphology and
reframe a previous work on neighborhood patches within MultiHU-TD. Experiments
on real HSIs showcase the interpretability of the model and the analysis of the
results. Python and MATLAB implementations are made available on GitHub.
","Mohamad Jouni, Mauro Dalla Mura, Lucas Drumetz, Pierre Comon",Pierre Comon,2023-10-05T19:38:01Z
"ADASR: An Adversarial Auto-Augmentation Framework for Hyperspectral and
  Multispectral Data Fusion","  Deep learning-based hyperspectral image (HSI) super-resolution, which aims to
generate high spatial resolution HSI (HR-HSI) by fusing hyperspectral image
(HSI) and multispectral image (MSI) with deep neural networks (DNNs), has
attracted lots of attention. However, neural networks require large amounts of
training data, hindering their application in real-world scenarios. In this
letter, we propose a novel adversarial automatic data augmentation framework
ADASR that automatically optimizes and augments HSI-MSI sample pairs to enrich
data diversity for HSI-MSI fusion. Our framework is sample-aware and optimizes
an augmentor network and two downsampling networks jointly by adversarial
learning so that we can learn more robust downsampling networks for training
the upsampling network. Extensive experiments on two public classical
hyperspectral datasets demonstrate the effectiveness of our ADASR compared to
the state-of-the-art methods.
","Jinghui Qin, Lihuang Fang, Ruitao Lu, Liang Lin, Yukai Shi",Yukai Shi,2023-10-11T07:30:37Z
"A Survey of Graph and Attention Based Hyperspectral Image Classification
  Methods for Remote Sensing Data","  The use of Deep Learning techniques for classification in Hyperspectral
Imaging (HSI) is rapidly growing and achieving improved performances. Due to
the nature of the data captured by sensors that produce HSI images, a common
issue is the dimensionality of the bands that may or may not contribute to the
label class distinction. Due to the widespread nature of class labels,
Principal Component Analysis is a common method used for reducing the
dimensionality. However,there may exist methods that incorporate all bands of
the Hyperspectral image with the help of the Attention mechanism. Furthermore,
to yield better spectral spatial feature extraction, recent methods have also
explored the usage of Graph Convolution Networks and their unique ability to
use node features in prediction, which is akin to the pixel spectral makeup. In
this survey we present a comprehensive summary of Graph based and Attention
based methods to perform Hyperspectral Image Classification for remote sensing
and aerial HSI images. We also summarize relevant datasets on which these
techniques have been evaluated and benchmark the processing techniques.
","Aryan Vats, Manan Suri",Manan Suri,2023-10-16T00:42:25Z
"Deep-Learning-based Change Detection with Spaceborne Hyperspectral
  PRISMA data","  Change detection (CD) methods have been applied to optical data for decades,
while the use of hyperspectral data with a fine spectral resolution has been
rarely explored. CD is applied in several sectors, such as environmental
monitoring and disaster management. Thanks to the PRecursore IperSpettrale
della Missione operativA (PRISMA), hyperspectral-from-space CD is now possible.
In this work, we apply standard and deep-learning (DL) CD methods to different
targets, from natural to urban areas. We propose a pipeline starting from
coregistration, followed by CD with a full-spectrum algorithm and by a DL
network developed for optical data. We find that changes in vegetation and
built environments are well captured. The spectral information is valuable to
identify subtle changes and the DL methods are less affected by noise compared
to the statistical method, but atmospheric effects and the lack of reliable
ground truth represent a major challenge to hyperspectral CD.
","J. F. Amieva, A. Austoni, M. A. Brovelli, L. Ansalone, P. Naylor, F. Serva, B. Le Saux",B. Le Saux,2023-10-20T16:22:53Z
"Deep Intrinsic Decomposition with Adversarial Learning for Hyperspectral
  Image Classification","  Convolutional neural networks (CNNs) have been demonstrated their powerful
ability to extract discriminative features for hyperspectral image
classification. However, general deep learning methods for CNNs ignore the
influence of complex environmental factor which enlarges the intra-class
variance and decreases the inter-class variance. This multiplies the difficulty
to extract discriminative features. To overcome this problem, this work
develops a novel deep intrinsic decomposition with adversarial learning, namely
AdverDecom, for hyperspectral image classification to mitigate the negative
impact of environmental factors on classification performance. First, we
develop a generative network for hyperspectral image (HyperNet) to extract the
environmental-related feature and category-related feature from the image.
Then, a discriminative network is constructed to distinguish different
environmental categories. Finally, a environmental and category joint learning
loss is developed for adversarial learning to make the deep model learn
discriminative features. Experiments are conducted over three commonly used
real-world datasets and the comparison results show the superiority of the
proposed method. The implementation of the proposed method and other compared
methods could be accessed at https://github.com/shendu-sw/Adversarial Learning
Intrinsic Decomposition for the sake of reproducibility.
","Zhiqiang Gong, Xian Zhou, Wen Yao",Wen Yao,2023-10-28T00:41:25Z
"Hyperspectral Image Reconstruction via Combinatorial Embedding of
  Cross-Channel Spatio-Spectral Clues","  Existing learning-based hyperspectral reconstruction methods show limitations
in fully exploiting the information among the hyperspectral bands. As such, we
propose to investigate the chromatic inter-dependencies in their respective
hyperspectral embedding space. These embedded features can be fully exploited
by querying the inter-channel correlations in a combinatorial manner, with the
unique and complementary information efficiently fused into the final
prediction. We found such independent modeling and combinatorial excavation
mechanisms are extremely beneficial to uncover marginal spectral features,
especially in the long wavelength bands. In addition, we have proposed a
spatio-spectral attention block and a spectrum-fusion attention module, which
greatly facilitates the excavation and fusion of information at both
semantically long-range levels and fine-grained pixel levels across all
dimensions. Extensive quantitative and qualitative experiments show that our
method (dubbed CESST) achieves SOTA performance. Code for this project is at:
https://github.com/AlexYangxx/CESST.
","Xingxing Yang, Jie Chen, Zaifeng Yang",Zaifeng Yang,2023-12-18T11:37:19Z
"Multilayer Simplex-structured Matrix Factorization for Hyperspectral
  Unmixing with Endmember Variability","  Given a hyperspectral image, the problem of hyperspectral unmixing (HU) is to
identify the endmembers (or materials) and the abundance (or endmembers'
contributions on pixels) that underlie the image. HU can be seen as a matrix
factorization problem with a simplex structure in the abundance matrix factor.
In practice, hyperspectral images may exhibit endmember variability (EV)
effects -- the endmember matrix factor varies from one pixel to another. In
this paper we consider a multilayer simplex-structured matrix factorization
model to account for the EV effects. Our multilayer model is based on the
postulate that if we arrange the varied endmembers as an expanded endmember
matrix, that matrix exhibits a low-rank structure. A variational
inference-based maximum-likelihood estimation method is employed to tackle the
multilayer factorization problem. Simulation results are provided to
demonstrate the performance of our multilayer factorization method.
","Junbin Liu, Yuening Li, Wing-Kin Ma",Wing-Kin Ma,2024-01-26T01:42:02Z
Deep Nonlinear Hyperspectral Unmixing Using Multi-task Learning,"  Nonlinear hyperspectral unmixing has recently received considerable
attention, as linear mixture models do not lead to an acceptable resolution in
some problems. In fact, most nonlinear unmixing methods are designed by
assuming specific assumptions on the nonlinearity model which subsequently
limits the unmixing performance. In this paper, we propose an unsupervised
nonlinear unmixing approach based on deep learning by incorporating a general
nonlinear model with no special assumptions. This model consists of two
branches. In the first branch, endmembers are learned by reconstructing the
rows of hyperspectral images using some hidden layers, and in the second
branch, abundance values are learned based on the columns of respective images.
Then, using multi-task learning, we introduce an auxiliary task to enforce the
two branches to work together. This technique can be considered as a
regularizer mitigating overfitting, which improves the performance of the total
network. Extensive experiments on synthetic and real data verify the
effectiveness of the proposed method compared to some state-of-the-art
hyperspectral unmixing methods.
","Saeid Mehrdad, Seyed AmirHossein Janani",Seyed AmirHossein Janani,2024-02-05T02:52:25Z
"Implementation of the Principal Component Analysis onto High-Performance
  Computer Facilities for Hyperspectral Dimensionality Reduction: Results and
  Comparisons","  Dimensionality reduction represents a critical preprocessing step in order to
increase the efficiency and the performance of many hyperspectral imaging
algorithms. However, dimensionality reduction algorithms, such as the Principal
Component Analysis (PCA), suffer from their computationally demanding nature,
becoming advisable for their implementation onto high-performance computer
architectures for applications under strict latency constraints. This work
presents the implementation of the PCA algorithm onto two different
high-performance devices, namely, an NVIDIA Graphics Processing Unit (GPU) and
a Kalray manycore, uncovering a highly valuable set of tips and tricks in order
to take full advantage of the inherent parallelism of these high-performance
computing platforms, and hence, reducing the time that is required to process a
given hyperspectral image. Moreover, the achieved results obtained with
different hyperspectral images have been compared with the ones that were
obtained with a field programmable gate array (FPGA)-based implementation of
the PCA algorithm that has been recently published, providing, for the first
time in the literature, a comprehensive analysis in order to highlight the pros
and cons of each option.
","E. Martel, R. Lazcano, J. Lopez, D. Madroñal, R. Salvador, S. Lopez, E. Juarez, R. Guerra, C. Sanz, R. Sarmiento",R. Sarmiento,2024-03-27T07:50:45Z
Equivariant Imaging for Self-supervised Hyperspectral Image Inpainting,"  Hyperspectral imaging (HSI) is a key technology for earth observation,
surveillance, medical imaging and diagnostics, astronomy and space exploration.
The conventional technology for HSI in remote sensing applications is based on
the push-broom scanning approach in which the camera records the spectral image
of a stripe of the scene at a time, while the image is generated by the
aggregation of measurements through time. In real-world airborne and spaceborne
HSI instruments, some empty stripes would appear at certain locations, because
platforms do not always maintain a constant programmed attitude, or have access
to accurate digital elevation maps (DEM), and the travelling track is not
necessarily aligned with the hyperspectral cameras at all times. This makes the
enhancement of the acquired HS images from incomplete or corrupted observations
an essential task. We introduce a novel HSI inpainting algorithm here, called
Hyperspectral Equivariant Imaging (Hyper-EI). Hyper-EI is a self-supervised
learning-based method which does not require training on extensive datasets or
access to a pre-trained model. Experimental results show that the proposed
method achieves state-of-the-art inpainting performance compared to the
existing methods.
","Shuo Li, Mike Davies, Mehrdad Yaghoobi",Mehrdad Yaghoobi,2024-04-19T19:55:15Z
"Importance of Disjoint Sampling in Conventional and Transformer Models
  for Hyperspectral Image Classification","  Disjoint sampling is critical for rigorous and unbiased evaluation of
state-of-the-art (SOTA) models. When training, validation, and test sets
overlap or share data, it introduces a bias that inflates performance metrics
and prevents accurate assessment of a model's true ability to generalize to new
examples. This paper presents an innovative disjoint sampling approach for
training SOTA models on Hyperspectral image classification (HSIC) tasks. By
separating training, validation, and test data without overlap, the proposed
method facilitates a fairer evaluation of how well a model can classify pixels
it was not exposed to during training or validation. Experiments demonstrate
the approach significantly improves a model's generalization compared to
alternatives that include training and validation data in test data. By
eliminating data leakage between sets, disjoint sampling provides reliable
metrics for benchmarking progress in HSIC. Researchers can have confidence that
reported performance truly reflects a model's capabilities for classifying new
scenes, not just memorized pixels. This rigorous methodology is critical for
advancing SOTA models and their real-world application to large-scale land
mapping with Hyperspectral sensors.
  The source code is available at
https://github.com/mahmad00/Disjoint-Sampling-for-Hyperspectral-Image-Classification.
","Muhammad Ahmad, Manuel Mazzara, Salvatore Distifano",Salvatore Distifano,2024-04-23T11:40:52Z
"Hyperspectral Band Selection based on Generalized 3DTV and Tensor CUR
  Decomposition","  Hyperspectral Imaging (HSI) serves as an important technique in remote
sensing. However, high dimensionality and data volume typically pose
significant computational challenges. Band selection is essential for reducing
spectral redundancy in hyperspectral imagery while retaining intrinsic critical
information. In this work, we propose a novel hyperspectral band selection
model by decomposing the data into a low-rank and smooth component and a sparse
one. In particular, we develop a generalized 3D total variation (G3DTV) by
applying the $\ell_1^p$-norm to derivatives to preserve spatial-spectral
smoothness. By employing the alternating direction method of multipliers
(ADMM), we derive an efficient algorithm, where the tensor low-rankness is
implied by the tensor CUR decomposition. We demonstrate the effectiveness of
the proposed approach through comparisons with various other state-of-the-art
band selection techniques using two benchmark real-world datasets. In addition,
we provide practical guidelines for parameter selection in both noise-free and
noisy scenarios.
","Katherine Henneberger, Jing Qin",Jing Qin,2024-05-02T02:23:38Z
"SpectralZoom: Efficient Segmentation with an Adaptive Hyperspectral
  Camera","  Hyperspectral image segmentation is crucial for many fields such as
agriculture, remote sensing, biomedical imaging, battlefield sensing and
astronomy. However, the challenge of hyper and multi spectral imaging is its
large data footprint. We propose both a novel camera design and a vision
transformer-based (ViT) algorithm that alleviate both the captured data
footprint and the computational load for hyperspectral segmentation. Our camera
is able to adaptively sample image regions or patches at different resolutions,
instead of capturing the entire hyperspectral cube at one high resolution. Our
segmentation algorithm works in concert with the camera, applying ViT-based
segmentation only to adaptively selected patches. We show results both in
simulation and on a real hardware platform demonstrating both accurate
segmentation results and reduced computational burden.
","Jackson Arnold, Sophia Rossi, Chloe Petrosino, Ethan Mitchell, Sanjeev J. Koppal",Sanjeev J. Koppal,2024-06-06T17:33:23Z
"Weighted Sum of Segmented Correlation: An Efficient Method for Spectra
  Matching in Hyperspectral Images","  Matching a target spectrum with known spectra in a spectral library is a
common method for material identification in hyperspectral imaging research.
Hyperspectral spectra exhibit precise absorption features across different
wavelength segments, and the unique shapes and positions of these absorptions
create distinct spectral signatures for each material, aiding in their
identification. Therefore, only the specific positions can be considered for
material identification. This study introduces the Weighted Sum of Segmented
Correlation method, which calculates correlation indices between various
segments of a library and a test spectrum, and derives a matching index,
favoring positive correlations and penalizing negative correlations using
assigned weights. The effectiveness of this approach is evaluated for mineral
identification in hyperspectral images from both Earth and Martian surfaces.
","Sampriti Soor, Priyanka Kumari, B. S. Daya Sagar, Amba Shetty",Amba Shetty,2024-06-18T18:51:00Z
"Real HSI-MSI-PAN image dataset for the
  hyperspectral/multi-spectral/panchromatic image fusion and super-resolution
  fields","  Nowadays, most of the hyperspectral image (HSI) fusion experiments are based
on simulated datasets to compare different fusion methods. However, most of the
spectral response functions and spatial downsampling functions used to create
the simulated datasets are not entirely accurate, resulting in deviations in
spatial and spectral features between the generated images for fusion and the
real images for fusion. This reduces the credibility of the fusion algorithm,
causing unfairness in the comparison between different algorithms and hindering
the development of the field of hyperspectral image fusion. Therefore, we
release a real HSI/MSI/PAN image dataset to promote the development of the
field of hyperspectral image fusion. These three images are spatially
registered, meaning fusion can be performed between HSI and MSI, HSI and PAN
image, MSI and PAN image, as well as among HSI, MSI, and PAN image. This real
dataset could be available at https://aistudio.baidu.com/datasetdetail/281612.
The related code to process the data could be available at
https://github.com/rs-lsl/CSSNet.
",Shuangliang Li,Shuangliang Li,2024-07-02T16:01:16Z
"HyperKAN: Kolmogorov-Arnold Networks make Hyperspectral Image
  Classificators Smarter","  In traditional neural network architectures, a multilayer perceptron (MLP) is
typically employed as a classification block following the feature extraction
stage. However, the Kolmogorov-Arnold Network (KAN) presents a promising
alternative to MLP, offering the potential to enhance prediction accuracy. In
this paper, we propose the replacement of linear and convolutional layers of
traditional networks with KAN-based counterparts. These modifications allowed
us to significantly increase the per-pixel classification accuracy for
hyperspectral remote-sensing images. We modified seven different neural network
architectures for hyperspectral image classification and observed a substantial
improvement in the classification accuracy across all the networks. The
architectures considered in the paper include baseline MLP, state-of-the-art 1D
(1DCNN) and 3D convolutional (two different 3DCNN, NM3DCNN), and transformer
(SSFTT) architectures, as well as newly proposed M1DCNN. The greatest effect
was achieved for convolutional networks working exclusively on spectral data,
and the best classification quality was achieved using a KAN-based transformer
architecture. All the experiments were conducted using seven openly available
hyperspectral datasets. Our code is available at
https://github.com/f-neumann77/HyperKAN.
","Valeriy Lobanov, Nikita Firsov, Evgeny Myasnikov, Roman Khabibullin, Artem Nikonorov",Artem Nikonorov,2024-07-07T06:36:09Z
Correlation Hyperspectral Imaging,"  Hyperspectral imaging aims at providing information on both the spatial and
the spectral distribution of light, with high resolution. However,
state-of-the-art protocols are characterized by an intrinsic trade-off imposing
to sacrifice either resolution or image acquisition speed. We address this
limitation by exploiting light intensity correlations, which are shown to
enable overcoming the typical downsides of traditional hyperspectral imaging
techniques, both scanning and snapshot. The proposed approach also opens
possibilities that are not otherwise achievable, such as sharper imaging and
natural filtering of broadband spectral components that would otherwise hide
the spectrum of interest. The enabled combination of high spatial and spectral
resolution, high speed, and insensitivity to undesired spectral features shall
lead to a paradigm change in hyperspectral imaging devices and open-up new
application scenarios.
","Gianlorenzo Massaro, Francesco V. Pepe, Milena D'Angelo",Milena D'Angelo,2024-07-18T19:54:44Z
"HyTAS: A Hyperspectral Image Transformer Architecture Search Benchmark
  and Analysis","  Hyperspectral Imaging (HSI) plays an increasingly critical role in precise
vision tasks within remote sensing, capturing a wide spectrum of visual data.
Transformer architectures have significantly enhanced HSI task performance,
while advancements in Transformer Architecture Search (TAS) have improved model
discovery. To harness these advancements for HSI classification, we make the
following contributions: i) We propose HyTAS, the first benchmark on
transformer architecture search for Hyperspectral imaging, ii) We
comprehensively evaluate 12 different methods to identify the optimal
transformer over 5 different datasets, iii) We perform an extensive factor
analysis on the Hyperspectral transformer search performance, greatly
motivating future research in this direction. All benchmark materials are
available at HyTAS.
","Fangqin Zhou, Mert Kilickaya, Joaquin Vanschoren, Ran Piao",Ran Piao,2024-07-23T08:18:43Z
Scribble-Based Interactive Segmentation of Medical Hyperspectral Images,"  Hyperspectral imaging (HSI) is an advanced medical imaging modality that
captures optical data across a broad spectral range, providing novel insights
into the biochemical composition of tissues. HSI may enable precise
differentiation between various tissue types and pathologies, making it
particularly valuable for tumour detection, tissue classification, and disease
diagnosis.
  Deep learning-based segmentation methods have shown considerable
advancements, offering automated and accurate results. However, these methods
face challenges with HSI datasets due to limited annotated data and
discrepancies from hardware and acquisition
techniques~\cite{clancy2020surgical,studier2023heiporspectral}. Variability in
clinical protocols also leads to different definitions of structure boundaries.
Interactive segmentation methods, utilizing user knowledge and clinical
insights, can overcome these issues and achieve precise segmentation results
\cite{zhao2013overview}.
  This work introduces a scribble-based interactive segmentation framework for
medical hyperspectral images. The proposed method utilizes deep learning for
feature extraction and a geodesic distance map generated from user-provided
scribbles to obtain the segmentation results. The experiment results show that
utilising the geodesic distance maps based on deep learning-extracted features
achieved better segmentation results than geodesic distance maps directly
generated from hyperspectral images, reconstructed RGB images, or Euclidean
distance maps.
","Zhonghao Wang, Junwen Wang, Charlie Budd, Oscar MacCormac, Jonathan Shapey, Tom Vercauteren",Tom Vercauteren,2024-08-05T12:33:07Z
"In Flight Boresight Rectification for Lightweight Airborne Pushbroom
  Imaging Spectrometry","  Hyperspectral cameras have recently been miniaturized for operation on
lightweight airborne platforms such as UAV or small aircraft. Unlike frame
cameras (RGB or Multispectral), many hyperspectral sensors use a linear array
or 'push-broom' scanning design. This design presents significant challenges
for image rectification and the calibration of the intrinsic and extrinsic
camera parameters. Typically, methods employed to address such tasks rely on a
precise GPS/INS estimate of the airborne platform trajectory and a detailed
terrain model. However, inaccuracies in the trajectory or surface model
information can introduce systematic errors and complicate geometric modeling
which ultimately degrade the quality of the rectification. To overcome these
challenges, we propose a method for tie point extraction and camera calibration
for 'push-broom' hyperspectral sensors using only the raw spectral imagery and
raw, possibly low quality, GPS/INS trajectory. We demonstrate that our approach
allows for the automatic calibration of airborne systems with hyperspectral
cameras, outperforms other state-of-the-art automatic rectification methods and
reaches an accuracy on par with manual calibration methods.
","Julien Yuuki Burkhard, Jesse Ray Murray Lahaye, Laurent Valentin Jospin, Jan Skaloud",Jan Skaloud,2024-09-10T13:55:47Z
"RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical
  Imaging","  This study investigates the reconstruction of hyperspectral signatures from
RGB data to enhance surgical imaging, utilizing the publicly available
HeiPorSPECTRAL dataset from porcine surgery and an in-house neurosurgery
dataset. Various architectures based on convolutional neural networks (CNNs)
and transformer models are evaluated using comprehensive metrics. Transformer
models exhibit superior performance in terms of RMSE, SAM, PSNR and SSIM by
effectively integrating spatial information to predict accurate spectral
profiles, encompassing both visible and extended spectral ranges. Qualitative
assessments demonstrate the capability to predict spectral profiles critical
for informed surgical decision-making during procedures. Challenges associated
with capturing both the visible and extended hyperspectral ranges are
highlighted using the MAE, emphasizing the complexities involved. The findings
open up the new research direction of hyperspectral reconstruction for surgical
applications and clinical use cases in real-time surgical environments.
","Tobias Czempiel, Alfie Roddan, Maria Leiloglou, Zepeng Hu, Kevin O'Neill, Giulio Anichini, Danail Stoyanov, Daniel Elson",Daniel Elson,2024-10-17T14:05:41Z
Hyperspectral Spatial Super-Resolution using Keystone Error,"  Hyperspectral images enable precise identification of ground objects by
capturing their spectral signatures with fine spectral resolution.While high
spatial resolution further enhances this capability, increasing spatial
resolution through hardware like larger telescopes is costly and inefficient. A
more optimal solution is using ground processing techniques, such as
hypersharpening, to merge high spectral and spatial resolution data. However,
this method works best when datasets are captured under similar conditions,
which is difficult when using data from different times. In this work, we
propose a superresolution approach to enhance hyperspectral data's spatial
resolution without auxiliary input. Our method estimates the high-resolution
point spread function (PSF) using blind deconvolution and corrects for
sampling-related blur using a model-based superresolution framework. This
differs from previous approaches by not assuming a known highresolution blur.
We also introduce an adaptive prior that improves performance compared to
existing methods. Applied to the visible and near-infrared (VNIR) spectrometer
of HySIS, ISRO hyperspectral sensor, our algorithm removes aliasing and boosts
resolution by approximately 1.3 times. It is versatile and can be applied to
similar systems.
","Ankur Garg, Meenakshi Sarkar, S. Manthira Moorthi, Debajyoti Dhar",Debajyoti Dhar,2024-10-24T12:37:18Z
Hyperspectral wavefront sensing with a multicore fiber,"  Single-shot hyperspectral wavefront sensing is essential for applications
like spatio-spectral coupling metrology in high power laser or fast material
dispersion imaging. Under broadband illumination, traditional wavefront sensors
assume an achromatic wavefront, which makes them unsuitable. We introduce a
hyperspectral wavefront sensing scheme based on the Hartmann wavefront sensing
principles, employing a multicore fiber as a modified Hartmann mask to overcome
these limitations. Our system leverages the angular memory effect and spectral
decorrelation from the multicore fiber, encoding wavefront gradients into
displacements and the spectral information into uncorrelated patterns. This
method retains the simplicity, compactness, and single-shot capability of
conventional wavefront sensors, with only a slight increase in computational
complexity. It also allows a tunable trade-off between spatial and spectral
resolution. We demonstrate its efficacy for recording the hyperspectral
wavefront cube from single-pulse acquisitions at the Apollon multi-PW laser
facility, and for performing multispectral microscopic imaging of dispersive
phase objects.
","Baptiste Blochet, Nathalie Lebas, Pascal Berto, Dimitrios Papadopoulos, Marc Guillon",Marc Guillon,2024-10-24T18:57:22Z
"Implementation strategies for hyperspectral unmixing using Bayesian
  source separation","  Bayesian Positive Source Separation (BPSS) is a useful unsupervised approach
for hyperspectral data unmixing, where numerical non-negativity of spectra and
abundances has to be ensured, such in remote sensing. Moreover, it is sensible
to impose a sum-to-one (full additivity) constraint to the estimated source
abundances in each pixel. Even though non-negativity and full additivity are
two necessary properties to get physically interpretable results, the use of
BPSS algorithms has been so far limited by high computation time and large
memory requirements due to the Markov chain Monte Carlo calculations. An
implementation strategy which allows one to apply these algorithms on a full
hyperspectral image, as typical in Earth and Planetary Science, is introduced.
Effects of pixel selection, the impact of such sampling on the relevance of the
estimated component spectra and abundance maps, as well as on the computation
times, are discussed. For that purpose, two different dataset have been used: a
synthetic one and a real hyperspectral image from Mars.
","Frederic Schmidt, Albrecht Schmidt, Erwan Treguier, Mael Guiheneuf, Said Moussaoui, Nicolas Dobigeon",Nicolas Dobigeon,2010-01-04T12:45:48Z
Hyperspectral pansharpening: a review,"  Pansharpening aims at fusing a panchromatic image with a multispectral one,
to generate an image with the high spatial resolution of the former and the
high spectral resolution of the latter. In the last decade, many algorithms
have been presented in the literature for pansharpening using multispectral
data. With the increasing availability of hyperspectral systems, these methods
are now being adapted to hyperspectral images. In this work, we compare new
pansharpening techniques designed for hyperspectral data with some of the state
of the art methods for multispectral pansharpening, which have been adapted for
hyperspectral data. Eleven methods from different classes (component
substitution, multiresolution analysis, hybrid, Bayesian and matrix
factorization) are analyzed. These methods are applied to three datasets and
their effectiveness and robustness are evaluated with widely used performance
indicators. In addition, all the pansharpening techniques considered in this
paper have been implemented in a MATLAB toolbox that is made available to the
community.
","Laetitia Loncan, Luis B. Almeida, José M. Bioucas-Dias, Xavier Briottet, Jocelyn Chanussot, Nicolas Dobigeon, Sophie Fabre, Wenzhi Liao, Giorgio A. Licciardi, Miguel Simões, Jean-Yves Tourneret, Miguel A. Veganzones, Gemine Vivone, Qi Wei, Naoto Yokoya",Naoto Yokoya,2015-04-17T15:07:11Z
"Instance Influence Estimation for Hyperspectral Target Signature
  Characterization using Extended Functions of Multiple Instances","  The Extended Functions of Multiple Instances (eFUMI) algorithm is a
generalization of Multiple Instance Learning (MIL). In eFUMI, only bag level
(i.e. set level) labels are needed to estimate target signatures from mixed
data. The training bags in eFUMI are labeled positive if any data point in a
bag contains or represents any proportion of the target signature and are
labeled as a negative bag if all data points in the bag do not represent any
target. From these imprecise labels, eFUMI has been shown to be effective at
estimating target signatures in hyperspectral subpixel target detection
problems. One motivating scenario for the use of eFUMI is where an analyst
circles objects/regions of interest in a hyperspectral scene such that the
target signatures of these objects can be estimated and be used to determine
whether other instances of the object appear elsewhere in the image collection.
The regions highlighted by the analyst serve as the imprecise labels for eFUMI.
Often, an analyst may want to iteratively refine their imprecise labels. In
this paper, we present an approach for estimating the influence on the
estimated target signature if the label for a particular input data point is
modified. This ""instance influence estimation"" guides an analyst to focus on
(re-)labeling the data points that provide the largest change in the resulting
estimated target signature and, thus, reduce the amount of time an analyst
needs to spend refining the labels for a hyperspectral scene. Results are shown
on real hyperspectral sub-pixel target detection data sets.
","Sheng Zou, Alina Zare",Alina Zare,2016-03-21T16:54:41Z
"Efficient quantitative hyperspectral image unmixing method for
  large-scale Raman micro-spectroscopy data analysis","  Vibrational micro-spectroscopy is a powerful optical tool, providing a
non-invasive label-free chemically specific imaging for many chemical and
biomedical applications. However, hyperspectral image produced by Raman
micro-spectroscopy typically consists of thousands discrete pixel points, each
having individual Raman spectrum at thousand wavenumbers, and therefore
requires appropriate image unmixing computational methods to retrieve
non-negative spatial concentration and corresponding non-negative spectra of
the image biochemical constituents. In this article, we present a new efficient
Quantitative Hyperspectral Image Unmixing (Q-HIU) method for large-scale Raman
micro-spectroscopy data analysis. This method enables to simultaneously analyse
multi-set Raman hyperspectral images in three steps: (i) Singular Value
Decomposition with innovative Automatic Divisive Correlation (SVD-ADC) which
autonomously filters spatially and spectrally uncorrelated noise from data;
(ii) a robust subtraction of fluorescent background from the data using a newly
developed algorithm called Bottom Gaussian Fitting (BGF); (iii) an efficient
Quantitative Unsupervised/Partially Supervised Non-negative Matrix
Factorization method (Q-US/PS-NMF), which rigorously retrieves non-negative
spatial concentration maps and spectral profiles of the samples' biochemical
constituents with no a priori information and with great operation speed.
Alternatively, the Q-US/PS-NMF is capable to work as a partially supervised
method, when one or several samples' constituents are known, which
significantly widens chemical and biomedical applications of the method. We
apply the Q-HIU to the analysis of real large-scale Raman hyperspectral images
of human atherosclerotic aortic tissues and our results show a
proof-of-principle for the proposed method to retrieve the biochemical
composition of the tissues.
","E. G. Lobanova, S. V. Lobanov",S. V. Lobanov,2018-03-05T18:34:52Z
Automatic Target Detection for Sparse Hyperspectral Images,"  In this work, a novel target detector for hyperspectral imagery is developed.
The detector is independent on the unknown covariance matrix, behaves well in
large dimensions, distributional free, invariant to atmospheric effects, and
does not require a background dictionary to be constructed. Based on a
modification of the robust principal component analysis (RPCA), a given
hyperspectral image (HSI) is regarded as being made up of the sum of a low-rank
background HSI and a sparse target HSI that contains the targets based on a
pre-learned target dictionary specified by the user. The sparse component is
directly used for the detection, that is, the targets are simply detected at
the non-zero entries of the sparse target HSI. Hence, a novel target detector
is developed, which is simply a sparse HSI generated automatically from the
original HSI, but containing only the targets with the background is
suppressed. The detector is evaluated on real experiments, and the results of
which demonstrate its effectiveness for hyperspectral target detection
especially when the targets are well matched to the surroundings.
","Ahmad W. Bitar, Jean-Philippe Ovarlez, Loong-Fah Cheong, Ali Chehab",Ali Chehab,2019-04-14T12:00:54Z
"More chemical detection through less sampling: amplifying chemical
  signals in hyperspectral data cubes through compressive sensing","  Compressive sensing (CS) is a method of sampling which permits some classes
of signals to be reconstructed with high accuracy even when they were
under-sampled. In this paper we explore a phenomenon in which bandwise CS
sampling of a hyperspectral data cube followed by reconstruction can actually
result in amplification of chemical signals contained in the cube. Perhaps most
surprisingly, chemical signal amplification generally seems to increase as the
level of sampling decreases. In some examples, the chemical signal is
significantly stronger in a data cube reconstructed from 10% CS sampling than
it is in the raw, 100% sampled data cube. We explore this phenomenon in two
real-world datasets including the Physical Sciences Inc. Fabry-P\'{e}rot
interferometer sensor multispectral dataset and the Johns Hopkins Applied
Physics Lab FTIR-based longwave infrared sensor hyperspectral dataset. Each of
these datasets contains the release of a chemical simulant, such as glacial
acetic acid, triethyl phospate, and sulfur hexafluoride, and in all cases we
use the adaptive coherence estimator (ACE) to detect a target signal in the
hyperspectral data cube. We end the paper by suggesting some theoretical
justifications for why chemical signals would be amplified in CS sampled and
reconstructed hyperspectral data cubes and discuss some practical implications.
","Henry Kvinge, Elin Farnell, Julia R. Dupuis, Michael Kirby, Chris Peterson, Elizabeth C. Schundler",Elizabeth C. Schundler,2019-06-27T17:56:28Z
"Multi-Target Multiple Instance Learning for Hyperspectral Target
  Detection","  In remote sensing, it is often challenging to acquire or collect a large
dataset that is accurately labeled. This difficulty is usually due to several
issues, including but not limited to the study site's spatial area and
accessibility, errors in the global positioning system (GPS), and mixed pixels
caused by an image's spatial resolution. We propose an approach, with two
variations, that estimates multiple target signatures from training samples
with imprecise labels: Multi-Target Multiple Instance Adaptive Cosine Estimator
(Multi-Target MI-ACE) and Multi-Target Multiple Instance Spectral Match Filter
(Multi-Target MI-SMF). The proposed methods address the problems above by
directly considering the multiple-instance, imprecisely labeled dataset. They
learn a dictionary of target signatures that optimizes detection against a
background using the Adaptive Cosine Estimator (ACE) and Spectral Match Filter
(SMF). Experiments were conducted to test the proposed algorithms using a
simulated hyperspectral dataset, the MUUFL Gulfport hyperspectral dataset
collected over the University of Southern Mississippi-Gulfpark Campus, and the
AVIRIS hyperspectral dataset collected over Santa Barbara County, California.
Both simulated and real hyperspectral target detection experiments show the
proposed algorithms are effective at learning target signatures and performing
target detection.
","Susan Meerdink, James Bocinsky, Alina Zare, Nicholas Kroeger, Connor McCurley, Daniel Shats, Paul Gader",Paul Gader,2019-09-07T18:30:54Z
"Fusion of Dual Spatial Information for Hyperspectral Image
  Classification","  The inclusion of spatial information into spectral classifiers for
fine-resolution hyperspectral imagery has led to significant improvements in
terms of classification performance. The task of spectral-spatial hyperspectral
image classification has remained challenging because of high intraclass
spectrum variability and low interclass spectral variability. This fact has
made the extraction of spatial information highly active. In this work, a novel
hyperspectral image classification framework using the fusion of dual spatial
information is proposed, in which the dual spatial information is built by both
exploiting pre-processing feature extraction and post-processing spatial
optimization. In the feature extraction stage, an adaptive texture smoothing
method is proposed to construct the structural profile (SP), which makes it
possible to precisely extract discriminative features from hyperspectral
images. The SP extraction method is used here for the first time in the remote
sensing community. Then, the extracted SP is fed into a spectral classifier. In
the spatial optimization stage, a pixel-level classifier is used to obtain the
class probability followed by an extended random walker-based spatial
optimization technique. Finally, a decision fusion rule is utilized to fuse the
class probabilities obtained by the two different stages. Experiments performed
on three data sets from different scenes illustrate that the proposed method
can outperform other state-of-the-art classification techniques. In addition,
the proposed feature extraction method, i.e., SP, can effectively improve the
discrimination between different land covers.
","Puhong Duan, Pedram Ghamisi, Xudong Kang, Behnood Rasti, Shutao Li, Richard Gloaguen",Richard Gloaguen,2020-10-23T12:20:18Z
Hyperspectral Anomaly Change Detection Based on Auto-encoder,"  With the hyperspectral imaging technology, hyperspectral data provides
abundant spectral information and plays a more important role in geological
survey, vegetation analysis and military reconnaissance. Different from normal
change detection, hyperspectral anomaly change detection (HACD) helps to find
those small but important anomaly changes between multi-temporal hyperspectral
images (HSI). In previous works, most classical methods use linear regression
to establish the mapping relationship between two HSIs and then detect the
anomalies from the residual image. However, the real spectral differences
between multi-temporal HSIs are likely to be quite complex and of nonlinearity,
leading to the limited performance of these linear predictors. In this paper,
we propose an original HACD algorithm based on auto-encoder (ACDA) to give a
nonlinear solution. The proposed ACDA can construct an effective predictor
model when facing complex imaging conditions. In the ACDA model, two systematic
auto-encoder (AE) networks are deployed to construct two predictors from two
directions. The predictor is used to model the spectral variation of the
background to obtain the predicted image under another imaging condition. Then
mean square error (MSE) between the predictive image and corresponding expected
image is computed to obtain the loss map, where the spectral differences of the
unchanged pixels are highly suppressed and anomaly changes are highlighted.
Ultimately, we take the minimum of the two loss maps of two directions as the
final anomaly change intensity map. The experiments results on public
""Viareggio 2013"" datasets demonstrate the efficiency and superiority over
traditional methods.
","Meiqi Hu, Chen Wu, Liangpei Zhang, Bo Du",Bo Du,2020-10-27T08:07:08Z
"Domain-Aware Unsupervised Hyperspectral Reconstruction for Aerial Image
  Dehazing","  Haze removal in aerial images is a challenging problem due to considerable
variation in spatial details and varying contrast. Changes in particulate
matter density often lead to degradation in visibility. Therefore, several
approaches utilize multi-spectral data as auxiliary information for haze
removal. In this paper, we propose SkyGAN for haze removal in aerial images.
SkyGAN consists of 1) a domain-aware hazy-to-hyperspectral (H2H) module, and 2)
a conditional GAN (cGAN) based multi-cue image-to-image translation module
(I2I) for dehazing. The proposed H2H module reconstructs several visual bands
from RGB images in an unsupervised manner, which overcomes the lack of hazy
hyperspectral aerial image datasets. The module utilizes task supervision and
domain adaptation in order to create a ""hyperspectral catalyst"" for image
dehazing. The I2I module uses the hyperspectral catalyst along with a
12-channel multi-cue input and performs effective image dehazing by utilizing
the entire visual spectrum. In addition, this work introduces a new dataset,
called Hazy Aerial-Image (HAI) dataset, that contains more than 65,000 pairs of
hazy and ground truth aerial images with realistic, non-homogeneous haze of
varying density. The performance of SkyGAN is evaluated on the recent
SateHaze1k dataset as well as the HAI dataset. We also present a comprehensive
evaluation of HAI dataset with a representative set of state-of-the-art
techniques in terms of PSNR and SSIM.
","Aditya Mehta, Harsh Sinha, Murari Mandal, Pratik Narang",Pratik Narang,2020-11-07T03:30:52Z
"Hyperspectral Band Selection for Multispectral Image Classification with
  Convolutional Networks","  In recent years, Hyperspectral Imaging (HSI) has become a powerful source for
reliable data in applications such as remote sensing, agriculture, and
biomedicine. However, hyperspectral images are highly data-dense and often
benefit from methods to reduce the number of spectral bands while retaining the
most useful information for a specific application. We propose a novel band
selection method to select a reduced set of wavelengths, obtained from an HSI
system in the context of image classification. Our approach consists of two
main steps: the first utilizes a filter-based approach to find relevant
spectral bands based on a collinearity analysis between a band and its
neighbors. This analysis helps to remove redundant bands and dramatically
reduces the search space. The second step applies a wrapper-based approach to
select bands from the reduced set based on their information entropy values,
and trains a compact Convolutional Neural Network (CNN) to evaluate the
performance of the current selection. We present classification results
obtained from our method and compare them to other feature selection methods on
two hyperspectral image datasets. Additionally, we use the original
hyperspectral data cube to simulate the process of using actual filters in a
multispectral imager. We show that our method produces more suitable results
for a multispectral sensor design.
","Giorgio Morales, John Sheppard, Riley Logan, Joseph Shaw",Joseph Shaw,2021-06-01T17:24:35Z
"Multi-scale Dynamic Graph Convolutional Network for Hyperspectral Image
  Classification","  Convolutional Neural Network (CNN) has demonstrated impressive ability to
represent hyperspectral images and to achieve promising results in
hyperspectral image classification. However, traditional CNN models can only
operate convolution on regular square image regions with fixed size and
weights, so they cannot universally adapt to the distinct local regions with
various object distributions and geometric appearances. Therefore, their
classification performances are still to be improved, especially in class
boundaries. To alleviate this shortcoming, we consider employing the recently
proposed Graph Convolutional Network (GCN) for hyperspectral image
classification, as it can conduct the convolution on arbitrarily structured
non-Euclidean data and is applicable to the irregular image regions represented
by graph topological information. Different from the commonly used GCN models
which work on a fixed graph, we enable the graph to be dynamically updated
along with the graph convolution process, so that these two steps can be
benefited from each other to gradually produce the discriminative embedded
features as well as a refined graph. Moreover, to comprehensively deploy the
multi-scale information inherited by hyperspectral images, we establish
multiple input graphs with different neighborhood scales to extensively exploit
the diversified spectral-spatial correlations at multiple scales. Therefore,
our method is termed 'Multi-scale Dynamic Graph Convolutional Network' (MDGCN).
The experimental results on three typical benchmark datasets firmly demonstrate
the superiority of the proposed MDGCN to other state-of-the-art methods in both
qualitative and quantitative aspects.
","Sheng Wan, Chen Gong, Ping Zhong, Bo Du, Lefei Zhang, Jian Yang",Jian Yang,2019-05-14T14:27:37Z
Hyperspectral Image Classification with Attention Aided CNNs,"  Convolutional neural networks (CNNs) have been widely used for hyperspectral
image classification. As a common process, small cubes are firstly cropped from
the hyperspectral image and then fed into CNNs to extract spectral and spatial
features. It is well known that different spectral bands and spatial positions
in the cubes have different discriminative abilities. If fully explored, this
prior information will help improve the learning capacity of CNNs. Along this
direction, we propose an attention aided CNN model for spectral-spatial
classification of hyperspectral images. Specifically, a spectral attention
sub-network and a spatial attention sub-network are proposed for spectral and
spatial classification, respectively. Both of them are based on the traditional
CNN model, and incorporate attention modules to aid networks focus on more
discriminative channels or positions. In the final classification phase, the
spectral classification result and the spatial classification result are
combined together via an adaptively weighted summation method. To evaluate the
effectiveness of the proposed model, we conduct experiments on three standard
hyperspectral datasets. The experimental results show that the proposed model
can achieve superior performance compared to several state-of-the-art
CNN-related models.
","Renlong Hang, Zhu Li, Qingshan Liu, Pedram Ghamisi, Shuvra S. Bhattacharyya",Shuvra S. Bhattacharyya,2020-05-25T08:40:56Z
"Hyperspectral Image Super-resolution via Deep Spatio-spectral
  Convolutional Neural Networks","  Hyperspectral images are of crucial importance in order to better understand
features of different materials. To reach this goal, they leverage on a high
number of spectral bands. However, this interesting characteristic is often
paid by a reduced spatial resolution compared with traditional multispectral
image systems. In order to alleviate this issue, in this work, we propose a
simple and efficient architecture for deep convolutional neural networks to
fuse a low-resolution hyperspectral image (LR-HSI) and a high-resolution
multispectral image (HR-MSI), yielding a high-resolution hyperspectral image
(HR-HSI). The network is designed to preserve both spatial and spectral
information thanks to an architecture from two folds: one is to utilize the
HR-HSI at a different scale to get an output with a satisfied spectral
preservation; another one is to apply concepts of multi-resolution analysis to
extract high-frequency information, aiming to output high quality spatial
details. Finally, a plain mean squared error loss function is used to measure
the performance during the training. Extensive experiments demonstrate that the
proposed network architecture achieves best performance (both qualitatively and
quantitatively) compared with recent state-of-the-art hyperspectral image
super-resolution approaches. Moreover, other significant advantages can be
pointed out by the use of the proposed approach, such as, a better network
generalization ability, a limited computational burden, and a robustness with
respect to the number of training samples.
","Jin-Fan Hu, Ting-Zhu Huang, Liang-Jian Deng, Tai-Xiang Jiang, Gemine Vivone, Jocelyn Chanussot",Jocelyn Chanussot,2020-05-29T05:56:50Z
"HyDe: The First Open-Source, Python-Based, GPU-Accelerated Hyperspectral
  Denoising Package","  As with any physical instrument, hyperspectral cameras induce different kinds
of noise in the acquired data. Therefore, Hyperspectral denoising is a crucial
step for analyzing hyperspectral images (HSIs). Conventional computational
methods rarely use GPUs to improve efficiency and are not fully open-source.
Alternatively, deep learning-based methods are often open-source and use GPUs,
but their training and utilization for real-world applications remain
non-trivial for many researchers. Consequently, we propose HyDe: the first
open-source, GPU-accelerated Python-based, hyperspectral image denoising
toolbox, which aims to provide a large set of methods with an easy-to-use
environment. HyDe includes a variety of methods ranging from low-rank
wavelet-based methods to deep neural network (DNN) models. HyDe's interface
dramatically improves the interoperability of these methods and the performance
of the underlying functions. In fact, these methods maintain similar HSI
denoising performance to their original implementations while consuming nearly
ten times less energy. Furthermore, we present a method for training DNNs for
denoising HSIs which are not spatially related to the training dataset, i.e.,
training on ground-level HSIs for denoising HSIs with other perspectives
including airborne, drone-borne, and space-borne. To utilize the trained DNNs,
we show a sliding window method to effectively denoise HSIs which would
otherwise require more than 40 GB. The package can be found at:
\url{https://github.com/Helmholtz-AI-Energy/HyDe}.
","Daniel Coquelin, Behnood Rasti, Markus Götz, Pedram Ghamisi, Richard Gloaguen, Achim Streit",Achim Streit,2022-04-14T14:08:55Z
A 3-stage Spectral-spatial Method for Hyperspectral Image Classification,"  Hyperspectral images often have hundreds of spectral bands of different
wavelengths captured by aircraft or satellites that record land coverage.
Identifying detailed classes of pixels becomes feasible due to the enhancement
in spectral and spatial resolution of hyperspectral images. In this work, we
propose a novel framework that utilizes both spatial and spectral information
for classifying pixels in hyperspectral images. The method consists of three
stages. In the first stage, the pre-processing stage, Nested Sliding Window
algorithm is used to reconstruct the original data by {enhancing the
consistency of neighboring pixels} and then Principal Component Analysis is
used to reduce the dimension of data. In the second stage, Support Vector
Machines are trained to estimate the pixel-wise probability map of each class
using the spectral information from the images. Finally, a smoothed total
variation model is applied to smooth the class probability vectors by {ensuring
spatial connectivity} in the images. We demonstrate the superiority of our
method against three state-of-the-art algorithms on six benchmark hyperspectral
data sets with 10 to 50 training labels for each class. The results show that
our method gives the overall best performance in accuracy. Especially, our gain
in accuracy increases when the number of labeled pixels decreases and therefore
our method is more advantageous to be applied to problems with small training
set. Hence it is of great practical significance since expert annotations are
often expensive and difficult to collect.
","Raymond H. Chan, Ruoning Li",Ruoning Li,2022-04-20T08:23:05Z
"Unsupervised Spatial-spectral Hyperspectral Image Reconstruction and
  Clustering with Diffusion Geometry","  Hyperspectral images, which store a hundred or more spectral bands of
reflectance, have become an important data source in natural and social
sciences. Hyperspectral images are often generated in large quantities at a
relatively coarse spatial resolution. As such, unsupervised machine learning
algorithms incorporating known structure in hyperspectral imagery are needed to
analyze these images automatically. This work introduces the Spatial-Spectral
Image Reconstruction and Clustering with Diffusion Geometry (DSIRC) algorithm
for partitioning highly mixed hyperspectral images. DSIRC reduces measurement
noise through a shape-adaptive reconstruction procedure. In particular, for
each pixel, DSIRC locates spectrally correlated pixels within a data-adaptive
spatial neighborhood and reconstructs that pixel's spectral signature using
those of its neighbors. DSIRC then locates high-density, high-purity pixels far
in diffusion distance (a data-dependent distance metric) from other
high-density, high-purity pixels and treats these as cluster exemplars, giving
each a unique label. Non-modal pixels are assigned the label of their diffusion
distance-nearest neighbor of higher density and purity that is already labeled.
Strong numerical results indicate that incorporating spatial information
through image reconstruction substantially improves the performance of
pixel-wise clustering.
","Kangning Cui, Ruoning Li, Sam L. Polk, James M. Murphy, Robert J. Plemmons, Raymond H. Chan",Raymond H. Chan,2022-04-28T13:42:12Z
Calibrated Vehicle Paint Signatures for Simulating Hyperspectral Imagery,"  We investigate a procedure for rapidly adding calibrated vehicle visible-near
infrared (VNIR) paint signatures to an existing hyperspectral simulator - The
Digital Imaging and Remote Sensing Image Generation (DIRSIG) model - to create
more diversity in simulated urban scenes. The DIRSIG model can produce
synthetic hyperspectral imagery with user-specified geometry, atmospheric
conditions, and ground target spectra. To render an object pixel's spectral
signature, DIRSIG uses a large database of reflectance curves for the
corresponding object material and a bidirectional reflectance model to
introduce s due to orientation and surface structure. However, this database
contains only a few spectral curves for vehicle paints and generates new paint
signatures by combining these curves internally. In this paper we demonstrate a
method to rapidly generate multiple paint spectra, flying a drone carrying a
pushbroom hyperspectral camera to image a university parking lot. We then
process the images to convert them from the digital count space to spectral
reflectance without the need of calibration panels in the scene, and port the
paint signatures into DIRSIG for successful integration into the newly rendered
sets of synthetic VNIR hyperspectral scenes.
","Zachary Mulhollan, Aneesh Rangnekar, Timothy Bauch, Matthew J. Hoffman, Anthony Vodacek",Anthony Vodacek,2020-04-16T16:26:57Z
"Feedback Refined Local-Global Network for Super-Resolution of
  Hyperspectral Imagery","  With the development of deep learning technology, multi-spectral image
super-resolution methods based on convolutional neural network have recently
achieved great progress. However, the single hyperspectral image
super-resolution remains a challenging problem due to the high-dimensional and
complex spectral characteristics of hyperspectral data, which make it difficult
to simultaneously capture spatial and spectral information. To deal with this
issue, we propose a novel Feedback Refined Local-Global Network (FRLGN) for the
super-resolution of hyperspectral image. To be specific, we develop a new
Feedback Structure and a Local-Global Spectral Block to alleviate the
difficulty in spatial and spectral feature extraction. The Feedback Structure
can transfer the high-level information to guide the generation process of
low-level feature, which is achieved by a recurrent structure with finite
unfoldings. Furthermore, in order to effectively use the high-level information
passed back, a Local-Global Spectral Block is constructed to handle the
feedback connections. The Local-Global Spectral Block utilizes the feedback
high-level information to correct the low-level feature from local spectral
bands and generates powerful high-level representations among global spectral
bands. By incorporating the Feedback Structure and Local-Global Spectral Block,
the FRLGN can fully exploit spatial-spectral correlations among spectral bands
and gradually reconstruct high-resolution hyperspectral images. The source code
of FRLGN is available at https://github.com/tangzhenjie/FRLGN.
","Zhenjie Tang, Qing Xu, Zhenwei Shi, Bin Pan",Bin Pan,2021-03-07T13:28:48Z
"The Effects of Spectral Dimensionality Reduction on Hyperspectral Pixel
  Classification: A Case Study","  This paper presents a systematic study of the effects of hyperspectral pixel
dimensionality reduction on the pixel classification task. We use five
dimensionality reduction methods -- PCA, KPCA, ICA, AE, and DAE -- to compress
301-dimensional hyperspectral pixels. Compressed pixels are subsequently used
to perform pixel classifications. Pixel classification accuracies together with
compression method, compression rates, and reconstruction errors provide a new
lens to study the suitability of a compression method for the task of pixel
classification. We use three high-resolution hyperspectral image datasets,
representing three common landscape types (i.e. urban, transitional suburban,
and forests) collected by the Remote Sensing and Spatial Ecosystem Modeling
laboratory of the University of Toronto. We found that PCA, KPCA, and ICA post
greater signal reconstruction capability; however, when compression rates are
more than 90\% these methods show lower classification scores. AE and DAE
methods post better classification accuracy at 95\% compression rate, however
their performance drops as compression rate approaches 97\%. Our results
suggest that both the compression method and the compression rate are important
considerations when designing a hyperspectral pixel classification pipeline.
","Kiran Mantripragada, Phuong D. Dao, Yuhong He, Faisal Z. Qureshi",Faisal Z. Qureshi,2021-04-01T22:22:47Z
Binary Change Guided Hyperspectral Multiclass Change Detection,"  Characterized by tremendous spectral information, hyperspectral image is able
to detect subtle changes and discriminate various change classes for change
detection. The recent research works dominated by hyperspectral binary change
detection, however, cannot provide fine change classes information. And most
methods incorporating spectral unmixing for hyperspectral multiclass change
detection (HMCD), yet suffer from the neglection of temporal correlation and
error accumulation. In this study, we proposed an unsupervised Binary Change
Guided hyperspectral multiclass change detection Network (BCG-Net) for HMCD,
which aims at boosting the multiclass change detection result and unmixing
result with the mature binary change detection approaches. In BCG-Net, a novel
partial-siamese united-unmixing module is designed for multi-temporal spectral
unmixing, and a groundbreaking temporal correlation constraint directed by the
pseudo-labels of binary change detection result is developed to guide the
unmixing process from the perspective of change detection, encouraging the
abundance of the unchanged pixels more coherent and that of the changed pixels
more accurate. Moreover, an innovative binary change detection rule is put
forward to deal with the problem that traditional rule is susceptible to
numerical values. The iterative optimization of the spectral unmixing process
and the change detection process is proposed to eliminate the accumulated
errors and bias from unmixing result to change detection result. The
experimental results demonstrate that our proposed BCG-Net could achieve
comparative or even outstanding performance of multiclass change detection
among the state-of-the-art approaches and gain better spectral unmixing results
at the same time.
","Meiqi Hu, Chen Wu, Bo Du, Liangpei Zhang",Liangpei Zhang,2021-12-08T13:17:24Z
"HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling
  Deep Network for Snapshot Compressive Imaging","  Hyperspectral imaging is an essential imaging modality for a wide range of
applications, especially in remote sensing, agriculture, and medicine. Inspired
by existing hyperspectral cameras that are either slow, expensive, or bulky,
reconstructing hyperspectral images (HSIs) from a low-budget snapshot
measurement has drawn wide attention. By mapping a truncated numerical
optimization algorithm into a network with a fixed number of phases, recent
deep unfolding networks (DUNs) for spectral snapshot compressive sensing (SCI)
have achieved remarkable success. However, DUNs are far from reaching the scope
of industrial applications limited by the lack of cross-phase feature
interaction and adaptive parameter adjustment. In this paper, we propose a
novel Hyperspectral Explicable Reconstruction and Optimal Sampling deep Network
for SCI, dubbed HerosNet, which includes several phases under the
ISTA-unfolding framework. Each phase can flexibly simulate the sensing matrix
and contextually adjust the step size in the gradient descent step, and
hierarchically fuse and interact the hidden states of previous phases to
effectively recover current HSI frames in the proximal mapping step.
Simultaneously, a hardware-friendly optimal binary mask is learned end-to-end
to further improve the reconstruction performance. Finally, our HerosNet is
validated to outperform the state-of-the-art methods on both simulation and
real datasets by large margins. The source code is available at
https://github.com/jianzhangcs/HerosNet.
","Xuanyu Zhang, Yongbing Zhang, Ruiqin Xiong, Qilin Sun, Jian Zhang",Jian Zhang,2021-12-12T13:42:49Z
"Unsupervised Diffusion and Volume Maximization-Based Clustering of
  Hyperspectral Images","  Hyperspectral images taken from aircraft or satellites contain information
from hundreds of spectral bands, within which lie latent lower-dimensional
structures that can be exploited for classifying vegetation and other
materials. A disadvantage of working with hyperspectral images is that, due to
an inherent trade-off between spectral and spatial resolution, they have a
relatively coarse spatial scale, meaning that single pixels may correspond to
spatial regions containing multiple materials. This article introduces the
Diffusion and Volume maximization-based Image Clustering (D-VIC) algorithm for
unsupervised material clustering to address this problem. By directly
incorporating pixel purity into its labeling procedure, D-VIC gives greater
weight to pixels that correspond to a spatial region containing just a single
material. D-VIC is shown to outperform comparable state-of-the-art methods in
extensive experiments on a range of hyperspectral images, including land-use
maps and highly mixed forest health surveys (in the context of ash dieback
disease), implying that it is well-equipped for unsupervised material
clustering of spectrally-mixed hyperspectral datasets.
","Sam L. Polk, Kangning Cui, Aland H. Y. Chan, David A. Coomes, Robert J. Plemmons, James M. Murphy",James M. Murphy,2022-03-18T14:39:42Z
"Supervised classification methods applied to airborne hyperspectral
  images: Comparative study using mutual information","  Nowadays, the hyperspectral remote sensing imagery HSI becomes an important
tool to observe the Earth's surface, detect the climatic changes and many other
applications. The classification of HSI is one of the most challenging tasks
due to the large amount of spectral information and the presence of redundant
and irrelevant bands. Although great progresses have been made on
classification techniques, few studies have been done to provide practical
guidelines to determine the appropriate classifier for HSI. In this paper, we
investigate the performance of four supervised learning algorithms, namely,
Support Vector Machines SVM, Random Forest RF, K-Nearest Neighbors KNN and
Linear Discriminant Analysis LDA with different kernels in terms of
classification accuracies. The experiments have been performed on three real
hyperspectral datasets taken from the NASA's Airborne Visible/Infrared Imaging
Spectrometer Sensor AVIRIS and the Reflective Optics System Imaging
Spectrometer ROSIS sensors. The mutual information had been used to reduce the
dimensionality of the used datasets for better classification efficiency. The
extensive experiments demonstrate that the SVM classifier with RBF kernel and
RF produced statistically better results and seems to be respectively the more
suitable as supervised classifiers for the hyperspectral remote sensing images.
  Keywords: hyperspectral images, mutual information, dimension reduction,
Support Vector Machines, K-Nearest Neighbors, Random Forest, Linear
Discriminant Analysis.
","Hasna Nhaila, Asma Elmaizi, Elkebir Sarhrouni, Ahmed Hammouch",Ahmed Hammouch,2022-10-27T13:39:08Z
"Unsupervised ore/waste classification on open-cut mine faces using
  close-range hyperspectral data","  The remote mapping of minerals and discrimination of ore and waste on
surfaces are important tasks for geological applications such as those in
mining. Such tasks have become possible using ground-based, close-range
hyperspectral sensors which can remotely measure the reflectance properties of
the environment with high spatial and spectral resolution. However, autonomous
mapping of mineral spectra measured on an open-cut mine face remains a
challenging problem due to the subtleness of differences in spectral absorption
features between mineral and rock classes as well as variability in the
illumination of the scene. An additional layer of difficulty arises when there
is no annotated data available to train a supervised learning algorithm. A
pipeline for unsupervised mapping of spectra on a mine face is proposed which
draws from several recent advances in the hyperspectral machine learning
literature. The proposed pipeline brings together unsupervised and
self-supervised algorithms in a unified system to map minerals on a mine face
without the need for human-annotated training data. The pipeline is evaluated
with a hyperspectral image dataset of an open-cut mine face comprising mineral
ore martite and non-mineralised shale. The combined system is shown to produce
a superior map to its constituent algorithms, and the consistency of its
mapping capability is demonstrated using data acquired at two different times
of day.
","Lloyd Windrim, Arman Melkumyan, Richard J. Murphy, Anna Chlingaryan, Raymond Leung",Raymond Leung,2023-02-09T21:03:03Z
"You Only Train Once: Learning a General Anomaly Enhancement Network with
  Random Masks for Hyperspectral Anomaly Detection","  In this paper, we introduce a new approach to address the challenge of
generalization in hyperspectral anomaly detection (AD). Our method eliminates
the need for adjusting parameters or retraining on new test scenes as required
by most existing methods. Employing an image-level training paradigm, we
achieve a general anomaly enhancement network for hyperspectral AD that only
needs to be trained once. Trained on a set of anomaly-free hyperspectral images
with random masks, our network can learn the spatial context characteristics
between anomalies and background in an unsupervised way. Additionally, a
plug-and-play model selection module is proposed to search for a
spatial-spectral transform domain that is more suitable for AD task than the
original data. To establish a unified benchmark to comprehensively evaluate our
method and existing methods, we develop a large-scale hyperspectral AD dataset
(HAD100) that includes 100 real test scenes with diverse anomaly targets. In
comparison experiments, we combine our network with a parameter-free detector
and achieve the optimal balance between detection accuracy and inference speed
among state-of-the-art AD methods. Experimental results also show that our
method still achieves competitive performance when the training and test set
are captured by different sensor devices. Our code is available at
https://github.com/ZhaoxuLi123/AETNet.
","Zhaoxu Li, Yingqian Wang, Chao Xiao, Qiang Ling, Zaiping Lin, Wei An",Wei An,2023-03-31T12:23:56Z
Unsupervised Hyperspectral Pansharpening via Low-rank Diffusion Model,"  Hyperspectral pansharpening is a process of merging a high-resolution
panchromatic (PAN) image and a low-resolution hyperspectral (LRHS) image to
create a single high-resolution hyperspectral (HRHS) image. Existing
Bayesian-based HS pansharpening methods require designing handcraft image prior
to characterize the image features, and deep learning-based HS pansharpening
methods usually require a large number of paired training data and suffer from
poor generalization ability. To address these issues, in this work, we propose
a low-rank diffusion model for hyperspectral pansharpening by simultaneously
leveraging the power of the pre-trained deep diffusion model and better
generalization ability of Bayesian methods. Specifically, we assume that the
HRHS image can be recovered from the product of two low-rank tensors, i.e., the
base tensor and the coefficient matrix. The base tensor lies on the image field
and has a low spectral dimension. Thus, we can conveniently utilize a
pre-trained remote sensing diffusion model to capture its image structures.
Additionally, we derive a simple yet quite effective way to pre-estimate the
coefficient matrix from the observed LRHS image, which preserves the spectral
information of the HRHS. Experimental results demonstrate that the proposed
method performs better than some popular traditional approaches and gains
better generalization ability than some DL-based methods. The code is released
in https://github.com/xyrui/PLRDiff.
","Xiangyu Rui, Xiangyong Cao, Li Pang, Zeyu Zhu, Zongsheng Yue, Deyu Meng",Deyu Meng,2023-05-18T12:38:29Z
"FactoFormer: Factorized Hyperspectral Transformers with Self-Supervised
  Pretraining","  Hyperspectral images (HSIs) contain rich spectral and spatial information.
Motivated by the success of transformers in the field of natural language
processing and computer vision where they have shown the ability to learn long
range dependencies within input data, recent research has focused on using
transformers for HSIs. However, current state-of-the-art hyperspectral
transformers only tokenize the input HSI sample along the spectral dimension,
resulting in the under-utilization of spatial information. Moreover,
transformers are known to be data-hungry and their performance relies heavily
on large-scale pretraining, which is challenging due to limited annotated
hyperspectral data. Therefore, the full potential of HSI transformers has not
been fully realized. To overcome these limitations, we propose a novel
factorized spectral-spatial transformer that incorporates factorized
self-supervised pretraining procedures, leading to significant improvements in
performance. The factorization of the inputs allows the spectral and spatial
transformers to better capture the interactions within the hyperspectral data
cubes. Inspired by masked image modeling pretraining, we also devise efficient
masking strategies for pretraining each of the spectral and spatial
transformers. We conduct experiments on six publicly available datasets for HSI
classification task and demonstrate that our model achieves state-of-the-art
performance in all the datasets. The code for our model will be made available
at https://github.com/csiro-robotics/factoformer.
","Shaheer Mohamed, Maryam Haghighat, Tharindu Fernando, Sridha Sridharan, Clinton Fookes, Peyman Moghadam",Peyman Moghadam,2023-09-18T02:05:52Z
"Multi-level Relation Learning for Cross-domain Few-shot Hyperspectral
  Image Classification","  Cross-domain few-shot hyperspectral image classification focuses on learning
prior knowledge from a large number of labeled samples from source domains and
then transferring the knowledge to the tasks which contain few labeled samples
in target domains. Following the metric-based manner, many current methods
first extract the features of the query and support samples, and then directly
predict the classes of query samples according to their distance to the support
samples or prototypes. The relations between samples have not been fully
explored and utilized. Different from current works, this paper proposes to
learn sample relations on different levels and take them into the model
learning process, to improve the cross-domain few-shot hyperspectral image
classification. Building on current method of ""Deep Cross-Domain Few-Shot
Learning for Hyperspectral Image Classification"" which adopts a domain
discriminator to deal with domain-level distribution difference, the proposed
method applies contrastive learning to learn the class-level sample relations
to obtain more discriminable sample features. In addition, it adopts a
transformer based cross-attention learning module to learn the set-level sample
relations and acquire the attention from query samples to support samples. Our
experimental results have demonstrated the contribution of the multi-level
relation learning mechanism for few-shot hyperspectral image classification
when compared with the state of the art methods.
","Chun Liu, Longwei Yang, Zheng Li, Wei Yang, Zhigang Han, Jianzhong Guo, Junyong Yu",Junyong Yu,2023-11-02T13:06:03Z
Band-wise Hyperspectral Image Pansharpening using CNN Model Propagation,"  Hyperspectral pansharpening is receiving a growing interest since the last
few years as testified by a large number of research papers and challenges. It
consists in a pixel-level fusion between a lower-resolution hyperspectral
datacube and a higher-resolution single-band image, the panchromatic image,
with the goal of providing a hyperspectral datacube at panchromatic resolution.
Thanks to their powerful representational capabilities, deep learning models
have succeeded to provide unprecedented results on many general purpose image
processing tasks. However, when moving to domain specific problems, as in this
case, the advantages with respect to traditional model-based approaches are
much lesser clear-cut due to several contextual reasons. Scarcity of training
data, lack of ground-truth, data shape variability, are some such factors that
limit the generalization capacity of the state-of-the-art deep learning
networks for hyperspectral pansharpening. To cope with these limitations, in
this work we propose a new deep learning method which inherits a simple
single-band unsupervised pansharpening model nested in a sequential band-wise
adaptive scheme, where each band is pansharpened refining the model tuned on
the preceding one. By doing so, a simple model is propagated along the
wavelength dimension, adaptively and flexibly, with no need to have a fixed
number of spectral bands, and, with no need to dispose of large, expensive and
labeled training datasets. The proposed method achieves very good results on
our datasets, outperforming both traditional and deep learning reference
methods. The implementation of the proposed method can be found on
https://github.com/giu-guarino/R-PNN
","Giuseppe Guarino, Matteo Ciotola, Gemine Vivone, Giuseppe Scarpa",Giuseppe Scarpa,2023-11-11T08:53:54Z
"Hyperspectral Image Compression Using Sampling and Implicit Neural
  Representations","  Hyperspectral images, which record the electromagnetic spectrum for a pixel
in the image of a scene, often store hundreds of channels per pixel and contain
an order of magnitude more information than a similarly-sized RBG color image.
Consequently, concomitant with the decreasing cost of capturing these images,
there is a need to develop efficient techniques for storing, transmitting, and
analyzing hyperspectral images. This paper develops a method for hyperspectral
image compression using implicit neural representations where a multilayer
perceptron network F with sinusoidal activation functions ""learns"" to map pixel
locations to pixel intensities for a given hyperspectral image I. F thus acts
as a compressed encoding of this image, and the original image is reconstructed
by evaluating F at each pixel location. We use a sampling method with two
factors: window size and sampling rate to reduce the compression time. We have
evaluated our method on four benchmarks -- Indian Pines, Jasper Ridge, Pavia
University, and Cuprite using PSNR and SSIM -- and we show that the proposed
method achieves better compression than JPEG, JPEG2000, and PCA-DCT at low
bitrates. Besides, we compare our results with the learning-based methods like
PCA+JPEG2000, FPCA+JPEG2000, 3D DCT, 3D DWT+SVR, and WSRC and show the
corresponding results in the ""Compression Results"" section. We also show that
our methods with sampling achieve better speed and performance than our method
without sampling.
","Shima Rezasoltani, Faisal Z. Qureshi",Faisal Z. Qureshi,2023-12-04T01:10:04Z
"Augmenting Prototype Network with TransMix for Few-shot Hyperspectral
  Image Classification","  Few-shot hyperspectral image classification aims to identify the classes of
each pixel in the images by only marking few of these pixels. And in order to
obtain the spatial-spectral joint features of each pixel, the fixed-size
patches centering around each pixel are often used for classification. However,
observing the classification results of existing methods, we found that
boundary patches corresponding to the pixels which are located at the boundary
of the objects in the hyperspectral images, are hard to classify. These
boundary patchs are mixed with multi-class spectral information. Inspired by
this, we propose to augment the prototype network with TransMix for few-shot
hyperspectrial image classification(APNT). While taking the prototype network
as the backbone, it adopts the transformer as feature extractor to learn the
pixel-to-pixel relation and pay different attentions to different pixels. At
the same time, instead of directly using the patches which are cut from the
hyperspectral images for training, it randomly mixs up two patches to imitate
the boundary patches and uses the synthetic patches to train the model, with
the aim to enlarge the number of hard training samples and enhance their
diversity. And by following the data agumentation technique TransMix, the
attention returned by the transformer is also used to mix up the labels of two
patches to generate better labels for synthetic patches. Compared with existing
methods, the proposed method has demonstrated sate of the art performance and
better robustness for few-shot hyperspectral image classification in our
experiments.
","Chun Liu, Longwei Yang, Dongmei Dong, Zheng Li, Wei Yang, Zhigang Han, Jiayao Wang",Jiayao Wang,2024-01-22T06:56:52Z
"Study of the gOMP Algorithm for Recovery of Compressed Sensed
  Hyperspectral Images","  Hyperspectral Imaging (HSI) is used in a wide range of applications such as
remote sensing, yet the transmission of the HS images by communication data
links becomes challenging due to the large number of spectral bands that the HS
images contain together with the limited data bandwidth available in real
applications. Compressive Sensing reduces the images by randomly subsampling
the spectral bands of each spatial pixel and then it performs the image
reconstruction of all the bands using recovery algorithms which impose sparsity
in a certain transform domain. Since the image pixels are not strictly sparse,
this work studies a data sparsification pre-processing stage prior to
compression to ensure the sparsity of the pixels. The sparsified images are
compressed $2.5\times$ and then recovered using the Generalized Orthogonal
Matching Pursuit algorithm (gOMP) characterized by high accuracy, low
computational requirements and fast convergence. The experiments are performed
in five conventional hyperspectral images where the effect of different
sparsification levels in the quality of the uncompressed as well as the
recovered images is studied. It is concluded that the gOMP algorithm
reconstructs the hyperspectral images with higher accuracy as well as faster
convergence when the pixels are highly sparsified and hence at the expense of
reducing the quality of the recovered images with respect to the original
images.
","Jon Alvarez Justo, Milica Orlandic",Milica Orlandic,2024-01-26T11:20:11Z
"Hyperspectral acquisition with ScanImage at the single pixel level:
  Application to time domain coherent Raman imaging","  We present a comprehensive strategy and its practical implementation using
the commercial ScanImage software platform to perform hyperspectral point
scanning microscopy when a fast time dependent signal varies at each pixel
level. In the proposed acquisition scheme the scan along the X axis is slowed
down while the data acquisition is maintained at high pace to enable the rapid
acquisition of the time dependent signal at each pixel level. The ScanImage
generated raw 2D images have a very asymmetric aspect ratio between X and Y,
the X axis encoding both for space and time acquisition. The results are X axis
macro-pixel where the associated time depend signal is sampled therefore
providing an hyperspectral information. We exemplified the proposed
hyperspectral scheme in the context of time domain coherent Raman imaging where
a pump pulse impulsively excites molecular vibrations that are subsequently
probed by a time delayed probe pulse. In this case the time dependent signal is
a fast acousto-optics delay line that can scan a delay of 4.5ps in 25$\mu$s, at
each pixel level. We this acquisition scheme we demonstrate ultra-fast
hyperspectral vibrational imaging in the low frequency range [10$cm^{-1}$, 150
$cm^{-1}$] over a 500 $\mu m$ field of view in 14ms (7 frames/s). The proposed
acquisition scheme can be readily extended to other applications requiring to
acquired a fast evolving signal at each pixel level.
","Samuel Metais, Sisira Suresh, Paulo Diniz, Siddarth Shivkumar, Randy Bartels, Nicolas Forget, Hervé Rigneault",Hervé Rigneault,2024-02-07T18:40:06Z
Red Teaming Models for Hyperspectral Image Analysis Using Explainable AI,"  Remote sensing (RS) applications in the space domain demand machine learning
(ML) models that are reliable, robust, and quality-assured, making red teaming
a vital approach for identifying and exposing potential flaws and biases. Since
both fields advance independently, there is a notable gap in integrating red
teaming strategies into RS. This paper introduces a methodology for examining
ML models operating on hyperspectral images within the HYPERVIEW challenge,
focusing on soil parameters' estimation. We use post-hoc explanation methods
from the Explainable AI (XAI) domain to critically assess the best performing
model that won the HYPERVIEW challenge and served as an inspiration for the
model deployed on board the INTUITION-1 hyperspectral mission. Our approach
effectively red teams the model by pinpointing and validating key shortcomings,
constructing a model that achieves comparable performance using just 1% of the
input features and a mere up to 5% performance loss. Additionally, we propose a
novel way of visualizing explanations that integrate domain-specific
information about hyperspectral bands (wavelengths) and data transformations to
better suit interpreting models for hyperspectral image analysis.
","Vladimir Zaigrajew, Hubert Baniecki, Lukasz Tulczyjew, Agata M. Wijata, Jakub Nalepa, Nicolas Longépé, Przemyslaw Biecek",Przemyslaw Biecek,2024-03-12T18:28:32Z
Hyperspectral Anomaly Detection with Self-Supervised Anomaly Prior,"  The majority of existing hyperspectral anomaly detection (HAD) methods use
the low-rank representation (LRR) model to separate the background and anomaly
components, where the anomaly component is optimized by handcrafted sparse
priors (e.g., $\ell_{2,1}$-norm). However, this may not be ideal since they
overlook the spatial structure present in anomalies and make the detection
result largely dependent on manually set sparsity. To tackle these problems, we
redefine the optimization criterion for the anomaly component in the LRR model
with a self-supervised network called self-supervised anomaly prior (SAP). This
prior is obtained by the pretext task of self-supervised learning, which is
customized to learn the characteristics of hyperspectral anomalies.
Specifically, this pretext task is a classification task to distinguish the
original hyperspectral image (HSI) and the pseudo-anomaly HSI, where the
pseudo-anomaly is generated from the original HSI and designed as a prism with
arbitrary polygon bases and arbitrary spectral bands. In addition, a
dual-purified strategy is proposed to provide a more refined background
representation with an enriched background dictionary, facilitating the
separation of anomalies from complex backgrounds. Extensive experiments on
various hyperspectral datasets demonstrate that the proposed SAP offers a more
accurate and interpretable solution than other advanced HAD methods.
","Yidan Liu, Weiying Xie, Kai Jiang, Jiaqing Zhang, Yunsong Li, Leyuan Fang",Leyuan Fang,2024-04-20T10:40:12Z
"Hyperspectral Image Reconstruction for Predicting Chick Embryo Mortality
  Towards Advancing Egg and Hatchery Industry","  As the demand for food surges and the agricultural sector undergoes a
transformative shift towards sustainability and efficiency, the need for
precise and proactive measures to ensure the health and welfare of livestock
becomes paramount. In the context of the broader agricultural landscape
outlined, the application of Hyperspectral Imaging (HSI) takes on profound
significance. HSI has emerged as a cutting-edge, non-destructive technique for
fast and accurate egg quality analysis, including the detection of chick embryo
mortality. However, the high cost and operational complexity compared to
conventional RGB imaging are significant bottlenecks in the widespread adoption
of HSI technology. To overcome these hurdles and unlock the full potential of
HSI, a promising solution is hyperspectral image reconstruction from standard
RGB images. This study aims to reconstruct hyperspectral images from RGB images
for non-destructive early prediction of chick embryo mortality. Firstly, the
performance of different image reconstruction algorithms, such as HRNET, MST++,
Restormer, and EDSR were compared to reconstruct the hyperspectral images of
the eggs in the early incubation period. Later, the reconstructed spectra were
used to differentiate live from dead chick-producing eggs using the XGBoost and
Random Forest classification methods. Among the reconstruction methods, HRNET
showed impressive reconstruction performance with MRAE of 0.0955, RMSE of
0.0159, and PSNR of 36.79 dB. This study motivated that harnessing imaging
technology integrated with smart sensors and data analytics has the potential
to improve automation, enhance biosecurity, and optimize resource management
towards sustainable agriculture 4.0.
","Md. Toukir Ahmed, Md Wadud Ahmed, Ocean Monjur, Jason Lee Emmert, Girish Chowdhary, Mohammed Kamruzzaman",Mohammed Kamruzzaman,2024-05-22T17:12:15Z
"C$^3$DG: Conditional Domain Generalization for Hyperspectral Imagery
  Classification with Convergence and Constrained-risk Theories","  Hyperspectral imagery (HSI) classification may suffer the challenge of
hyperspectral-monospectra, where different classes present similar spectra.
Joint spatial-spectral feature extraction is a popular solution for the
problem, but this strategy tends to inflate accuracy since test pixels may
exist in training patches. Domain generalization methods show promising
potential, but they still fail to distinguish similar spectra across varying
domains, in addition, the theoretical support is usually ignored. In this
paper, we only rely on spectral information to solve the
hyperspectral-monospectra problem, and propose a Convergence and
Error-Constrained Conditional Domain Generalization method for Hyperspectral
Imagery Classification (C$^3$DG). The major contributions of this paper include
two aspects: the Conditional Revising Inference Block (CRIB), and the
corresponding theories for model convergence and generalization errors. CRIB is
the kernel structure of the proposed method, which employs a shared encoder and
multi-branch decoders to fully leverage the conditional distribution during
training, achieving a decoupling that aligns with the generation mechanisms of
HSI. Moreover, to ensure model convergence and maintain controllable error, we
propose the optimization convergence theorem and risk upper bound theorem. In
the optimization convergence theorem, we ensure the model convergence by
demonstrating that the gradients of the loss terms are not contradictory. In
the risk upper bound theorem, our theoretical analysis explores the
relationship between test-time training and recent related work to establish a
concrete bound for error. Experimental results on three benchmark datasets
indicate the superiority of C$^3$DG.
","Zhe Gao, Bin Pan, Zhenwei Shi",Zhenwei Shi,2024-07-04T18:03:45Z
"A self-supervised and adversarial approach to hyperspectral demosaicking
  and RGB reconstruction in surgical imaging","  Hyperspectral imaging holds promises in surgical imaging by offering
biological tissue differentiation capabilities with detailed information that
is invisible to the naked eye. For intra-operative guidance, real-time spectral
data capture and display is mandated. Snapshot mosaic hyperspectral cameras are
currently seen as the most suitable technology given this requirement. However,
snapshot mosaic imaging requires a demosaicking algorithm to fully restore the
spatial and spectral details in the images. Modern demosaicking approaches
typically rely on synthetic datasets to develop supervised learning methods, as
it is practically impossible to simultaneously capture both snapshot and
high-resolution spectral images of the exact same surgical scene. In this work,
we present a self-supervised demosaicking and RGB reconstruction method that
does not depend on paired high-resolution data as ground truth. We leverage
unpaired standard high-resolution surgical microscopy images, which only
provide RGB data but can be collected during routine surgeries. Adversarial
learning complemented by self-supervised approaches are used to drive our
hyperspectral-based RGB reconstruction into resembling surgical microscopy
images and increasing the spatial resolution of our demosaicking. The spatial
and spectral fidelity of the reconstructed hyperspectral images have been
evaluated quantitatively. Moreover, a user study was conducted to evaluate the
RGB visualisation generated from these spectral images. Both spatial detail and
colour accuracy were assessed by neurosurgical experts. Our proposed
self-supervised demosaicking method demonstrates improved results compared to
existing methods, demonstrating its potential for seamless integration into
intra-operative workflows.
","Peichao Li, Oscar MacCormac, Jonathan Shapey, Tom Vercauteren",Tom Vercauteren,2024-07-27T15:29:35Z
"Theoretical and Practical Progress in Hyperspectral Pixel Unmixing with
  Large Spectral Libraries from a Sparse Perspective","  Hyperspectral unmixing is the process of determining the presence of
individual materials and their respective abundances from an observed pixel
spectrum. Unmixing is a fundamental process in hyperspectral image analysis,
and is growing in importance as increasingly large spectral libraries are
created and used. Unmixing is typically done with ordinary least squares (OLS)
regression. However, unmixing with large spectral libraries where the materials
present in a pixel are not a priori known, solving for the coefficients in OLS
requires inverting a non-invertible matrix from a large spectral library. A
number of regression methods are available that can produce a numerical
solution using regularization, but with considerably varied effectiveness.
Also, simple methods that are unpopular in the statistics literature (i.e.
step-wise regression) are used with some level of effectiveness in
hyperspectral analysis. In this paper, we provide a thorough performance
evaluation of the methods considered, evaluating methods based on how often
they select the correct materials in the models. Investigated methods include
ordinary least squares regression, non-negative least squares regression, ridge
regression, lasso regression, step-wise regression and Bayesian model
averaging. We evaluated these unmixing approaches using multiple criteria:
incorporation of non-negative abundances, model size, accurate mineral
detection and root mean squared error (RMSE). We provide a taxonomy of the
regression methods, showing that most methods can be understood as Bayesian
methods with specific priors. We conclude that methods that can be derived with
priors that correspond to the phenomenology of hyperspectral imagery outperform
those with priors that are optimal for prediction performance under the
assumptions of ordinary least squares linear regression.
","Jade Preston, William Basener",William Basener,2024-08-14T14:24:56Z
"BihoT: A Large-Scale Dataset and Benchmark for Hyperspectral Camouflaged
  Object Tracking","  Hyperspectral object tracking (HOT) has exhibited potential in various
applications, particularly in scenes where objects are camouflaged. Existing
trackers can effectively retrieve objects via band regrouping because of the
bias in existing HOT datasets, where most objects tend to have distinguishing
visual appearances rather than spectral characteristics. This bias allows the
tracker to directly use the visual features obtained from the false-color
images generated by hyperspectral images without the need to extract spectral
features. To tackle this bias, we find that the tracker should focus on the
spectral information when object appearance is unreliable. Thus, we provide a
new task called hyperspectral camouflaged object tracking (HCOT) and
meticulously construct a large-scale HCOT dataset, termed BihoT, which consists
of 41,912 hyperspectral images covering 49 video sequences. The dataset covers
various artificial camouflage scenes where objects have similar appearances,
diverse spectrums, and frequent occlusion, making it a very challenging dataset
for HCOT. Besides, a simple but effective baseline model, named spectral
prompt-based distractor-aware network (SPDAN), is proposed, comprising a
spectral embedding network (SEN), a spectral prompt-based backbone network
(SPBN), and a distractor-aware module (DAM). Specifically, the SEN extracts
spectral-spatial features via 3-D and 2-D convolutions. Then, the SPBN
fine-tunes powerful RGB trackers with spectral prompts and alleviates the
insufficiency of training samples. Moreover, the DAM utilizes a novel statistic
to capture the distractor caused by occlusion from objects and background.
Extensive experiments demonstrate that our proposed SPDAN achieves
state-of-the-art performance on the proposed BihoT and other HOT datasets.
","Hanzheng Wang, Wei Li, Xiang-Gen Xia, Qian Du",Qian Du,2024-08-22T09:07:51Z
"Detection and tracking of gas plumes in LWIR hyperspectral video
  sequence data","  Automated detection of chemical plumes presents a segmentation challenge. The
segmentation problem for gas plumes is difficult due to the diffusive nature of
the cloud. The advantage of considering hyperspectral images in the gas plume
detection problem over the conventional RGB imagery is the presence of
non-visual data, allowing for a richer representation of information. In this
paper we present an effective method of visualizing hyperspectral video
sequences containing chemical plumes and investigate the effectiveness of
segmentation techniques on these post-processed videos. Our approach uses a
combination of dimension reduction and histogram equalization to prepare the
hyperspectral videos for segmentation. First, Principal Components Analysis
(PCA) is used to reduce the dimension of the entire video sequence. This is
done by projecting each pixel onto the first few Principal Components resulting
in a type of spectral filter. Next, a Midway method for histogram equalization
is used. These methods redistribute the intensity values in order to reduce
flicker between frames. This properly prepares these high-dimensional video
sequences for more traditional segmentation techniques. We compare the ability
of various clustering techniques to properly segment the chemical plume. These
include K-means, spectral clustering, and the Ginzburg-Landau functional.
","Torin Gerhart, Justin Sunu, Ekaterina Merkurjev, Jen-Mei Chang, Jerome Gilles, Andrea L. Bertozzi",Andrea L. Bertozzi,2024-11-01T00:33:29Z
"Persistent Homology on Grassmann Manifolds for Analysis of Hyperspectral
  Movies","  The existence of characteristic structure, or shape, in complex data sets has
been recognized as increasingly important for mathematical data analysis. This
realization has motivated the development of new tools such as persistent
homology for exploring topological invariants, or features, in large data sets.
In this paper we apply persistent homology to the characterization of gas
plumes in time dependent sequences of hyperspectral cubes, i.e. the analysis of
4-way arrays. We investigate hyperspectral movies of Long-Wavelength Infrared
data monitoring an experimental release of chemical simulant into the air. Our
approach models regions of interest within the hyperspectral data cubes as
points on the real Grassmann manifold $G(k, n)$ (whose points parameterize the
$k$-dimensional subspaces of $\mathbb{R}^n$), contrasting our approach with the
more standard framework in Euclidean space. An advantage of this approach is
that it allows a sequence of time slices in a hyperspectral movie to be
collapsed to a sequence of points in such a way that some of the key structure
within and between the slices is encoded by the points on the Grassmann
manifold. This motivates the search for topological features, associated with
the evolution of the frames of a hyperspectral movie, within the corresponding
points on the Grassmann manifold. The proposed mathematical model affords the
processing of large data sets while retaining valuable discriminatory
information. In this paper, we discuss how embedding our data in the Grassmann
manifold, together with topological data analysis, captures dynamical events
that occur as the chemical plume is released and evolves.
","Sofya Chepushtanova, Michael Kirby, Chris Peterson, Lori Ziegelmeier",Lori Ziegelmeier,2016-07-07T23:39:29Z
"Hyperspectral band selection using genetic algorithm and support vector
  machines for early identification of charcoal rot disease in soybean","  Charcoal rot is a fungal disease that thrives in warm dry conditions and
affects the yield of soybeans and other important agronomic crops worldwide.
There is a need for robust, automatic and consistent early detection and
quantification of disease symptoms which are important in breeding programs for
the development of improved cultivars and in crop production for the
implementation of disease control measures for yield protection. Current
methods of plant disease phenotyping are predominantly visual and hence are
slow and prone to human error and variation. There has been increasing interest
in hyperspectral imaging applications for early detection of disease symptoms.
However, the high dimensionality of hyperspectral data makes it very important
to have an efficient analysis pipeline in place for the identification of
disease so that effective crop management decisions can be made. The focus of
this work is to determine the minimal number of most effective hyperspectral
bands that can distinguish between healthy and diseased specimens early in the
growing season. Healthy and diseased hyperspectral data cubes were captured at
3, 6, 9, 12, and 15 days after inoculation. We utilized inoculated and control
specimens from 4 different genotypes. Each hyperspectral image was captured at
240 different wavelengths in the range of 383 to 1032 nm. We used a combination
of genetic algorithm as an optimizer and support vector machines as a
classifier for identification of maximally effective band combinations. A
binary classification between healthy and infected samples using six selected
band combinations obtained a classification accuracy of 97% and a F1 score of
0.97 for the infected class. The results demonstrated that these carefully
chosen bands are more informative than RGB images, and could be used in a
multispectral camera for remote identification of charcoal rot infection in
soybean.
","Koushik Nagasubramanian, Sarah Jones, Soumik Sarkar, Asheesh K. Singh, Arti Singh, Baskar Ganapathysubramanian",Baskar Ganapathysubramanian,2017-10-12T18:27:41Z
"A Novel Approach for Dimensionality Reduction and Classification of
  Hyperspectral Images based on Normalized Synergy","  During the last decade, hyperspectral images have attracted increasing
interest from researchers worldwide. They provide more detailed information
about an observed area and allow an accurate target detection and precise
discrimination of objects compared to classical RGB and multispectral images.
Despite the great potentialities of hyperspectral technology, the analysis and
exploitation of the large volume data remain a challenging task. The existence
of irrelevant redundant and noisy images decreases the classification accuracy.
As a result, dimensionality reduction is a mandatory step in order to select a
minimal and effective images subset. In this paper, a new filter approach
normalized mutual synergy (NMS) is proposed in order to detect relevant bands
that are complementary in the class prediction better than the original
hyperspectral cube data. The algorithm consists of two steps: images selection
through normalized synergy information and pixel classification. The proposed
approach measures the discriminative power of the selected bands based on a
combination of their maximal normalized synergic information, minimum
redundancy and maximal mutual information with the ground truth. A comparative
study using the support vector machine (SVM) and k-nearest neighbor (KNN)
classifiers is conducted to evaluate the proposed approach compared to the
state of art band selection methods. Experimental results on three benchmark
hyperspectral images proposed by the NASA ""Aviris Indiana Pine"", ""Salinas"" and
""Pavia University"" demonstrated the robustness, effectiveness and the
discriminative power of the proposed approach over the literature approaches.
  Keywords: Hyperspectral images; target detection; pixel classification;
dimensionality reduction; band selection; information theory; mutual
information; normalized synergy
","Asma Elmaizi, Hasna Nhaila, Elkebir Sarhrouni, Ahmed Hammouch, Nacir Chafik",Nacir Chafik,2022-10-25T10:36:26Z
"Semantic Segmentation in Satellite Hyperspectral Imagery by Deep
  Learning","  Satellites are increasingly adopting on-board AI to optimize operations and
increase autonomy through in-orbit inference. The use of Deep Learning (DL)
models for segmentation in hyperspectral imagery offers advantages for remote
sensing applications. In this work, we train and test 20 models for multi-class
segmentation in hyperspectral imagery, selected for their potential in future
space deployment. These models include 1D and 2D Convolutional Neural Networks
(CNNs) and the latest vision transformers (ViTs). We propose a lightweight
1D-CNN model, 1D-Justo-LiuNet, which outperforms state-of-the-art models in the
hypespectral domain. 1D-Justo-LiuNet exceeds the performance of 2D-CNN UNets
and outperforms Apple's lightweight vision transformers designed for mobile
inference. 1D-Justo-LiuNet achieves the highest accuracy (0.93) with the
smallest model size (4,563 parameters) among all tested models, while
maintaining fast inference. Unlike 2D-CNNs and ViTs, which encode both spectral
and spatial information, 1D-Justo-LiuNet focuses solely on the rich spectral
features in hyperspectral data, benefitting from the high-dimensional feature
space. Our findings are validated across various satellite datasets, with the
HYPSO-1 mission serving as the primary case study for sea, land, and cloud
segmentation. We further confirm our conclusions through generalization tests
on other hyperspectral missions, such as NASA's EO-1. Based on its superior
performance and compact size, we conclude that 1D-Justo-LiuNet is highly
suitable for in-orbit deployment, providing an effective solution for
optimizing and automating satellite operations at edge.
","Jon Alvarez Justo, Alexandru Ghita, Daniel Kovac, Joseph L. Garrett, Mariana-Iuliana Georgescu, Jesus Gonzalez-Llorente, Radu Tudor Ionescu, Tor Arne Johansen",Tor Arne Johansen,2023-10-24T21:57:59Z
Hyperspectral near infrared imaging using a tunable spectral phasor,"  Hyperspectral imaging captures both spectral and spatial information from a
sample. The near infrared (NIR, > 800 nm) is advantageous for biomedical
imaging as it falls into the tissue transparency window but also contains
vibrational overtone and combination modes useful for molecular fingerprinting.
Here, we demonstrate hyperspectral NIR imaging using a spectral phasor
transformation (HyperNIR). This method employs a liquid crystal variable
retarder (LCVR) for tunable, wavelength-dependent sine-, cosine and no
filtering that transforms optical signals into phasor space. Spectral
information is thus obtained with just three images. The LCVR can be adjusted
to cover a spectral range from 900 nm to 1600 nm in windows tunable from 50 nm
to 700 nm. This approach enables distinguishing NIR fluorophores with emission
peaks less than 5 nm apart. Furthermore, we demonstrate label-free
hyperspectral NIR reflectance imaging to identify plastic polymers and to
monitor in vivo plant health. The approach uses the full camera resolution and
reaches hyperspectral frame rates of 0.2 per second, limited only by the
switching rate of the LCVR. HyperNIR facilitates straightforward hyperspectral
imaging with standard NIR cameras for applications in biomedical imaging and
environmental monitoring.
","Jan Stegemann, Franziska Gröniger, Krisztian Neutsch, Han Li, Benjamin Flavel, Justus Tom Metternich, Luise Erpenbeck, Poul Petersen, Per Niklas Hedde, Sebastian Kruss",Sebastian Kruss,2024-07-31T15:27:25Z
Bayesian segmentation of hyperspectral images,"  In this paper we consider the problem of joint segmentation of hyperspectral
images in the Bayesian framework. The proposed approach is based on a Hidden
Markov Modeling (HMM) of the images with common segmentation, or equivalently
with common hidden classification label variables which is modeled by a Potts
Markov Random Field. We introduce an appropriate Markov Chain Monte Carlo
(MCMC) algorithm to implement the method and show some simulation results.
","Adel Mohammadpour, Olivier Féron, Ali Mohammad-Djafari",Ali Mohammad-Djafari,2007-08-22T13:18:25Z
Hyperspectral optical diffraction tomography,"  Here, we present a novel microscopic technique for measuring
wavelength-dependent three-dimensional (3-D) distributions of the refractive
indices (RIs) of microscopic samples in the visible wavelengths. Employing 3-D
quantitative phase microscopy techniques with a wavelength-swept source, 3-D RI
tomograms were obtained in the range of 450 - 700 nm with a spectral resolution
of a few nanometers. The capability of the technique was demonstrated by
measuring the hyperspectral 3-D RI tomograms of polystyrene beads, human red
blood cells, and hepatocytes. The results demonstrate the potential for
label-free molecular specific 3-D tomography of biological samples.
","JaeHwang Jung, Kyoohyun Kim, Jonghee Yoon, YongKeun Park",YongKeun Park,2015-11-05T08:31:05Z
"Generalized Alternating Projection Based Total Variation Minimization
  for Compressive Sensing","  We consider the total variation (TV) minimization problem used for
compressive sensing and solve it using the generalized alternating projection
(GAP) algorithm. Extensive results demonstrate the high performance of proposed
algorithm on compressive sensing, including two dimensional images,
hyperspectral images and videos. We further derive the Alternating Direction
Method of Multipliers (ADMM) framework with TV minimization for video and
hyperspectral image compressive sensing under the CACTI and CASSI framework,
respectively. Connections between GAP and ADMM are also provided.
",Xin Yuan,Xin Yuan,2015-11-12T13:35:58Z
"Detecting Burnscar from Hyperspectral Imagery via Sparse Representation
  with Low-Rank Interference","  In this paper, we propose a burnscar detection model for hyperspectral
imaging (HSI) data. The proposed model contains two-processing steps in which
the first step separate and then suppress the cloud information presenting in
the data set using an RPCA algorithm and the second step detect the burnscar
area in the low-rank component output of the first step. Experiments are
conducted on the public MODIS dataset available at NASA official website.
","Minh Dao, Xiang Xiang, Bulent Ayhan, Chiman Kwan, Trac D. Tran",Trac D. Tran,2016-05-01T18:18:45Z
"Robust control of varying weak hyperspectral target detection with
  sparse non-negative representation","  In this study, a multiple-comparison approach is developed for detecting
faint hyperspectral sources. The detection method relies on a sparse and
non-negative representation on a highly coherent dictionary to track a
spatially varying source. A robust control of the detection errors is ensured
by learning the test statistic distributions on the data. The resulting control
is based on the false discovery rate, to take into account the large number of
pixels to be tested. This method is applied to data recently recorded by the
three-dimensional spectrograph Multi-Unit Spectrograph Explorer.
","Raphael Bacher, Celine Meillier, Florent Chatelain, Olivier Michel",Olivier Michel,2017-02-02T10:37:40Z
"Bayesian Unmixing using Sparse Dirichlet Prior with Polynomial
  Post-nonlinear Mixing Model","  A sparse Dirichlet prior is proposed for estimating the abundance vector of
hyperspectral images with a nonlinear mixing model. This sparse prior is led to
an unmixing procedure in a semi-supervised scenario in which exact materials
are unknown. The nonlinear model is a polynomial post-nonlinear mixing model
that represents each hyperspectral pixel as a nonlinear function of pure
spectral signatures corrupted by additive white noise. Simulation results show
more than 50% improvement in the estimation error.
","Fahime Amiri, Mohammad Hossein Kahaei",Mohammad Hossein Kahaei,2018-03-02T14:59:22Z
"Hyperspectral Super-Resolution with Coupled Tucker Approximation:
  Recoverability and SVD-based algorithms","  We propose a novel approach for hyperspectral super-resolution, that is based
on low-rank tensor approximation for a coupled low-rank multilinear (Tucker)
model. We show that the correct recovery holds for a wide range of multilinear
ranks. For coupled tensor approximation, we propose two SVD-based algorithms
that are simple and fast, but with a performance comparable to the
state-of-the-art methods. The approach is applicable to the case of unknown
spatial degradation and to the pansharpening problem.
","Clémence Prévost, Konstantin Usevich, Pierre Comon, David Brie",David Brie,2018-11-21T14:36:19Z
"Hyperspectral phase imaging based on denoising in complex-valued
  eigensubspace","  A new denoising algorithm for hyperspectral complex domain data has been
developed and studied. This algorithm is based on the complex domain
block-matching 3D filter including the 3D Wiener filtering stage. The developed
algorithm is applied and tuned to work in the singular value decomposition
(SVD) eigenspace of reduced dimension. The accuracy and quantitative advantage
of the new algorithm are demonstrated in simulation tests and in the processing
of the experimental data. It is shown that the algorithm is effective and
provides reliable results even for highly noisy data.
","Igor Shevkunov, Vladimir Katkovnik, Daniel Claus, Giancarlo Pedrini, Nikolay Petrov, Karen Egiazarian",Karen Egiazarian,2019-07-06T09:47:28Z
Hyperspectral Image Denoising with Log-Based Robust PCA,"  It is a challenging task to remove heavy and mixed types of noise from
Hyperspectral images (HSIs). In this paper, we propose a novel nonconvex
approach to RPCA for HSI denoising, which adopts the log-determinant rank
approximation and a novel $\ell_{2,\log}$ norm, to restrict the low-rank or
column-wise sparse properties for the component matrices, respectively.For the
$\ell_{2,\log}$-regularized shrinkage problem, we develop an efficient,
closed-form solution, which is named $\ell_{2,\log}$-shrinkage operator, which
can be generally used in other problems. Extensive experiments on both
simulated and real HSIs demonstrate the effectiveness of the proposed method in
denoising HSIs.
","Yang Liu, Qian Zhang, Yongyong Chen, Qiang Cheng, Chong Peng",Chong Peng,2021-05-25T13:32:01Z
"Closed-form detector for solid sub-pixel targets in multivariate
  t-distributed background clutter","  The generalized likelihood ratio test (GLRT) is used to derive a detector for
solid sub-pixel targets in hyperspectral imagery. A closed-form solution is
obtained that optimizes the replacement target model when the background is a
fat-tailed elliptically-contoured multivariate t-distribution. This generalizes
GLRT-based detectors that have previously been derived for the replacement
target model with Gaussian background, and for the additive target model with
an elliptically-contoured background. Experiments with simulated hyperspectral
data illustrate the performance of this detector in various parameter regimes.
","James Theiler, Beate Zimmer, Amanda Ziemann",Amanda Ziemann,2018-04-05T21:28:51Z
"Lensless hyperspectral imaging by Fourier transform spectroscopy for
  broadband visible light: phase retrieval technique","  A novel phase retrieval algorithm for broadband hyperspectral phase imaging
from noisy intensity observations is proposed. It utilizes advantages of the
Fourier Transform spectroscopy in the self-referencing optical setup and
provides, additionally beyond spectral intensity distribution, reconstruction
of the investigated object's phase. The noise amplification Fellgett's
disadvantage is relaxed by the application of sparse wavefront noise filtering
embedded in the proposed algorithm. The algorithm reliability is proved by
simulation tests and results of physical experiments on transparent objects
which demonstrate precise phase imaging and object depth (profile)
reconstructions.
","Igor Shevkunov, Vladimir Katkovnik, Karen Egiazarian",Karen Egiazarian,2020-02-24T07:03:53Z
"Does Normalization Methods Play a Role for Hyperspectral Image
  Classification?","  For Hyperspectral image (HSI) datasets, each class have their salient feature
and classifiers classify HSI datasets according to the class's saliency
features, however, there will be different salient features when use different
normalization method. In this letter, we report the effect on classifiers by
different normalization methods and recommend the best normalization methods
for classifier after analyzing the impact of different normalization methods on
classifiers. Pavia University datasets, Indian Pines datasets and Kennedy Space
Center datasets will apply to several typical classifiers in order to evaluate
and analysis the impact of different normalization methods on typical
classifiers.
","Faxian Cao, Zhijing Yang, Jinchang Ren, Mengying Jiang, Wing-Kuen Ling",Wing-Kuen Ling,2017-10-09T05:08:32Z
Hyperspectral Image Clustering with Spatially-Regularized Ultrametrics,"  We propose a method for the unsupervised clustering of hyperspectral images
based on spatially regularized spectral clustering with ultrametric path
distances. The proposed method efficiently combines data density and geometry
to distinguish between material classes in the data, without the need for
training labels. The proposed method is efficient, with quasilinear scaling in
the number of data points, and enjoys robust theoretical performance
guarantees. Extensive experiments on synthetic and real HSI data demonstrate
its strong performance compared to benchmark and state-of-the-art methods. In
particular, the proposed method achieves not only excellent labeling accuracy,
but also efficiently estimates the number of clusters.
","Shukun Zhang, James M. Murphy",James M. Murphy,2020-04-10T14:27:41Z
MXR-U-Nets for Real Time Hyperspectral Reconstruction,"  In recent times, CNNs have made significant contributions to applications in
image generation, super-resolution and style transfer. In this paper, we build
upon the work of Howard and Gugger, He et al. and Misra, D. and propose a CNN
architecture that accurately reconstructs hyperspectral images from their RGB
counterparts. We also propose a much shallower version of our best model with a
10% relative memory footprint and 3x faster inference, thus enabling real-time
video applications while still experiencing only about a 0.5% decrease in
performance.
","Atmadeep Banerjee, Akash Palrecha",Akash Palrecha,2020-04-15T11:06:48Z
Deep Diffusion Processes for Active Learning of Hyperspectral Images,"  A method for active learning of hyperspectral images (HSI) is proposed, which
combines deep learning with diffusion processes on graphs. A deep variational
autoencoder extracts smoothed, denoised features from a high-dimensional HSI,
which are then used to make labeling queries based on graph diffusion
processes. The proposed method combines the robust representations of deep
learning with the mathematical tractability of diffusion geometry, and leads to
strong performance on real HSI.
","Abiy Tasissa, Duc Nguyen, James Murphy",James Murphy,2021-01-08T19:38:54Z
"Hyperspectral and LiDAR data classification based on linear
  self-attention","  An efficient linear self-attention fusion model is proposed in this paper for
the task of hyperspectral image (HSI) and LiDAR data joint classification. The
proposed method is comprised of a feature extraction module, an attention
module, and a fusion module. The attention module is a plug-and-play linear
self-attention module that can be extensively used in any model. The proposed
model has achieved the overall accuracy of 95.40\% on the Houston dataset. The
experimental results demonstrate the superiority of the proposed method over
other state-of-the-art models.
","Min Feng, Feng Gao, Jian Fang, Junyu Dong",Junyu Dong,2021-04-06T05:57:41Z
"Measuring the Ripeness of Fruit with Hyperspectral Imaging and Deep
  Learning","  We present a system to measure the ripeness of fruit with a hyperspectral
camera and a suitable deep neural network architecture. This architecture did
outperform competitive baseline models on the prediction of the ripeness state
of fruit. For this, we recorded a data set of ripening avocados and kiwis,
which we make public. We also describe the process of data collection in a
manner that the adaption for other fruit is easy. The trained network is
validated empirically, and we investigate the trained features. Furthermore, a
technique is introduced to visualize the ripening process.
","Leon Amadeus Varga, Jan Makowski, Andreas Zell",Andreas Zell,2021-04-20T07:43:19Z
Hyperspectral super-resolution via low rank tensor triple decomposition,"  Hyperspectral image (HSI) and multispectral image (MSI) fusion aims at
producing a super-resolution image (SRI). In this paper, we establish a
nonconvex optimization model for image fusion problems through low-rank tensor
triple decomposition. Using the L-BFGS approach, we develop a first-order
optimization algorithm for obtaining the desired super-resolution image
(TTDSR). Furthermore, two detailed methods are provided for calculating the
gradient of the objective function. With the aid of the Kurdyka-Lojasiewicz
property, the iterative sequence is proved to converge to a stationary point.
Finally, experimental results on different datasets show the effectiveness of
our proposed approach.
","Xiaofei Cui, Jingya Chang",Jingya Chang,2023-06-18T06:54:16Z
"Hyperspectral Reconstruction of Skin Through Fusion of Scattering
  Transform Features","  Hyperspectral imagery (HSI) is an established technique with an array of
applications, but its use is limited due to both practical and technical issues
associated with spectral devices. The goal of the ICASSP 2024 'Hyper-Skin'
Challenge is to extract skin HSI from matching RGB images and an infrared band.
To address this problem we propose a model using features of the scattering
transform - a type of convolutional neural network with predefined filters. Our
model matches and inverts those features, rather than the pixel values,
reducing the complexity of matching while grouping similar features together,
resulting in an improved learning process.
","Wojciech Czaja, Jeremiah Emidih, Brandon Kolstoe, Richard G. Spencer",Richard G. Spencer,2024-04-15T13:34:27Z
"Non-Destructive Peat Analysis using Hyperspectral Imaging and Machine
  Learning","  Peat, a crucial component in whisky production, imparts distinctive and
irreplaceable flavours to the final product. However, the extraction of peat
disrupts ancient ecosystems and releases significant amounts of carbon,
contributing to climate change. This paper aims to address this issue by
conducting a feasibility study on enhancing peat use efficiency in whisky
manufacturing through non-destructive analysis using hyperspectral imaging.
Results show that shot-wave infrared (SWIR) data is more effective for
analyzing peat samples and predicting total phenol levels, with accuracies up
to 99.81%.
","Yijun Yan, Jinchang Ren, Barry Harrison, Oliver Lewis, Yinhe Li, Ping Ma",Ping Ma,2024-05-03T15:47:07Z
"Sparsity Constrained Graph Regularized NMF for Spectral Unmixing of
  Hyperspectral Data","  Hyperspectral images contain mixed pixels due to low spatial resolution of
hyperspectral sensors. Mixed pixels are pixels containing more than one
distinct material called endmembers. The presence percentages of endmembers in
mixed pixels are called abundance fractions. Spectral unmixing problem refers
to decomposing these pixels into a set of endmembers and abundance fractions.
Due to nonnegativity constraint on abundance fractions, nonnegative matrix
factorization methods (NMF) have been widely used for solving spectral unmixing
problem. In this paper we have used graph regularized NMF (GNMF) method
combined with sparseness constraint to decompose mixed pixels in hyperspectral
imagery. This method preserves the geometrical structure of data while
representing it in low dimensional space. Adaptive regularization parameter
based on temperature schedule in simulated annealing method also has been used
in this paper for the sparseness term. Proposed algorithm is applied on
synthetic and real datasets. Synthetic data is generated based on endmembers
from USGS spectral library. AVIRIS Cuprite dataset is used as real dataset for
evaluation of proposed method. Results are quantified based on spectral angle
distance (SAD) and abundance angle distance (AAD) measures. Results in
comparison with other methods show that the proposed method can unmix data more
effectively. Specifically for the Cuprite dataset, performance of the proposed
method is approximately 10% better than the VCA and Sparse NMF in terms of root
mean square of SAD.
","Roozbeh Rajabi, Hassan Ghassemian",Hassan Ghassemian,2014-11-03T08:41:32Z
An automatic bad band preremoval algorithm for hyperspectral imagery,"  For most hyperspectral remote sensing applications, removing bad bands, such
as water absorption bands, is a required preprocessing step. Currently, the
commonly applied method is by visual inspection, which is very time-consuming
and it is easy to overlook some noisy bands. In this study, we find an inherent
connection between target detection algorithms and the corrupted band removal.
As an example, for the matched filter (MF), which is the most widely used
target detection method for hyperspectral data, we present an automatic
MF-based algorithm for bad band identification. The MF detector is a filter
vector, and the resulting filter output is the sum of all bands weighted by the
MF coefficients. Therefore, we can identify bad bands only by using the MF
filter vector itself, the absolute value of whose entry accounts for the
importance of each band for the target detection. For a specific target of
interest, the bands with small MF weights correspond to the noisy or bad ones.
Based on this fact, we develop an automatic bad band preremoval algorithm by
utilizing the average absolute value of MF weights for multiple targets within
a scene. Experiments with three well known hyperspectral datasets show that our
method can always identify the water absorption and other low signal-to-noise
(SNR) bands that are usually chosen as bad bands manually.
","Luyan Ji, Xiurui Geng, Yongchao Zhao, Fuxiang Wang",Fuxiang Wang,2016-10-19T09:31:31Z
"Segmented and Non-Segmented Stacked Denoising Autoencoder for
  Hyperspectral Band Reduction","  Hyperspectral image analysis often requires selecting the most informative
bands instead of processing the whole data without losing the key information.
Existing band reduction (BR) methods have the capability to reveal the
nonlinear properties exhibited in the data but at the expense of loosing its
original representation. To cope with the said issue, an unsupervised
non-linear segmented and non-segmented stacked denoising autoencoder (UDAE)
based BR method is proposed. Our aim is to find an optimal mapping and
construct a lower-dimensional space that has a similar structure to the
original data with least reconstruction error. The proposed method first
confronts the original hyperspectral data into smaller regions in a spatial
domain and then each region is processed by UDAE individually. This results in
reduced complexity and improved efficiency of BR for both semi-supervised and
unsupervised tasks, i.e. classification and clustering. Our experiments on
publicly available hyperspectral datasets with various types of classifiers
demonstrate the effectiveness of UDAE method which equates favorably with other
state-of-the-art dimensionality reduction and BR methods.
","Muhammad Ahmad, Asad Khan, Adil Mehmood Khan, Rasheed Hussain",Rasheed Hussain,2017-05-19T10:33:21Z
"Hyperspectral Imaging Technology and Transfer Learning Utilized in
  Identification Haploid Maize Seeds","  It is extremely important to correctly identify the cultivars of maize seeds
in the breeding process of maize. In this paper, the transfer learning as a
method of deep learning is adopted to establish a model by combining with the
hyperspectral imaging technology. The haploid seeds can be recognized from
large amount of diploid maize ones with great accuracy through the model.
First, the information of maize seeds on each wave band is collected using the
hyperspectral imaging technology, and then the recognition model is built on
VGG-19 network, which is pre-trained by large-scale computer vision database
(Image-Net). The correct identification rate of model utilizing seed spectral
images containing 256 wave bands (862.5-1704.2nm) reaches 96.32%, and the
correct identification rate of the model utilizing the seed spectral images
containing single-band reaches 95.75%. The experimental results show that, CNN
model which is pre-trained by visible light image database can be applied to
the near-infrared hyperspectral imaging-based identification of maize seeds,
and high accurate identification rate can be achieved. Meanwhile, when there is
small amount of data samples, it can still realize high recognition by using
transfer learning. The model not only meets the requirements of breeding
recognition, but also greatly reduce the cost occurred in sample collection.
","Wen-Xuan Liao, Xuan-Yu Wang, Dong An, Yao-Guang Wei",Yao-Guang Wei,2018-05-30T02:55:14Z
Hyperspectral Image Classification in the Presence of Noisy Labels,"  Label information plays an important role in supervised hyperspectral image
classification problem. However, current classification methods all ignore an
important and inevitable problem---labels may be corrupted and collecting clean
labels for training samples is difficult, and often impractical. Therefore, how
to learn from the database with noisy labels is a problem of great practical
importance. In this paper, we study the influence of label noise on
hyperspectral image classification, and develop a random label propagation
algorithm (RLPA) to cleanse the label noise. The key idea of RLPA is to exploit
knowledge (e.g., the superpixel based spectral-spatial constraints) from the
observed hyperspectral images and apply it to the process of label propagation.
Specifically, RLPA first constructs a spectral-spatial probability transfer
matrix (SSPTM) that simultaneously considers the spectral similarity and
superpixel based spatial information. It then randomly chooses some training
samples as ""clean"" samples and sets the rest as unlabeled samples, and
propagates the label information from the ""clean"" samples to the rest unlabeled
samples with the SSPTM. By repeating the random assignment (of ""clean"" labeled
samples and unlabeled samples) and propagation, we can obtain multiple labels
for each training sample. Therefore, the final propagated label can be
calculated by a majority vote algorithm. Experimental studies show that RLPA
can reduce the level of noisy label and demonstrates the advantages of our
proposed method over four major classifiers with a significant margin---the
gains in terms of the average OA, AA, Kappa are impressive, e.g., 9.18%, 9.58%,
and 0.1043. The Matlab source code is available at
https://github.com/junjun-jiang/RLPA
","Junjun Jiang, Jiayi Ma, Zheng Wang, Chen Chen, Xianming Liu",Xianming Liu,2018-09-12T01:20:46Z
"Low-Rank Tensor Modeling for Hyperspectral Unmixing Accounting for
  Spectral Variability","  Traditional hyperspectral unmixing methods neglect the underlying variability
of spectral signatures often observed in typical hyperspectral images (HI),
propagating these missmodeling errors throughout the whole unmixing process.
Attempts to model material spectra as members of sets or as random variables
tend to lead to severely ill-posed unmixing problems. Although parametric
models have been proposed to overcome this drawback by handling endmember
variability through generalizations of the mixing model, the success of these
techniques depend on employing appropriate regularization strategies. Moreover,
the existing approaches fail to adequately explore the natural multidimensinal
representation of HIs. Recently, tensor-based strategies considered low-rank
decompositions of hyperspectral images as an alternative to impose
low-dimensional structures on the solutions of standard and multitemporal
unmixing problems. These strategies, however, present two main drawbacks: 1)
they confine the solutions to low-rank tensors, which often cannot represent
the complexity of real-world scenarios; and 2) they lack guarantees that
endmembers and abundances will be correctly factorized in their respective
tensors. In this work, we propose a more flexible approach, called ULTRA-V,
that imposes low-rank structures through regularizations whose strictness is
controlled by scalar parameters. Simulations attest the superior accuracy of
the method when compared with state-of-the-art unmixing algorithms that account
for spectral variability.
","Tales Imbiriba, Ricardo Augusto Borsoi, José Carlos Moreira Bermudez",José Carlos Moreira Bermudez,2018-11-02T21:09:58Z
"CoSpace: Common Subspace Learning from Hyperspectral-Multispectral
  Correspondences","  With a large amount of open satellite multispectral imagery (e.g., Sentinel-2
and Landsat-8), considerable attention has been paid to global multispectral
land cover classification. However, its limited spectral information hinders
further improving the classification performance. Hyperspectral imaging enables
discrimination between spectrally similar classes but its swath width from
space is narrow compared to multispectral ones. To achieve accurate land cover
classification over a large coverage, we propose a cross-modality feature
learning framework, called common subspace learning (CoSpace), by jointly
considering subspace learning and supervised classification. By locally
aligning the manifold structure of the two modalities, CoSpace linearly learns
a shared latent subspace from hyperspectral-multispectral(HS-MS)
correspondences. The multispectral out-of-samples can be then projected into
the subspace, which are expected to take advantages of rich spectral
information of the corresponding hyperspectral data used for learning, and thus
leads to a better classification. Extensive experiments on two simulated HSMS
datasets (University of Houston and Chikusei), where HS-MS data sets have
trade-offs between coverage and spectral resolution, are performed to
demonstrate the superiority and effectiveness of the proposed method in
comparison with previous state-of-the-art methods.
","Danfeng Hong, Naoto Yokoya, Jocelyn Chanussot, Xiao Xiang Zhu",Xiao Xiang Zhu,2018-12-30T10:03:08Z
"Hyperspectral Image Classification with Deep Metric Learning and
  Conditional Random Field","  To improve the classification performance in the context of hyperspectral
image processing, many works have been developed based on two common
strategies, namely the spatial-spectral information integration and the
utilization of neural networks. However, both strategies typically require more
training data than the classical algorithms, aggregating the shortage of
labeled samples. In this letter, we propose a novel framework that organically
combines the spectrum-based deep metric learning model and the conditional
random field algorithm. The deep metric learning model is supervised by the
center loss to produce spectrum-based features that gather more tightly in
Euclidean space within classes. The conditional random field with Gaussian edge
potentials, which is firstly proposed for image segmentation tasks, is
introduced to give the pixel-wise classification over the hyperspectral image
by utilizing both the geographical distances between pixels and the Euclidean
distances between the features produced by the deep metric learning model. The
proposed framework is trained by spectral pixels at the deep metric learning
stage and utilizes the half handcrafted spatial features at the conditional
random field stage. This settlement alleviates the shortage of training data to
some extent. Experiments on two real hyperspectral images demonstrate the
advantages of the proposed method in terms of both classification accuracy and
computation cost.
","Yi Liang, Xin Zhao, Alan J. X. Guo, Fei Zhu",Fei Zhu,2019-03-04T09:26:03Z
"Superpixel Contracted Graph-Based Learning for Hyperspectral Image
  Classification","  A central problem in hyperspectral image classification is obtaining high
classification accuracy when using a limited amount of labelled data. In this
paper we present a novel graph-based framework, which aims to tackle this
problem in the presence of large scale data input. Our approach utilises a
novel superpixel method, specifically designed for hyperspectral data, to
define meaningful local regions in an image, which with high probability share
the same classification label. We then extract spectral and spatial features
from these regions and use these to produce a contracted weighted
graph-representation, where each node represents a region rather than a pixel.
Our graph is then fed into a graph-based semi-supervised classifier which gives
the final classification. We show that using superpixels in a graph
representation is an effective tool for speeding up graphical classifiers
applied to hyperspectral images. We demonstrate through exhaustive quantitative
and qualitative results that our proposed method produces accurate
classifications when an incredibly small amount of labelled data is used. We
show that our approach mitigates the major drawbacks of existing approaches,
resulting in our approach outperforming several comparative state-of-the-art
techniques.
","Philip Sellars, Angelica Aviles-Rivero, Carola-Bibiane Schönlieb",Carola-Bibiane Schönlieb,2019-03-14T13:23:43Z
"Simultaneous Spectral-Spatial Feature Selection and Extraction for
  Hyperspectral Images","  In hyperspectral remote sensing data mining, it is important to take into
account of both spectral and spatial information, such as the spectral
signature, texture feature and morphological property, to improve the
performances, e.g., the image classification accuracy. In a feature
representation point of view, a nature approach to handle this situation is to
concatenate the spectral and spatial features into a single but high
dimensional vector and then apply a certain dimension reduction technique
directly on that concatenated vector before feed it into the subsequent
classifier. However, multiple features from various domains definitely have
different physical meanings and statistical properties, and thus such
concatenation hasn't efficiently explore the complementary properties among
different features, which should benefit for boost the feature
discriminability. Furthermore, it is also difficult to interpret the
transformed results of the concatenated vector. Consequently, finding a
physically meaningful consensus low dimensional feature representation of
original multiple features is still a challenging task. In order to address the
these issues, we propose a novel feature learning framework, i.e., the
simultaneous spectral-spatial feature selection and extraction algorithm, for
hyperspectral images spectral-spatial feature representation and
classification. Specifically, the proposed method learns a latent low
dimensional subspace by projecting the spectral-spatial feature into a common
feature space, where the complementary information has been effectively
exploited, and simultaneously, only the most significant original features have
been transformed. Encouraging experimental results on three public available
hyperspectral remote sensing datasets confirm that our proposed method is
effective and efficient.
","Lefei Zhang, Qian Zhang, Bo Du, Xin Huang, Yuan Yan Tang, Dacheng Tao",Dacheng Tao,2019-04-08T12:05:59Z
"Three-Dimensional Fourier Scattering Transform and Classification of
  Hyperspectral Images","  Recent developments in machine learning and signal processing have resulted
in many new techniques that are able to effectively capture the intrinsic yet
complex properties of hyperspectral imagery. Tasks ranging from anomaly
detection to classification can now be solved by taking advantage of very
efficient algorithms which have their roots in representation theory and in
computational approximation. Time-frequency methods are one example of such
techniques. They provide means to analyze and extract the spectral content from
data. On the other hand, hierarchical methods such as neural networks
incorporate spatial information across scales and model multiple levels of
dependencies between spectral features. Both of these approaches have recently
been proven to provide significant advances in the spectral-spatial
classification of hyperspectral imagery. The 3D Fourier scattering transform,
which is introduced in this paper, is an amalgamation of time-frequency
representations with neural network architectures. It leverages the benefits
provided by the Short-Time Fourier Transform with the numerical efficiency of
deep learning network structures. We test the proposed method on several
standard hyperspectral datasets, and we present results that indicate that the
3D Fourier scattering transform is highly effective at representing spectral
content when compared with other state-of-the-art spectral-spatial
classification methods.
","Ilya Kavalerov, Weilin Li, Wojciech Czaja, Rama Chellappa",Rama Chellappa,2019-06-17T00:47:31Z
"Invariant Attribute Profiles: A Spatial-Frequency Joint Feature
  Extractor for Hyperspectral Image Classification","  Up to the present, an enormous number of advanced techniques have been
developed to enhance and extract the spatially semantic information in
hyperspectral image processing and analysis. However, locally semantic change,
such as scene composition, relative position between objects, spectral
variability caused by illumination, atmospheric effects, and material mixture,
has been less frequently investigated in modeling spatial information. As a
consequence, identifying the same materials from spatially different scenes or
positions can be difficult. In this paper, we propose a solution to address
this issue by locally extracting invariant features from hyperspectral imagery
(HSI) in both spatial and frequency domains, using a method called invariant
attribute profiles (IAPs). IAPs extract the spatial invariant features by
exploiting isotropic filter banks or convolutional kernels on HSI and spatial
aggregation techniques (e.g., superpixel segmentation) in the Cartesian
coordinate system. Furthermore, they model invariant behaviors (e.g., shift,
rotation) by the means of a continuous histogram of oriented gradients
constructed in a Fourier polar coordinate. This yields a combinatorial
representation of spatial-frequency invariant features with application to HSI
classification. Extensive experiments conducted on three promising
hyperspectral datasets (Houston2013 and Houston2018) demonstrate the
superiority and effectiveness of the proposed IAP method in comparison with
several state-of-the-art profile-related techniques. The codes will be
available from the website:
https://sites.google.com/view/danfeng-hong/data-code.
","Danfeng Hong, Xin Wu, Pedram Ghamisi, Jocelyn Chanussot, Naoto Yokoya, Xiao Xiang Zhu",Xiao Xiang Zhu,2019-12-18T19:27:07Z
"Active Deep Densely Connected Convolutional Network for Hyperspectral
  Image Classification","  Deep learning based methods have seen a massive rise in popularity for
hyperspectral image classification over the past few years. However, the
success of deep learning is attributed greatly to numerous labeled samples. It
is still very challenging to use only a few labeled samples to train deep
learning models to reach a high classification accuracy. An active
deep-learning framework trained by an end-to-end manner is, therefore, proposed
by this paper in order to minimize the hyperspectral image classification
costs. First, a deep densely connected convolutional network is considered for
hyperspectral image classification. Different from the traditional active
learning methods, an additional network is added to the designed deep densely
connected convolutional network to predict the loss of input samples. Then, the
additional network could be used to suggest unlabeled samples that the deep
densely connected convolutional network is more likely to produce a wrong
label. Note that the additional network uses the intermediate features of the
deep densely connected convolutional network as input. Therefore, the proposed
method is an end-to-end framework. Subsequently, a few of the selected samples
are labelled manually and added to the training samples. The deep densely
connected convolutional network is therefore trained using the new training
set. Finally, the steps above are repeated to train the whole framework
iteratively. Extensive experiments illustrates that the method proposed could
reach a high accuracy in classification after selecting just a few samples.
","Bing Liu, Anzhu Yu, Pengqiang Zhang, Lei Ding, Wenyue Guo, Kuiliang Gao, Xibing Zuo",Xibing Zuo,2020-09-01T09:53:38Z
"Few-Shot Hyperspectral Image Classification With Unknown Classes Using
  Multitask Deep Learning","  Current hyperspectral image classification assumes that a predefined
classification system is closed and complete, and there are no unknown or novel
classes in the unseen data. However, this assumption may be too strict for the
real world. Often, novel classes are overlooked when the classification system
is constructed. The closed nature forces a model to assign a label given a new
sample and may lead to overestimation of known land covers (e.g., crop area).
To tackle this issue, we propose a multitask deep learning method that
simultaneously conducts classification and reconstruction in the open world
(named MDL4OW) where unknown classes may exist. The reconstructed data are
compared with the original data; those failing to be reconstructed are
considered unknown, based on the assumption that they are not well represented
in the latent features due to the lack of labels. A threshold needs to be
defined to separate the unknown and known classes; we propose two strategies
based on the extreme value theory for few-shot and many-shot scenarios. The
proposed method was tested on real-world hyperspectral images; state-of-the-art
results were achieved, e.g., improving the overall accuracy by 4.94% for the
Salinas data. By considering the existence of unknown classes in the open
world, our method achieved more accurate hyperspectral image classification,
especially under the few-shot context.
","Shengjie Liu, Qian Shi, Liangpei Zhang",Liangpei Zhang,2020-09-08T03:53:10Z
"Joint and Progressive Subspace Analysis (JPSA) with Spatial-Spectral
  Manifold Alignment for Semi-Supervised Hyperspectral Dimensionality Reduction","  Conventional nonlinear subspace learning techniques (e.g., manifold learning)
usually introduce some drawbacks in explainability (explicit mapping) and
cost-effectiveness (linearization), generalization capability (out-of-sample),
and representability (spatial-spectral discrimination). To overcome these
shortcomings, a novel linearized subspace analysis technique with
spatial-spectral manifold alignment is developed for a semi-supervised
hyperspectral dimensionality reduction (HDR), called joint and progressive
subspace analysis (JPSA). The JPSA learns a high-level, semantically
meaningful, joint spatial-spectral feature representation from hyperspectral
data by 1) jointly learning latent subspaces and a linear classifier to find an
effective projection direction favorable for classification; 2) progressively
searching several intermediate states of subspaces to approach an optimal
mapping from the original space to a potential more discriminative subspace; 3)
spatially and spectrally aligning manifold structure in each learned latent
subspace in order to preserve the same or similar topological property between
the compressed data and the original data. A simple but effective classifier,
i.e., nearest neighbor (NN), is explored as a potential application for
validating the algorithm performance of different HDR approaches. Extensive
experiments are conducted to demonstrate the superiority and effectiveness of
the proposed JPSA on two widely-used hyperspectral datasets: Indian Pines
(92.98\%) and the University of Houston (86.09\%) in comparison with previous
state-of-the-art HDR methods. The demo of this basic work (i.e., ECCV2018) is
openly available at https://github.com/danfenghong/ECCV2018_J-Play.
","Danfeng Hong, Naoto Yokoya, Jocelyn Chanussot, Jian Xu, Xiao Xiang Zhu",Xiao Xiang Zhu,2020-09-21T16:29:59Z
"Endmember-Guided Unmixing Network (EGU-Net): A General Deep Learning
  Framework for Self-Supervised Hyperspectral Unmixing","  Over the past decades, enormous efforts have been made to improve the
performance of linear or nonlinear mixing models for hyperspectral unmixing,
yet their ability to simultaneously generalize various spectral variabilities
and extract physically meaningful endmembers still remains limited due to the
poor ability in data fitting and reconstruction and the sensitivity to various
spectral variabilities. Inspired by the powerful learning ability of deep
learning, we attempt to develop a general deep learning approach for
hyperspectral unmixing, by fully considering the properties of endmembers
extracted from the hyperspectral imagery, called endmember-guided unmixing
network (EGU-Net). Beyond the alone autoencoder-like architecture, EGU-Net is a
two-stream Siamese deep network, which learns an additional network from the
pure or nearly-pure endmembers to correct the weights of another unmixing
network by sharing network parameters and adding spectrally meaningful
constraints (e.g., non-negativity and sum-to-one) towards a more accurate and
interpretable unmixing solution. Furthermore, the resulting general framework
is not only limited to pixel-wise spectral unmixing but also applicable to
spatial information modeling with convolutional operators for spatial-spectral
unmixing. Experimental results conducted on three different datasets with the
ground-truth of abundance maps corresponding to each material demonstrate the
effectiveness and superiority of the EGU-Net over state-of-the-art unmixing
algorithms. The codes will be available from the website:
https://github.com/danfenghong/IEEE_TNNLS_EGU-Net.
","Danfeng Hong, Lianru Gao, Jing Yao, Naoto Yokoya, Jocelyn Chanussot, Uta Heiden, Bing Zhang",Bing Zhang,2021-05-21T08:07:12Z
"Hyperspectral Remote Sensing Image Classification Based on Multi-scale
  Cross Graphic Convolution","  The mining and utilization of features directly affect the classification
performance of models used in the classification and recognition of
hyperspectral remote sensing images. Traditional models usually conduct feature
mining from a single perspective, with the features mined being limited and the
internal relationships between them being ignored. Consequently, useful
features are lost and classification results are unsatisfactory. To fully mine
and utilize image features, a new multi-scale feature-mining learning algorithm
(MGRNet) is proposed. The model uses principal component analysis to reduce the
dimensionality of the original hyperspectral image (HSI) to retain 99.99% of
its semantic information and extract dimensionality reduction features. Using a
multi-scale convolution algorithm, the input dimensionality reduction features
were mined to obtain shallow features, which then served as inputs into a
multi-scale graph convolution algorithm to construct the internal relationships
between eigenvalues at different scales. We then carried out cross fusion of
multi-scale information obtained by graph convolution, before inputting the new
information obtained into the residual network algorithm for deep feature
mining. Finally, a flexible maximum transfer function classifier was used to
predict the final features and complete the classification. Experiments on
three common hyperspectral datasets showed the MGRNet algorithm proposed in
this paper to be superior to traditional methods in recognition accuracy.
","Yunsong Zhao, Yin Li, Zhihan Chen, Tianchong Qiu, Guojin Liu",Guojin Liu,2021-06-28T15:28:09Z
"Hyperspectral Chemical Plume Detection Algorithms Based On
  Multidimensional Iterative Filtering Decomposition","  Chemicals released in the air can be extremely dangerous for human beings and
the environment. Hyperspectral images can be used to identify chemical plumes,
however the task can be extremely challenging. Assuming we know a priori that
some chemical plume, with a known frequency spectrum, has been photographed
using a hyperspectral sensor, we can use standard techniques like the so called
matched filter or adaptive cosine estimator, plus a properly chosen threshold
value, to identify the position of the chemical plume. However, due to noise
and sensors fault, the accurate identification of chemical pixels is not easy
even in this apparently simple situation. In this paper we present a
post-processing tool that, in a completely adaptive and data driven fashion,
allows to improve the performance of any classification methods in identifying
the boundaries of a plume. This is done using the Multidimensional Iterative
Filtering (MIF) algorithm (arXiv:1411.6051, arXiv:1507.07173), which is a
non-stationary signal decomposition method like the pioneering Empirical Mode
Decomposition (EMD) method. Moreover, based on the MIF technique, we propose
also a pre-processing method that allows to decorrelate and mean-center a
hyperspectral dataset. The Cosine Similarity measure, which often fails in
practice, appears to become a successful and outperforming classifier when
equipped with such pre-processing method. We show some examples of the proposed
methods when applied to real life problems.
","Antonio Cicone, Jingfang Liu, Haomin Zhou",Haomin Zhou,2015-12-07T11:06:10Z
"Unsupervised Band Selection of Hyperspectral Images via Multi-dictionary
  Sparse Representation","  Hyperspectral images have far more spectral bands than ordinary multispectral
images. Rich band information provides more favorable conditions for the
tremendous applications. However, significant increase in the dimensionality of
spectral bands may lead to the curse of dimensionality, especially for
classification applications. Furthermore, there are a large amount of redundant
information among the raw image cubes due to water absorptions, sensor noises
and other influence factors. Band selection is a direct and effective method to
remove redundant information and reduce the spectral dimension for decreasing
computational complexity and avoiding the curse of dimensionality. In this
paper, we present a novel learning framework for band selection based on the
idea of sparse representation. More specifically, first each band is
approximately represented by the linear combination of other bands, then the
original band image can be represented by a multi-dictionary learning
mechanism. As a result, a group of weights can be obtained by sparse
optimization for all bands. Finally, the specific bands will be selected, if
they get higher weights than other bands in the representation of the original
image. Experimental results on three widely used hyperspectral datasets show
that our proposed algorithm achieves better performance in hyperspectral image
classification, when compared with other state-of-art band selection methods.
","Fei Li, Pingping Zhang, Huchuan Lu",Huchuan Lu,2018-02-20T07:04:09Z
HSI-CNN: A Novel Convolution Neural Network for Hyperspectral Image,"  With the development of deep learning, the performance of hyperspectral image
(HSI) classification has been greatly improved in recent years. The shortage of
training samples has become a bottleneck for further improvement of
performance. In this paper, we propose a novel convolutional neural network
framework for the characteristics of hyperspectral image data, called HSI-CNN.
Firstly, the spectral-spatial feature is extracted from a target pixel and its
neighbors. Then, a number of one-dimensional feature maps, obtained by
convolution operation on spectral-spatial features, are stacked into a
two-dimensional matrix. Finally, the two-dimensional matrix considered as an
image is fed into standard CNN. This is why we call it HSI-CNN. In addition, we
also implements two depth network classification models, called HSI-CNN+XGBoost
and HSI-CapsNet, in order to compare the performance of our framework.
Experiments show that the performance of hyperspectral image classification is
improved efficiently with HSI-CNN framework. We evaluate the model's
performance using four popular HSI datasets, which are the Kennedy Space Center
(KSC), Indian Pines (IP), Pavia University scene (PU) and Salinas scene (SA).
As far as we concerned, HSI-CNN has got the state-of-art accuracy among all
methods we have known on these datasets of 99.28%, 99.09%, 99.42%, 98.95%
separately.
","Yanan Luo, Jie Zou, Chengfei Yao, Tao Li, Gang Bai",Gang Bai,2018-02-28T15:31:20Z
"Developing a machine learning framework for estimating soil moisture
  with VNIR hyperspectral data","  In this paper, we investigate the potential of estimating the soil-moisture
content based on VNIR hyperspectral data combined with LWIR data. Measurements
from a multi-sensor field campaign represent the benchmark dataset which
contains measured hyperspectral, LWIR, and soil-moisture data conducted on
grassland site. We introduce a regression framework with three steps consisting
of feature selection, preprocessing, and well-chosen regression models. The
latter are mainly supervised machine learning models. An exception are the
self-organizing maps which combine unsupervised and supervised learning. We
analyze the impact of the distinct preprocessing methods on the regression
results. Of all regression models, the extremely randomized trees model without
preprocessing provides the best estimation performance. Our results reveal the
potential of the respective regression framework combined with the VNIR
hyperspectral data to estimate soil moisture measured under real-world
conditions. In conclusion, the results of this paper provide a basis for
further improvements in different research directions.
","Sina Keller, Felix M. Riese, Johanna Stötzer, Philipp M. Maier, Stefan Hinz",Stefan Hinz,2018-04-24T13:52:35Z
"Hyperspectral Super-resolution: A Coupled Nonnegative Block-term Tensor
  Decomposition Approach","  Hyperspectral super-resolution (HSR) aims at fusing a hyperspectral image
(HSI) and a multispectral image (MSI) to produce a super-resolution image
(SRI). Recently, a coupled tensor factorization approach was proposed to handle
this challenging problem, which admits a series of advantages over the classic
matrix factorization-based methods. In particular, modeling the HSI and MSI as
low-rank tensors following the {\it canonical polyadic decomposition} (CPD)
model, the approach is able to provably identify the SRI, under some mild
conditions. However, the latent factors in the CPD model have no physical
meaning, which makes utilizing prior information of spectral images as
constraints or regularizations difficult---but using such information is often
important in practice, especially when the data is noisy. In this work, we
propose an alternative coupled tensor decomposition approach, where the HSI and
MSI are assumed to follow the {\it block-term decomposition (BTD)} model.
Notably, the new method also entails identifiability of the SRI under realistic
conditions. More importantly, when modeling a spectral image as a BTD tensor,
the latent factors have clear physical meaning, and thus prior knowledge about
spectral images can be naturally incorporated. Simulations using real
hyperspectral images are employed to showcase the effectiveness of the proposed
approach with nonnegativity constraints.
","Guoyong Zhang, Xiao Fu, Kejun Huang, Jun Wang",Jun Wang,2019-10-22T23:21:45Z
"6 nm super-resolution optical transmission and scattering spectroscopic
  imaging of carbon nanotubes using a nanometer-scale white light source","  Optical hyperspectral imaging based on absorption and scattering of photons
at the visible and adjacent frequencies denotes one of the most informative and
inclusive characterization methods in material research. Unfortunately,
restricted by the diffraction limit of light, it is unable to resolve the
nanoscale inhomogeneity in light-matter interactions, which is diagnostic of
the local modulation in material structure and properties. Moreover, many
nanomaterials have highly anisotropic optical properties that are outstandingly
appealing yet hard to characterize through conventional optical methods.
Therefore, there has been a pressing demand in the diverse fields including
electronics, photonics, physics, and materials science to extend the optical
hyperspectral imaging into the nanometer length scale. In this work, we report
a super-resolution hyperspectral imaging technique that simultaneously measures
optical absorption and scattering spectra with the illumination from a
tungsten-halogen lamp. We demonstrated sub-5 nm spatial resolution in both
visible and near-infrared wavelengths (415 to 980 nm) for the hyperspectral
imaging of strained single-walled carbon nanotubes (SWNT) and reconstructed
true-color images to reveal the longitudinal and transverse optical
transition-induced light absorption and scattering in the SWNTs. This is the
first time transverse optical absorption in SWNTs were clearly observed
experimentally. The new technique provides rich near-field spectroscopic
information that had made it possible to analyze the spatial modulation of
band-structure along a single SWNT induced through strain engineering.
","Xuezhi Ma, Qiushi Liu, Ning Yu, Da Xu, Sanggon Kim, Zebin Liu, Kaili Jiang, Bryan M. Wong, Ruoxue Yan, Ming Liu",Ming Liu,2020-06-08T19:39:47Z
"Spatial--spectral FFPNet: Attention-Based Pyramid Network for
  Segmentation and Classification of Remote Sensing Images","  We consider the problem of segmentation and classification of high-resolution
and hyperspectral remote sensing images. Unlike conventional natural (RGB)
images, the inherent large scale and complex structures of remote sensing
images pose major challenges such as spatial object distribution diversity and
spectral information extraction when existing models are directly applied for
image classification. In this study, we develop an attention-based pyramid
network for segmentation and classification of remote sensing datasets.
Attention mechanisms are used to develop the following modules: i) a novel and
robust attention-based multi-scale fusion method effectively fuses useful
spatial or spectral information at different and same scales; ii) a region
pyramid attention mechanism using region-based attention addresses the target
geometric size diversity in large-scale remote sensing images; and iii
cross-scale attention} in our adaptive atrous spatial pyramid pooling network
adapts to varied contents in a feature-embedded space. Different forms of
feature fusion pyramid frameworks are established by combining these
attention-based modules. First, a novel segmentation framework, called the
heavy-weight spatial feature fusion pyramid network (FFPNet), is proposed to
address the spatial problem of high-resolution remote sensing images. Second,
an end-to-end spatial--spectral FFPNet is presented for classifying
hyperspectral images. Experiments conducted on ISPRS Vaihingen and ISPRS
Potsdam high-resolution datasets demonstrate the competitive segmentation
accuracy achieved by the proposed heavy-weight spatial FFPNet. Furthermore,
experiments on the Indian Pines and the University of Pavia hyperspectral
datasets indicate that the proposed spatial--spectral FFPNet outperforms the
current state-of-the-art methods in hyperspectral image classification.
","Qingsong Xu, Xin Yuan, Chaojun Ouyang, Yue Zeng",Yue Zeng,2020-08-20T04:55:34Z
"Blind Image Fusion for Hyperspectral Imaging with the Directional Total
  Variation","  Hyperspectral imaging is a cutting-edge type of remote sensing used for
mapping vegetation properties, rock minerals and other materials. A major
drawback of hyperspectral imaging devices is their intrinsic low spatial
resolution. In this paper, we propose a method for increasing the spatial
resolution of a hyperspectral image by fusing it with an image of higher
spatial resolution that was obtained with a different imaging modality. This is
accomplished by solving a variational problem in which the regularization
functional is the directional total variation. To accommodate for possible
mis-registrations between the two images, we consider a non-convex blind
super-resolution problem where both a fused image and the corresponding
convolution kernel are estimated. Using this approach, our model can realign
the given images if needed. Our experimental results indicate that the
non-convexity is negligible in practice and that reliable solutions can be
computed using a variety of different optimization algorithms. Numerical
results on real remote sensing data from plant sciences and urban monitoring
show the potential of the proposed method and suggests that it is robust with
respect to the regularization parameters, mis-registration and the shape of the
kernel.
","Leon Bungert, David A. Coomes, Matthias J. Ehrhardt, Jennifer Rasch, Rafael Reisenhofer, Carola-Bibiane Schönlieb",Carola-Bibiane Schönlieb,2017-10-04T15:18:13Z
"Spectral-Spatial Recurrent-Convolutional Networks for In-Vivo
  Hyperspectral Tumor Type Classification","  Early detection of cancerous tissue is crucial for long-term patient
survival. In the head and neck region, a typical diagnostic procedure is an
endoscopic intervention where a medical expert manually assesses tissue using
RGB camera images. While healthy and tumor regions are generally easier to
distinguish, differentiating benign and malignant tumors is very challenging.
This requires an invasive biopsy, followed by histological evaluation for
diagnosis. Also, during tumor resection, tumor margins need to be verified by
histological analysis. To avoid unnecessary tissue resection, a non-invasive,
image-based diagnostic tool would be very valuable. Recently, hyperspectral
imaging paired with deep learning has been proposed for this task,
demonstrating promising results on ex-vivo specimens. In this work, we
demonstrate the feasibility of in-vivo tumor type classification using
hyperspectral imaging and deep learning. We analyze the value of using multiple
hyperspectral bands compared to conventional RGB images and we study several
machine learning models' ability to make use of the additional spectral
information. Based on our insights, we address spectral and spatial processing
using recurrent-convolutional models for effective spectral aggregating and
spatial feature learning. Our best model achieves an AUC of 76.3%,
significantly outperforming previous conventional and deep learning methods.
","Marcel Bengs, Nils Gessert, Wiebke Laffers, Dennis Eggert, Stephan Westermann, Nina A. Mueller, Andreas O. H. Gerstner, Christian Betz, Alexander Schlaefer",Alexander Schlaefer,2020-07-02T12:00:53Z
"Advances in Deep Learning for Hyperspectral Image Analysis--Addressing
  Challenges Arising in Practical Imaging Scenarios","  Deep neural networks have proven to be very effective for computer vision
tasks, such as image classification, object detection, and semantic
segmentation -- these are primarily applied to color imagery and video. In
recent years, there has been an emergence of deep learning algorithms being
applied to hyperspectral and multispectral imagery for remote sensing and
biomedicine tasks. These multi-channel images come with their own unique set of
challenges that must be addressed for effective image analysis. Challenges
include limited ground truth (annotation is expensive and extensive labeling is
often not feasible), and high dimensional nature of the data (each pixel is
represented by hundreds of spectral bands), despite being presented by a large
amount of unlabeled data and the potential to leverage multiple sensors/sources
that observe the same scene. In this chapter, we will review recent advances in
the community that leverage deep learning for robust hyperspectral image
analysis despite these unique challenges -- specifically, we will review
unsupervised, semi-supervised and active learning approaches to image analysis,
as well as transfer learning approaches for multi-source (e.g. multi-sensor, or
multi-temporal) image analysis.
","Xiong Zhou, Saurabh Prasad",Saurabh Prasad,2020-07-16T19:51:02Z
"Coupled Convolutional Neural Network with Adaptive Response Function
  Learning for Unsupervised Hyperspectral Super-Resolution","  Due to the limitations of hyperspectral imaging systems, hyperspectral
imagery (HSI) often suffers from poor spatial resolution, thus hampering many
applications of the imagery. Hyperspectral super-resolution refers to fusing
HSI and MSI to generate an image with both high spatial and high spectral
resolutions. Recently, several new methods have been proposed to solve this
fusion problem, and most of these methods assume that the prior information of
the Point Spread Function (PSF) and Spectral Response Function (SRF) are known.
However, in practice, this information is often limited or unavailable. In this
work, an unsupervised deep learning-based fusion method - HyCoNet - that can
solve the problems in HSI-MSI fusion without the prior PSF and SRF information
is proposed. HyCoNet consists of three coupled autoencoder nets in which the
HSI and MSI are unmixed into endmembers and abundances based on the linear
unmixing model. Two special convolutional layers are designed to act as a
bridge that coordinates with the three autoencoder nets, and the PSF and SRF
parameters are learned adaptively in the two convolution layers during the
training process. Furthermore, driven by the joint loss function, the proposed
method is straightforward and easily implemented in an end-to-end training
manner. The experiments performed in the study demonstrate that the proposed
method performs well and produces robust results for different datasets and
arbitrary PSFs and SRFs.
","Ke Zheng, Lianru Gao, Wenzhi Liao, Danfeng Hong, Bing Zhang, Ximin Cui, Jocelyn Chanussot",Jocelyn Chanussot,2020-07-28T06:17:02Z
A Plug-and-Play Priors Framework for Hyperspectral Unmixing,"  Spectral unmixing is a widely used technique in hyperspectral image
processing and analysis. It aims to separate mixed pixels into the component
materials and their corresponding abundances. Early solutions to spectral
unmixing are performed independently on each pixel. Nowadays, investigating
proper priors into the unmixing problem has been popular as it can
significantly enhance the unmixing performance. However, it is non-trivial to
handcraft a powerful regularizer, and complex regularizers may introduce extra
difficulties in solving optimization problems in which they are involved. To
address this issue, we present a plug-and-play (PnP) priors framework for
hyperspectral unmixing. More specifically, we use the alternating direction
method of multipliers (ADMM) to decompose the optimization problem into two
iterative subproblems. One is a regular optimization problem depending on the
forward model, and the other is a proximity operator related to the prior model
and can be regarded as an image denoising problem. Our framework is flexible
and extendable which allows a wide range of denoisers to replace prior models
and avoids handcrafting regularizers. Experiments conducted on both synthetic
data and real airborne data illustrate the superiority of the proposed strategy
compared with other state-of-the-art hyperspectral unmixing methods.
","Min zhao, Xiuheng Wang, Jie Chen, Wei Chen",Wei Chen,2020-12-24T02:48:50Z
"Interpretable Hyperspectral AI: When Non-Convex Modeling meets
  Hyperspectral Remote Sensing","  Hyperspectral imaging, also known as image spectrometry, is a landmark
technique in geoscience and remote sensing (RS). In the past decade, enormous
efforts have been made to process and analyze these hyperspectral (HS) products
mainly by means of seasoned experts. However, with the ever-growing volume of
data, the bulk of costs in manpower and material resources poses new challenges
on reducing the burden of manual labor and improving efficiency. For this
reason, it is, therefore, urgent to develop more intelligent and automatic
approaches for various HS RS applications. Machine learning (ML) tools with
convex optimization have successfully undertaken the tasks of numerous
artificial intelligence (AI)-related applications. However, their ability in
handling complex practical problems remains limited, particularly for HS data,
due to the effects of various spectral variabilities in the process of HS
imaging and the complexity and redundancy of higher dimensional HS signals.
Compared to the convex models, non-convex modeling, which is capable of
characterizing more complex real scenes and providing the model
interpretability technically and theoretically, has been proven to be a
feasible solution to reduce the gap between challenging HS vision tasks and
currently advanced intelligent data processing models.
","Danfeng Hong, Wei He, Naoto Yokoya, Jing Yao, Lianru Gao, Liangpei Zhang, Jocelyn Chanussot, Xiao Xiang Zhu",Xiao Xiang Zhu,2021-03-02T03:32:10Z
"Hyperspectral Image Denoising and Anomaly Detection Based on Low-rank
  and Sparse Representations","  Hyperspectral imaging measures the amount of electromagnetic energy across
the instantaneous field of view at a very high resolution in hundreds or
thousands of spectral channels. This enables objects to be detected and the
identification of materials that have subtle differences between them. However,
the increase in spectral resolution often means that there is a decrease in the
number of photons received in each channel, which means that the noise linked
to the image formation process is greater. This degradation limits the quality
of the extracted information and its potential applications. Thus, denoising is
a fundamental problem in hyperspectral image (HSI) processing. As images of
natural scenes with highly correlated spectral channels, HSIs are characterized
by a high level of self-similarity and can be well approximated by low-rank
representations. These characteristics underlie the state-of-the-art methods
used in HSI denoising. However, where there are rarely occurring pixel types,
the denoising performance of these methods is not optimal, and the subsequent
detection of these pixels may be compromised. To address these hurdles, in this
article, we introduce RhyDe (Robust hyperspectral Denoising), a powerful HSI
denoiser, which implements explicit low-rank representation, promotes
self-similarity, and, by using a form of collaborative sparsity, preserves rare
pixels. The denoising and detection effectiveness of the proposed robust HSI
denoiser is illustrated using semireal and real data.
","Lina Zhuang, Lianru Gao, Bing Zhang, Xiyou Fu, Jose M. Bioucas-Dias",Jose M. Bioucas-Dias,2021-03-12T18:07:27Z
"HYPERION: Hyperspectral Penetrating-type Ellipsoidal Reconstruction for
  Terahertz Blind Source Separation","  Terahertz (THz) technology has been a great candidate for applications,
including pharmaceutic analysis, chemical identification, and remote sensing
and imaging due to its non-invasive and non-destructive properties. Among those
applications, penetrating-type hyperspectral THz signals, which provide crucial
material information, normally involve a noisy, complex mixture system.
Additionally, the measured THz signals could be ill-conditioned due to the
overlap of the material absorption peak in the measured bands. To address those
issues, we consider penetrating-type signal mixtures and aim to develop a blind
hyperspectral unmixing (HU) method without requiring any information from a
prebuilt database. The proposed HYperspectral Penetrating-type Ellipsoidal
ReconstructION (HYPERION) algorithm is unsupervised, not relying on collecting
extensive data or sophisticated model training. Instead, it is developed based
on elegant ellipsoidal geometry under a very mild requirement on data purity,
whose excellent efficacy is experimentally demonstrated.
","Chia-Hsiang Lin, Yi-Chun Hung, Feng-Yu Wang, Shang-Hua Yang",Shang-Hua Yang,2021-09-12T04:13:34Z
"FastHyMix: Fast and Parameter-free Hyperspectral Image Mixed Noise
  Removal","  Hyperspectral imaging with high spectral resolution plays an important role
in finding objects, identifying materials, or detecting processes. The decrease
of the widths of spectral bands leads to a decrease in the signal-to-noise
ratio (SNR) of measurements. The decreased SNR reduces the reliability of
measured features or information extracted from HSIs. Furthermore, the image
degradations linked with various mechanisms also result in different types of
noise, such as Gaussian noise, impulse noise, deadlines, and stripes. This
paper introduces a fast and parameter-free hyperspectral image mixed noise
removal method (termed FastHyMix), which characterizes the complex distribution
of mixed noise by using a Gaussian mixture model and exploits two main
characteristics of hyperspectral data, namely low-rankness in the spectral
domain and high correlation in the spatial domain. The Gaussian mixture model
enables us to make a good estimation of Gaussian noise intensity and the
location of sparse noise. The proposed method takes advantage of the
low-rankness using subspace representation and the spatial correlation of HSIs
by adding a powerful deep image prior, which is extracted from a neural
denoising network. An exhaustive array of experiments and comparisons with
state-of-the-art denoisers were carried out. The experimental results show
significant improvement in both synthetic and real datasets. A MATLAB demo of
this work will be available at https://github.com/LinaZhuang for the sake of
reproducibility.
","Lina Zhuang, Michael K. Ng",Michael K. Ng,2021-09-18T08:35:45Z
"Graph Embedding via High Dimensional Model Representation for
  Hyperspectral Images","  Learning the manifold structure of remote sensing images is of paramount
relevance for modeling and understanding processes, as well as to encapsulate
the high dimensionality in a reduced set of informative features for subsequent
classification, regression, or unmixing. Manifold learning methods have shown
excellent performance to deal with hyperspectral image (HSI) analysis but,
unless specifically designed, they cannot provide an explicit embedding map
readily applicable to out-of-sample data. A common assumption to deal with the
problem is that the transformation between the high-dimensional input space and
the (typically low) latent space is linear. This is a particularly strong
assumption, especially when dealing with hyperspectral images due to the
well-known nonlinear nature of the data. To address this problem, a manifold
learning method based on High Dimensional Model Representation (HDMR) is
proposed, which enables to present a nonlinear embedding function to project
out-of-sample samples into the latent space. The proposed method is compared to
manifold learning methods along with its linear counterparts and achieves
promising performance in terms of classification accuracy of a representative
set of hyperspectral images.
","Gulsen Taskin, Gustau Camps-Valls",Gustau Camps-Valls,2021-11-29T16:42:15Z
Unmixing based PAN guided fusion network for hyperspectral imagery,"  The hyperspectral image (HSI) has been widely used in many applications due
to its fruitful spectral information. However, the limitation of imaging
sensors has reduced its spatial resolution that causes detail loss. One
solution is to fuse the low spatial resolution hyperspectral image (LR-HSI) and
the panchromatic image (PAN) with inverse features to get the high-resolution
hyperspectral image (HR-HSI). Most of the existing fusion methods just focus on
small fusion ratios like 4 or 6, which might be impractical for some large
ratios' HSI and PAN image pairs. Moreover, the ill-posedness of restoring
detail information in HSI with hundreds of bands from PAN image with only one
band has not been solved effectively, especially under large fusion ratios.
Therefore, a lightweight unmixing-based pan-guided fusion network (Pgnet) is
proposed to mitigate this ill-posedness and improve the fusion performance
significantly. Note that the fusion process of the proposed network is under
the projected low-dimensional abundance subspace with an extremely large fusion
ratio of 16. Furthermore, based on the linear and nonlinear relationships
between the PAN intensity and abundance, an interpretable PAN detail inject
network (PDIN) is designed to inject the PAN details into the abundance feature
efficiently. Comprehensive experiments on simulated and real datasets
demonstrate the superiority and generality of our method over several
state-of-the-art (SOTA) methods qualitatively and quantitatively (The codes in
pytorch and paddle versions and dataset could be available at
https://github.com/rs-lsl/Pgnet). (This is a improved version compared with the
publication in Tgrs with the modification in the deduction of the PDIN block.)
","Shuangliang Li, Yugang Tian, Hao Xia, Qingwei Liu",Qingwei Liu,2022-01-27T04:37:23Z
Deep Hyperspectral Unmixing using Transformer Network,"  Currently, this paper is under review in IEEE. Transformers have intrigued
the vision research community with their state-of-the-art performance in
natural language processing. With their superior performance, transformers have
found their way in the field of hyperspectral image classification and achieved
promising results. In this article, we harness the power of transformers to
conquer the task of hyperspectral unmixing and propose a novel deep unmixing
model with transformers. We aim to utilize the ability of transformers to
better capture the global feature dependencies in order to enhance the quality
of the endmember spectra and the abundance maps. The proposed model is a
combination of a convolutional autoencoder and a transformer. The hyperspectral
data is encoded by the convolutional encoder. The transformer captures
long-range dependencies between the representations derived from the encoder.
The data are reconstructed using a convolutional decoder. We applied the
proposed unmixing model to three widely used unmixing datasets, i.e., Samson,
Apex, and Washington DC mall and compared it with the state-of-the-art in terms
of root mean squared error and spectral angle distance. The source code for the
proposed model will be made publicly available at
\url{https://github.com/preetam22n/DeepTrans-HSU}.
","Preetam Ghosh, Swalpa Kumar Roy, Bikram Koirala, Behnood Rasti, Paul Scheunders",Paul Scheunders,2022-03-31T14:47:36Z
"Compressed AFM-IR hyperspectral nanoimaging of single Leishmania
  parasites","  Infrared hyperspectral imaging is a powerful approach in the field of
materials and life sciences. However, the extension to modern sub-diffraction
nanoimaging still remains a highly inefficient technique, as it acquires data
via inherent sequential schemes. Here, we introduce the mathematical technique
of low-rank matrix reconstruction to the sub-diffraction scheme of atomic force
microscopy-based infrared spectroscopy (AFM-IR), for efficient hyperspectral
infrared nanoimaging. To demonstrate its application potential, we chose the
trypanosomatid unicellular parasites Leishmania species as a realistic target
of biological importance. The mid-infrared spectral fingerprint window covering
the spectral range from 1300 to 1900 cm$^{-1}$ was chosen and a step width of
220 nm was applied for nanoimaging of single parasites. Multivariate statistics
approaches such as hierarchical cluster analysis (HCA) were used for extracting
the chemically distinct spatial locations. Subsequently, we randomly selected
only 5% from an originally gathered data cube of 134 (x) $\times$ 50 (y)
$\times$ 148 (spectral) AFM-IR measurements and reconstructed the full data set
by low-rank matrix recovery. The technique is evaluated by showing agreement in
the cluster regions between full and reconstructed data cubes. We conclude that
the corresponding measurement time of more than 14 hours can be reduced to less
than 1 hour. These findings can significantly boost the practical applicability
of hyperspectral nanoimaging in both academic and industrial settings involving
nano- and bio-materials.
","A. Hornemann, M. Marschall, S. Metzner, P. Patoka, S. Cortes, G. Wübbeler, A. Hoehl, E. Rühl, B. Kästner, C. Elster",C. Elster,2022-05-04T12:21:23Z
"Terrain Classification using Transfer Learning on Hyperspectral Images:
  A Comparative study","  A Hyperspectral image contains much more number of channels as compared to a
RGB image, hence containing more information about entities within the image.
The convolutional neural network (CNN) and the Multi-Layer Perceptron (MLP)
have been proven to be an effective method of image classification. However,
they suffer from the issues of long training time and requirement of large
amounts of the labeled data, to achieve the expected outcome. These issues
become more complex while dealing with hyperspectral images. To decrease the
training time and reduce the dependence on large labeled dataset, we propose
using the method of transfer learning. The hyperspectral dataset is
preprocessed to a lower dimension using PCA, then deep learning models are
applied to it for the purpose of classification. The features learned by this
model are then used by the transfer learning model to solve a new
classification problem on an unseen dataset. A detailed comparison of CNN and
multiple MLP architectural models is performed, to determine an optimum
architecture that suits best the objective. The results show that the scaling
of layers not always leads to increase in accuracy but often leads to
overfitting, and also an increase in the training time.The training time is
reduced to greater extent by applying the transfer learning approach rather
than just approaching the problem by directly training a new model on large
datasets, without much affecting the accuracy.
","Uphar Singh, Kumar Saurabh, Neelaksh Trehan, Ranjana Vyas, O. P. Vyas",O. P. Vyas,2022-06-19T14:36:33Z
"Hyperspectral image reconstruction for spectral camera based on ghost
  imaging via sparsity constraints using V-DUnet","  Spectral camera based on ghost imaging via sparsity constraints (GISC
spectral camera) obtains three-dimensional (3D) hyperspectral information with
two-dimensional (2D) compressive measurements in a single shot, which has
attracted much attention in recent years. However, its imaging quality and
real-time performance of reconstruction still need to be further improved.
Recently, deep learning has shown great potential in improving the
reconstruction quality and reconstruction speed for computational imaging. When
applying deep learning into GISC spectral camera, there are several challenges
need to be solved: 1) how to deal with the large amount of 3D hyperspectral
data, 2) how to reduce the influence caused by the uncertainty of the random
reference measurements, 3) how to improve the reconstructed image quality as
far as possible. In this paper, we present an end-to-end V-DUnet for the
reconstruction of 3D hyperspectral data in GISC spectral camera. To reduce the
influence caused by the uncertainty of the measurement matrix and enhance the
reconstructed image quality, both differential ghost imaging results and the
detected measurements are sent into the network's inputs. Compared with
compressive sensing algorithm, such as PICHCS and TwIST, it not only
significantly improves the imaging quality with high noise immunity, but also
speeds up the reconstruction time by more than two orders of magnitude.
","Ziyan Chen, Zhentao Liu, Chenyu Hu, Heng Wu, Jianrong Wu, Jinda Lin, Zhishen Tong, Hong Yu, Shensheng Han",Shensheng Han,2022-06-28T04:46:07Z
"Quantitative Assessment of DESIS Hyperspectral Data for Plant
  Biodiversity Estimation in Australia","  Diversity of terrestrial plants plays a key role in maintaining a stable,
healthy, and productive ecosystem. Though remote sensing has been seen as a
promising and cost-effective proxy for estimating plant diversity, there is a
lack of quantitative studies on how confidently plant diversity can be inferred
from spaceborne hyperspectral data. In this study, we assessed the ability of
hyperspectral data captured by the DLR Earth Sensing Imaging Spectrometer
(DESIS) for estimating plant species richness in the Southern Tablelands and
Snowy Mountains regions in southeast Australia. Spectral features were firstly
extracted from DESIS spectra with principal component analysis, canonical
correlation analysis, and partial least squares analysis. Then regression was
conducted between the extracted features and plant species richness with
ordinary least squares regression, kernel ridge regression, and Gaussian
process regression. Results were assessed with the coefficient of correlation
($r$) and Root-Mean-Square Error (RMSE), based on a two-fold cross validation
scheme. With the best performing model, $r$ is 0.71 and RMSE is 5.99 for the
Southern Tablelands region, while $r$ is 0.62 and RMSE is 6.20 for the Snowy
Mountains region. The assessment results reported in this study provide
supports for future studies on understanding the relationship between
spaceborne hyperspectral measurements and terrestrial plant biodiversity.
","Yiqing Guo, Karel Mokany, Cindy Ong, Peyman Moghadam, Simon Ferrier, Shaun R. Levick",Shaun R. Levick,2022-07-06T07:14:55Z
"Linking Common Multispectral Vegetation Indices to Hyperspectral Mixture
  Models: Results from 5 nm, 3 m Airborne Imaging Spectroscopy in a Diverse
  Agricultural Landscape","  For decades, agronomists have used remote sensing to monitor key crop
parameters like biomass, fractional cover, and plant health. Vegetation indices
(VIs) are popular for this purpose, primarily leveraging the spectral red edge
in multispectral imagery. In contrast, spectral mixture models use the full
reflectance spectrum to simultaneously estimate area fractions of multiple
endmember materials present within a mixed pixel. Here, we characterize the
relationships between hyperspectral endmember fractions and 6 common
multispectral VIs in crops & soils of California agriculture. Fractional area
of green vegetation (Fv) was estimated directly from 64,000,000 5 nm, 3 to 5 m
reflectance spectra compiled from a mosaic of 15 AVIRIS-ng flightlines.
Simulated Planet SuperDove reflectance spectra were then derived from the
AVIRIS-ng, and used to compute 6 popular VIs (NDVI, NIRv, EVI, EVI2, SR, DVI).
Multispectral VIs were compared to hyperspectral Fv using parametric (Pearson
correlation, r) and nonparametric (Mutual Information, MI) similarity metrics.
4 VIs (NIRv, DVI, EVI, EVI2) showed strong linear relationships to Fv (r >
0.94; MI > 1.2). NIRv & DVI showed strong interrelation (r > 0.99, MI > 2.4),
but deviated significantly from 1:1 relative to Fv. EVI & EVI2 were also
strongly interrelated (r > 0.99, MI > 2.3) and more closely followed a 1:1
relation with Fv. In contrast, NDVI & SR showed weaker, nonlinear,
heteroskedastic relation to Fv (r < 0.84, MI = 0.69). NDVI showed especially
severe sensitivity to substrate background reflectance (-0.05 < NDVI < +0.6 for
unvegetated spectra) and saturation (0.2 < Fv < 0.8 for NDVI = 0.7). These
direct observational constraints on multispectral VI and hyperspectral mixture
model comparability can serve as a quantitative benchmark for agronomic
applications in the coming era of increasing spatial & spectral resolution
Earth observation.
","Daniel Sousa, Christopher Small",Christopher Small,2022-08-12T19:55:48Z
High-speed scanless entire bandwidth mid-infrared chemical imaging,"  Mid-infrared spectroscopy probes molecular vibrations to identify chemical
species and functional groups. Therefore, mid-infrared hyperspectral imaging is
one of the most powerful and promising candidates for chemical imaging using
optical methods. Yet high-speed and entire bandwidth mid-infrared hyperspectral
imaging has not been realized. Here we report a mid-infrared hyperspectral
chemical imaging technique that uses chirped pulse upconversion of sub-cycle
pulses at the image plane. This technique offers a lateral resolution of 15
$\mu$m, and the field of view is adjustable between 800 $\mu$m $\times$ 600
$\mu$m to 12 mm $\times$ 9 mm. The hyperspectral imaging produces a 640
$\times$ 480 pixel image in 8 s, which covers a spectral range of 640-3015
cm$^{-1}$, comprising 1069 wavelength points and offering a wavenumber
resolution of 2.6-3.7 cm$^{-1}$. For discrete frequency mid-infrared imaging,
the measurement speed reaches a frame rate of 5 kHz, the repetition rate of the
laser. As a demonstration, we effectively identified and mapped different
components in a microfluidic device, plant cell, and mouse embryo section. The
great capacity and latent force of this technique in chemical imaging promise
to be applied to many fields such as chemical analysis, biology, and medicine.
","Yue Zhao, Shota Kusama, Yuji Furutani, Wei-Hong Huang, Chih-Wei Luo, Takao Fuji",Takao Fuji,2022-09-14T02:20:10Z
"Hyperspectral Remote Sensing Benchmark Database for Oil Spill Detection
  with an Isolation Forest-Guided Unsupervised Detector","  Oil spill detection has attracted increasing attention in recent years since
marine oil spill accidents severely affect environments, natural resources, and
the lives of coastal inhabitants. Hyperspectral remote sensing images provide
rich spectral information which is beneficial for the monitoring of oil spills
in complex ocean scenarios. However, most of the existing approaches are based
on supervised and semi-supervised frameworks to detect oil spills from
hyperspectral images (HSIs), which require a huge amount of effort to annotate
a certain number of high-quality training sets. In this study, we make the
first attempt to develop an unsupervised oil spill detection method based on
isolation forest for HSIs. First, considering that the noise level varies among
different bands, a noise variance estimation method is exploited to evaluate
the noise level of different bands, and the bands corrupted by severe noise are
removed. Second, kernel principal component analysis (KPCA) is employed to
reduce the high dimensionality of the HSIs. Then, the probability of each pixel
belonging to one of the classes of seawater and oil spills is estimated with
the isolation forest, and a set of pseudo-labeled training samples is
automatically produced using the clustering algorithm on the detected
probability. Finally, an initial detection map can be obtained by performing
the support vector machine (SVM) on the dimension-reduced data, and then, the
initial detection result is further optimized with the extended random walker
(ERW) model so as to improve the detection accuracy of oil spills. Experiments
on airborne hyperspectral oil spill data (HOSD) created by ourselves
demonstrate that the proposed method obtains superior detection performance
with respect to other state-of-the-art detection approaches.
","Puhong Duan, Xudong Kang, Pedram Ghamisi",Pedram Ghamisi,2022-09-28T02:26:42Z
"A Novel Filter Approach for Band Selection and Classification of
  Hyperspectral Remotely Sensed Images Using Normalized Mutual Information and
  Support Vector Machines","  Band selection is a great challenging task in the classification of
hyperspectral remotely sensed images HSI. This is resulting from its high
spectral resolution, the many class outputs and the limited number of training
samples. For this purpose, this paper introduces a new filter approach for
dimension reduction and classification of hyperspectral images using
information theoretic (normalized mutual information) and support vector
machines SVM. This method consists to select a minimal subset of the most
informative and relevant bands from the input datasets for better
classification efficiency. We applied our proposed algorithm on two well-known
benchmark datasets gathered by the NASA's AVIRIS sensor over Indiana and
Salinas valley in USA. The experimental results were assessed based on
different evaluation metrics widely used in this area. The comparison with the
state of the art methods proves that our method could produce good performance
with reduced number of selected bands in a good timing.
  Keywords: Dimension reduction, Hyperspectral images, Band selection,
Normalized mutual information, Classification, Support vector machines
","Hasna Nhaila, Asma Elmaizi, Elkebir Sarhrouni, Ahmed Hammouch",Ahmed Hammouch,2022-10-27T14:23:06Z
"Hyperspectral Image Segmentation: A Preliminary Study on the Oral and
  Dental Spectral Image Database (ODSI-DB)","  Visual discrimination of clinical tissue types remains challenging, with
traditional RGB imaging providing limited contrast for such tasks.
Hyperspectral imaging (HSI) is a promising technology providing rich spectral
information that can extend far beyond three-channel RGB imaging. Moreover,
recently developed snapshot HSI cameras enable real-time imaging with
significant potential for clinical applications. Despite this, the
investigation into the relative performance of HSI over RGB imaging for
semantic segmentation purposes has been limited, particularly in the context of
medical imaging. Here we compare the performance of state-of-the-art deep
learning image segmentation methods when trained on hyperspectral images, RGB
images, hyperspectral pixels (minus spatial context), and RGB pixels
(disregarding spatial context). To achieve this, we employ the recently
released Oral and Dental Spectral Image Database (ODSI-DB), which consists of
215 manually segmented dental reflectance spectral images with 35 different
classes across 30 human subjects. The recent development of snapshot HSI
cameras has made real-time clinical HSI a distinct possibility, though
successful application requires a comprehensive understanding of the additional
information HSI offers. Our work highlights the relative importance of spectral
resolution, spectral range, and spatial information to both guide the
development of HSI cameras and inform future clinical HSI applications.
","Luis C. Garcia-Peraza-Herrera, Conor Horgan, Sebastien Ourselin, Michael Ebner, Tom Vercauteren",Tom Vercauteren,2023-03-14T21:57:11Z
Progressive Content-aware Coded Hyperspectral Compressive Imaging,"  Hyperspectral imaging plays a pivotal role in a wide range of applications,
like remote sensing, medicine, and cytology. By acquiring 3D hyperspectral
images (HSIs) via 2D sensors, the coded aperture snapshot spectral imaging
(CASSI) has achieved great success due to its hardware-friendly implementation
and fast imaging speed. However, for some less spectrally sparse scenes, single
snapshot and unreasonable coded aperture design tend to make HSI recovery more
ill-posed and yield poor spatial and spectral fidelity. In this paper, we
propose a novel Progressive Content-Aware CASSI framework, dubbed PCA-CASSI,
which captures HSIs with multiple optimized content-aware coded apertures and
fuses all the snapshots for reconstruction progressively. Simultaneously, by
mapping the Range-Null space Decomposition (RND) into a deep network with
several phases, an RND-HRNet is proposed for HSI recovery. Each recovery phase
can fully exploit the hidden physical information in the coded apertures via
explicit $\mathcal{R}$$-$$\mathcal{N}$ decomposition and explore the
spatial-spectral correlation by dual transformer blocks. Our method is
validated to surpass other state-of-the-art methods on both multiple- and
single-shot HSI imaging tasks by large margins.
","Xuanyu Zhang, Bin Chen, Wenzhen Zou, Shuai Liu, Yongbing Zhang, Ruiqin Xiong, Jian Zhang",Jian Zhang,2023-03-17T04:42:27Z
"Operational Neural Networks for Parameter-Efficient Hyperspectral
  Single-Image Super-Resolution","  Hyperspectral Imaging is a crucial tool in remote sensing which captures far
more spectral information than standard color images. However, the increase in
spectral information comes at the cost of spatial resolution. Super-resolution
is a popular technique where the goal is to generate a high-resolution version
of a given low-resolution input. The majority of modern super-resolution
approaches use convolutional neural networks. However, convolution itself is a
linear operation and the networks rely on the non-linear activation functions
after each layer to provide the necessary non-linearity to learn the complex
underlying function. This means that convolutional neural networks tend to be
very deep to achieve the desired results. Recently, self-organized operational
neural networks have been proposed that aim to overcome this limitation by
replacing the convolutional filters with learnable non-linear functions through
the use of MacLaurin series expansions. This work focuses on extending the
convolutional filters of a popular super-resolution model to more powerful
operational filters to enhance the model performance on hyperspectral images.
We also investigate the effects that residual connections and different
normalization types have on this type of enhanced network. Despite having fewer
parameters than their convolutional network equivalents, our results show that
operational neural networks achieve superior super-resolution performance on
small hyperspectral image datasets. Our code is made available on Github:
https://github.com/aulrichsen/SRONN.
","Alexander Ulrichsen, Paul Murray, Stephen Marshall, Moncef Gabbouj, Serkan Kiranyaz, Mehmet Yamac, Nour Aburaed",Nour Aburaed,2023-03-29T12:48:51Z
"GlobalMind: Global Multi-head Interactive Self-attention Network for
  Hyperspectral Change Detection","  High spectral resolution imagery of the Earth's surface enables users to
monitor changes over time in fine-grained scale, playing an increasingly
important role in agriculture, defense, and emergency response. However, most
current algorithms are still confined to describing local features and fail to
incorporate a global perspective, which limits their ability to capture
interactions between global features, thus usually resulting in incomplete
change regions. In this paper, we propose a Global Multi-head INteractive
self-attention change Detection network (GlobalMind) to explore the implicit
correlation between different surface objects and variant land cover
transformations, acquiring a comprehensive understanding of the data and
accurate change detection result. Firstly, a simple but effective Global Axial
Segmentation (GAS) strategy is designed to expand the self-attention
computation along the row space or column space of hyperspectral images,
allowing the global connection with high efficiency. Secondly, with GAS, the
global spatial multi-head interactive self-attention (Global-M) module is
crafted to mine the abundant spatial-spectral feature involving potential
correlations between the ground objects from the entire rich and complex
hyperspectral space. Moreover, to acquire the accurate and complete
cross-temporal changes, we devise a global temporal interactive multi-head
self-attention (GlobalD) module which incorporates the relevance and variation
of bi-temporal spatial-spectral features, deriving the integrate potential same
kind of changes in the local and global range with the combination of GAS. We
perform extensive experiments on five mostly used hyperspectral datasets, and
our method outperforms the state-of-the-art algorithms with high accuracy and
efficiency.
","Meiqi Hu, Chen Wu, Liangpei Zhang",Liangpei Zhang,2023-04-18T01:43:17Z
"DGCNet: An Efficient 3D-Densenet based on Dynamic Group Convolution for
  Hyperspectral Remote Sensing Image Classification","  Deep neural networks face many problems in the field of hyperspectral image
classification, lack of effective utilization of spatial spectral information,
gradient disappearance and overfitting as the model depth increases. In order
to accelerate the deployment of the model on edge devices with strict latency
requirements and limited computing power, we introduce a lightweight model
based on the improved 3D-Densenet model and designs DGCNet. It improves the
disadvantage of group convolution. Referring to the idea of dynamic network,
dynamic group convolution(DGC) is designed on 3d convolution kernel. DGC
introduces small feature selectors for each grouping to dynamically decide
which part of the input channel to connect based on the activations of all
input channels. Multiple groups can capture different and complementary visual
and semantic features of input images, allowing convolution neural network(CNN)
to learn rich features. 3D convolution extracts high-dimensional and redundant
hyperspectral data, and there is also a lot of redundant information between
convolution kernels. DGC module allows 3D-Densenet to select channel
information with richer semantic features and discard inactive regions. The
3D-CNN passing through the DGC module can be regarded as a pruned network. DGC
not only allows 3D-CNN to complete sufficient feature extraction, but also
takes into account the requirements of speed and calculation amount. The
inference speed and accuracy have been improved, with outstanding performance
on the IN, Pavia and KSC datasets, ahead of the mainstream hyperspectral image
classification methods.
",Guandong Li,Guandong Li,2023-07-13T10:19:48Z
"Spatial-Spectral Hyperspectral Classification based on Learnable 3D
  Group Convolution","  Deep neural networks have faced many problems in hyperspectral image
classification, including the ineffective utilization of spectral-spatial joint
information and the problems of gradient vanishing and overfitting that arise
with increasing depth. In order to accelerate the deployment of models on edge
devices with strict latency requirements and limited computing power, this
paper proposes a learnable group convolution network (LGCNet) based on an
improved 3D-DenseNet model and a lightweight model design. The LGCNet module
improves the shortcomings of group convolution by introducing a dynamic
learning method for the input channels and convolution kernel grouping,
enabling flexible grouping structures and generating better representation
ability. Through the overall loss and gradient of the backpropagation network,
the 3D group convolution is dynamically determined and updated in an end-to-end
manner. The learnable number of channels and corresponding grouping can capture
different complementary visual features of input images, allowing the CNN to
learn richer feature representations. When extracting high-dimensional and
redundant hyperspectral data, the 3D convolution kernels also contain a large
amount of redundant information. The LGC module allows the 3D-DenseNet to
choose channel information with more semantic features, and is very efficient,
making it suitable for embedding in any deep neural network for acceleration
and efficiency improvements. LGC enables the 3D-CNN to achieve sufficient
feature extraction while also meeting speed and computing requirements.
Furthermore, LGCNet has achieved progress in inference speed and accuracy, and
outperforms mainstream hyperspectral image classification methods on the Indian
Pines, Pavia University, and KSC datasets.
","Guandong Li, Mengxia Ye",Mengxia Ye,2023-07-15T05:47:12Z
Spectral lens enables a minimalist framework for hyperspectral imaging,"  Conventional lens-based imaging techniques have long been limited to
capturing only the intensity distribution of objects, resulting in the loss of
other crucial dimensions such as spectral data. Here, we report a spectral lens
that captures both spatial and spectral information, and further demonstrate a
minimalist framework wherein hyperspectral imaging can be readily achieved by
replacing lenses in standard cameras with our spectral lens. As a paradigm, we
capitalize on planar liquid crystal optics to implement the proposed framework.
Our experiments with various targets show that the resulting hyperspectral
camera exhibits excellent performance in both spectral and spatial domains.
With merits such as ultra-compactness and strong compatibility, our framework
paves a practical pathway for advancing hyperspectral imaging apparatus toward
miniaturization, with great potential for portable applications.
","Zhou Zhou, Yiheng Zhang, Yingxin Xie, Tian Huang, Zile Li, Peng Chen, Yanqing Lu, Shaohua Yu, Shuang Zhang, Guoxing Zheng",Guoxing Zheng,2023-08-24T13:37:55Z
"Hyperspectral Image Denoising via Self-Modulating Convolutional Neural
  Networks","  Compared to natural images, hyperspectral images (HSIs) consist of a large
number of bands, with each band capturing different spectral information from a
certain wavelength, even some beyond the visible spectrum. These
characteristics of HSIs make them highly effective for remote sensing
applications. That said, the existing hyperspectral imaging devices introduce
severe degradation in HSIs. Hence, hyperspectral image denoising has attracted
lots of attention by the community lately. While recent deep HSI denoising
methods have provided effective solutions, their performance under real-life
complex noise remains suboptimal, as they lack adaptability to new data. To
overcome these limitations, in our work, we introduce a self-modulating
convolutional neural network which we refer to as SM-CNN, which utilizes
correlated spectral and spatial information. At the core of the model lies a
novel block, which we call spectral self-modulating residual block (SSMRB),
that allows the network to transform the features in an adaptive manner based
on the adjacent spectral data, enhancing the network's ability to handle
complex noise. In particular, the introduction of SSMRB transforms our
denoising network into a dynamic network that adapts its predicted features
while denoising every input HSI with respect to its spatio-spectral
characteristics. Experimental analysis on both synthetic and real data shows
that the proposed SM-CNN outperforms other state-of-the-art HSI denoising
methods both quantitatively and qualitatively on public benchmark datasets.
","Orhan Torun, Seniha Esen Yuksel, Erkut Erdem, Nevrez Imamoglu, Aykut Erdem",Aykut Erdem,2023-09-15T06:57:43Z
"Learning Interpretable Deep Disentangled Neural Networks for
  Hyperspectral Unmixing","  Although considerable effort has been dedicated to improving the solution to
the hyperspectral unmixing problem, non-idealities such as complex radiation
scattering and endmember variability negatively impact the performance of most
existing algorithms and can be very challenging to address. Recently, deep
learning-based frameworks have been explored for hyperspectral umixing due to
their flexibility and powerful representation capabilities. However, such
techniques either do not address the non-idealities of the unmixing problem, or
rely on black-box models which are not interpretable. In this paper, we propose
a new interpretable deep learning method for hyperspectral unmixing that
accounts for nonlinearity and endmember variability. The proposed method
leverages a probabilistic variational deep-learning framework, where
disentanglement learning is employed to properly separate the abundances and
endmembers. The model is learned end-to-end using stochastic backpropagation,
and trained using a self-supervised strategy which leverages benefits from
semi-supervised learning techniques. Furthermore, the model is carefully
designed to provide a high degree of interpretability. This includes modeling
the abundances as a Dirichlet distribution, the endmembers using
low-dimensional deep latent variable representations, and using two-stream
neural networks composed of additive piecewise-linear/nonlinear components.
Experimental results on synthetic and real datasets illustrate the performance
of the proposed method compared to state-of-the-art algorithms.
","Ricardo Augusto Borsoi, Deniz Erdoğmuş, Tales Imbiriba",Tales Imbiriba,2023-10-03T18:21:37Z
Masking Hyperspectral Imaging Data with Pretrained Models,"  The presence of undesired background areas associated with potential noise
and unknown spectral characteristics degrades the performance of hyperspectral
data processing. Masking out unwanted regions is key to addressing this issue.
Processing only regions of interest yields notable improvements in terms of
computational costs, required memory, and overall performance. The proposed
processing pipeline encompasses two fundamental parts: regions of interest mask
generation, followed by the application of hyperspectral data processing
techniques solely on the newly masked hyperspectral cube. The novelty of our
work lies in the methodology adopted for the preliminary image segmentation. We
employ the Segment Anything Model (SAM) to extract all objects within the
dataset, and subsequently refine the segments with a zero-shot Grounding Dino
object detector, followed by intersection and exclusion filtering steps,
without the need for fine-tuning or retraining. To illustrate the efficacy of
the masking procedure, the proposed method is deployed on three challenging
applications scenarios that demand accurate masking; shredded plastics
characterization, drill core scanning, and litter monitoring. The numerical
evaluation of the proposed masking method on the three applications is provided
along with the used hyperparameters. The scripts for the method will be
available at https://github.com/hifexplo/Masking.
","Elias Arbash, Andréa de Lima Ribeiro, Sam Thiele, Nina Gnann, Behnood Rasti, Margret Fuchs, Pedram Ghamisi, Richard Gloaguen",Richard Gloaguen,2023-11-06T12:08:35Z
"In2SET: Intra-Inter Similarity Exploiting Transformer for Dual-Camera
  Compressive Hyperspectral Imaging","  Dual-Camera Compressed Hyperspectral Imaging (DCCHI) offers the capability to
reconstruct 3D Hyperspectral Image (HSI) by fusing compressive and Panchromatic
(PAN) image, which has shown great potential for snapshot hyperspectral imaging
in practice. In this paper, we introduce a novel DCCHI reconstruction network,
the Intra-Inter Similarity Exploiting Transformer (In2SET). Our key insight is
to make full use of the PAN image to assist the reconstruction. To this end, we
propose using the intra-similarity within the PAN image as a proxy for
approximating the intra-similarity in the original HSI, thereby offering an
enhanced content prior for more accurate HSI reconstruction. Furthermore, we
aim to align the features from the underlying HSI with those of the PAN image,
maintaining semantic consistency and introducing new contextual information for
the reconstruction process. By integrating In2SET into a PAN-guided unrolling
framework, our method substantially enhances the spatial-spectral fidelity and
detail of the reconstructed images, providing a more comprehensive and accurate
depiction of the scene. Extensive experiments conducted on both real and
simulated datasets demonstrate that our approach consistently outperforms
existing state-of-the-art methods in terms of reconstruction quality and
computational complexity. Code will be released.
","Xin Wang, Lizhi Wang, Xiangtian Ma, Maoqing Zhang, Lin Zhu, Hua Huang",Hua Huang,2023-12-20T13:55:25Z
"PCB-Vision: A Multiscene RGB-Hyperspectral Benchmark Dataset of Printed
  Circuit Boards","  Addressing the critical theme of recycling electronic waste (E-waste), this
contribution is dedicated to developing advanced automated data processing
pipelines as a basis for decision-making and process control. Aligning with the
broader goals of the circular economy and the United Nations (UN) Sustainable
Development Goals (SDG), our work leverages non-invasive analysis methods
utilizing RGB and hyperspectral imaging data to provide both quantitative and
qualitative insights into the E-waste stream composition for optimizing
recycling efficiency. In this paper, we introduce 'PCB-Vision'; a pioneering
RGB-hyperspectral printed circuit board (PCB) benchmark dataset, comprising 53
RGB images of high spatial resolution paired with their corresponding high
spectral resolution hyperspectral data cubes in the visible and near-infrared
(VNIR) range. Grounded in open science principles, our dataset provides a
comprehensive resource for researchers through high-quality ground truths,
focusing on three primary PCB components: integrated circuits (IC), capacitors,
and connectors. We provide extensive statistical investigations on the proposed
dataset together with the performance of several state-of-the-art (SOTA)
models, including U-Net, Attention U-Net, Residual U-Net, LinkNet, and
DeepLabv3+. By openly sharing this multi-scene benchmark dataset along with the
baseline codes, we hope to foster transparent, traceable, and comparable
developments of advanced data processing across various scientific communities,
including, but not limited to, computer vision and remote sensing. Emphasizing
our commitment to supporting a collaborative and inclusive scientific
community, all materials, including code, data, ground truth, and masks, will
be accessible at https://github.com/hifexplo/PCBVision.
","Elias Arbash, Margret Fuchs, Behnood Rasti, Sandra Lorenz, Pedram Ghamisi, Richard Gloaguen",Richard Gloaguen,2024-01-12T12:00:26Z
Classification of grapevine varieties using UAV hyperspectral imaging,"  The classification of different grapevine varieties is a relevant phenotyping
task in Precision Viticulture since it enables estimating the growth of
vineyard rows dedicated to different varieties, among other applications
concerning the wine industry. This task can be performed with destructive
methods that require time-consuming tasks, including data collection and
analysis in the laboratory. However, Unmanned Aerial Vehicles (UAV) provide a
more efficient and less prohibitive approach to collecting hyperspectral data,
despite acquiring noisier data. Therefore, the first task is the processing of
these data to correct and downsample large amounts of data. In addition, the
hyperspectral signatures of grape varieties are very similar. In this work, a
Convolutional Neural Network (CNN) is proposed for classifying seventeen
varieties of red and white grape variants. Rather than classifying single
samples, these are processed together with their neighbourhood. Hence, the
extraction of spatial and spectral features is addressed with 1) a spatial
attention layer and 2) Inception blocks. The pipeline goes from processing to
dataset elaboration, finishing with the training phase. The fitted model is
evaluated in terms of response time, accuracy and data separability, and
compared with other state-of-the-art CNNs for classifying hyperspectral data.
Our network was proven to be much more lightweight with a reduced number of
input bands, a lower number of trainable weights and therefore, reduced
training time. Despite this, the evaluated metrics showed much better results
for our network (~99% overall accuracy), in comparison with previous works
barely achieving 81% OA.
","Alfonso López, Carlos Javier Ogayar, Francisco Ramón Feito, Joaquim João Sousa",Joaquim João Sousa,2024-01-23T15:35:50Z
"Transformer based Endmember Fusion with Spatial Context for
  Hyperspectral Unmixing","  In recent years, transformer-based deep learning networks have gained
popularity in Hyperspectral (HS) unmixing applications due to their superior
performance. The attention mechanism within transformers facilitates
input-dependent weighting and enhances contextual awareness during training.
Drawing inspiration from this, we propose a novel attention-based Hyperspectral
Unmixing algorithm called Transformer-based Endmember Fusion with Spatial
Context for Hyperspectral Unmixing (FusionNet). This network leverages an
ensemble of endmembers for initial guidance, effectively addressing the issue
of relying on a single initialization. This approach helps avoid suboptimal
results that many algorithms encounter due to their dependence on a singular
starting point. The FusionNet incorporates a Pixel Contextualizer (PC),
introducing contextual awareness into abundance prediction by considering
neighborhood pixels. Unlike Convolutional Neural Networks (CNNs) and
traditional Transformer-based approaches, which are constrained by specific
kernel or window shapes, the Fusion network offers flexibility in choosing any
arbitrary configuration of the neighborhood. We conducted a comparative
analysis between the FusionNet algorithm and eight state-of-the-art algorithms
using three widely recognized real datasets and one synthetic dataset. The
results demonstrate that FusionNet offers competitive performance compared to
the other algorithms.
","R. M. K. L. Ratnayake, D. M. U. P. Sumanasekara, H. M. K. D. Wickramathilaka, G. M. R. I. Godaliyadda, M. P. B. Ekanayake, H. M. V. R. Herath",H. M. V. R. Herath,2024-02-06T09:30:17Z
"Spatio-spectral classification of hyperspectral images for brain cancer
  detection during surgical operations","  Surgery for brain cancer is a major problem in neurosurgery. The diffuse
infiltration into the surrounding normal brain by these tumors makes their
accurate identification by the naked eye difficult. Since surgery is the common
treatment for brain cancer, an accurate radical resection of the tumor leads to
improved survival rates for patients. However, the identification of the tumor
boundaries during surgery is challenging. Hyperspectral imaging is a
noncontact, non-ionizing and non-invasive technique suitable for medical
diagnosis. This study presents the development of a novel classification method
taking into account the spatial and spectral characteristics of the
hyperspectral images to help neurosurgeons to accurately determine the tumor
boundaries in surgical-time during the resection, avoiding excessive excision
of normal tissue or unintentionally leaving residual tumor. The algorithm
proposed in this study to approach an efficient solution consists of a hybrid
framework that combines both supervised and unsupervised machine learning
methods. To evaluate the proposed approach, five hyperspectral images of
surface of the brain affected by glioblastoma tumor in vivo from five different
patients have been used. The final classification maps obtained have been
analyzed and validated by specialists. These preliminary results are promising,
obtaining an accurate delineation of the tumor area.
","H. Fabelo, S. Ortega, D. Ravi, B. R. Kiran, C. Sosa, D. Bulters, G. M. Callico, H. Bulstrode, A. Szolna, J. F. Pineiro, S. Kabwama, D. Madronal, R. Lazcano, A. J. OShanahan, S. Bisshopp, M. Hernandez, A. Baez-Quevedo, G. Z. Yang, B. Stanciulescu, R. Salvador, E. Juarez, R. Sarmiento",R. Sarmiento,2024-02-11T12:58:42Z
"DMSSN: Distilled Mixed Spectral-Spatial Network for Hyperspectral
  Salient Object Detection","  Hyperspectral salient object detection (HSOD) has exhibited remarkable
promise across various applications, particularly in intricate scenarios where
conventional RGB-based approaches fall short. Despite the considerable progress
in HSOD method advancements, two critical challenges require immediate
attention. Firstly, existing hyperspectral data dimension reduction techniques
incur a loss of spectral information, which adversely affects detection
accuracy. Secondly, previous methods insufficiently harness the inherent
distinctive attributes of hyperspectral images (HSIs) during the feature
extraction process. To address these challenges, we propose a novel approach
termed the Distilled Mixed Spectral-Spatial Network (DMSSN), comprising a
Distilled Spectral Encoding process and a Mixed Spectral-Spatial Transformer
(MSST) feature extraction network. The encoding process utilizes knowledge
distillation to construct a lightweight autoencoder for dimension reduction,
striking a balance between robust encoding capabilities and low computational
costs. The MSST extracts spectral-spatial features through multiple attention
head groups, collaboratively enhancing its resistance to intricate scenarios.
Moreover, we have created a large-scale HSOD dataset, HSOD-BIT, to tackle the
issue of data scarcity in this field and meet the fundamental data requirements
of deep network training. Extensive experiments demonstrate that our proposed
DMSSN achieves state-of-the-art performance on multiple datasets. We will soon
make the code and dataset publicly available on
https://github.com/anonymous0519/HSOD-BIT.
","Haolin Qin, Tingfa Xu, Peifu Liu, Jingxuan Xu, Jianan Li",Jianan Li,2024-03-31T14:04:57Z
"LiDAR-Guided Cross-Attention Fusion for Hyperspectral Band Selection and
  Image Classification","  The fusion of hyperspectral and LiDAR data has been an active research topic.
Existing fusion methods have ignored the high-dimensionality and redundancy
challenges in hyperspectral images, despite that band selection methods have
been intensively studied for hyperspectral image (HSI) processing. This paper
addresses this significant gap by introducing a cross-attention mechanism from
the transformer architecture for the selection of HSI bands guided by LiDAR
data. LiDAR provides high-resolution vertical structural information, which can
be useful in distinguishing different types of land cover that may have similar
spectral signatures but different structural profiles. In our approach, the
LiDAR data are used as the ""query"" to search and identify the ""key"" from the
HSI to choose the most pertinent bands for LiDAR. This method ensures that the
selected HSI bands drastically reduce redundancy and computational requirements
while working optimally with the LiDAR data. Extensive experiments have been
undertaken on three paired HSI and LiDAR data sets: Houston 2013, Trento and
MUUFL. The results highlight the superiority of the cross-attention mechanism,
underlining the enhanced classification accuracy of the identified HSI bands
when fused with the LiDAR features. The results also show that the use of fewer
bands combined with LiDAR surpasses the performance of state-of-the-art fusion
models.
","Judy X Yang, Jun Zhou, Jing Wang, Hui Tian, Alan Wee-Chung Liew",Alan Wee-Chung Liew,2024-04-05T04:11:31Z
"On-chip Real-time Hyperspectral Imager with Full CMOS Resolution Enabled
  by Massively Parallel Neural Network","  Traditional spectral imaging methods are constrained by the time-consuming
scanning process, limiting the application in dynamic scenarios. One-shot
spectral imaging based on reconstruction has been a hot research topic recently
and the primary challenges still lie in both efficient fabrication techniques
suitable for mass production and the high-speed, high-accuracy reconstruction
algorithm for real-time spectral imaging. In this study, we introduce an
innovative on-chip real-time hyperspectral imager that leverages nanophotonic
film spectral encoders and a Massively Parallel Network (MP-Net), featuring a 4
* 4 array of compact, all-dielectric film units for the micro-spectrometers.
Each curved nanophotonic film unit uniquely modulates incident light across the
underlying 3 * 3 CMOS image sensor (CIS) pixels, enabling a high spatial
resolution equivalent to the full CMOS resolution. The implementation of
MP-Net, specially designed to address variability in transmittance and
manufacturing errors such as misalignment and non-uniformities in thin film
deposition, can greatly increase the structural tolerance of the device and
reduce the preparation requirement, further simplifying the manufacturing
process. Tested in varied environments on both static and moving objects, the
real-time hyperspectral imager demonstrates the robustness and high-fidelity
spatial-spectral data capabilities across diverse scenarios. This on-chip
hyperspectral imager represents a significant advancement in real-time,
high-resolution spectral imaging, offering a versatile solution for
applications ranging from environmental monitoring, remote sensing to consumer
electronics.
","Junren Wen, Haiqi Gao, Weiming Shi, Shuaibo Feng, Lingyun Hao, Yujie Liu, Liang Xu, Yuchuan Shao, Yueguang Zhang, Weidong Shen, Chenying Yang",Chenying Yang,2024-04-15T06:38:33Z
"S$^2$Mamba: A Spatial-spectral State Space Model for Hyperspectral Image
  Classification","  Land cover analysis using hyperspectral images (HSI) remains an open problem
due to their low spatial resolution and complex spectral information. Recent
studies are primarily dedicated to designing Transformer-based architectures
for spatial-spectral long-range dependencies modeling, which is computationally
expensive with quadratic complexity. Selective structured state space model
(Mamba), which is efficient for modeling long-range dependencies with linear
complexity, has recently shown promising progress. However, its potential in
hyperspectral image processing that requires handling numerous spectral bands
has not yet been explored. In this paper, we innovatively propose S$^2$Mamba, a
spatial-spectral state space model for hyperspectral image classification, to
excavate spatial-spectral contextual features, resulting in more efficient and
accurate land cover analysis. In S$^2$Mamba, two selective structured state
space models through different dimensions are designed for feature extraction,
one for spatial, and the other for spectral, along with a spatial-spectral
mixture gate for optimal fusion. More specifically, S$^2$Mamba first captures
spatial contextual relations by interacting each pixel with its adjacent
through a Patch Cross Scanning module and then explores semantic information
from continuous spectral bands through a Bi-directional Spectral Scanning
module. Considering the distinct expertise of the two attributes in homogenous
and complicated texture scenes, we realize the Spatial-spectral Mixture Gate by
a group of learnable matrices, allowing for the adaptive incorporation of
representations learned across different dimensions. Extensive experiments
conducted on HSI classification benchmarks demonstrate the superiority and
prospect of S$^2$Mamba. The code will be made available at:
https://github.com/PURE-melo/S2Mamba.
","Guanchun Wang, Xiangrong Zhang, Zelin Peng, Tianyang Zhang, Licheng Jiao",Licheng Jiao,2024-04-28T15:12:56Z
"Multi-Teacher Multi-Objective Meta-Learning for Zero-Shot Hyperspectral
  Band Selection","  Band selection plays a crucial role in hyperspectral image classification by
removing redundant and noisy bands and retaining discriminative ones. However,
most existing deep learning-based methods are aimed at dealing with a specific
band selection dataset, and need to retrain parameters for new datasets, which
significantly limits their generalizability.To address this issue, a novel
multi-teacher multi-objective meta-learning network (M$^3$BS) is proposed for
zero-shot hyperspectral band selection. In M$^3$BS, a generalizable graph
convolution network (GCN) is constructed to generate dataset-agnostic base, and
extract compatible meta-knowledge from multiple band selection tasks. To
enhance the ability of meta-knowledge extraction, multiple band selection
teachers are introduced to provide diverse high-quality experiences.strategy
Finally, subsequent classification tasks are attached and jointly optimized
with multi-teacher band selection tasks through multi-objective meta-learning
in an end-to-end trainable way. Multi-objective meta-learning guarantees to
coordinate diverse optimization objectives automatically and adapt to various
datasets simultaneously. Once the optimization is accomplished, the acquired
meta-knowledge can be directly transferred to unseen datasets without any
retraining or fine-tuning. Experimental results demonstrate the effectiveness
and efficiency of our proposed method on par with state-of-the-art baselines
for zero-shot hyperspectral band selection.
","Jie Feng, Xiaojian Zhong, Di Li, Weisheng Dong, Ronghua Shang, Licheng Jiao",Licheng Jiao,2024-06-12T07:13:31Z
HyperSIGMA: Hyperspectral Intelligence Comprehension Foundation Model,"  Foundation models (FMs) are revolutionizing the analysis and understanding of
remote sensing (RS) scenes, including aerial RGB, multispectral, and SAR
images. However, hyperspectral images (HSIs), which are rich in spectral
information, have not seen much application of FMs, with existing methods often
restricted to specific tasks and lacking generality. To fill this gap, we
introduce HyperSIGMA, a vision transformer-based foundation model for HSI
interpretation, scalable to over a billion parameters. To tackle the spectral
and spatial redundancy challenges in HSIs, we introduce a novel sparse sampling
attention (SSA) mechanism, which effectively promotes the learning of diverse
contextual features and serves as the basic block of HyperSIGMA. HyperSIGMA
integrates spatial and spectral features using a specially designed spectral
enhancement module. In addition, we construct a large-scale hyperspectral
dataset, HyperGlobal-450K, for pre-training, which contains about 450K
hyperspectral images, significantly surpassing existing datasets in scale.
Extensive experiments on various high-level and low-level HSI tasks demonstrate
HyperSIGMA's versatility and superior representational capability compared to
current state-of-the-art methods. Moreover, HyperSIGMA shows significant
advantages in scalability, robustness, cross-modal transferring capability, and
real-world applicability.
","Di Wang, Meiqi Hu, Yao Jin, Yuchun Miao, Jiaqi Yang, Yichu Xu, Xiaolei Qin, Jiaqi Ma, Lingyu Sun, Chenxing Li, Chuan Fu, Hongruixuan Chen, Chengxi Han, Naoto Yokoya, Jing Zhang, Minqiang Xu, Lin Liu, Lefei Zhang, Chen Wu, Bo Du, Dacheng Tao, Liangpei Zhang",Liangpei Zhang,2024-06-17T13:22:58Z
"Cost-efficient Active Illumination Camera For Hyper-spectral
  Reconstruction","  Hyper-spectral imaging has recently gained increasing attention for use in
different applications, including agricultural investigation, ground tracking,
remote sensing and many other. However, the high cost, large physical size and
complicated operation process stop hyperspectral cameras from being employed
for various applications and research fields. In this paper, we introduce a
cost-efficient, compact and easy to use active illumination camera that may
benefit many applications. We developed a fully functional prototype of such
camera. With the hope of helping with agricultural research, we tested our
camera for plant root imaging. In addition, a U-Net model for spectral
reconstruction was trained by using a reference hyperspectral camera's data as
ground truth and our camera's data as input. We demonstrated our camera's
ability to obtain additional information over a typical RGB camera. In
addition, the ability to reconstruct hyperspectral data from multi-spectral
input makes our device compatible to models and algorithms developed for
hyperspectral applications with no modifications required.
","Yuxuan Zhang, T. M. Sazzad, Yangyang Song, Spencer J. Chang, Ritesh Chowdhry, Tomas Mejia, Anna Hampton, Shelby Kucharski, Stefan Gerber, Barry Tillman, Marcio F. R. Resende, William M. Hammond, Chris H. Wilson, Alina Zare, Sanjeev J. Koppal",Sanjeev J. Koppal,2024-06-27T22:19:19Z
"Hierarchical Homogeneity-Based Superpixel Segmentation: Application to
  Hyperspectral Image Analysis","  Hyperspectral image (HI) analysis approaches have recently become
increasingly complex and sophisticated. Recently, the combination of
spectral-spatial information and superpixel techniques have addressed some
hyperspectral data issues, such as the higher spatial variability of spectral
signatures and dimensionality of the data. However, most existing superpixel
approaches do not account for specific HI characteristics resulting from its
high spectral dimension. In this work, we propose a multiscale superpixel
method that is computationally efficient for processing hyperspectral data. The
Simple Linear Iterative Clustering (SLIC) oversegmentation algorithm, on which
the technique is based, has been extended hierarchically. Using a novel robust
homogeneity testing, the proposed hierarchical approach leads to superpixels of
variable sizes but with higher spectral homogeneity when compared to the
classical SLIC segmentation. For validation, the proposed homogeneity-based
hierarchical method was applied as a preprocessing step in the spectral
unmixing and classification tasks carried out using, respectively, the
Multiscale sparse Unmixing Algorithm (MUA) and the CNN-Enhanced Graph
Convolutional Network (CEGCN) methods. Simulation results with both synthetic
and real data show that the technique is competitive with state-of-the-art
solutions.
","Luciano Carvalho Ayres, Sérgio José Melo de Almeida, José Carlos Moreira Bermudez, Ricardo Augusto Borsoi",Ricardo Augusto Borsoi,2024-07-22T01:20:32Z
"A Multitask Deep Learning Model for Classification and Regression of
  Hyperspectral Images: Application to the large-scale dataset","  Multitask learning is a widely recognized technique in the field of computer
vision and deep learning domain. However, it is still a research question in
remote sensing, particularly for hyperspectral imaging. Moreover, most of the
research in the remote sensing domain focuses on small and single-task-based
annotated datasets, which limits the generalizability and scalability of the
developed models to more diverse and complex real-world scenarios. Thus, in
this study, we propose a multitask deep learning model designed to perform
multiple classification and regression tasks simultaneously on hyperspectral
images. We validated our approach on a large hyperspectral dataset called
TAIGA, which contains 13 forest variables, including three categorical
variables and ten continuous variables with different biophysical parameters.
We design a sharing encoder and task-specific decoder network to streamline
feature learning while allowing each task-specific decoder to focus on the
unique aspects of its respective task.
  Additionally, a dense atrous pyramid pooling layer and attention network were
integrated to extract multi-scale contextual information and enable selective
information processing by prioritizing task-specific features. Further, we
computed multitask loss and optimized its parameters for the proposed framework
to improve the model performance and efficiency across diverse tasks. A
comprehensive qualitative and quantitative analysis of the results shows that
the proposed method significantly outperforms other state-of-the-art methods.
We trained our model across 10 seeds/trials to ensure robustness. Our proposed
model demonstrates higher mean performance while maintaining lower or
equivalent variability. To make the work reproducible, the codes will be
available at
https://github.com/Koushikey4596/Multitask-Deep-Learning-Model-for-Taiga-datatset.
","Koushikey Chhapariya, Alexandre Benoit, Krishna Mohan Buddhiraju, Anil Kumar",Anil Kumar,2024-07-23T11:14:54Z
SpectralEarth: Training Hyperspectral Foundation Models at Scale,"  Foundation models have triggered a paradigm shift in computer vision and are
increasingly being adopted in remote sensing, particularly for multispectral
imagery. Yet, their potential in hyperspectral imaging (HSI) remains untapped
due to the absence of comprehensive and globally representative hyperspectral
datasets. To close this gap, we introduce SpectralEarth, a large-scale
multi-temporal dataset designed to pretrain hyperspectral foundation models
leveraging data from the Environmental Mapping and Analysis Program (EnMAP).
SpectralEarth comprises 538,974 image patches covering 415,153 unique locations
from more than 11,636 globally distributed EnMAP scenes spanning two years of
archive. Additionally, 17.5% of these locations include multiple timestamps,
enabling multi-temporal HSI analysis. Utilizing state-of-the-art
self-supervised learning (SSL) algorithms, we pretrain a series of foundation
models on SpectralEarth. We integrate a spectral adapter into classical vision
backbones to accommodate the unique characteristics of HSI. In tandem, we
construct four downstream datasets for land-cover and crop-type mapping,
providing benchmarks for model evaluation. Experimental results support the
versatility of our models, showcasing their generalizability across different
tasks and sensors. We also highlight computational efficiency during model
fine-tuning. The dataset, models, and source code will be made publicly
available.
","Nassim Ait Ali Braham, Conrad M Albrecht, Julien Mairal, Jocelyn Chanussot, Yi Wang, Xiao Xiang Zhu",Xiao Xiang Zhu,2024-08-15T22:55:59Z
"ERX: A Fast Real-Time Anomaly Detection Algorithm for Hyperspectral Line
  Scanning","  Detecting unexpected objects (anomalies) in real time has great potential for
monitoring, managing, and protecting the environment. Hyperspectral line-scan
cameras are a low-cost solution that enhance confidence in anomaly detection
over RGB and multispectral imagery. However, existing line-scan algorithms are
too slow when using small computers (e.g. those onboard a drone or small
satellite), do not adapt to changing scenery, or lack robustness against
geometric distortions. This paper introduces the Exponentially moving RX
algorithm (ERX) to address these issues, and compares it with existing RX-based
anomaly detection methods for hyperspectral line scanning. Three large and more
complex datasets are also introduced to better assess the practical challenges
when using line-scan cameras (two hyperspectral and one multispectral). ERX is
evaluated using a Jetson Xavier NX compute module, achieving the best
combination of speed and detection performance. This research paves the way for
future studies in grouping and locating anomalous objects, adaptive and
automatic threshold selection, and real-time field tests. The datasets and the
Python code are available at: https://github.com/WiseGamgee/HyperAD.
","Samuel Garske, Bradley Evans, Christopher Artlett, KC Wong",KC Wong,2024-08-27T10:44:34Z
"A Generalized Tensor Formulation for Hyperspectral Image
  Super-Resolution Under General Spatial Blurring","  Hyperspectral super-resolution is commonly accomplished by the fusing of a
hyperspectral imaging of low spatial resolution with a multispectral image of
high spatial resolution, and many tensor-based approaches to this task have
been recently proposed. Yet, it is assumed in such tensor-based methods that
the spatial-blurring operation that creates the observed hyperspectral image
from the desired super-resolved image is separable into independent horizontal
and vertical blurring. Recent work has argued that such separable spatial
degradation is ill-equipped to model the operation of real sensors which may
exhibit, for example, anisotropic blurring. To accommodate this fact, a
generalized tensor formulation based on a Kronecker decomposition is proposed
to handle any general spatial-degradation matrix, including those that are not
separable as previously assumed. Analysis of the generalized formulation
reveals conditions under which exact recovery of the desired super-resolved
image is guaranteed, and a practical algorithm for such recovery, driven by a
blockwise-group-sparsity regularization, is proposed. Extensive experimental
results demonstrate that the proposed generalized tensor approach outperforms
not only traditional matrix-based techniques but also state-of-the-art
tensor-based methods; the gains with respect to the latter are especially
significant in cases of anisotropic spatial blurring.
","Yinjian Wang, Wei Li, Yuanyuan Gui, Qian Du, James E. Fowler",James E. Fowler,2024-09-27T13:23:17Z
"Joint Bayesian endmember extraction and linear unmixing for
  hyperspectral imagery","  This paper studies a fully Bayesian algorithm for endmember extraction and
abundance estimation for hyperspectral imagery. Each pixel of the hyperspectral
image is decomposed as a linear combination of pure endmember spectra following
the linear mixing model. The estimation of the unknown endmember spectra is
conducted in a unified manner by generating the posterior distribution of
abundances and endmember parameters under a hierarchical Bayesian model. This
model assumes conjugate prior distributions for these parameters, accounts for
non-negativity and full-additivity constraints, and exploits the fact that the
endmember proportions lie on a lower dimensional simplex. A Gibbs sampler is
proposed to overcome the complexity of evaluating the resulting posterior
distribution. This sampler generates samples distributed according to the
posterior distribution and estimates the unknown parameters using these
generated samples. The accuracy of the joint Bayesian estimator is illustrated
by simulations conducted on synthetic and real AVIRIS images.
","Nicolas Dobigeon, Said Moussaoui, Martial Coulon, Jean-Yves Tourneret, Alfred O. Hero",Alfred O. Hero,2009-03-17T22:26:11Z
On the unmixing of MEx/OMEGA hyperspectral data,"  This article presents a comparative study of three different types of
estimators used for supervised linear unmixing of two MEx/OMEGA hyperspectral
cubes. The algorithms take into account the constraints of the abundance
fractions, in order to get physically interpretable results. Abundance maps
show that the Bayesian maximum a posteriori probability (MAP) estimator
proposed in Themelis and Rontogiannis (2008) outperforms the other two schemes,
offering a compromise between complexity and estimation performance. Thus, the
MAP estimator is a candidate algorithm to perform ice and minerals detection on
large hyperspectral datasets.
","Konstantinos E. Themelis, Frédéric Schmidt, Olga Sykioti, Athanasios A. Rontogiannis, Konstantinos D. Koutroumbas, Ioannis A. Daglis",Ioannis A. Daglis,2011-12-07T11:33:23Z
"Unsupervised Post-Nonlinear Unmixing of Hyperspectral Images Using a
  Hamiltonian Monte Carlo Algorithm","  This paper presents a nonlinear mixing model for hyperspectral image
unmixing. The proposed model assumes that the pixel reflectances are
post-nonlinear functions of unknown pure spectral components contaminated by an
additive white Gaussian noise. These nonlinear functions are approximated using
polynomials leading to a polynomial post-nonlinear mixing model. A Bayesian
algorithm is proposed to estimate the parameters involved in the model yielding
an unsupervised nonlinear unmixing algorithm. Due to the large number of
parameters to be estimated, an efficient Hamiltonian Monte Carlo algorithm is
investigated. The classical leapfrog steps of this algorithm are modified to
handle the parameter constraints. The performance of the unmixing strategy,
including convergence and parameter tuning, is first evaluated on synthetic
data. Simulations conducted with real data finally show the accuracy of the
proposed unmixing strategy for the analysis of hyperspectral images.
","Yoann Altmann, Nicolas Dobigeon, Jean-Yves Tourneret",Jean-Yves Tourneret,2013-04-09T09:23:20Z
"Exploiting Structural Complexity for Robust and Rapid Hyperspectral
  Imaging","  This paper presents several strategies for spectral de-noising of
hyperspectral images and hypercube reconstruction from a limited number of
tomographic measurements. In particular we show that the non-noisy spectral
data, when stacked across the spectral dimension, exhibits low-rank. On the
other hand, under the same representation, the spectral noise exhibits a banded
structure. Motivated by this we show that the de-noised spectral data and the
unknown spectral noise and the respective bands can be simultaneously estimated
through the use of a low-rank and simultaneous sparse minimization operation
without prior knowledge of the noisy bands. This result is novel for for
hyperspectral imaging applications. In addition, we show that imaging for the
Computed Tomography Imaging Systems (CTIS) can be improved under limited angle
tomography by using low-rank penalization. For both of these cases we exploit
the recent results in the theory of low-rank matrix completion using nuclear
norm minimization.
","Gregory Ely, Shuchin Aeron, Eric L. Miller",Eric L. Miller,2013-05-09T18:24:20Z
"Residual component analysis of hyperspectral images -- Application to
  joint nonlinear unmixing and nonlinearity detection","  This paper presents a nonlinear mixing model for joint hyperspectral image
unmixing and nonlinearity detection. The proposed model assumes that the pixel
reflectances are linear combinations of known pure spectral components
corrupted by an additional nonlinear term, affecting the endmembers and
contaminated by an additive Gaussian noise. A Markov random field is considered
for nonlinearity detection based on the spatial structure of the nonlinear
terms. The observed image is segmented into regions where nonlinear terms, if
present, share similar statistical properties. A Bayesian algorithm is proposed
to estimate the parameters involved in the model yielding a joint nonlinear
unmixing and nonlinearity detection algorithm. The performance of the proposed
strategy is first evaluated on synthetic data. Simulations conducted with real
data show the accuracy of the proposed unmixing and nonlinearity detection
strategy for the analysis of hyperspectral images.
","Yoann Altmann, Nicolas Dobigeon, Steve McLaughlin, Jean-Yves Tourneret",Jean-Yves Tourneret,2013-07-22T13:35:28Z
Blind and fully constrained unmixing of hyperspectral images,"  This paper addresses the problem of blind and fully constrained unmixing of
hyperspectral images. Unmixing is performed without the use of any dictionary,
and assumes that the number of constituent materials in the scene and their
spectral signatures are unknown. The estimated abundances satisfy the desired
sum-to-one and nonnegativity constraints. Two models with increasing complexity
are developed to achieve this challenging task, depending on how noise
interacts with hyperspectral data. The first one leads to a convex optimization
problem, and is solved with the Alternating Direction Method of Multipliers.
The second one accounts for signal-dependent noise, and is addressed with a
Reweighted Least Squares algorithm. Experiments on synthetic and real data
demonstrate the effectiveness of our approach.
","Rita Ammanouil, André Ferrari, Cédric Richard, David Mary",David Mary,2014-03-03T02:06:36Z
"Fast forward feature selection for the nonlinear classification of
  hyperspectral images","  A fast forward feature selection algorithm is presented in this paper. It is
based on a Gaussian mixture model (GMM) classifier. GMM are used for
classifying hyperspectral images. The algorithm selects iteratively spectral
features that maximizes an estimation of the classification rate. The
estimation is done using the k-fold cross validation. In order to perform fast
in terms of computing time, an efficient implementation is proposed. First, the
GMM can be updated when the estimation of the classification rate is computed,
rather than re-estimate the full model. Secondly, using marginalization of the
GMM, sub models can be directly obtained from the full model learned with all
the spectral features. Experimental results for two real hyperspectral data
sets show that the method performs very well in terms of classification
accuracy and processing time. Furthermore, the extracted model contains very
few spectral channels.
","Mathieu Fauvel, Clement Dechesne, Anthony Zullo, Frédéric Ferraty",Frédéric Ferraty,2015-01-05T13:37:37Z
Robust Linear Spectral Unmixing using Anomaly Detection,"  This paper presents a Bayesian algorithm for linear spectral unmixing of
hyperspectral images that accounts for anomalies present in the data. The model
proposed assumes that the pixel reflectances are linear mixtures of unknown
endmembers, corrupted by an additional nonlinear term modelling anomalies and
additive Gaussian noise. A Markov random field is used for anomaly detection
based on the spatial and spectral structures of the anomalies. This allows
outliers to be identified in particular regions and wavelengths of the data
cube. A Bayesian algorithm is proposed to estimate the parameters involved in
the model yielding a joint linear unmixing and anomaly detection algorithm.
Simulations conducted with synthetic and real hyperspectral images demonstrate
the accuracy of the proposed unmixing and outlier detection strategy for the
analysis of hyperspectral images.
","Yoann Altmann, Steve McLaughlin, Alfred Hero",Alfred Hero,2015-01-15T16:24:35Z
"Estimating the Intrinsic Dimension of Hyperspectral Images Using an
  Eigen-Gap Approach","  Linear mixture models are commonly used to represent hyperspectral datacube
as a linear combinations of endmember spectra. However, determining of the
number of endmembers for images embedded in noise is a crucial task. This paper
proposes a fully automatic approach for estimating the number of endmembers in
hyperspectral images. The estimation is based on recent results of random
matrix theory related to the so-called spiked population model. More precisely,
we study the gap between successive eigenvalues of the sample covariance matrix
constructed from high dimensional noisy samples. The resulting estimation
strategy is unsupervised and robust to correlated noise. This strategy is
validated on both synthetic and real images. The experimental results are very
promising and show the accuracy of this algorithm with respect to
state-of-the-art algorithms.
","A. Halimi, P. Honeine, M. Kharouf, C. Richard, J. -Y. Tourneret",J. -Y. Tourneret,2015-01-22T16:18:35Z
Generalized Inpainting Method for Hyperspectral Image Acquisition,"  A recently designed hyperspectral imaging device enables multiplexed
acquisition of an entire data volume in a single snapshot thanks to
monolithically-integrated spectral filters. Such an agile imaging technique
comes at the cost of a reduced spatial resolution and the need for a
demosaicing procedure on its interleaved data. In this work, we address both
issues and propose an approach inspired by recent developments in compressed
sensing and analysis sparse models. We formulate our superresolution and
demosaicing task as a 3-D generalized inpainting problem. Interestingly, the
target spatial resolution can be adjusted for mitigating the compression level
of our sensing. The reconstruction procedure uses a fast greedy method called
Pseudo-inverse IHT. We also show on simulations that a random arrangement of
the spectral filters on the sensor is preferable to regular mosaic layout as it
improves the quality of the reconstruction. The efficiency of our technique is
demonstrated through numerical experiments on both synthetic and real data as
acquired by the snapshot imager.
","K. Degraux, V. Cambareri, L. Jacques, B. Geelen, C. Blanch, G. Lafruit",G. Lafruit,2015-02-06T10:45:36Z
"Kernel Task-Driven Dictionary Learning for Hyperspectral Image
  Classification","  Dictionary learning algorithms have been successfully used in both
reconstructive and discriminative tasks, where the input signal is represented
by a linear combination of a few dictionary atoms. While these methods are
usually developed under $\ell_1$ sparsity constrain (prior) in the input
domain, recent studies have demonstrated the advantages of sparse
representation using structured sparsity priors in the kernel domain. In this
paper, we propose a supervised dictionary learning algorithm in the kernel
domain for hyperspectral image classification. In the proposed formulation, the
dictionary and classifier are obtained jointly for optimal classification
performance. The supervised formulation is task-driven and provides learned
features from the hyperspectral data that are well suited for the
classification task. Moreover, the proposed algorithm uses a joint
($\ell_{12}$) sparsity prior to enforce collaboration among the neighboring
pixels. The simulation results illustrate the efficiency of the proposed
dictionary learning algorithm.
","Soheil Bahrampour, Nasser M. Nasrabadi, Asok Ray, Kenneth W. Jenkins",Kenneth W. Jenkins,2015-02-10T21:27:27Z
Hyperspectral Unmixing via Turbo Bilinear Approximate Message Passing,"  The goal of hyperspectral unmixing is to decompose an electromagnetic
spectral dataset measured over M spectral bands and T pixels into N constituent
material spectra (or ""end-members"") with corresponding spatial abundances. In
this paper, we propose a novel approach to hyperspectral unmixing based on
loopy belief propagation (BP) that enables the exploitation of spectral
coherence in the endmembers and spatial coherence in the abundances. In
particular, we partition the factor graph into spectral coherence, spatial
coherence, and bilinear subgraphs, and pass messages between them using a
""turbo"" approach. To perform message passing within the bilinear subgraph, we
employ the bilinear generalized approximate message passing algorithm
(BiG-AMP), a recently proposed belief-propagation-based approach to matrix
factorization. Furthermore, we propose an expectation-maximization (EM)
strategy to tune the prior parameters and a model-order selection strategy to
select the number of materials N. Numerical experiments conducted with both
synthetic and real-world data show favorable unmixing performance relative to
existing methods.
","Jeremy Vila, Philip Schniter, Joseph Meola",Joseph Meola,2015-02-23T14:13:01Z
"Hyperspectral Image Classification and Clutter Detection via Multiple
  Structural Embeddings and Dimension Reductions","  We present a new and effective approach for Hyperspectral Image (HSI)
classification and clutter detection, overcoming a few long-standing challenges
presented by HSI data characteristics. Residing in a high-dimensional spectral
attribute space, HSI data samples are known to be strongly correlated in their
spectral signatures, exhibit nonlinear structure due to several physical laws,
and contain uncertainty and noise from multiple sources. In the presented
approach, we generate an adaptive, structurally enriched representation
environment, and employ the locally linear embedding (LLE) in it. There are two
structure layers external to LLE. One is feature space embedding: the HSI data
attributes are embedded into a discriminatory feature space where
spatio-spectral coherence and distinctive structures are distilled and
exploited to mitigate various difficulties encountered in the native
hyperspectral attribute space. The other structure layer encloses the ranges of
algorithmic parameters for LLE and feature embedding, and supports a
multiplexing and integrating scheme for contending with multi-source
uncertainty. Experiments on two commonly used HSI datasets with a small number
of learning samples have rendered remarkably high-accuracy classification
results, as well as distinctive maps of detected clutter regions.
","Alexandros-Stavros Iliopoulos, Tiancheng Liu, Xiaobai Sun",Xiaobai Sun,2015-06-03T04:04:43Z
Optimal Sparse Kernel Learning for Hyperspectral Anomaly Detection,"  In this paper, a novel framework of sparse kernel learning for Support Vector
Data Description (SVDD) based anomaly detection is presented. In this work,
optimal sparse feature selection for anomaly detection is first modeled as a
Mixed Integer Programming (MIP) problem. Due to the prohibitively high
computational complexity of the MIP, it is relaxed into a Quadratically
Constrained Linear Programming (QCLP) problem. The QCLP problem can then be
practically solved by using an iterative optimization method, in which multiple
subsets of features are iteratively found as opposed to a single subset. The
QCLP-based iterative optimization problem is solved in a finite space called
the \emph{Empirical Kernel Feature Space} (EKFS) instead of in the input space
or \emph{Reproducing Kernel Hilbert Space} (RKHS). This is possible because of
the fact that the geometrical properties of the EKFS and the corresponding RKHS
remain the same. Now, an explicit nonlinear exploitation of the data in a
finite EKFS is achievable, which results in optimal feature ranking.
Experimental results based on a hyperspectral image show that the proposed
method can provide improved performance over the current state-of-the-art
techniques.
","Zhimin Peng, Prudhvi Gurram, Heesung Kwon, Wotao Yin",Wotao Yin,2015-06-08T16:51:40Z
"Robust Collaborative Nonnegative Matrix Factorization For Hyperspectral
  Unmixing (R-CoNMF)","  The recently introduced collaborative nonnegative matrix factorization
(CoNMF) algorithm was conceived to simultaneously estimate the number of
endmembers, the mixing matrix, and the fractional abundances from hyperspectral
linear mixtures. This paper introduces R-CoNMF, which is a robust version of
CoNMF. The robustness has been added by a) including a volume regularizer which
penalizes the distance to a mixing matrix inferred by a pure pixel algorithm;
and by b) introducing a new proximal alternating optimization (PAO) algorithm
for which convergence to a critical point is guaranteed. Our experimental
results indicate that R-CoNMF provides effective estimates both when the number
of endmembers are unknown and when they are known.
","Jun Li, Jose M. Bioucas-Dias, Antonio Plaza, Lin Liu",Lin Liu,2015-06-16T08:21:16Z
"Spatially resolved optical absorption spectroscopy of single- and
  few-layer MoS2 by hyperspectral imaging","  The possibility of spatially resolving the optical properties of atomically
thin materials is especially appealing as they can be modulated at the micro-
and nanoscale by reducing their thickness, changing the doping level or
applying a mechanical deformation. Therefore, optical spectroscopy techniques
with high spatial resolution are necessary to get a deeper insight into the
properties of two-dimensional materials. Here we study the optical absorption
of single- and few-layer molybdenum disulfide (MoS2) in the spectral range from
1.24 eV to 3.22 eV (385 nm to 1000 nm) by developing a hyperspectral imaging
technique that allows one to probe the optical properties with diffraction
limited spatial resolution. We find hyperspectral imaging very suited to study
indirect bandgap semiconductors, unlike photoluminescence that only provides
high luminescence yield for direct gap semiconductors. Moreover, this work
opens the door to study the spatial variation of the optical properties of
other two-dimensional systems, including non-semiconducting materials where
scanning photoluminescence cannot be employed.
","Andres Castellanos-Gomez, Jorge Quereda, Herko P. van der Meulen, Nicolás Agraït, Gabino Rubio-Bollinger",Gabino Rubio-Bollinger,2015-07-03T10:51:37Z
"Semiblind Hyperspectral Unmixing in the Presence of Spectral Library
  Mismatches","  The dictionary-aided sparse regression (SR) approach has recently emerged as
a promising alternative to hyperspectral unmixing (HU) in remote sensing. By
using an available spectral library as a dictionary, the SR approach identifies
the underlying materials in a given hyperspectral image by selecting a small
subset of spectral samples in the dictionary to represent the whole image. A
drawback with the current SR developments is that an actual spectral signature
in the scene is often assumed to have zero mismatch with its corresponding
dictionary sample, and such an assumption is considered too ideal in practice.
In this paper, we tackle the spectral signature mismatch problem by proposing a
dictionary-adjusted nonconvex sparsity-encouraging regression (DANSER)
framework. The main idea is to incorporate dictionary correcting variables in
an SR formulation. A simple and low per-iteration complexity algorithm is
tailor-designed for practical realization of DANSER. Using the same dictionary
correcting idea, we also propose a robust subspace solution for dictionary
pruning. Extensive simulations and real-data experiments show that the proposed
method is effective in mitigating the undesirable spectral signature mismatch
effects.
","Xiao Fu, Wing-Kin Ma, José Bioucas-Dias, Tsung-Han Chan",Tsung-Han Chan,2015-07-07T03:00:17Z
"Feature Selection for classification of hyperspectral data by minimizing
  a tight bound on the VC dimension","  Hyperspectral data consists of large number of features which require
sophisticated analysis to be extracted. A popular approach to reduce
computational cost, facilitate information representation and accelerate
knowledge discovery is to eliminate bands that do not improve the
classification and analysis methods being applied. In particular, algorithms
that perform band elimination should be designed to take advantage of the
specifics of the classification method being used. This paper employs a
recently proposed filter-feature-selection algorithm based on minimizing a
tight bound on the VC dimension. We have successfully applied this algorithm to
determine a reasonable subset of bands without any user-defined stopping
criteria on widely used hyperspectral images and demonstrate that this method
outperforms state-of-the-art methods in terms of both sparsity of feature set
as well as accuracy of classification.\end{abstract}
","Phool Preet, Sanjit Singh Batra,  Jayadeva", Jayadeva,2015-09-27T17:36:18Z
"Spectral-Spatial Classification of Hyperspectral Image Using
  Autoencoders","  Hyperspectral image (HSI) classification is a hot topic in the remote sensing
community. This paper proposes a new framework of spectral-spatial feature
extraction for HSI classification, in which for the first time the concept of
deep learning is introduced. Specifically, the model of autoencoder is
exploited in our framework to extract various kinds of features. First we
verify the eligibility of autoencoder by following classical spectral
information based classification and use autoencoders with different depth to
classify hyperspectral image. Further in the proposed framework, we combine PCA
on spectral dimension and autoencoder on the other two spatial dimensions to
extract spectral-spatial information for classification. The experimental
results show that this framework achieves the highest classification accuracy
among all methods, and outperforms classical classifiers such as SVM and
PCA-based SVM.
","Zhouhan Lin, Yushi Chen, Xing Zhao, Gang Wang",Gang Wang,2015-11-09T22:29:13Z
"Hyperspectral Unmixing in Presence of Endmember Variability,
  Nonlinearity or Mismodelling Effects","  This paper presents three hyperspectral mixture models jointly with Bayesian
algorithms for supervised hyperspectral unmixing. Based on the residual
component analysis model, the proposed general formulation assumes the linear
model to be corrupted by an additive term whose expression can be adapted to
account for nonlinearities (NL), endmember variability (EV), or mismodelling
effects (ME). The NL effect is introduced by considering a polynomial
expression that is related to bilinear models. The proposed new formulation of
EV accounts for shape and scale endmember changes while enforcing a smooth
spectral/spatial variation. The ME formulation takes into account the effect of
outliers and copes with some types of EV and NL. The known constraints on the
parameter of each observation model are modeled via suitable priors. The
posterior distribution associated with each Bayesian model is optimized using a
coordinate descent algorithm which allows the computation of the maximum a
posteriori estimator of the unknown model parameters. The proposed mixture and
Bayesian models and their estimation algorithms are validated on both synthetic
and real images showing competitive results regarding the quality of the
inferences and the computational complexity when compared to the
state-of-the-art algorithms.
","Abderrahim Halimi, Paul Honeine, Jose Bioucas-Dias",Jose Bioucas-Dias,2015-11-18T08:50:21Z
"Hyperspectral Image Classification with Support Vector Machines on
  Kernel Distribution Embeddings","  We propose a novel approach for pixel classification in hyperspectral images,
leveraging on both the spatial and spectral information in the data. The
introduced method relies on a recently proposed framework for learning on
distributions -- by representing them with mean elements in reproducing kernel
Hilbert spaces (RKHS) and formulating a classification algorithm therein. In
particular, we associate each pixel to an empirical distribution of its
neighbouring pixels, a judicious representation of which in an RKHS, in
conjunction with the spectral information contained in the pixel itself, give a
new explicit set of features that can be fed into a suite of standard
classification techniques -- we opt for a well-established framework of support
vector machines (SVM). Furthermore, the computational complexity is reduced via
random Fourier features formalism. We study the consistency and the convergence
rates of the proposed method and the experiments demonstrate strong performance
on hyperspectral data with gains in comparison to the state-of-the-art results.
","Gianni Franchi, Jesus Angulo, Dino Sejdinovic",Dino Sejdinovic,2016-05-30T08:26:28Z
Multiple Instance Hyperspectral Target Characterization,"  In this paper, two methods for multiple instance target characterization,
MI-SMF and MI-ACE, are presented. MI-SMF and MI-ACE estimate a discriminative
target signature from imprecisely-labeled and mixed training data. In many
applications, such as sub-pixel target detection in remotely-sensed
hyperspectral imagery, accurate pixel-level labels on training data is often
unavailable and infeasible to obtain. Furthermore, since sub-pixel targets are
smaller in size than the resolution of a single pixel, training data is
comprised only of mixed data points (in which target training points are
mixtures of responses from both target and non-target classes). Results show
improved, consistent performance over existing multiple instance concept
learning methods on several hyperspectral sub-pixel target detection problems.
","Alina Zare, Changzhe Jiao, Taylor Glenn",Taylor Glenn,2016-06-20T22:35:12Z
"Multiclass feature learning for hyperspectral image classification:
  sparse and hierarchical solutions","  In this paper, we tackle the question of discovering an effective set of
spatial filters to solve hyperspectral classification problems. Instead of
fixing a priori the filters and their parameters using expert knowledge, we let
the model find them within random draws in the (possibly infinite) space of
possible filters. We define an active set feature learner that includes in the
model only features that improve the classifier. To this end, we consider a
fast and linear classifier, multiclass logistic classification, and show that
with a good representation (the filters discovered), such a simple classifier
can reach at least state of the art performances. We apply the proposed active
set learner in four hyperspectral image classification problems, including
agricultural and urban classification at different resolutions, as well as
multimodal data. We also propose a hierarchical setting, which allows to
generate more complex banks of features that can better describe the
nonlinearities present in the data.
","Devis Tuia, Rémi Flamary, Nicolas Courty",Nicolas Courty,2016-06-23T12:05:23Z
"Spectral Angle Based Unary Energy Functions for Spatial-Spectral
  Hyperspectral Classification using Markov Random Fields","  In this paper, we propose and compare two spectral angle based approaches for
spatial-spectral classification. Our methods use the spectral angle to generate
unary energies in a grid-structured Markov random field defined over the pixel
labels of a hyperspectral image. The first approach is to use the exponential
spectral angle mapper (ESAM) kernel/covariance function, a spectral angle based
function, with the support vector machine and the Gaussian process classifier.
The second approach is to directly use the minimum spectral angle between the
test pixel and the training pixels as the unary energy. We compare the proposed
methods with the state-of-the-art Markov random field methods that use support
vector machines and Gaussian processes with squared exponential
kernel/covariance function. In our experiments with two datasets, it is seen
that using minimum spectral angle as unary energy produces better or comparable
results to the existing methods at a smaller running time.
","Utsav B. Gewali, Sildomar T. Monteiro",Sildomar T. Monteiro,2016-10-22T01:44:37Z
"BASS Net: Band-Adaptive Spectral-Spatial Feature Learning Neural Network
  for Hyperspectral Image Classification","  Deep learning based landcover classification algorithms have recently been
proposed in literature. In hyperspectral images (HSI) they face the challenges
of large dimensionality, spatial variability of spectral signatures and
scarcity of labeled data. In this article we propose an end-to-end deep
learning architecture that extracts band specific spectral-spatial features and
performs landcover classification. The architecture has fewer independent
connection weights and thus requires lesser number of training data. The method
is found to outperform the highest reported accuracies on popular hyperspectral
image data sets.
","Anirban Santara, Kaustubh Mani, Pranoot Hatwar, Ankit Singh, Ankur Garg, Kirti Padia, Pabitra Mitra",Pabitra Mitra,2016-12-01T05:00:02Z
"Total variation regularized non-negative matrix factorization for smooth
  hyperspectral unmixing","  Hyperspectral analysis has gained popularity over recent years as a way to
infer what materials are displayed on a picture whose pixels consist of a
mixture of spectral signatures. Computing both signatures and mixture
coefficients is known as unsupervised unmixing, a set of techniques usually
based on non-negative matrix factorization. Unmixing is a difficult non-convex
problem, and algorithms may converge to one out of many local minima, which may
be far removed from the true global minimum. Computing this true minimum is
NP-hard and seems therefore out of reach. Aiming for interesting local minima,
we investigate the addition of total variation regularization terms. Advantages
of these regularizers are two-fold. Their computation is typically rather
light, and they are deemed to preserve sharp edges in pictures. This paper
describes an algorithm for regularized hyperspectral unmixing based on the
Alternating Direction Method of Multipliers.
","Adrien Faivre, Clément Dombry",Clément Dombry,2017-06-28T12:25:05Z
"A new bandwidth selection criterion for using SVDD to analyze
  hyperspectral data","  This paper presents a method for hyperspectral image classification that uses
support vector data description (SVDD) with the Gaussian kernel function. SVDD
has been a popular machine learning technique for single-class classification,
but selecting the proper Gaussian kernel bandwidth to achieve the best
classification performance is always a challenging problem. This paper proposes
a new automatic, unsupervised Gaussian kernel bandwidth selection approach
which is used with a multiclass SVDD classification scheme. The performance of
the multiclass SVDD classification scheme is evaluated on three frequently used
hyperspectral data sets, and preliminary results show that the proposed method
can achieve better performance than published results on these data sets.
","Yuwei Liao, Deovrat Kakde, Arin Chaudhuri, Hansi Jiang, Carol Sadek, Seunghyun Kong",Seunghyun Kong,2018-03-08T23:02:16Z
A Low-rank Tensor Regularization Strategy for Hyperspectral Unmixing,"  Tensor-based methods have recently emerged as a more natural and effective
formulation to address many problems in hyperspectral imaging. In hyperspectral
unmixing (HU), low-rank constraints on the abundance maps have been shown to
act as a regularization which adequately accounts for the multidimensional
structure of the underlying signal. However, imposing a strict low-rank
constraint for the abundance maps does not seem to be adequate, as important
information that may be required to represent fine scale abundance behavior may
be discarded. This paper introduces a new low-rank tensor regularization that
adequately captures the low-rank structure underlying the abundance maps
without hindering the flexibility of the solution. Simulation results with
synthetic and real data show that the the extra flexibility introduced by the
proposed regularization significantly improves the unmixing results.
","Tales Imbiriba, Ricardo Augusto Borsoi, José Carlos Moreira Bermudez",José Carlos Moreira Bermudez,2018-03-16T18:06:46Z
"A Data Dependent Multiscale Model for Hyperspectral Unmixing With
  Spectral Variability","  Spectral variability in hyperspectral images can result from factors
including environmental, illumination, atmospheric and temporal changes. Its
occurrence may lead to the propagation of significant estimation errors in the
unmixing process. To address this issue, extended linear mixing models have
been proposed which lead to large scale nonsmooth ill-posed inverse problems.
Furthermore, the regularization strategies used to obtain meaningful results
have introduced interdependencies among abundance solutions that further
increase the complexity of the resulting optimization problem. In this paper we
present a novel data dependent multiscale model for hyperspectral unmixing
accounting for spectral variability. The new method incorporates spatial
contextual information to the abundances in extended linear mixing models by
using a multiscale transform based on superpixels. The proposed method results
in a fast algorithm that solves the abundance estimation problem only once in
each scale during each iteration. Simulation results using synthetic and real
images compare the performances, both in accuracy and execution time, of the
proposed algorithm and other state-of-the-art solutions.
","Ricardo Augusto Borsoi, Tales Imbiriba, José Carlos Moreira Bermudez",José Carlos Moreira Bermudez,2018-08-02T23:28:54Z
"Improved Deep Spectral Convolution Network For Hyperspectral Unmixing
  With Multinomial Mixture Kernel and Endmember Uncertainty","  In this study, we propose a novel framework for hyperspectral unmixing by
using an improved deep spectral convolution network (DSCN++) combined with
endmember uncertainty. DSCN++ is used to compute high-level representations
which are further modeled with Multinomial Mixture Model to estimate abundance
maps. In the reconstruction step, a new trainable uncertainty term based on a
nonlinear neural network model is introduced to provide robustness to endmember
uncertainty. For the optimization of the coefficients of the multinomial model
and the uncertainty term, Wasserstein Generative Adversarial Network (WGAN) is
exploited to improve stability and to capture uncertainty. Experiments are
performed on both real and synthetic datasets. The results validate that the
proposed method obtains state-of-the-art hyperspectral unmixing performance
particularly on the real datasets compared to the baseline techniques.
","Savas Ozkan, Gozde Bozdagi Akar",Gozde Bozdagi Akar,2018-08-03T07:40:25Z
"Target And Background Separation in Hyperspectral Imagery for Automatic
  Target Detection","  In this paper, we propose a method for separating known targets of interests
from the background in hyperspectral imagery. More precisely, we regard the
given hyperspectral image (HSI) as being made up of the sum of low-rank
background HSI and a sparse target HSI that contains the known targets based on
a pre-learned target dictionary specified by the user. Based on the proposed
method, two strategies are outlined and evaluated independently to realize the
target detection on both synthetic and real experiments.
","Ahmad W. Bitar, Loong-Fah Cheong, Jean-Philippe Ovarlez",Jean-Philippe Ovarlez,2018-08-16T21:01:42Z
Terahertz hyperspectral imaging with dual chip-scale combs,"  Hyperspectral imaging is a technique that allows for the creation of
multi-color images. At terahertz wavelengths, it has emerged as a prominent
tool for a number of applications, ranging from non-ionizing cancer diagnosis
and pharmaceutical characterization to non-destructive artifact testing.
Contemporary terahertz imaging systems typically rely on non-linear optical
down-conversion of a fiber-based near-infrared femtosecond laser, requiring
complex optical systems. Here, we demonstrate hyperspectral imaging with
chip-scale frequency combs based on terahertz quantum cascade lasers. The dual
combs are free-running and emit coherent terahertz radiation that covers a
bandwidth of 220 GHz at 3.4 THz with ~10 {\mu}W per line. The combination of
the fast acquisition rate of dual-comb spectroscopy with the monolithic design,
scalability, and chip-scale size of the combs is highly appealing for future
imaging applications in biomedicine and in the pharmaceutical industry.
","Lukasz A. Sterczewski, Jonas Westberg, Yang Yang, David Burghoff, John Reno, Qing Hu, Gerard Wysocki",Gerard Wysocki,2018-12-09T15:48:13Z
"Material Based Object Tracking in Hyperspectral Videos: Benchmark and
  Algorithms","  Traditional color images only depict color intensities in red, green and blue
channels, often making object trackers fail in challenging scenarios, e.g.,
background clutter and rapid changes of target appearance. Alternatively,
material information of targets contained in a large amount of bands of
hyperspectral images (HSI) is more robust to these difficult conditions. In
this paper, we conduct a comprehensive study on how material information can be
utilized to boost object tracking from three aspects: benchmark dataset,
material feature representation and material based tracking. In terms of
benchmark, we construct a dataset of fully-annotated videos, which contain both
hyperspectral and color sequences of the same scene. Material information is
represented by spectral-spatial histogram of multidimensional gradient, which
describes the 3D local spectral-spatial structure in an HSI, and fractional
abundances of constituted material components which encode the underlying
material distribution. These two types of features are embedded into
correlation filters, yielding material based tracking. Experimental results on
the collected benchmark dataset show the potentials and advantages of material
based object tracking.
","Fengchao Xiong, Jun Zhou, Yuntao Qian",Yuntao Qian,2018-12-11T01:35:15Z
"Dimensionality Reduction of Hyperspectral Imagery Based on
  Spatial-spectral Manifold Learning","  The graph embedding (GE) methods have been widely applied for dimensionality
reduction of hyperspectral imagery (HSI). However, a major challenge of GE is
how to choose proper neighbors for graph construction and explore the spatial
information of HSI data. In this paper, we proposed an unsupervised
dimensionality reduction algorithm termed spatial-spectral manifold
reconstruction preserving embedding (SSMRPE) for HSI classification. At first,
a weighted mean filter (WMF) is employed to preprocess the image, which aims to
reduce the influence of background noise. According to the spatial consistency
property of HSI, the SSMRPE method utilizes a new spatial-spectral combined
distance (SSCD) to fuse the spatial structure and spectral information for
selecting effective spatial-spectral neighbors of HSI pixels. Then, it explores
the spatial relationship between each point and its neighbors to adjusts the
reconstruction weights for improving the efficiency of manifold reconstruction.
As a result, the proposed method can extract the discriminant features and
subsequently improve the classification performance of HSI. The experimental
results on PaviaU and Salinas hyperspectral datasets indicate that SSMRPE can
achieve better classification accuracies in comparison with some
state-of-the-art methods.
","Hong Huang, Guangyao Shi, Haibo He, Yule Duan, Fulin Luo",Fulin Luo,2018-12-22T14:06:21Z
Is Pretraining Necessary for Hyperspectral Image Classification?,"  We address two questions for training a convolutional neural network (CNN)
for hyperspectral image classification: i) is it possible to build a
pre-trained network? and ii) is the pre-training effective in furthering the
performance? To answer the first question, we have devised an approach that
pre-trains a network on multiple source datasets that differ in their
hyperspectral characteristics and fine-tunes on a target dataset. This approach
effectively resolves the architectural issue that arises when transferring
meaningful information between the source and the target networks. To answer
the second question, we carried out several ablation experiments. Based on the
experimental results, a network trained from scratch performs as good as a
network fine-tuned from a pre-trained network. However, we observed that
pre-training the network has its own advantage in achieving better performances
when deeper networks are required.
","Hyungtae Lee, Sungmin Eum, Heesung Kwon",Heesung Kwon,2019-01-24T22:01:48Z
"Deep Hyperspectral Prior: Denoising, Inpainting, Super-Resolution","  Deep learning algorithms have demonstrated state-of-the-art performance in
various tasks of image restoration. This was made possible through the ability
of CNNs to learn from large exemplar sets. However, the latter becomes an issue
for hyperspectral image processing where datasets commonly consist of just a
few images. In this work, we propose a new approach to denoising, inpainting,
and super-resolution of hyperspectral image data using intrinsic properties of
a CNN without any training. The performance of the given algorithm is shown to
be comparable to the performance of trained networks, while its application is
not restricted by the availability of training data. This work is an extension
of original ""deep prior"" algorithm to HSI domain and 3D-convolutional networks.
","Oleksii Sidorov, Jon Yngve Hardeberg",Jon Yngve Hardeberg,2019-02-01T12:20:38Z
"A laboratory-created dataset with ground-truth for hyperspectral
  unmixing evaluation","  Spectral unmixing is an important and challenging problem in hyperspectral
data processing. This topic has been extensively studied and a variety of
unmixing algorithms have been proposed in the literature. However, the lack of
publicly available dataset with ground-truth makes it difficult to evaluate and
compare the performance of unmixing algorithms in a quantitative and objective
manner. Most of the existing works rely on the use of numerical synthetic data
and an intuitive inspection of the results of real data. To alleviate this
dilemma, in this study, we design several experimental scenes in our
laboratory, including printed checkerboards, mixed quartz sands, and reflection
with a vertical board. A dataset is then created by imaging these scenes with
the hyperspectral camera in our laboratory, providing 36 mixtures with more
than 130, 000 pixels with 256 wavelength bands ranging from 400nm to 1000nm.
The experimental settings are strictly controlled so that pure material
spectral signatures and material compositions are known. To the best of our
knowledge, this dataset is the first publicly available dataset created in a
systematic manner with ground-truth for spectral unmixing. Some typical linear
and nonlinear unmixing algorithms are also tested with this dataset and lead to
meaningful results.
","Min Zhao, Jie Chen, Zhe He",Zhe He,2019-02-22T02:51:12Z
"A Dictionary-Based Generalization of Robust PCA Part II: Applications to
  Hyperspectral Demixing","  We consider the task of localizing targets of interest in a hyperspectral
(HS) image based on their spectral signature(s), by posing the problem as two
distinct convex demixing task(s). With applications ranging from remote sensing
to surveillance, this task of target detection leverages the fact that each
material/object possesses its own characteristic spectral response, depending
upon its composition. However, since $\textit{signatures}$ of different
materials are often correlated, matched filtering-based approaches may not be
apply here. To this end, we model a HS image as a superposition of a low-rank
component and a dictionary sparse component, wherein the dictionary consists of
the $\textit{a priori}$ known characteristic spectral responses of the target
we wish to localize, and develop techniques for two different sparsity
structures, resulting from different model assumptions. We also present the
corresponding recovery guarantees, leveraging our recent theoretical results
from a companion paper. Finally, we analyze the performance of the proposed
approach via experimental evaluations on real HS datasets for a classification
task, and compare its performance with related techniques.
","Sirisha Rambhatla, Xingguo Li, Jineng Ren, Jarvis Haupt",Jarvis Haupt,2019-02-26T21:42:17Z
Target-based Hyperspectral Demixing via Generalized Robust PCA,"  Localizing targets of interest in a given hyperspectral (HS) image has
applications ranging from remote sensing to surveillance. This task of target
detection leverages the fact that each material/object possesses its own
characteristic spectral response, depending upon its composition. As
$\textit{signatures}$ of different materials are often correlated, matched
filtering based approaches may not be appropriate in this case. In this work,
we present a technique to localize targets of interest based on their spectral
signatures. We also present the corresponding recovery guarantees, leveraging
our recent theoretical results. To this end, we model a HS image as a
superposition of a low-rank component and a dictionary sparse component,
wherein the dictionary consists of the $\textit{a priori}$ known characteristic
spectral responses of the target we wish to localize. Finally, we analyze the
performance of the proposed approach via experimental validation on real HS
data for a classification task, and compare it with related techniques.
","Sirisha Rambhatla, Xingguo Li, Jarvis Haupt",Jarvis Haupt,2019-02-26T21:43:51Z
"Algorithms and Comparisons of Non-negative Matrix Factorization with
  Volume Regularization for Hyperspectral Unmixing","  In this work, we consider nonnegative matrix factorization (NMF) with a
regularization that promotes small volume of the convex hull spanned by the
basis matrix. We present highly efficient algorithms for three different volume
regularizers, and compare them on endmember recovery in hyperspectral unmixing.
The NMF algorithms developed in this work are shown to outperform the
state-of-the-art volume-regularized NMF methods, and produce meaningful
decompositions on real-world hyperspectral images in situations where
endmembers are highly mixed (no pure pixels). Furthermore, our extensive
numerical experiments show that when the data is highly separable, meaning that
there are data points close to the true endmembers, and there are a few
endmembers, the regularizer based on the determinant of the Gramian produces
the best results in most cases. For data that is less separable and/or contains
more endmembers, the regularizer based on the logarithm of the determinant of
the Gramian performs best in general.
","M. S. Ang, Nicolas Gillis",Nicolas Gillis,2019-03-11T15:19:10Z
"Spectral Unmixing: A Derivation of the Extended Linear Mixing Model from
  the Hapke Model","  In hyperspectral imaging, spectral unmixing aims at decomposing the image
into a set of reference spectral signatures corresponding to the materials
present in the observed scene and their relative proportions in every pixel.
While a linear mixing model was used for a long time, the complex nature of the
physical mixing processes, led to shift the community's attention towards
nonlinear models and algorithms accounting for the variability of the
endmembers. Such intra class variations are due to local changes in the
physico-chemical composition of the materials, and to illumination changes. In
the physical remote sensing community, a popular model accounting for
illumination variability is the radiative transfer model proposed by Hapke. It
is however too complex to be directly used in hyperspectral unmixing in a
tractable way. Instead, the Extended Linear Mixing Model (ELMM) allows to
easily unmix hyperspectral data accounting for changing illumination
conditions. In this letter, we show that the ELMM can be obtained from the
Hapke model by successive simplifiying physical assumptions, thus theoretically
confirming its relevance to handle illumination induced variability in the
unmixing problem.
","Lucas Drumetz, Jocelyn Chanussot, Christian Jutten",Christian Jutten,2019-03-28T16:11:50Z
"Spectral Variability Aware Blind Hyperspectral Image Unmixing Based on
  Convex Geometry","  Hyperspectral image unmixing has proven to be a useful technique to interpret
hyperspectral data, and is a prolific research topic in the community. Most of
the approaches used to perform linear unmixing are based on convex geometry
concepts, because of the strong geometrical structure of the linear mixing
model. However, two main phenomena lead to question this model, namely
nonlinearities and the spectral variability of the materials. Many algorithms
based on convex geometry are still used when considering these two limitations
of the linear model. A natural question is to wonder to what extent these
concepts and tools (Intrinsic Dimensionality estimation, endmember extraction
algorithms, pixel purity) can be safely used in these different scenarios. In
this paper, we analyze them with a focus on endmember variability, assuming
that the linear model holds. In the light of this analysis, we propose an
integrated unmixing chain which tries to adress the shortcomings of the
classical tools used in the linear case, based on our previously proposed
extended linear mixing model. We show the interest of the proposed approach on
simulated and real datasets.
","Lucas Drumetz, Jocelyn Chanussot, Christian Jutten, Wing-Kin Ma, Akira Iwasaki",Akira Iwasaki,2019-04-08T08:34:34Z
"Band Attention Convolutional Networks For Hyperspectral Image
  Classification","  Redundancy and noise exist in the bands of hyperspectral images (HSIs). Thus,
it is a good property to be able to select suitable parts from hundreds of
input bands for HSIs classification methods. In this letter, a band attention
module (BAM) is proposed to implement the deep learning based HSIs
classification with the capacity of band selection or weighting. The proposed
BAM can be seen as a plug-and-play complementary component of the existing
classification networks which fully considers the adverse effects caused by the
redundancy of the bands when using convolutional neural networks (CNNs) for
HSIs classification. Unlike most of deep learning methods used in HSIs, the
band attention module which is customized according to the characteristics of
hyperspectral images is embedded in the ordinary CNNs for better performance.
At the same time, unlike classical band selection or weighting methods, the
proposed method achieves the end-to-end training instead of the separated
stages. Experiments are carried out on two HSI benchmark datasets. Compared to
some classical and advanced deep learning methods, numerical simulations under
different evaluation criteria show that the proposed method have good
performance. Last but not least, some advanced CNNs are combined with the
proposed BAM for better performance.
","Hongwei Dong, Lamei Zhang, Bin Zou",Bin Zou,2019-06-11T03:56:20Z
Noise Removal of FTIR Hyperspectral Images via MMSE,"  Fourier transform infrared (FTIR) hyperspectral imaging systems are deployed
in various fields where spectral information is exploited. Chemical warfare
agent (CWA) detection is one of such fields and it requires a fast and accurate
process from the measurement to the visualization of detection results,
including noise removal. A general concern of existing noise removal algorithms
is a trade-off between time and performance. This paper suggests a minimum mean
square error (MMSE) approach as an efficient noise removal algorithm for FTIR
hyperspectral images. The experimental result shows that the MMSE estimator
spends less time to achieve comparable performance to the existing algorithms.
","Chang Sik Lee, Hyeong Geun Yu, Dong Jo Park, Dong Eui Chang, Hyunwoo Nam, Byeong Hwang Park",Byeong Hwang Park,2019-07-16T04:44:18Z
Hyperspectral City V1.0 Dataset and Benchmark,"  This document introduces the background and the usage of the Hyperspectral
City Dataset and the benchmark. The documentation first starts with the
background and motivation of the dataset. Follow it, we briefly describe the
method of collecting the dataset and the processing method from raw dataset to
the final release dataset, specifically, the version 1.0. We also provide the
detailed usage of the dataset and the evaluation metric for submitted the
result for the 2019 Hyperspectral City Challenge.
","Shaodi You, Erqi Huang, Shuaizhe Liang, Yongrong Zheng, Yunxiang Li, Fan Wang, Sen Lin, Qiu Shen, Xun Cao, Diming Zhang, Yuanjiang Li, Yu Li, Ying Fu, Boxin Shi, Feng Lu, Yinqiang Zheng, Robby T. Tan",Robby T. Tan,2019-07-24T07:13:27Z
"Segmenting Hyperspectral Images Using Spectral-Spatial Convolutional
  Neural Networks With Training-Time Data Augmentation","  Hyperspectral imaging provides detailed information about the scanned
objects, as it captures their spectral characteristics within a large number of
wavelength bands. Classification of such data has become an active research
topic due to its wide applicability in a variety of fields. Deep learning has
established the state of the art in the area, and it constitutes the current
research mainstream. In this letter, we introduce a new spectral-spatial
convolutional neural network, benefitting from a battery of data augmentation
techniques which help deal with a real-life problem of lacking ground-truth
training data. Our rigorous experiments showed that the proposed method
outperforms other spectral-spatial techniques from the literature, and delivers
precise hyperspectral classification in real time.
","Jakub Nalepa, Lukasz Tulczyjew, Michal Myller, Michal Kawulok",Michal Kawulok,2019-07-27T15:32:10Z
"Is There Any Recovery Guarantee with Coupled Structured Matrix
  Factorization for Hyperspectral Super-Resolution?","  Coupled structured matrix factorization (CoSMF) for hyperspectral
super-resolution (HSR) has recently drawn significant interest in hyperspectral
imaging for remote sensing. Presently there is very few work that studies the
theoretical recovery guarantees of CoSMF. This paper makes one such endeavor by
considering the CoSMF formulation by Wei et al., which, simply speaking, is
similar to coupled non-negative matrix factorization. Assuming no noise, we
show sufficient conditions under which the globably optimal solution to the
CoSMF problem is guaranteed to deliver certain recovery accuracies. Our
analysis suggests that sparsity and the pure-pixel (or separability) condition
play a hidden role in enabling CoSMF to achieve some good recovery
characteristics.
","Huikang Liu, Ruiyuan Wu, Wing-Kin Ma",Wing-Kin Ma,2019-07-30T03:58:31Z
Deep Sparse Band Selection for Hyperspectral Face Recognition,"  Hyperspectral imaging systems collect and process information from specific
wavelengths across the electromagnetic spectrum. The fusion of multi-spectral
bands in the visible spectrum has been exploited to improve face recognition
performance over all the conventional broad band face images. In this book
chapter, we propose a new Convolutional Neural Network (CNN) framework which
adopts a structural sparsity learning technique to select the optimal spectral
bands to obtain the best face recognition performance over all of the spectral
bands. Specifically, in this method, images from all bands are fed to a CNN,
and the convolutional filters in the first layer of the CNN are then
regularized by employing a group Lasso algorithm to zero out the redundant
bands during the training of the network. Contrary to other methods which
usually select the useful bands manually or in a greedy fashion, our method
selects the optimal spectral bands automatically to achieve the best face
recognition performance over all spectral bands. Moreover, experimental results
demonstrate that our method outperforms state of the art band selection methods
for face recognition on several publicly-available hyperspectral face image
datasets.
","Fariborz Taherkhani, Jeremy Dawson, Nasser M. Nasrabadi",Nasser M. Nasrabadi,2019-08-15T23:51:33Z
"Hyperspectral and multispectral image fusion under spectrally varying
  spatial blurs -- Application to high dimensional infrared astronomical
  imaging","  Hyperspectral imaging has become a significant source of valuable data for
astronomers over the past decades. Current instrumental and observing time
constraints allow direct acquisition of multispectral images, with high spatial
but low spectral resolution, and hyperspectral images, with low spatial but
high spectral resolution. To enhance scientific interpretation of the data, we
propose a data fusion method which combines the benefits of each image to
recover a high spatio-spectral resolution datacube. The proposed inverse
problem accounts for the specificities of astronomical instruments, such as
spectrally variant blurs. We provide a fast implementation by solving the
problem in the frequency domain and in a low-dimensional subspace to
efficiently handle the convolution operators as well as the high dimensionality
of the data. We conduct experiments on a realistic synthetic dataset of
simulated observation of the upcoming James Webb Space Telescope, and we show
that our fusion algorithm outperforms state-of-the-art methods commonly used in
remote sensing for Earth observation.
","Claire Guilloteau, Thomas Oberlin, Olivier Berné, Nicolas Dobigeon",Nicolas Dobigeon,2019-12-26T13:58:40Z
"Unsupervised Feature Learning by Autoencoder and Prototypical
  Contrastive Learning for Hyperspectral Classification","  Unsupervised learning methods for feature extraction are becoming more and
more popular. We combine the popular contrastive learning method (prototypical
contrastive learning) and the classic representation learning method
(autoencoder) to design an unsupervised feature learning network for
hyperspectral classification. Experiments have proved that our two proposed
autoencoder networks have good feature learning capabilities by themselves, and
the contrastive learning network we designed can better combine the features of
the two to learn more representative features. As a result, our method
surpasses other comparison methods in the hyperspectral classification
experiments, including some supervised methods. Moreover, our method maintains
a fast feature extraction speed than baseline methods. In addition, our method
reduces the requirements for huge computing resources, separates feature
extraction and contrastive learning, and allows more researchers to conduct
research and experiments on unsupervised contrastive learning.
","Zeyu Cao, Xiaorun Li, Liaoying Zhao",Liaoying Zhao,2020-09-02T11:17:48Z
"Attachment and antibiotic response of early-stage biofilms studied using
  resonant hyperspectral imaging","  Many bacterial species readily develop biofilms that act as a protective
matrix against external challenge, e.g. from antimicrobial treatment.
Therefore, biofilms are often responsible for persistent and recurring
infections. Established methods for studying biofilms are either destructive or
they focus on the biofilm surface. A non-destructive method that is sensitive
to the underside of the biofilm is highly desirable, as it allows studying the
penetration of antibiotics through the film. Here, we demonstrate that the high
surface sensitivity of resonant hyperspectral imaging provides this capability.
The method allows us to monitor the early stages of Escherichia coli biofilm
formation, cell attachment and microcolony formation, in-situ and in real time.
We study the response of the biofilm to a number of different antibiotics and
verify our observations using confocal microscopy. Based on this ability to
closely monitor the surface-bound cells, resonant hyperspectral imaging gives
new insights into the antimicrobial resistance of biofilms.
","Yue Wang, Christopher P. Reardon, Nicholas Read, Stephen Thorpe, Adrian Evans, Neil Todd, Marjan Van Der Woude, Thomas F. Krauss",Thomas F. Krauss,2020-09-07T23:05:04Z
"Hyperspectral Image Super-Resolution via Deep Prior Regularization with
  Parameter Estimation","  Hyperspectral image (HSI) super-resolution is commonly used to overcome the
hardware limitations of existing hyperspectral imaging systems on spatial
resolution. It fuses a low-resolution (LR) HSI and a high-resolution (HR)
conventional image of the same scene to obtain an HR HSI. In this work, we
propose a method that integrates a physical model and deep prior information.
Specifically, a novel, yet effective two-stream fusion network is designed to
serve as a {regularizer} for the fusion problem. This fusion problem is
formulated as an optimization problem whose solution can be obtained by solving
a Sylvester equation. Furthermore, the regularization parameter is
simultaneously estimated to automatically adjust contribution of the physical
model and {the} learned prior to reconstruct the final HR HSI. Experimental
results on {both simulated and real data} demonstrate the superiority of the
proposed method over other state-of-the-art methods on both quantitative and
qualitative comparisons.
","Xiuheng Wang, Jie Chen, Qi Wei, Cédric Richard",Cédric Richard,2020-09-09T12:01:44Z
"LiteDepthwiseNet: An Extreme Lightweight Network for Hyperspectral Image
  Classification","  Deep learning methods have shown considerable potential for hyperspectral
image (HSI) classification, which can achieve high accuracy compared with
traditional methods. However, they often need a large number of training
samples and have a lot of parameters and high computational overhead. To solve
these problems, this paper proposes a new network architecture,
LiteDepthwiseNet, for HSI classification. Based on 3D depthwise convolution,
LiteDepthwiseNet can decompose standard convolution into depthwise convolution
and pointwise convolution, which can achieve high classification performance
with minimal parameters. Moreover, we remove the ReLU layer and Batch
Normalization layer in the original 3D depthwise convolution, which
significantly improves the overfitting phenomenon of the model on small sized
datasets. In addition, focal loss is used as the loss function to improve the
model's attention on difficult samples and unbalanced data, and its training
performance is significantly better than that of cross-entropy loss or balanced
cross-entropy loss. Experiment results on three benchmark hyperspectral
datasets show that LiteDepthwiseNet achieves state-of-the-art performance with
a very small number of parameters and low computational cost.
","Benlei Cui, XueMei Dong, Qiaoqiao Zhan, Jiangtao Peng, Weiwei Sun",Weiwei Sun,2020-10-15T13:12:17Z
"Hyperspectral classification of blood-like substances using machine
  learning methods combined with genetic algorithms in transductive and
  inductive scenarios","  This study is focused on applying genetic algorithms (GA) to model and band
selection in hyperspectral image classification. We use a forensic-inspired
data set of seven hyperspectral images with blood and five visually similar
substances to test GA-optimised classifiers in two scenarios: when the training
and test data come from the same image and when they come from different
images, which is a more challenging task due to significant spectra
differences. In our experiments we compare GA with a classic model optimisation
through grid search. Our results show that GA-based model optimisation can
reduce the number of bands and create an accurate classifier that outperforms
the GS-based reference models, provided that during model optimisation it has
access to examples similar to test data. We illustrate this with experiment
highlighting the importance of a validation set.
","Filip Pałka, Wojciech Książek, Paweł Pławiak, Michał Romaszewski, Kamil Książek",Kamil Książek,2020-11-04T09:18:16Z
Convolutional Autoencoder for Blind Hyperspectral Image Unmixing,"  In the remote sensing context spectral unmixing is a technique to decompose a
mixed pixel into two fundamental representatives: endmembers and abundances. In
this paper, a novel architecture is proposed to perform blind unmixing on
hyperspectral images. The proposed architecture consists of convolutional
layers followed by an autoencoder. The encoder transforms the feature space
produced through convolutional layers to a latent space representation. Then,
from these latent characteristics the decoder reconstructs the roll-out image
of the monochrome image which is at the input of the architecture; and each
single-band image is fed sequentially. Experimental results on real
hyperspectral data concludes that the proposed algorithm outperforms existing
unmixing methods at abundance estimation and generates competitive results for
endmember extraction with RMSE and SAD as the metrics, respectively.
","Yasiru Ranasinghe, Sanjaya Herath, Kavinga Weerasooriya, Mevan Ekanayake, Roshan Godaliyadda, Parakrama Ekanayake, Vijitha Herath",Vijitha Herath,2020-11-18T17:41:31Z
"Tech Report: A Homogeneity-Based Multiscale Hyperspectral Image
  Representation for Sparse Spectral Unmixing","  Several approaches have been proposed to solve the spectral unmixing problem
in hyperspectral image analysis. Among them the use of sparse regression
techniques aims to characterize the abundances in pixels based on a large
library of spectral signatures known a priori. Recently, the integration of
image spatial-contextual information significantly enhanced the performance of
sparse unmixing. In this work, we propose a computationally efficient
multiscale representation method for hyperspectral data adapted to the unmixing
problem. The proposed method is based on a hierarchical extension of the SLIC
oversegmentation algorithm constructed using a robust homogeneity testing. The
image is subdivided into a set of spectrally homogeneous regions formed by
pixels with similar characteristics (superpixels). This representation is then
used to provide prior spatial regularity information for the abundances of
materials present in the scene, improving the conditioning of the unmixing
problem. Simulation results illustrate that the method is capable of estimating
abundances with high quality and low computational cost, especially in noisy
scenarios.
","L. C. Ayres, S. J. M. de Almeida, J. C. M. Bermudez, R. A. Borsoi",R. A. Borsoi,2021-02-11T01:54:27Z
"ADMM and Spectral Proximity Operators in Hyperspectral Broadband Phase
  Retrieval for Quantitative Phase Imaging","  A novel formulation of the hyperspectral broadband phase retrieval is
developed for the scenario where both object and modulation phase masks are
spectrally varying. The proposed algorithm is based on a complex domain version
of the alternating direction method of multipliers (ADMM) and Spectral
Proximity Operators (SPO) derived for Gaussian and Poissonian observations.
Computations for these operators are reduced to the solution of sets of cubic
(for Gaussian) and quadratic (for Poissonian) algebraic equations. These
proximity operators resolve two problems. Firstly, the complex domain spectral
components of signals are extracted from the total intensity observations
calculated as sums of the signal spectral intensities. In this way, the
spectral analysis of the total intensities is achieved. Secondly, the noisy
observations are filtered, compromising noisy intensity observations and their
predicted counterparts. The ability to resolve the hyperspectral broadband
phase retrieval problem and to find the spectrum varying object are essentially
defined by the spectral properties of object and image formation operators. The
simulation tests demonstrate that the phase retrieval in this formulation can
be successfully resolved.
","Vladimir Katkovnik, Igor Shevkunov, Karen Egiazarian",Karen Egiazarian,2021-05-14T08:05:01Z
"SSCAN: A Spatial-spectral Cross Attention Network for Hyperspectral
  Image Denoising","  Hyperspectral images (HSIs) have been widely used in a variety of
applications thanks to the rich spectral information they are able to provide.
Among all HSI processing tasks, HSI denoising is a crucial step. Recently, deep
learning-based image denoising methods have made great progress and achieved
great performance. However, existing methods tend to ignore the correlations
between adjacent spectral bands, leading to problems such as spectral
distortion and blurred edges in denoised results. In this study, we propose a
novel HSI denoising network, termed SSCAN, that combines group convolutions and
attention modules. Specifically, we use a group convolution with a spatial
attention module to facilitate feature extraction by directing models'
attention to band-wise important features. We propose a spectral-spatial
attention block (SSAB) to exploit the spatial and spectral information in
hyperspectral images in an effective manner. In addition, we adopt residual
learning operations with skip connections to ensure training stability. The
experimental results indicate that the proposed SSCAN outperforms several
state-of-the-art HSI denoising algorithms.
","Zhiqiang Wang, Zhenfeng Shao, Xiao Huang, Jiaming Wang, Tao Lu, Sihang Zhang",Sihang Zhang,2021-05-23T14:36:17Z
"Enhanced Hyperspectral Image Super-Resolution via RGB Fusion and TV-TV
  Minimization","  Hyperspectral (HS) images contain detailed spectral information that has
proven crucial in applications like remote sensing, surveillance, and
astronomy. However, because of hardware limitations of HS cameras, the captured
images have low spatial resolution. To improve them, the low-resolution
hyperspectral images are fused with conventional high-resolution RGB images via
a technique known as fusion based HS image super-resolution. Currently, the
best performance in this task is achieved by deep learning (DL) methods. Such
methods, however, cannot guarantee that the input measurements are satisfied in
the recovered image, since the learned parameters by the network are applied to
every test image. Conversely, model-based algorithms can typically guarantee
such measurement consistency. Inspired by these observations, we propose a
framework that integrates learning and model based methods. Experimental
results show that our method produces images of superior spatial and spectral
resolution compared to the current leading methods, whether model- or DL-based.
","Marija Vella, Bowen Zhang, Wei Chen, João F. C. Mota",João F. C. Mota,2021-06-13T18:52:47Z
"AVHYAS: A Free and Open Source QGIS Plugin for Advanced Hyperspectral
  Image Analysis","  Advanced Hyperspectral Data Analysis Software (AVHYAS) plugin is a python3
based quantum GIS (QGIS) plugin designed to process and analyse hyperspectral
(Hx) images. It is developed to guarantee full usage of present and future Hx
airborne or spaceborne sensors and provides access to advanced algorithms for
Hx data processing. The software is freely available and offers a range of
basic and advanced tools such as atmospheric correction (for airborne AVIRISNG
image), standard processing tools as well as powerful machine learning and Deep
Learning interfaces for Hx data analysis.
","Rosly Boy Lyngdoh, Anand S Sahadevan, Touseef Ahmad, Pradyuman Singh Rathore, Manoj Mishra, Praveen Kumar Gupta, Arundhati Misra",Arundhati Misra,2021-06-24T05:55:15Z
On Hyperspectral Unmixing,"  In this article the author reviews Jos\'e Bioucas-Dias' key contributions to
hyperspectral unmixing (HU), in memory of him as an influential scholar and for
his many beautiful ideas introduced to the hyperspectral community. Our story
will start with vertex component analysis (VCA) -- one of the most celebrated
HU algorithms, with more than 2,000 Google Scholar citations. VCA was
pioneering, invented at a time when HU research just began to emerge, and it
shows sharp insights on a then less-understood subject. Then we will turn to
SISAL, another widely-used algorithm. SISAL is not only a highly successful
algorithm, it is also a demonstration of its inventor's ingenuity on applied
optimization and on smart formulation for practical noisy cases. Our tour will
end with dependent component analysis (DECA), perhaps a less well-known
contribution. DECA adopts a statistical inference framework, and the author's
latest research indicates that such framework has great potential for further
development, e.g., there are hidden connections between SISAL and DECA. The
development of DECA shows foresight years ahead, in that regard.
",Wing-Kin Ma,Wing-Kin Ma,2021-06-27T09:30:57Z
"An Open-channel Microfluidic Membrane Device for In situ Hyperspectral
  mapping of enzymatic cellulose hydrolysis","  Synchrotron infrared hyperspectral microscopy is a label-free and
non-invasive technique well suited for imaging of chemical events in situ. It
can track the spatial and temporal distributions of molecules of interests in a
specimen in its native state by the molecule's characteristic vibrational
modes. Despite tremendous progress made in recent years, IR hyperspectral
imaging of chemical events in biomaterials in liquids remains challenging
because of the demanding requirements on environmental control and strong
infrared absorption of water. Here we report a multi-phase capillary-driven
membrane device for label-free and real-time investigation of enzymatic
deconstruction of algal cellulose purified from Cladophora aegagropila.
","Hoi-Ying N. Holman, Wujun Zhao, Jennifer D. Nill, Liang Chen, Sankar Raju Narayanasamy, Tina Jeoh",Tina Jeoh,2021-07-16T05:06:02Z
"Adaptive non-Zero Mean Gaussian Detection and Application to
  Hyperspectral Imaging","  Classical target detection schemes are usually obtained deriving the
likelihood ratio under Gaussian hypothesis and replacing the unknown background
parameters by their estimates. In most applications, interference signals are
assumed to be Gaussian with zero mean or with a known mean vector that can be
removed and with unknown covariance matrix. When mean vector is unknown, it has
to be jointly estimated with the covariance matrix, as it is the case for
instance in hyperspectral imaging. In this paper, the adaptive versions of the
classical Matched Filter and the Normalized Matched Filter, as well as two
versions of the Kelly detector are first derived and then are analyzed for the
case when the mean vector of the background is unknown. More precisely,
theoretical closed-form expressions for false-alarm regulation are derived and
the Constant False Alarm Rate property is pursued to allow the detector to be
independent of nuisance parameters. Finally, the theoretical contribution is
validated through simulations and on real hyperspectral scenes.
","Joana Frontera-Pons, Frederic Pascal, Jean-Philippe Ovarlez",Jean-Philippe Ovarlez,2014-04-11T01:42:39Z
"Integration of LiDAR and Hyperspectral Data for Land-cover
  Classification: A Case Study","  In this paper, an approach is proposed to fuse LiDAR and hyperspectral data,
which considers both spectral and spatial information in a single framework.
Here, an extended self-dual attribute profile (ESDAP) is investigated to
extract spatial information from a hyperspectral data set. To extract spectral
information, a few well-known classifiers have been used such as support vector
machines (SVMs), random forests (RFs), and artificial neural networks (ANNs).
The proposed method accurately classify the relatively volumetric data set in a
few CPU processing time in a real ill-posed situation where there is no balance
between the number of training samples and the number of features. The
classification part of the proposed approach is fully-automatic.
","Pedram Ghamisi, Gabriele Cavallaro,  Dan,  Wu, Jon Atli Benediktsson, Antonio Plaza",Antonio Plaza,2017-07-09T21:35:54Z
"Sparse and Low-Rank Matrix Decomposition for Automatic Target Detection
  in Hyperspectral Imagery","  Given a target prior information, our goal is to propose a method for
automatically separating targets of interests from the background in
hyperspectral imagery. More precisely, we regard the given hyperspectral image
(HSI) as being made up of the sum of low-rank background HSI and a sparse
target HSI that contains the targets based on a pre-learned target dictionary
constructed from some online spectral libraries. Based on the proposed method,
two strategies are briefly outlined and evaluated to realize the target
detection on both synthetic and real experiments.
","Ahmad W. Bitar, Loong-Fah Cheong, Jean-Philippe Ovarlez",Jean-Philippe Ovarlez,2017-11-24T14:16:07Z
"Explaining hyperspectral imaging based plant disease identification: 3D
  CNN and saliency maps","  Our overarching goal is to develop an accurate and explainable model for
plant disease identification using hyperspectral data. Charcoal rot is a soil
borne fungal disease that affects the yield of soybean crops worldwide.
Hyperspectral images were captured at 240 different wavelengths in the range of
383 - 1032 nm. We developed a 3D Convolutional Neural Network model for soybean
charcoal rot disease identification. Our model has classification accuracy of
95.73\% and an infected class F1 score of 0.87. We infer the trained model
using saliency map and visualize the most sensitive pixel locations that enable
classification. The sensitivity of individual wavelengths for classification
was also determined using the saliency map visualization. We identify the most
sensitive wavelength as 733 nm using the saliency map visualization. Since the
most sensitive wavelength is in the Near Infrared Region(700 - 1000 nm) of the
electromagnetic spectrum, which is also the commonly used spectrum region for
determining the vegetation health of the plant, we were more confident in the
predictions using our model.
","Koushik Nagasubramanian, Sarah Jones, Asheesh K. Singh, Arti Singh, Baskar Ganapathysubramanian, Soumik Sarkar",Soumik Sarkar,2018-04-24T03:39:36Z
Rank Minimization for Snapshot Compressive Imaging,"  Snapshot compressive imaging (SCI) refers to compressive imaging systems
where multiple frames are mapped into a single measurement, with video
compressive imaging and hyperspectral compressive imaging as two representative
applications. Though exciting results of high-speed videos and hyperspectral
images have been demonstrated, the poor reconstruction quality precludes SCI
from wide applications.This paper aims to boost the reconstruction quality of
SCI via exploiting the high-dimensional structure in the desired signal. We
build a joint model to integrate the nonlocal self-similarity of
video/hyperspectral frames and the rank minimization approach with the SCI
sensing process. Following this, an alternating minimization algorithm is
developed to solve this non-convex problem. We further investigate the special
structure of the sampling process in SCI to tackle the computational workload
and memory issues in SCI reconstruction. Both simulation and real data
(captured by four different SCI cameras) results demonstrate that our proposed
algorithm leads to significant improvements compared with current
state-of-the-art algorithms. We hope our results will encourage the researchers
and engineers to pursue further in compressive imaging for real applications.
","Yang Liu, Xin Yuan, Jinli Suo, David J. Brady, Qionghai Dai",Qionghai Dai,2018-07-20T13:44:37Z
"Hyperspectral Images Classification Using Energy Profiles of Spatial and
  Spectral Features","  This paper proposes a spatial feature extraction method based on energy of
the features for classification of the hyperspectral data. A proposed
orthogonal filter set extracts spatial features with maximum energy from the
principal components and then, a profile is constructed based on these
features. The important characteristic of the proposed approach is that the
filter sets coefficients are extracted from statistical properties of data,
thus they are more consistent with the type and texture of the remotely sensed
images compared with those of other filters such as Gabor. To assess the
performance of the proposed feature extraction method, the extracted features
are fed into a support vector machine (SVM) classifier. Experiments on the
widely used hyperspectral images namely, Indian Pines, and Salinas data sets
reveal that the proposed approach improves the classification results in
comparison with some recent spectral spatial classification methods.
",Hamid Reza Shahdoosti,Hamid Reza Shahdoosti,2018-07-24T07:52:25Z
"A novel statistical metric learning for hyperspectral image
  classification","  In this paper, a novel statistical metric learning is developed for
spectral-spatial classification of the hyperspectral image. First, the standard
variance of the samples of each class in each batch is used to decrease the
intra-class variance within each class. Then, the distances between the means
of different classes are used to penalize the inter-class variance of the
training samples. Finally, the standard variance between the means of different
classes is added as an additional diversity term to repulse different classes
from each other. Experiments have conducted over two real-world hyperspectral
image datasets and the experimental results have shown the effectiveness of the
proposed statistical metric learning.
","Zhiqiang Gong, Ping Zhong, Weidong Hu, Zixuan Xiao, Xuping Yin",Xuping Yin,2019-05-13T15:28:15Z
"Constrained low-tubal-rank tensor recovery for hyperspectral images
  mixed noise removal by bilateral random projections","  In this paper, we propose a novel low-tubal-rank tensor recovery model, which
directly constrains the tubal rank prior for effectively removing the mixed
Gaussian and sparse noise in hyperspectral images. The constraints of
tubal-rank and sparsity can govern the solution of the denoised tensor in the
recovery procedure. To solve the constrained low-tubal-rank model, we develop
an iterative algorithm based on bilateral random projections to efficiently
solve the proposed model. The advantage of random projections is that the
approximation of the low-tubal-rank tensor can be obtained quite accurately in
an inexpensive manner. Experimental examples for hyperspectral image denoising
are presented to demonstrate the effectiveness and efficiency of the proposed
method.
","Hao Zhang, Xi-Le Zhao, Tai-Xiang Jiang, Michael Kwok-Po Ng",Michael Kwok-Po Ng,2019-05-15T04:20:12Z
"Clustered Multitask Nonnegative Matrix Factorization for Spectral
  Unmixing of Hyperspectral Data","  In this paper, the new algorithm based on clustered multitask network is
proposed to solve spectral unmixing problem in hyperspectral imagery. In the
proposed algorithm, the clustered network is employed. Each pixel in the
hyperspectral image considered as a node in this network. The nodes in the
network are clustered using the fuzzy c-means clustering method. Diffusion
least mean square strategy has been used to optimize the proposed cost
function. To evaluate the proposed method, experiments are conducted on
synthetic and real datasets. Simulation results based on spectral angle
distance, abundance angle distance and reconstruction error metrics illustrate
the advantage of the proposed algorithm compared with other methods.
","Sara Khoshsokhan, Roozbeh Rajabi, Hadi Zayyani",Hadi Zayyani,2019-05-16T20:22:37Z
"Fusion of heterogeneous bands and kernels in hyperspectral image
  processing","  Hyperspectral imaging is a powerful technology that is plagued by large
dimensionality. Herein, we explore a way to combat that hindrance via
non-contiguous and contiguous (simpler to realize sensor) band grouping for
dimensionality reduction. Our approach is different in the respect that it is
flexible and it follows a well-studied process of visual clustering in
high-dimensional spaces. Specifically, we extend the improved visual assessment
of cluster tendency and clustering in ordered dissimilarity data unsupervised
clustering algorithms for supervised hyperspectral learning. In addition, we
propose a way to extract diverse features via the use of different proximity
metrics (ways to measure the similarity between bands) and kernel functions.
The discovered features are fused with $l_{\infty}$-norm multiple kernel
learning. Experiments are conducted on two benchmark datasets and our results
are compared to related work. These datasets indicate that contiguous or not is
application specific, but heterogeneous features and kernels usually lead to
performance gain.
","Muhammad Aminul Islam, Derek T. Anderson, John E. Ball, Nicolas H. Younan",Nicolas H. Younan,2019-05-22T15:21:36Z
Hyperspectral terahertz microscopy via nonlinear ghost imaging,"  We experimentally demonstrate Time-Resolved Nonlinear Ghost Imaging and its
ability to perform hyperspectral imaging in difficult-to-access wavelength
regions, such as the Terahertz domain. We operate by combining nonlinear
quadratic sparse generation and nonlinear detection in the Fourier plane. We
demonstrate that traditional time-slice approaches are prone to essential
limitations in near-field imaging due to space-time coupling, which is overcome
by our technique. As a proof-of-concept of our implementation, we show that we
can provide experimental access to hyperspectral images completely
unrecoverable through standard fixed-time methods.
","Luana Olivieri, Juan S. Totero Gongora, Luke Peters, Vittorio Cecconi, Antonio Cutrona, Jacob Tunesi, Robyn Tucker, Alessia Pasquazi, Marco Peccianti",Marco Peccianti,2019-10-24T16:01:53Z
Hyperspectral Super-Resolution via Coupled Tensor Ring Factorization,"  Hyperspectral super-resolution (HSR) fuses a low-resolution hyperspectral
image (HSI) and a high-resolution multispectral image (MSI) to obtain a
high-resolution HSI (HR-HSI). In this paper, we propose a new model, named
coupled tensor ring factorization (CTRF), for HSR. The proposed CTRF approach
simultaneously learns high spectral resolution core tensor from the HSI and
high spatial resolution core tensors from the MSI, and reconstructs the HR-HSI
via tensor ring (TR) representation (Figure~\ref{fig:framework}). The CTRF
model can separately exploit the low-rank property of each class (Section
\ref{sec:analysis}), which has been never explored in the previous coupled
tensor model. Meanwhile, it inherits the simple representation of coupled
matrix/CP factorization and flexible low-rank exploration of coupled Tucker
factorization.
  Guided by Theorem~\ref{th:1}, we further propose a spectral nuclear norm
regularization to explore the global spectral low-rank property.
  The experiments have demonstrated the advantage of the proposed nuclear norm
regularized CTRF (NCTRF) as compared to previous matrix/tensor and deep
learning methods.
","Wei He, Yong Chen, Naoto Yokoya, Chao Li, Qibin Zhao",Qibin Zhao,2020-01-06T13:19:59Z
"Spatial-Spectral Residual Network for Hyperspectral Image
  Super-Resolution","  Deep learning-based hyperspectral image super-resolution (SR) methods have
achieved great success recently. However, most existing models can not
effectively explore spatial information and spectral information between bands
simultaneously, obtaining relatively low performance. To address this issue, in
this paper, we propose a novel spectral-spatial residual network for
hyperspectral image super-resolution (SSRNet). Our method can effectively
explore spatial-spectral information by using 3D convolution instead of 2D
convolution, which enables the network to better extract potential information.
Furthermore, we design a spectral-spatial residual module (SSRM) to adaptively
learn more effective features from all the hierarchical features in units
through local feature fusion, significantly improving the performance of the
algorithm. In each unit, we employ spatial and temporal separable 3D
convolution to extract spatial and spectral information, which not only reduces
unaffordable memory usage and high computational cost, but also makes the
network easier to train. Extensive evaluations and comparisons on three
benchmark datasets demonstrate that the proposed approach achieves superior
performance in comparison to existing state-of-the-art methods.
","Qi Wang, Qiang Li, Xuelong Li",Xuelong Li,2020-01-14T03:34:55Z
Hyperspectral Infrared Microscopy With Visible Light,"  Hyperspectral microscopy is an imaging technique that provides spectroscopic
information with high spatial resolution. When applied in the relevant
wavelength region, such as in the infrared (IR), it can reveal a rich spectral
fingerprint across different regions of a sample. Challenges associated with
low efficiency and high cost of IR light sources and detector arrays have
limited its broad adoption. We introduce a new approach to IR hyperspectral
microscopy, where the IR spectral map of the sample is obtained with
off-the-shelf components built for visible light. The technique is based on the
nonlinear interference of correlated photons generated via parametric
down-conversion. We demonstrate chemical mapping of a patterned sample, in
which different areas have distinctive IR spectroscopic fingerprints. The
technique provides a wide field of view, fast readout, and negligible heat
delivered to the sample, which makes it highly relevant to material and
biological applications.
","Anna V. Paterova, Sivakumar M. Maniam, Hongzhi Yang, Gianluca Grenci, Leonid A. Krivitsky",Leonid A. Krivitsky,2020-02-14T10:29:32Z
Hyperspectral imaging for dynamic thin film interferometry,"  Dynamic thin film interferometry is a technique used to non-invasively
characterize the thickness of thin liquid films. Recovering the underlying
thickness from the captured interferograms, unconditionally and automatically
is still an open problem. Here we report a compact setup employing a snapshot
hyperspectral camera and the related algorithms for the automated determination
of thickness profiles of dynamic thin liquid films. The proposed technique is
shown to recover film thickness profiles to within 100 nm of accuracy as
compared to those profiles reconstructed through the manual color matching
process. Subsequently, we discuss the characteristics and advantages of
hyperspectral interferometry including the increased robustness against
imagining noise as well as the ability to perform thickness reconstruction
without considering the absolute light intensity information.
","Vineeth Chandran Suja, John Sentmanat, Gregory Hofmann, Charles Scales, Gerald G Fuller",Gerald G Fuller,2020-05-10T02:23:06Z
"Unsupervised Segmentation of Hyperspectral Remote Sensing Images with
  Superpixels","  In this paper, we propose an unsupervised method for hyperspectral remote
sensing image segmentation. The method exploits the mean-shift clustering
algorithm that takes as input a preliminary hyperspectral superpixels
segmentation together with the spectral pixel information. The proposed method
does not require the number of segmentation classes as input parameter, and it
does not exploit any a-priori knowledge about the type of land-cover or
land-use to be segmented (e.g. water, vegetation, building etc.). Experiments
on Salinas, SalinasA, Pavia Center and Pavia University datasets are carried
out. Performance are measured in terms of normalized mutual information,
adjusted Rand index and F1-score. Results demonstrate the validity of the
proposed method in comparison with the state of the art.
","Mirko Paolo Barbato, Paolo Napoletano, Flavio Piccoli, Raimondo Schettini",Raimondo Schettini,2022-04-26T13:20:33Z
"A Method for Finding Structured Sparse Solutions to Non-negative Least
  Squares Problems with Applications","  Demixing problems in many areas such as hyperspectral imaging and
differential optical absorption spectroscopy (DOAS) often require finding
sparse nonnegative linear combinations of dictionary elements that match
observed data. We show how aspects of these problems, such as misalignment of
DOAS references and uncertainty in hyperspectral endmembers, can be modeled by
expanding the dictionary with grouped elements and imposing a structured
sparsity assumption that the combinations within each group should be sparse or
even 1-sparse. If the dictionary is highly coherent, it is difficult to obtain
good solutions using convex or greedy methods, such as non-negative least
squares (NNLS) or orthogonal matching pursuit. We use penalties related to the
Hoyer measure, which is the ratio of the $l_1$ and $l_2$ norms, as sparsity
penalties to be added to the objective in NNLS-type models. For solving the
resulting nonconvex models, we propose a scaled gradient projection algorithm
that requires solving a sequence of strongly convex quadratic programs. We
discuss its close connections to convex splitting methods and difference of
convex programming. We also present promising numerical results for example
DOAS analysis and hyperspectral demixing problems.
","Ernie Esser, Yifei Lou, Jack Xin",Jack Xin,2013-01-03T10:09:41Z
"Adversarial Networks for Spatial Context-Aware Spectral Image
  Reconstruction from RGB","  Hyperspectral signal reconstruction aims at recovering the original spectral
input that produced a certain trichromatic (RGB) response from a capturing
device or observer. Given the heavily underconstrained, non-linear nature of
the problem, traditional techniques leverage different statistical properties
of the spectral signal in order to build informative priors from real world
object reflectances for constructing such RGB to spectral signal mapping.
However, most of them treat each sample independently, and thus do not benefit
from the contextual information that the spatial dimensions can provide. We
pose hyperspectral natural image reconstruction as an image to image mapping
learning problem, and apply a conditional generative adversarial framework to
help capture spatial semantics. This is the first time Convolutional Neural
Networks -and, particularly, Generative Adversarial Networks- are used to solve
this task. Quantitative evaluation shows a Root Mean Squared Error (RMSE) drop
of 33.2% and a Relative RMSE drop of 54.0% on the ICVL natural hyperspectral
image dataset.
","Aitor Alvarez-Gila, Joost van de Weijer, Estibaliz Garrote",Estibaliz Garrote,2017-09-01T12:00:51Z
Deep Spectral Convolution Network for HyperSpectral Unmixing,"  In this paper, we propose a novel hyperspectral unmixing technique based on
deep spectral convolution networks (DSCN). Particularly, three important
contributions are presented throughout this paper. First, fully-connected
linear operation is replaced with spectral convolutions to extract local
spectral characteristics from hyperspectral signatures with a deeper network
architecture. Second, instead of batch normalization, we propose a spectral
normalization layer which improves the selectivity of filters by normalizing
their spectral responses. Third, we introduce two fusion configurations that
produce ideal abundance maps by using the abstract representations computed
from previous layers. In experiments, we use two real datasets to evaluate the
performance of our method with other baseline techniques. The experimental
results validate that the proposed method outperforms baselines based on Root
Mean Square Error (RMSE).
","Savas Ozkan, Gozde Bozdagi Akar",Gozde Bozdagi Akar,2018-06-22T09:02:43Z
"Ground Truth Simulation for Deep Learning Classification of
  Mid-Resolution Venus Images Via Unmixing of High-Resolution Hyperspectral
  Fenix Data","  Training a deep neural network for classification constitutes a major problem
in remote sensing due to the lack of adequate field data. Acquiring
high-resolution ground truth (GT) by human interpretation is both
cost-ineffective and inconsistent. We propose, instead, to utilize
high-resolution, hyperspectral images for solving this problem, by unmixing
these images to obtain reliable GT for training a deep network. Specifically,
we simulate GT from high-resolution, hyperspectral FENIX images, and use it for
training a convolutional neural network (CNN) for pixel-based classification.
We show how the model can be transferred successfully to classify new
mid-resolution VENuS imagery.
","Ido Faran, Nathan S. Netanyahu, Eli David, Maxim Shoshany, Fadi Kizel, Jisung Geba Chang, Ronit Rud",Ronit Rud,2019-11-24T01:31:35Z
"Learning Endmember Dynamics in Multitemporal Hyperspectral Data Using a
  State-Space Model Formulation","  Hyperspectral image unmixing is an inverse problem aiming at recovering the
spectral signatures of pure materials of interest (called endmembers) and
estimating their proportions (called abundances) in every pixel of the image.
However, in spite of a tremendous applicative potential and the avent of new
satellite sensors with high temporal resolution, multitemporal hyperspectral
unmixing is still a relatively underexplored research avenue in the community,
compared to standard image unmixing. In this paper, we propose a new framework
for multitemporal unmixing and endmember extraction based on a state-space
model, and present a proof of concept on simulated data to show how this
representation can be used to inform multitemporal unmixing with external prior
knowledge, or on the contrary to learn the dynamics of the quantities involved
from data using neural network architectures adapted to the identification of
dynamical systems.
","Lucas Drumetz, Mauro Dalla Mura, Guillaume Tochon, Ronan Fablet",Ronan Fablet,2019-11-27T08:38:07Z
"Semi-supervised Hyperspectral Image Classification with Graph Clustering
  Convolutional Networks","  Hyperspectral image classification (HIC) is an important but challenging
task, and a problem that limits the algorithmic development in this field is
that the ground truths of hyperspectral images (HSIs) are extremely hard to
obtain. Recently a handful of HIC methods are developed based on the graph
convolution networks (GCNs), which effectively relieves the scarcity of labeled
data for deep learning based HIC methods. To further lift the classification
performance, in this work we propose a graph convolution network (GCN) based
framework for HSI classification that uses two clustering operations to better
exploit multi-hop node correlations and also effectively reduce graph size. In
particular, we first cluster the pixels with similar spectral features into a
superpixel and build the graph based on the superpixels of the input HSI. Then
instead of performing convolution over this superpixel graph, we further
partition it into several sub-graphs by pruning the edges with weak weights, so
as to strengthen the correlations of nodes with high similarity. This second
round of clustering also further reduces the graph size, thus reducing the
computation burden of graph convolution. Experimental results on three widely
used benchmark datasets well prove the effectiveness of our proposed framework.
","Hao Zeng, Qingjie Liu, Mingming Zhang, Xiaoqing Han, Yunhong Wang",Yunhong Wang,2020-12-20T14:16:59Z
"Polarized hyperspectral imaging with single fiber bundle via incoherent
  light transmission matrix approach","  The scattering of multispectral incoherent light is a common and unfavorable
signal scrambling in natural scenes. However, the blurred light spot due to
scattering still holds lots of information remaining to be explored. Former
methods failed to recover the polarized hyperspectral information from
scattered incoherent light or relied on additional dispersion elements. Here we
put forward the transmission matrix (TM) approach for extended objects under
incoherent illumination by speculating the unknown TM through experimentally
calibrated or digitally emulated ways. Employing a fiber bundle as a powerful
imaging and dispersion element, we recover the spatial information in 252
polarized-spectral channels from a single speckle, thus achieving single-shot,
high-resolution, broadband hyperspectral imaging for two polarization states
with the cheap, compact, fiber-bundle-only system. Based on the scattering
principle itself, our method not only greatly improves the robustness of the TM
approach to retrieve the input spectral information, but also reveals the
feasibility to explore the polarized spatio-spectral information from blurry
speckles only with the help of simple optical setups.
","Yitong Li, Zhengbo Zhu, Ze Li, Donglin Ma",Donglin Ma,2021-01-11T13:54:01Z
"Using Low-rank Representation of Abundance Maps and Nonnegative Tensor
  Factorization for Hyperspectral Nonlinear Unmixing","  Tensor-based methods have been widely studied to attack inverse problems in
hyperspectral imaging since a hyperspectral image (HSI) cube can be naturally
represented as a third-order tensor, which can perfectly retain the spatial
information in the image. In this article, we extend the linear tensor method
to the nonlinear tensor method and propose a nonlinear low-rank tensor unmixing
algorithm to solve the generalized bilinear model (GBM). Specifically, the
linear and nonlinear parts of the GBM can both be expressed as tensors.
Furthermore, the low-rank structures of abundance maps and nonlinear
interaction abundance maps are exploited by minimizing their nuclear norm, thus
taking full advantage of the high spatial correlation in HSIs. Synthetic and
real-data experiments show that the low rank of abundance maps and nonlinear
interaction abundance maps exploited in our method can improve the performance
of the nonlinear unmixing. A MATLAB demo of this work will be available at
https://github.com/LinaZhuang for the sake of reproducibility.
","Lianru Gao, Zhicheng Wang, Lina Zhuang, Haoyang Yu, Bing Zhang, Jocelyn Chanussot",Jocelyn Chanussot,2021-03-30T09:37:25Z
"Self-Regression Learning for Blind Hyperspectral Image Fusion Without
  Label","  Hyperspectral image fusion (HIF) is critical to a wide range of applications
in remote sensing and many computer vision applications. Most traditional HIF
methods assume that the observation model is predefined or known. However, in
real applications, the observation model involved are often complicated and
unknown, which leads to the serious performance drop of many advanced HIF
methods. Also, deep learning methods can achieve outstanding performance, but
they generally require a large number of image pairs for model training, which
are difficult to obtain in realistic scenarios. Towards these issues, we
proposed a self-regression learning method that alternatively reconstructs
hyperspectral image (HSI) and estimate the observation model. In particular, we
adopt an invertible neural network (INN) for restoring the HSI, and two
fully-connected network (FCN) for estimating the observation model. Moreover,
\emph{SoftMax} nonlinearity is applied to the FCN for satisfying the
non-negative, sparsity and equality constraints. Besides, we proposed a local
consistency loss function to constrain the observation model by exploring
domain specific knowledge. Finally, we proposed an angular loss function to
improve spectral reconstruction accuracy. Extensive experiments on both
synthetic and real-world dataset show that our model can outperform the
state-of-the-art methods
","Wu Wang, Yue Huang, Xinhao Ding",Xinhao Ding,2021-03-31T04:48:21Z
Hyperspectral Absorption Microscopy Using Photoacoustic Remote Sensing,"  An improved method of remote optical absorption spectroscopy and
hyperspectral optical absorption imaging is described which takes advantage of
the photoacoustic remote sensing detection architecture. A wide range of
photoacoustic excitation wavelengths ranging from 210 nm to 1550 nm was
provided by a nanosecond tunable source allowing access to various salient
endogenous chromophores such as DNA, hemeproteins, and lipids. Sensitivity of
the device was demonstrated by characterizing the infrared absorption spectrum
of water. Meanwhile, the efficacy of the technique was explored by recovering
cell nuclei and oxygen saturation from a live chicken embryo model and by
recovering adipocytes from freshly resected murine adipose tissue. This
represents a continued investigation into the characteristics of the
hyperspectral photoacoustic remote sensing technique which may represent an
effective means of non-destructive endogenous contrast characterization and
visualization.
","Kevan Bell, Lyazzat Mukhangaliyeva, Layla Khalili, Parsin Haji Reza",Parsin Haji Reza,2021-02-26T15:07:26Z
Spatial-Spectral Clustering with Anchor Graph for Hyperspectral Image,"  Hyperspectral image (HSI) clustering, which aims at dividing hyperspectral
pixels into clusters, has drawn significant attention in practical
applications. Recently, many graph-based clustering methods, which construct an
adjacent graph to model the data relationship, have shown dominant performance.
However, the high dimensionality of HSI data makes it hard to construct the
pairwise adjacent graph. Besides, abundant spatial structures are often
overlooked during the clustering procedure. In order to better handle the high
dimensionality problem and preserve the spatial structures, this paper proposes
a novel unsupervised approach called spatial-spectral clustering with anchor
graph (SSCAG) for HSI data clustering. The SSCAG has the following
contributions: 1) the anchor graph-based strategy is used to construct a
tractable large graph for HSI data, which effectively exploits all data points
and reduces the computational complexity; 2) a new similarity metric is
presented to embed the spatial-spectral information into the combined adjacent
graph, which can mine the intrinsic property structure of HSI data; 3) an
effective neighbors assignment strategy is adopted in the optimization, which
performs the singular value decomposition (SVD) on the adjacent graph to get
solutions efficiently. Extensive experiments on three public HSI datasets show
that the proposed SSCAG is competitive against the state-of-the-art approaches.
","Qi Wang, Yanling Miao, Mulin Chen, Xuelong Li",Xuelong Li,2021-04-24T08:09:27Z
"3D/2D regularized CNN feature hierarchy for Hyperspectral image
  classification","  Convolutional Neural Networks (CNN) have been rigorously studied for
Hyperspectral Image Classification (HSIC) and are known to be effective in
exploiting joint spatial-spectral information with the expense of lower
generalization performance and learning speed due to the hard labels and
non-uniform distribution over labels. Several regularization techniques have
been used to overcome the aforesaid issues. However, sometimes models learn to
predict the samples extremely confidently which is not good from a
generalization point of view. Therefore, this paper proposed an idea to enhance
the generalization performance of a hybrid CNN for HSIC using soft labels that
are a weighted average of the hard labels and uniform distribution over ground
labels. The proposed method helps to prevent CNN from becoming over-confident.
We empirically show that in improving generalization performance, label
smoothing also improves model calibration which significantly improves
beam-search. Several publicly available Hyperspectral datasets are used to
validate the experimental evaluation which reveals improved generalization
performance, statistical significance, and computational complexity as compared
to the state-of-the-art models. The code will be made available at
https://github.com/mahmad00.
","Muhammad Ahmad, Manuel Mazzara, Salvatore Distefano",Salvatore Distefano,2021-04-25T11:26:56Z
"The Application of Convolutional Neural Networks for Tomographic
  Reconstruction of Hyperspectral Images","  A novel method, utilizing convolutional neural networks (CNNs), is proposed
to reconstruct hyperspectral cubes from computed tomography imaging
spectrometer (CTIS) images. Current reconstruction algorithms are usually
subject to long reconstruction times and mediocre precision in cases of a large
number of spectral channels. The constructed CNNs deliver higher precision and
shorter reconstruction time than a sparse expectation maximization algorithm.
In addition, the network can handle two different types of real-world images at
the same time -- specifically ColorChecker and carrot spectral images are
considered. This work paves the way toward real-time reconstruction of
hyperspectral cubes from CTIS images.
","Wei-Chih Huang, Mads Svanborg Peters, Mads Juul Ahlebaek, Mads Toudal Frandsen, René Lynge Eriksen, Bjarke Jørgensen",Bjarke Jørgensen,2021-08-30T18:11:08Z
"Dual camera snapshot hyperspectral imaging system via physics informed
  learning","  We consider using the system's optical imaging process with convolutional
neural networks (CNNs) to solve the snapshot hyperspectral imaging
reconstruction problem, which uses a dual-camera system to capture the
three-dimensional hyperspectral images (HSIs) in a compressed way. Various
methods using CNNs have been developed in recent years to reconstruct HSIs, but
most of the supervised deep learning methods aimed to fit a brute-force mapping
relationship between the captured compressed image and standard HSIs. Thus, the
learned mapping would be invalid when the observation data deviate from the
training data. Especially, we usually don't have ground truth in real-life
scenarios. In this paper, we present a self-supervised dual-camera equipment
with an untrained physics-informed CNNs framework. Extensive simulation and
experimental results show that our method without training can be adapted to a
wide imaging environment with good performance. Furthermore, compared with the
training-based methods, our system can be constantly fine-tuned and
self-improved in real-life scenarios.
","Hui Xie, Zhuang Zhao, Jing Han, Yi Zhang, Lianfa Bai, Jun Lu",Jun Lu,2021-09-06T13:39:54Z
"Unsupervised Change Detection in Hyperspectral Images using Feature
  Fusion Deep Convolutional Autoencoders","  Binary change detection in bi-temporal co-registered hyperspectral images is
a challenging task due to a large number of spectral bands present in the data.
Researchers, therefore, try to handle it by reducing dimensions. The proposed
work aims to build a novel feature extraction system using a feature fusion
deep convolutional autoencoder for detecting changes between a pair of such
bi-temporal co-registered hyperspectral images. The feature fusion considers
features across successive levels and multiple receptive fields and therefore
adds a competitive edge over the existing feature extraction methods. The
change detection technique described is completely unsupervised and is much
more elegant than other supervised or semi-supervised methods which require
some amount of label information. Different methods have been applied to the
extracted features to find the changes in the two images and it is found that
the proposed method clearly outperformed the state of the art methods in
unsupervised change detection for all the datasets.
","Debasrita Chakraborty, Ashish Ghosh",Ashish Ghosh,2021-09-10T16:52:31Z
"Improving Autoencoder Training Performance for Hyperspectral Unmixing
  with Network Reinitialisation","  Neural networks, in particular autoencoders, are one of the most promising
solutions for unmixing hyperspectral data, i.e. reconstructing the spectra of
observed substances (endmembers) and their relative mixing fractions
(abundances), which is needed for effective hyperspectral analysis and
classification. However, as we show in this paper, the training of autoencoders
for unmixing is highly dependent on weights initialisation; some sets of
weights lead to degenerate or low-performance solutions, introducing negative
bias in the expected performance. In this work, we experimentally investigate
autoencoders stability as well as network reinitialisation methods based on
coefficients of neurons' dead activations. We demonstrate that the proposed
techniques have a positive effect on autoencoder training in terms of
reconstruction, abundances and endmembers errors.
","Kamil Książek, Przemysław Głomb, Michał Romaszewski, Michał Cholewa, Bartosz Grabowski, Krisztián Búza",Krisztián Búza,2021-09-28T14:07:24Z
"Spectral unmixing of Raman microscopic images of single human cells
  using Independent Component Analysis","  Application of independent component analysis (ICA) as an unmixing and image
clustering technique for high spatial resolution Raman maps is reported. A
hyperspectral map of a fixed human cell was collected by a Raman micro
spectrometer in a raster pattern on a 0.5um grid. Unlike previously used
unsupervised machine learning techniques such as principal component analysis,
ICA is based on non-Gaussianity and statistical independence of data which is
the case for mixture Raman spectra. Hence, ICA is a great candidate for
assembling pseudo-colour maps from the spectral hypercube of Raman spectra. Our
experimental results revealed that ICA is capable of reconstructing false
colour maps of Raman hyperspectral data of human cells, showing the nuclear
region constituents as well as subcellular organelle in the cytoplasm and
distribution of mitochondria in the perinuclear region. Minimum preprocessing
requirements and label-free nature of the ICA method make it a great unmixed
method for extraction of endmembers in Raman hyperspectral maps of living
cells.
","M. Hamed Mozaffari, Li-Lin Tay",Li-Lin Tay,2021-10-25T18:13:24Z
"Multi-Fake Evolutionary Generative Adversarial Networks for Imbalance
  Hyperspectral Image Classification","  This paper presents a novel multi-fake evolutionary generative adversarial
network(MFEGAN) for handling imbalance hyperspectral image classification. It
is an end-to-end approach in which different generative objective losses are
considered in the generator network to improve the classification performance
of the discriminator network. Thus, the same discriminator network has been
used as a standard classifier by embedding the classifier network on top of the
discriminating function. The effectiveness of the proposed method has been
validated through two hyperspectral spatial-spectral data sets. The same
generative and discriminator architectures have been utilized with two
different GAN objectives for a fair performance comparison with the proposed
method. It is observed from the experimental validations that the proposed
method outperforms the state-of-the-art methods with better classification
performance.
","Tanmoy Dam, Nidhi Swami, Sreenatha G. Anavatti, Hussein A. Abbass",Hussein A. Abbass,2021-11-07T07:29:24Z
"A Trainable Spectral-Spatial Sparse Coding Model for Hyperspectral Image
  Restoration","  Hyperspectral imaging offers new perspectives for diverse applications,
ranging from the monitoring of the environment using airborne or satellite
remote sensing, precision farming, food safety, planetary exploration, or
astrophysics. Unfortunately, the spectral diversity of information comes at the
expense of various sources of degradation, and the lack of accurate
ground-truth ""clean"" hyperspectral signals acquired on the spot makes
restoration tasks challenging. In particular, training deep neural networks for
restoration is difficult, in contrast to traditional RGB imaging problems where
deep models tend to shine. In this paper, we advocate instead for a hybrid
approach based on sparse coding principles that retains the interpretability of
classical techniques encoding domain knowledge with handcrafted image priors,
while allowing to train model parameters end-to-end without massive amounts of
data. We show on various denoising benchmarks that our method is
computationally efficient and significantly outperforms the state of the art.
","Théo Bodrito, Alexandre Zouaoui, Jocelyn Chanussot, Julien Mairal",Julien Mairal,2021-11-18T14:16:04Z
Extending the Unmixing methods to Multispectral Images,"  In the past few decades, there has been intensive research concerning the
Unmixing of hyperspectral images. Some methods such as NMF, VCA, and N-FINDR
have become standards since they show robustness in dealing with the unmixing
of hyperspectral images. However, the research concerning the unmixing of
multispectral images is relatively scarce. Thus, we extend some unmixing
methods to the multispectral images. In this paper, we have created two
simulated multispectral datasets from two hyperspectral datasets whose ground
truths are given. Then we apply the unmixing methods (VCA, NMF, N-FINDR) to
these two datasets. By comparing and analyzing the results, we have been able
to demonstrate some interesting results for the utilization of VCA, NMF, and
N-FINDR with multispectral datasets. Besides, this also demonstrates the
possibilities in extending these unmixing methods to the field of multispectral
imaging.
","Jizhen Cai, Hermine Chatoux, Clotilde Boust, Alamin Mansouri",Alamin Mansouri,2021-11-23T14:10:36Z
"Sparse Subspace Clustering Friendly Deep Dictionary Learning for
  Hyperspectral Image Classification","  Subspace clustering techniques have shown promise in hyperspectral image
segmentation. The fundamental assumption in subspace clustering is that the
samples belonging to different clusters/segments lie in separable subspaces.
What if this condition does not hold? We surmise that even if the condition
does not hold in the original space, the data may be nonlinearly transformed to
a space where it will be separable into subspaces. In this work, we propose a
transformation based on the tenets of deep dictionary learning (DDL). In
particular, we incorporate the sparse subspace clustering (SSC) loss in the DDL
formulation. Here DDL nonlinearly transforms the data such that the transformed
representation (of the data) is separable into subspaces. We show that the
proposed formulation improves over the state-of-the-art deep learning
techniques in hyperspectral image clustering.
","Anurag Goel, Angshul Majumdar",Angshul Majumdar,2021-11-27T15:23:58Z
"Hyperspectral Image Segmentation based on Graph Processing over
  Multilayer Networks","  Hyperspectral imaging is an important sensing technology with broad
applications and impact in areas including environmental science, weather, and
geo/space exploration. One important task of hyperspectral image (HSI)
processing is the extraction of spectral-spatial features. Leveraging on the
recent-developed graph signal processing over multilayer networks (M-GSP), this
work proposes several approaches to HSI segmentation based on M-GSP feature
extraction. To capture joint spectral-spatial information, we first customize a
tensor-based multilayer network (MLN) model for HSI, and define a MLN singular
space for feature extraction. We then develop an unsupervised HSI segmentation
method by utilizing MLN spectral clustering. Regrouping HSI pixels via
MLN-based clustering, we further propose a semi-supervised HSI classification
based on multi-resolution fusions of superpixels. Our experimental results
demonstrate the strength of M-GSP in HSI processing and spectral-spatial
information extraction.
","Songyang Zhang, Qinwen Deng, Zhi Ding",Zhi Ding,2021-11-29T23:28:18Z
"Unsupervised Sparse Unmixing of Atmospheric Trace Gases from
  Hyperspectral Satellite Data","  In this letter, a new approach for the retrieval of the vertical column
concentrations of trace gases from hyperspectral satellite observations, is
proposed. The main idea is to perform a linear spectral unmixing by estimating
the abundances of trace gases spectral signatures in each mixed pixel collected
by an imaging spectrometer in the ultraviolet region. To this aim, the sparse
nature of the measurements is brought to light and the compressive sensing
paradigm is applied to estimate the concentrations of the gases' endemembers
given by an a priori wide spectral library, including reference cross sections
measured at different temperatures and pressures at the same time. The proposed
approach has been experimentally assessed using both simulated and real
hyperspectral dataset. Specifically, the experimental analysis relies on the
retrieval of sulfur dioxide during volcanic emissions using data collected by
the TROPOspheric Monitoring Instrument. To validate the procedure, we also
compare the obtained results with the sulfur dioxide total column product based
on the differential optical absorption spectroscopy technique and the retrieved
concentrations estimated using the blind source separation.
","Nicomino Fiscante, Pia Addabbo, Filippo Biondi, Gaetano Giunta, Danilo Orlando",Danilo Orlando,2022-01-14T17:43:30Z
"Hyperspectral Image Super-resolution with Deep Priors and Degradation
  Model Inversion","  To overcome inherent hardware limitations of hyperspectral imaging systems
with respect to their spatial resolution, fusion-based hyperspectral image
(HSI) super-resolution is attracting increasing attention. This technique aims
to fuse a low-resolution (LR) HSI and a conventional high-resolution (HR) RGB
image in order to obtain an HR HSI. Recently, deep learning architectures have
been used to address the HSI super-resolution problem and have achieved
remarkable performance. However, they ignore the degradation model even though
this model has a clear physical interpretation and may contribute to improve
the performance. We address this problem by proposing a method that, on the one
hand, makes use of the linear degradation model in the data-fidelity term of
the objective function and, on the other hand, utilizes the output of a
convolutional neural network for designing a deep prior regularizer in spectral
and spatial gradient domains. Experiments show the performance improvement
achieved with this strategy.
","Xiuheng Wang, Jie Chen, Cédric Richard",Cédric Richard,2022-01-24T18:17:40Z
"Faster hyperspectral image classification based on selective kernel
  mechanism using deep convolutional networks","  Hyperspectral imagery is rich in spatial and spectral information. Using
3D-CNN can simultaneously acquire features of spatial and spectral dimensions
to facilitate classification of features, but hyperspectral image information
spectral dimensional information redundancy. The use of continuous 3D-CNN will
result in a high amount of parameters, and the computational power requirements
of the device are high, and the training takes too long. This letter designed
the Faster selective kernel mechanism network (FSKNet), FSKNet can balance this
problem. It designs 3D-CNN and 2D-CNN conversion modules, using 3D-CNN to
complete feature extraction while reducing the dimensionality of spatial and
spectrum. However, such a model is not lightweight enough. In the converted
2D-CNN, a selective kernel mechanism is proposed, which allows each neuron to
adjust the receptive field size based on the two-way input information scale.
Under the Selective kernel mechanism, it mainly includes two components, se
module and variable convolution. Se acquires channel dimensional attention and
variable convolution to obtain spatial dimension deformation information of
ground objects. The model is more accurate, faster, and less computationally
intensive. FSKNet achieves high accuracy on the IN, UP, Salinas, and Botswana
data sets with very small parameters.
","Guandong Li, Chunju Zhang",Chunju Zhang,2022-02-14T02:14:50Z
"A spectral-spatial fusion anomaly detection method for hyperspectral
  imagery","  In hyperspectral, high-quality spectral signals convey subtle spectral
differences to distinguish similar materials, thereby providing unique
advantage for anomaly detection. Hence fine spectra of anomalous pixels can be
effectively screened out from heterogeneous background pixels. Since the same
materials have similar characteristics in spatial and spectral dimension,
detection performance can be significantly enhanced by jointing spatial and
spectral information. In this paper, a spectralspatial fusion anomaly detection
(SSFAD) method is proposed for hyperspectral imagery. First, original spectral
signals are mapped to a local linear background space composed of median and
mean with high confidence, where saliency weight and feature enhancement
strategies are implemented to obtain an initial detection map in spectral
domain. Futhermore, to make full use of similarity information of local
background around testing pixel, a new detector is designed to extract the
local similarity spatial features of patch images in spatial domain. Finally,
anomalies are detected by adaptively combining the spectral and spatial
detection maps. The experimental results demonstrate that our proposed method
has superior detection performance than traditional methods.
","Zengfu Hou, Siyuan Cheng, Ting Hu",Ting Hu,2022-02-24T03:54:48Z
"Evaluation of Dirichlet Process Gaussian Mixtures for Segmentation on
  Noisy Hyperspectral Images","  Image segmentation is a fundamental step for the interpretation of Remote
Sensing Images. Clustering or segmentation methods usually precede the
classification task and are used as support tools for manual labeling. The most
common algorithms, such as k-means, mean-shift, and MRS, require an extra
manual step to find the scale parameter. The segmentation results are severely
affected if the parameters are not correctly tuned and diverge from the optimal
values. Additionally, the search for the optimal scale is a costly task, as it
requires a comprehensive hyper-parameter search. This paper proposes and
evaluates a method for segmentation of Hyperspectral Images using the Dirichlet
Process Gaussian Mixture Model. Our model can self-regulate the parameters
until it finds the optimal values of scale and the number of clusters in a
given dataset. The results demonstrate the potential of our method to find
objects in a Hyperspectral Image while bypassing the burden of manual search of
the optimal parameters. In addition, our model also produces similar results on
noisy datasets, while previous research usually required a pre-processing task
for noise reduction and spectral smoothing.
","Kiran Mantripragada, Faisal Z. Qureshi",Faisal Z. Qureshi,2022-03-05T21:44:52Z
"Picosecond Hyperspectral Fringe Pattern Projection for 3D Surface
  Measurement","  Active stereovision systems for the 3D measurement of surfaces rely on the
sequential projection of different fringe patterns onto the scene to robustly
and accurately generate 3D surface data. This limits the temporal resolution to
the time by which a sufficiently high number of patterns can be projected and
recorded. By encoding patterns spectrally and recording them with a
hyperspectral imager, it is possible to record several patterns in a single
image, limiting the temporal resolution to only the duration of the
illumination. A picosecond 3D surface measurement was demonstrated using a high
pulse energy femtosecond Ti:Sa laser, spectrally broadened in a hollow core
fiber, and two hyperspectral cameras recording the patterns generated by
diffraction at an Echelle grating.
","Sebastian Ritter, Meritxell Cabrejo Ponce, Nils C. Geib, Sabine Häussler, Stefan Heist, Falk Eilenberger",Falk Eilenberger,2022-03-18T15:15:50Z
"Classification of Hyperspectral Images Using SVM with Shape-adaptive
  Reconstruction and Smoothed Total Variation","  In this work, a novel algorithm called SVM with Shape-adaptive Reconstruction
and Smoothed Total Variation (SaR-SVM-STV) is introduced to classify
hyperspectral images, which makes full use of spatial and spectral information.
The Shape-adaptive Reconstruction (SaR) is introduced to preprocess each pixel
based on the Pearson Correlation between pixels in its shape-adaptive (SA)
region. Support Vector Machines (SVMs) are trained to estimate the pixel-wise
probability maps of each class. Then the Smoothed Total Variation (STV) model
is applied to denoise and generate the final classification map. Experiments
show that SaR-SVM-STV outperforms the SVM-STV method with a few training
labels, demonstrating the significance of reconstructing hyperspectral images
before classification.
","Ruoning Li, Kangning Cui, Raymond H. Chan, Robert J. Plemmons",Robert J. Plemmons,2022-03-29T14:39:21Z
"Integration of Physics-Based and Data-Driven Models for Hyperspectral
  Image Unmixing","  Spectral unmixing is one of the most important quantitative analysis tasks in
hyperspectral data processing. Conventional physics-based models are
characterized by clear interpretation. However they may not be suitable for
analyzing scenes with unknown complex physical characteristics. Data-driven
methods have developed rapidly in recent years, in particular deep learning
methods because they possess superior capability in modeling complex and
nonlinear systems. Simply transferring these methods as black-boxes to conduct
unmixing may lead to low physical interpretability and generalization ability.
This article reviews hyperspectral unmixing works that integrate advantages of
both physics-based models and data-driven methods by means of deep neural
network structures design, prior design and loss design. Most of these methods
derive from a common mathematical optimization framework, and combine good
interpretability with high accuracy.
","Jie Chen, Min Zhao, Xiuheng Wang, Cédric Richard, Susanto Rahardja",Susanto Rahardja,2022-06-11T12:02:31Z
"Masked Spatial-Spectral Autoencoders Are Excellent Hyperspectral
  Defenders","  Deep learning methodology contributes a lot to the development of
hyperspectral image (HSI) analysis community. However, it also makes HSI
analysis systems vulnerable to adversarial attacks. To this end, we propose a
masked spatial-spectral autoencoder (MSSA) in this paper under self-supervised
learning theory, for enhancing the robustness of HSI analysis systems. First, a
masked sequence attention learning module is conducted to promote the inherent
robustness of HSI analysis systems along spectral channel. Then, we develop a
graph convolutional network with learnable graph structure to establish global
pixel-wise combinations.In this way, the attack effect would be dispersed by
all the related pixels among each combination, and a better defense performance
is achievable in spatial aspect.Finally, to improve the defense transferability
and address the problem of limited labelled samples, MSSA employs spectra
reconstruction as a pretext task and fits the datasets in a self-supervised
manner.Comprehensive experiments over three benchmarks verify the effectiveness
of MSSA in comparison with the state-of-the-art hyperspectral classification
methods and representative adversarial defense strategies.
","Jiahao Qi, Zhiqiang Gong, Xingyue Liu, Kangcheng Bin, Chen Chen, Yongqian Li, Wei Xue, Yu Zhang, Ping Zhong",Ping Zhong,2022-07-16T01:33:13Z
A Dynamical Systems Algorithm for Clustering in Hyperspectral Imagery,"  In this paper we present a new dynamical systems algorithm for clustering in
hyperspectral images. The main idea of the algorithm is that data points are
\`pushed\' in the direction of increasing density and groups of pixels that end
up in the same dense regions belong to the same class. This is essentially a
numerical solution of the differential equation defined by the gradient of the
density of data points on the data manifold. The number of classes is automated
and the resulting clustering can be extremely accurate. In addition to
providing a accurate clustering, this algorithm presents a new tool for
understanding hyperspectral data in high dimensions. We evaluate the algorithm
on the Urban (Available at www.tec.ary.mil/Hypercube/) scene comparing
performance against the k-means algorithm using pre-identified classes of
materials as ground truth.
","William F. Basener, Alexey Castrodad, David Messinger, Jennifer Mahle, Paul Prue",Paul Prue,2022-07-21T17:31:57Z
A Multibranch Convolutional Neural Network for Hyperspectral Unmixing,"  Hyperspectral unmixing remains one of the most challenging tasks in the
analysis of such data. Deep learning has been blooming in the field and proved
to outperform other classic unmixing techniques, and can be effectively
deployed onboard Earth observation satellites equipped with hyperspectral
imagers. In this letter, we follow this research pathway and propose a
multi-branch convolutional neural network that benefits from fusing spectral,
spatial, and spectral-spatial features in the unmixing process. The results of
our experiments, backed up with the ablation study, revealed that our
techniques outperform others from the literature and lead to higher-quality
fractional abundance estimation. Also, we investigated the influence of
reducing the training sets on the capabilities of all algorithms and their
robustness against noise, as capturing large and representative ground-truth
sets is time-consuming and costly in practice, especially in emerging Earth
observation scenarios.
","Lukasz Tulczyjew, Michal Kawulok, Nicolas Longépé, Bertrand Le Saux, Jakub Nalepa",Jakub Nalepa,2022-08-03T21:59:03Z
"Deep Hyperspectral and Multispectral Image Fusion with Inter-image
  Variability","  Hyperspectral and multispectral image fusion allows us to overcome the
hardware limitations of hyperspectral imaging systems inherent to their lower
spatial resolution. Nevertheless, existing algorithms usually fail to consider
realistic image acquisition conditions. This paper presents a general imaging
model that considers inter-image variability of data from heterogeneous sources
and flexible image priors. The fusion problem is stated as an optimization
problem in the maximum a posteriori framework. We introduce an original image
fusion method that, on the one hand, solves the optimization problem accounting
for inter-image variability with an iteratively reweighted scheme and, on the
other hand, that leverages light-weight CNN-based networks to learn realistic
image priors from data. In addition, we propose a zero-shot strategy to
directly learn the image-specific prior of the latent images in an unsupervised
manner. The performance of the algorithm is illustrated with real data subject
to inter-image variability.
","Xiuheng Wang, Ricardo Augusto Borsoi, Cédric Richard, Jie Chen",Jie Chen,2022-08-24T08:53:38Z
"An Algorithm and Heuristic based on Normalized Mutual Information for
  Dimensionality Reduction and Classification of Hyperspectral images","  In the feature classification domain, the choice of data affects widely the
results. The Hyperspectral image (HSI), is a set of more than a hundred
bidirectional measures (called bands), of the same region (called ground truth
map: GT). The HSI is modelized at a set of N vectors. So we have N features (or
attributes) expressing N vectors of measures for C substances (called classes).
The problematic is that it's pratically impossible to investgate all possible
subsets. So we must find K vectors among N, such as relevant and no redundant
ones; in order to classify substances. Here we introduce an algorithm based on
Normalized Mutual Information to select relevant and no redundant bands,
necessary to increase classification accuracy of HSI.
  Keywords: Feature Selection, Normalized Mutual information, Hyperspectral
images, Classification, Redundancy.
","Elkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine",Driss Aboutajdine,2022-10-22T02:58:04Z
"Band selection and classification of hyperspectral images by minimizing
  normalized mutual information","  Hyperspectral images (HSI) classification is a high technical remote sensing
tool. The main goal is to classify the point of a region. The HIS contains more
than a hundred bidirectional measures, called bands (or simply images), of the
same region called Ground Truth Map (GT). Unfortunately, some bands contain
redundant information, others are affected by the noise, and the high
dimensionalities of features make the accuracy of classification lower. All
these bands can be important for some applications, but for the classification
a small subset of these is relevant. In this paper we use mutual information
(MI) to select the relevant bands; and the Normalized Mutual Information
coefficient to avoid and control redundant ones. This is a feature selection
scheme and a Filter strategy. We establish this study on HSI AVIRIS 92AV3C.
This is effectiveness, and fast scheme to control redundancy. Index Terms:
Hyperspectral images, Classification, Feature Selection, Normalized Mutual
Information, Redundancy.
","E. Sarhrouni, A. Hammouch, D. Aboutajdine",D. Aboutajdine,2022-10-22T04:10:10Z
"A novel filter based on three variables mutual information for
  dimensionality reduction and classification of hyperspectral images","  The high dimensionality of hyperspectral images (HSI) that contains more than
hundred bands (images) for the same region called Ground Truth Map, often
imposes a heavy computational burden for image processing and complicates the
learning process. In fact, the removal of irrelevant, noisy and redundant bands
helps increase the classification accuracy. Band selection filter based on
""Mutual Information"" is a common technique for dimensionality reduction. In
this paper, a categorization of dimensionality reduction methods according to
the evaluation process is presented. Moreover, a new filter approach based on
three variables mutual information is developed in order to measure band
correlation for classification, it considers not only bands relevance but also
bands interaction. The proposed approach is compared to a reproduced filter
algorithm based on mutual information. Experimental results on HSI AVIRIS
92AV3C have shown that the proposed approach is very competitive, effective and
outperforms the reproduced filter strategy performance.
  Keywords - Hyperspectral images, Classification, band Selection, Three
variables Mutual Information, information gain.
","Asma Elmaizi, Elkebir Sarhrouni, Ahmed hammouch, Chafik Nacir",Chafik Nacir,2022-10-26T10:29:00Z
"A new band selection approach based on information theory and support
  vector machine for hyperspectral images reduction and classification","  The high dimensionality of hyperspectral images consisting of several bands
often imposes a big computational challenge for image processing. Therefore,
spectral band selection is an essential step for removing the irrelevant, noisy
and redundant bands. Consequently increasing the classification accuracy.
However, identification of useful bands from hundreds or even thousands of
related bands is a nontrivial task. This paper aims at identifying a small set
of highly discriminative bands, for improving computational speed and
prediction accuracy. Hence, we proposed a new strategy based on joint mutual
information to measure the statistical dependence and correlation between the
selected bands and evaluate the relative utility of each one to classification.
The proposed filter approach is compared to an effective reproduced filters
based on mutual information. Simulations results on the hyperpectral image HSI
AVIRIS 92AV3C using the SVM classifier have shown that the effective proposed
algorithm outperforms the reproduced filters strategy performance.
  Keywords-Hyperspectral images, Classification, band Selection, Joint Mutual
Information, dimensionality reduction ,correlation, SVM.
","A. Elmaizi, E. Sarhrouni, A. Hammouch, C. Nacir",C. Nacir,2022-10-26T10:54:23Z
Deep Cost-sensitive Learning for Wheat Frost Detection,"  Frost damage is one of the main factors leading to wheat yield reduction.
Therefore, the detection of wheat frost accurately and efficiently is
beneficial for growers to take corresponding measures in time to reduce
economic loss. To detect the wheat frost, in this paper we create a
hyperspectral wheat frost data set by collecting the data characterized by
temperature, wheat yield, and hyperspectral information provided by the
handheld hyperspectral spectrometer. However, due to the imbalance of data,
that is, the number of healthy samples is much higher than the number of frost
damage samples, a deep learning algorithm tends to predict biasedly towards the
healthy samples resulting in model overfitting of the healthy samples.
Therefore, we propose a method based on deep cost-sensitive learning, which
uses a one-dimensional convolutional neural network as the basic framework and
incorporates cost-sensitive learning with fixed factors and adjustment factors
into the loss function to train the network. Meanwhile, the accuracy and score
are used as evaluation metrics. Experimental results show that the detection
accuracy and the score reached 0.943 and 0.623 respectively, this demonstration
shows that this method not only ensures the overall accuracy but also
effectively improves the detection rate of frost samples.
","Shujian Cao, Lin Cui, Haipeng Liu",Haipeng Liu,2022-12-25T05:07:24Z
"Real-Time Semantic Segmentation using Hyperspectral Images for Mapping
  Unstructured and Unknown Environments","  Autonomous navigation in unstructured off-road environments is greatly
improved by semantic scene understanding. Conventional image processing
algorithms are difficult to implement and lack robustness due to a lack of
structure and high variability across off-road environments. The use of neural
networks and machine learning can overcome the previous challenges but they
require large labeled data sets for training. In our work we propose the use of
hyperspectral images for real-time pixel-wise semantic classification and
segmentation, without the need of any prior training data. The resulting
segmented image is processed to extract, filter, and approximate objects as
polygons, using a polygon approximation algorithm. The resulting polygons are
then used to generate a semantic map of the environment. Using our framework.
we show the capability to add new semantic classes in run-time for
classification. The proposed methodology is also shown to operate in real-time
and produce outputs at a frequency of 1Hz, using high resolution hyperspectral
images.
","Anthony Medellin, Anant Bhamri, Reza Langari, Swaminathan Gopalswamy",Swaminathan Gopalswamy,2023-03-27T22:33:55Z
"Parameter optimization for low-rank matrix recovery in hyperspectral
  imaging","  An approach to parameter optimization for the low-rank matrix recovery method
in hyperspectral imaging is discussed. We formulate an optimization problem
with respect to the initial parameters of the low-rank matrix recovery method.
The performance for different parameter settings is compared in terms of
computational times and memory. The results are evaluated by computing the peak
signal-to-noise ratio as a quantitative measure. The potential improvement of
the performance of the noise reduction method is discussed when optimizing the
choice of the initial values. The optimization method is tested on standard and
openly available hyperspectral data sets including Indian Pines, Pavia Centre,
and Pavia University.
",Monika Wolfmayr,Monika Wolfmayr,2023-05-16T21:56:55Z
Snapshot hyperspectral imaging of intracellular lasers,"  Intracellular lasers are emerging as powerful biosensors for multiplexed
tracking and precision sensing of cells and their microenvironment. This
sensing capacity is enabled by quantifying their narrow-linewidth emission
spectra, which is presently challenging to do at high speeds. In this work, we
demonstrate rapid snapshot hyperspectral imaging of intracellular lasers. Using
integral field mapping with a microlens array and a diffraction grating, we
obtain images of the spatial and spectral intensity distribution from a single
camera acquisition. We demonstrate widefield hyperspectral imaging over a
3$\times$3 mm$^2$ field of view and volumetric imaging over
250$\times$250$\times$800 $\mu$m$^3$ volumes with a spatial resolution of 5
$\mu$m and a spectral resolution of less than 0.8 nm. We evaluate the
performance and outline the challenges and strengths of snapshot methods in the
context of characterising the emission from intracellular lasers. This method
offers new opportunities for a diverse range of applications, including
high-throughput and long-term biosensing with intracellular lasers.
","Soraya Caixeiro, Philip Wijesinghe, Kishan Dholakia, Malte C. Gather",Malte C. Gather,2023-06-01T18:48:21Z
"Self-supervised Deep Hyperspectral Inpainting with the Sparsity and
  Low-Rank Considerations","  Hyperspectral images are typically composed of hundreds of narrow and
contiguous spectral bands, each containing information about the material
composition of the imaged scene. However, these images can be affected by
various sources of noise, distortions, or data losses, which can significantly
degrade their quality and usefulness. To address these problems, we introduce
two novel self-supervised Hyperspectral Images (HSI) inpainting algorithms: Low
Rank and Sparsity Constraint Plug-and-Play (LRS-PnP), and its extension
LRS-PnP-DIP, which features the strong learning capability, but is still free
of external training data. We conduct the stability analysis under some mild
assumptions which guarantees the algorithm to converge. It is specifically very
helpful for the practical applications. Extensive experiments demonstrate that
the proposed solution is able to produce visually and qualitatively superior
inpainting results, achieving state-of-the-art performance. The code for
reproducing the results is available at
\url{https://github.com/shuoli0708/LRS-PnP-DIP}.
","Shuo Li, Mehrdad Yaghoobi",Mehrdad Yaghoobi,2023-06-13T20:49:02Z
Multi-Scale U-Shape MLP for Hyperspectral Image Classification,"  Hyperspectral images have significant applications in various domains, since
they register numerous semantic and spatial information in the spectral band
with spatial variability of spectral signatures. Two critical challenges in
identifying pixels of the hyperspectral image are respectively representing the
correlated information among the local and global, as well as the abundant
parameters of the model. To tackle this challenge, we propose a Multi-Scale
U-shape Multi-Layer Perceptron (MUMLP) a model consisting of the designed MSC
(Multi-Scale Channel) block and the UMLP (U-shape Multi-Layer Perceptron)
structure. MSC transforms the channel dimension and mixes spectral band feature
to embed the deep-level representation adequately. UMLP is designed by the
encoder-decoder structure with multi-layer perceptron layers, which is capable
of compressing the large-scale parameters. Extensive experiments are conducted
to demonstrate our model can outperform state-of-the-art methods
across-the-board on three wide-adopted public datasets, namely Pavia
University, Houston 2013 and Houston 2018
","Moule Lin, Weipeng Jing, Donglin Di, Guangsheng Chen, Houbing Song",Houbing Song,2023-07-05T08:52:27Z
"A Vision for Cleaner Rivers: Harnessing Snapshot Hyperspectral Imaging
  to Detect Macro-Plastic Litter","  Plastic waste entering the riverine harms local ecosystems leading to
negative ecological and economic impacts. Large parcels of plastic waste are
transported from inland to oceans leading to a global scale problem of floating
debris fields. In this context, efficient and automatized monitoring of
mismanaged plastic waste is paramount. To address this problem, we analyze the
feasibility of macro-plastic litter detection using computational imaging
approaches in river-like scenarios. We enable near-real-time tracking of
partially submerged plastics by using snapshot Visible-Shortwave Infrared
hyperspectral imaging. Our experiments indicate that imaging strategies
associated with machine learning classification approaches can lead to high
detection accuracy even in challenging scenarios, especially when leveraging
hyperspectral data and nonlinear classifiers. All code, data, and models are
available online:
https://github.com/RIVeR-Lab/hyperspectral_macro_plastic_detection.
","Nathaniel Hanson, Ahmet Demirkaya, Deniz Erdoğmuş, Aron Stubbins, Taşkın Padır, Tales Imbiriba",Tales Imbiriba,2023-07-22T18:59:27Z
"Hyperspectral Benchmark: Bridging the Gap between HSI Applications
  through Comprehensive Dataset and Pretraining","  Hyperspectral Imaging (HSI) serves as a non-destructive spatial spectroscopy
technique with a multitude of potential applications. However, a recurring
challenge lies in the limited size of the target datasets, impeding exhaustive
architecture search. Consequently, when venturing into novel applications,
reliance on established methodologies becomes commonplace, in the hope that
they exhibit favorable generalization characteristics. Regrettably, this
optimism is often unfounded due to the fine-tuned nature of models tailored to
specific HSI contexts.
  To address this predicament, this study introduces an innovative benchmark
dataset encompassing three markedly distinct HSI applications: food inspection,
remote sensing, and recycling. This comprehensive dataset affords a finer
assessment of hyperspectral model capabilities. Moreover, this benchmark
facilitates an incisive examination of prevailing state-of-the-art techniques,
consequently fostering the evolution of superior methodologies.
  Furthermore, the enhanced diversity inherent in the benchmark dataset
underpins the establishment of a pretraining pipeline for HSI. This pretraining
regimen serves to enhance the stability of training processes for larger
models. Additionally, a procedural framework is delineated, offering insights
into the handling of applications afflicted by limited target dataset sizes.
","Hannah Frank, Leon Amadeus Varga, Andreas Zell",Andreas Zell,2023-09-20T08:08:34Z
"Implementation of hyperspectral inversion algorithms on FPGA: Hardware
  comparison using High Level Synthesis","  Hyperspectral imaging is gathering significant attention due to its potential
in various domains such as geology, agriculture, ecology, and surveillance.
However, the associated processing algorithms, which are essential for
enhancing output quality and extracting relevant information, are often
computationally intensive and have to deal with substantial data volumes. Our
focus lies on reconfigurable hardware, particularly recent FPGAs. While FPGA
design can be complex, High Level Synthesis (HLS) workflows have emerged as a
solution, abstracting low-level design intricacies and enhancing productivity.
Despite successful prior efforts using HLS for hyperspectral imaging
acceleration, we lack a comprehensive research to benchmark various algorithms
and architectures within a unified framework. This study aims to quantitatively
evaluate performance across different inversion algorithms and design
architectures, providing insights for optimal trade-offs for specific
applications. We apply this analysis to the case study of spectrum
reconstruction processed from interferometric acquisitions taken by Fourier
transform spectrometers.
","El Mehdi Abdali, Daniele Picone, Mauro Dalla-Mura, Stéphane Mancini",Stéphane Mancini,2023-10-03T09:24:36Z
"C-Silicon-based metasurfaces for aperture-robust spectrometer/imaging
  with angle integration","  Compared with conventional grating-based spectrometers, reconstructive
spectrometers based on spectrally engineered filtering have the advantage of
miniaturization because of the less demand for dispersive optics and free
propagation space. However, available reconstructive spectrometers fail to
balance the performance on operational bandwidth, spectral diversity and
angular stability. In this work, we proposed a compact silicon metasurfaces
based spectrometer/camera. After angle integration, the spectral response of
the system is robust to angle/aperture within a wide working bandwidth from
400nm to 800nm. It is experimentally demonstrated that the proposed method
could maintain the spectral consistency from F/1.8 to F/4 (The corresponding
angle of incident light ranges from 7{\deg} to 16{\deg}) and the incident
hyperspectral signal could be accurately reconstructed with a fidelity
exceeding 99%. Additionally, a spectral imaging system with 400x400 pixels is
also established in this work. The accurate reconstructed hyperspectral image
indicates that the proposed aperture-robust spectrometer has the potential to
be extended as a high-resolution broadband hyperspectral camera.
","Weizhu Xu, Qingbin Fan, Peicheng Lin, Jiarong Wang, Hao Hu, Tao Yue, Xuemei Hu, Ting Xu",Ting Xu,2023-10-31T09:00:39Z
"Attention based Dual-Branch Complex Feature Fusion Network for
  Hyperspectral Image Classification","  This research work presents a novel dual-branch model for hyperspectral image
classification that combines two streams: one for processing standard
hyperspectral patches using Real-Valued Neural Network (RVNN) and the other for
processing their corresponding Fourier transforms using Complex-Valued Neural
Network (CVNN). The proposed model is evaluated on the Pavia University and
Salinas datasets. Results show that the proposed model outperforms
state-of-the-art methods in terms of overall accuracy, average accuracy, and
Kappa. Through the incorporation of Fourier transforms in the second stream,
the model is able to extract frequency information, which complements the
spatial information extracted by the first stream. The combination of these two
streams improves the overall performance of the model. Furthermore, to enhance
the model performance, the Squeeze and Excitation (SE) mechanism has been
utilized. Experimental evidence show that SE block improves the models overall
accuracy by almost 1\%.
","Mohammed Q. Alkhatib, Mina Al-Saad, Nour Aburaed, M. Sami Zitouni, Hussain Al Ahmad",Hussain Al Ahmad,2023-11-02T22:31:24Z
"SpACNN-LDVAE: Spatial Attention Convolutional Latent Dirichlet
  Variational Autoencoder for Hyperspectral Pixel Unmixing","  The hyperspectral pixel unmixing aims to find the underlying materials
(endmembers) and their proportions (abundances) in pixels of a hyperspectral
image. This work extends the Latent Dirichlet Variational Autoencoder (LDVAE)
pixel unmixing scheme by taking into account local spatial context while
performing pixel unmixing. The proposed method uses an isotropic convolutional
neural network with spatial attention to encode pixels as a dirichlet
distribution over endmembers. We have evaluated our model on Samson, Hydice
Urban, Cuprite, and OnTech-HSI-Syn-21 datasets. Our model also leverages the
transfer learning paradigm for Cuprite Dataset, where we train the model on
synthetic data and evaluate it on the real-world data. The results suggest that
incorporating spatial context improves both endmember extraction and abundance
estimation.
","Soham Chitnis, Kiran Mantripragada, Faisal Z. Qureshi",Faisal Z. Qureshi,2023-11-17T18:45:00Z
"DiffSpectralNet : Unveiling the Potential of Diffusion Models for
  Hyperspectral Image Classification","  Hyperspectral images (HSI) have become popular for analysing remotely sensed
images in multiple domain like agriculture, medical. However, existing models
struggle with complex relationships and characteristics of spectral-spatial
data due to the multi-band nature and data redundancy of hyperspectral data. To
address this limitation, we propose a new network called DiffSpectralNet, which
combines diffusion and transformer techniques. Our approach involves a two-step
process. First, we use an unsupervised learning framework based on the
diffusion model to extract both high-level and low-level spectral-spatial
features. The diffusion method is capable of extracting diverse and meaningful
spectral-spatial features, leading to improvement in HSI classification. Then,
we employ a pretrained denoising U-Net to extract intermediate hierarchical
features for classification. Finally, we use a supervised transformer-based
classifier to perform the HSI classification. Through comprehensive experiments
on HSI datasets, we evaluate the classification performance of DiffSpectralNet.
The results demonstrate that our framework significantly outperforms existing
approaches, achieving state-of-the-art performance.
","Neetu Sigger, Tuan Thanh Nguyen, Gianluca Tozzi, Quoc-Tuan Vien, Sinh Van Nguyen",Sinh Van Nguyen,2023-10-29T15:26:37Z
"Hyperspectral shadow removal with Iterative Logistic Regression and
  latent Parametric Linear Combination of Gaussians","  Shadow detection and removal is a challenging problem in the analysis of
hyperspectral images. Yet, this step is crucial for analyzing data for remote
sensing applications like methane detection. In this work, we develop a shadow
detection and removal method only based on the spectrum of each pixel and the
overall distribution of spectral values. We first introduce Iterative Logistic
Regression (ILR) to learn a spectral basis in which shadows can be linearly
classified. We then model the joint distribution of the mean radiance and the
projection coefficients of the spectra onto the above basis as a parametric
linear combination of Gaussians. We can then extract the maximum likelihood
mixing parameter of the Gaussians to estimate the shadow coverage and to
correct the shadowed spectra. Our correction scheme reduces correction
artefacts at shadow borders. The shadow detection and removal method is applied
to hyperspectral images from MethaneAIR, a precursor to the satellite
MethaneSAT.
","Core Francisco Park, Maya Nasr, Manuel Pérez-Carrasco, Eleanor Walker, Douglas Finkbeiner, Cecilia Garraffo",Cecilia Garraffo,2023-12-24T02:16:05Z
"Autonomous Hyperspectral Characterisation Station: Robotically Assisted
  Characterisation of Polymer Degradation","  This paper addresses the gap between the capabilities and utilisation of
robotics and automation in laboratory settings and builds upon the concept of
Self Driving Labs (SDL). %to significantly impact laboratory operations. We
introduce an innovative approach to the temporal characterisation of materials.
The article discusses the challenges posed by manual methods involving
established laboratory equipment and presents an automated hyperspectral
characterisation station. This station integrates robot-aided hyperspectral
imaging, complex material characterisation modeling, and automated data
analysis, offering a non-destructive and comprehensive approach. This work
explains how the proposed assembly can automatically measure the half-life of
biodegradable polymers with higher throughput and accuracy than manual methods.
The investigation explores the effect of pH, number of average molecular weight
(Mn), end groups, and blends on the degradation rate of polylactic acid (PLA).
The contributions of the paper lie in introducing an adaptable classification
station for novel characterisation methods and presenting an innovative
methodology for polymer degradation rate measurement. The proposed system has
the potential to accelerate the development of high-throughput screening and
characterisation methods in material and chemistry laboratories.
","Shayan Azizi, Ehsan Asadi, Shaun Howard, Benjamin W. Muir, Riley O'Shea, Alireza Bab-Hadiashar",Alireza Bab-Hadiashar,2024-02-19T01:26:22Z
"Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder
  Super-resolution Network","  Existing hyperspectral image (HSI) super-resolution (SR) methods struggle to
effectively capture the complex spectral-spatial relationships and low-level
details, while diffusion models represent a promising generative model known
for their exceptional performance in modeling complex relations and learning
high and low-level visual features. The direct application of diffusion models
to HSI SR is hampered by challenges such as difficulties in model convergence
and protracted inference time. In this work, we introduce a novel
Group-Autoencoder (GAE) framework that synergistically combines with the
diffusion model to construct a highly effective HSI SR model (DMGASR). Our
proposed GAE framework encodes high-dimensional HSI data into low-dimensional
latent space where the diffusion model works, thereby alleviating the
difficulty of training the diffusion model while maintaining band correlation
and considerably reducing inference time. Experimental results on both natural
and remote sensing hyperspectral datasets demonstrate that the proposed method
is superior to other state-of-the-art methods both visually and metrically.
","Zhaoyang Wang, Dongyang Li, Mingyang Zhang, Hao Luo, Maoguo Gong",Maoguo Gong,2024-02-27T07:57:28Z
"Advancing dermatological diagnosis: Development of a hyperspectral
  dermatoscope for enhanced skin imaging","  Clinical dermatology necessitates precision and innovation for efficient
diagnosis and treatment of various skin conditions. This paper introduces the
development of a cutting-edge hyperspectral dermatoscope (the Hyperscope)
tailored for human skin analysis. We detail the requirements to such a device
and the design considerations, from optical configurations to sensor selection,
necessary to capture a wide spectral range with high fidelity. Preliminary
results from 15 individuals and 160 recorded skin images demonstrate the
potential of the Hyperscope in identifying and characterizing various skin
conditions, offering a promising avenue for non-invasive skin evaluation and a
platform for future research in dermatology-related hyperspectral imaging.
","Martin J. Hetz, Carina Nogueira Garcia, Sarah Haggenmüller, Titus J. Brinker",Titus J. Brinker,2024-03-01T15:35:48Z
"Hybrid Convolutional and Attention Network for Hyperspectral Image
  Denoising","  Hyperspectral image (HSI) denoising is critical for the effective analysis
and interpretation of hyperspectral data. However, simultaneously modeling
global and local features is rarely explored to enhance HSI denoising. In this
letter, we propose a hybrid convolution and attention network (HCANet), which
leverages both the strengths of convolution neural networks (CNNs) and
Transformers. To enhance the modeling of both global and local features, we
have devised a convolution and attention fusion module aimed at capturing
long-range dependencies and neighborhood spectral correlations. Furthermore, to
improve multi-scale information aggregation, we design a multi-scale
feed-forward network to enhance denoising performance by extracting features at
different scales. Experimental results on mainstream HSI datasets demonstrate
the rationality and effectiveness of the proposed HCANet. The proposed model is
effective in removing various types of complex noise. Our codes are available
at \url{https://github.com/summitgao/HCANet}.
","Shuai Hu, Feng Gao, Xiaowei Zhou, Junyu Dong, Qian Du",Qian Du,2024-03-15T07:18:43Z
"Transformers Fusion across Disjoint Samples for Hyperspectral Image
  Classification","  3D Swin Transformer (3D-ST) known for its hierarchical attention and
window-based processing, excels in capturing intricate spatial relationships
within images. Spatial-spectral Transformer (SST), meanwhile, specializes in
modeling long-range dependencies through self-attention mechanisms. Therefore,
this paper introduces a novel method: an attentional fusion of these two
transformers to significantly enhance the classification performance of
Hyperspectral Images (HSIs). What sets this approach apart is its emphasis on
the integration of attentional mechanisms from both architectures. This
integration not only refines the modeling of spatial and spectral information
but also contributes to achieving more precise and accurate classification
results. The experimentation and evaluation of benchmark HSI datasets
underscore the importance of employing disjoint training, validation, and test
samples. The results demonstrate the effectiveness of the fusion approach,
showcasing its superiority over traditional methods and individual
transformers. Incorporating disjoint samples enhances the robustness and
reliability of the proposed methodology, emphasizing its potential for
advancing hyperspectral image classification.
","Muhammad Ahmad, Manuel Mazzara, Salvatore Distifano",Salvatore Distifano,2024-05-02T08:49:01Z
Hyperspectral Image Dataset for Individual Penguin Identification,"  Remote individual animal identification is important for food safety, sport,
and animal conservation. Numerous existing remote individual animal
identification studies have focused on RGB images. In this paper, we tackle
individual penguin identification using hyperspectral (HS) images. To the best
of our knowledge, it is the first work to analyze spectral differences between
penguin individuals using an HS camera. We have constructed a novel penguin HS
image dataset, including 990 hyperspectral images of 27 penguins. We
experimentally demonstrate that the spectral information of HS image pixels can
be used for individual penguin identification. The experimental results show
the effectiveness of using HS images for individual penguin identification. The
dataset and source code are available here:
https://033labcodes.github.io/igrass24_penguin/
","Youta Noboru, Yuko Ozasa, Masayuki Tanaka",Masayuki Tanaka,2024-05-23T03:43:13Z
"Hyperspectral and multispectral image fusion with arbitrary resolution
  through self-supervised representations","  The fusion of a low-resolution hyperspectral image (LR-HSI) with a
high-resolution multispectral image (HR-MSI) has emerged as an effective
technique for achieving HSI super-resolution (SR). Previous studies have mainly
concentrated on estimating the posterior distribution of the latent
high-resolution hyperspectral image (HR-HSI), leveraging an appropriate image
prior and likelihood computed from the discrepancy between the latent HSI and
observed images. Low rankness stands out for preserving latent HSI
characteristics through matrix factorization among the various priors. However,
this method only enhances resolution within the dimensions of the two
modalities. To overcome this limitation, we propose a novel continuous low-rank
factorization (CLoRF) by integrating two neural representations into the matrix
factorization, capturing spatial and spectral information, respectively. This
approach enables us to harness both the low rankness from the matrix
factorization and the continuity from neural representation in a
self-supervised manner. Theoretically, we prove the low-rank property and
Lipschitz continuity in the proposed continuous low-rank factorization.
Experimentally, our method significantly surpasses existing techniques and
achieves user-desired resolutions without the need for neural network
retraining.
","Ting Wang, Zipei Yan, Jizhou Li, Xile Zhao, Chao Wang, Michael Ng",Michael Ng,2024-05-28T04:29:23Z
Exploiting Frequency Correlation for Hyperspectral Image Reconstruction,"  Deep priors have emerged as potent methods in hyperspectral image (HSI)
reconstruction. While most methods emphasize space-domain learning using image
space priors like non-local similarity, frequency-domain learning using image
frequency priors remains neglected, limiting the reconstruction capability of
networks. In this paper, we first propose a Hyperspectral Frequency Correlation
(HFC) prior rooted in in-depth statistical frequency analyses of existent HSI
datasets. Leveraging the HFC prior, we subsequently establish the frequency
domain learning composed of a Spectral-wise self-Attention of Frequency (SAF)
and a Spectral-spatial Interaction of Frequency (SIF) targeting low-frequency
and high-frequency components, respectively. The outputs of SAF and SIF are
adaptively merged by a learnable gating filter, thus achieving a thorough
exploitation of image frequency priors. Integrating the frequency domain
learning and the existing space domain learning, we finally develop the
Correlation-driven Mixing Domains Transformer (CMDT) for HSI reconstruction.
Extensive experiments highlight that our method surpasses various
state-of-the-art (SOTA) methods in reconstruction quality and computational
efficiency.
","Muge Yan, Lizhi Wang, Lin Zhu, Hua Huang",Hua Huang,2024-06-02T09:36:37Z
"Non-negative Einstein tensor factorization for unmixing hyperspectral
  images","  In this manuscript, we introduce a tensor-based approach to Non-Negative
Tensor Factorization (NTF). The method entails tensor dimension reduction
through the utilization of the Einstein product. To maintain the regularity and
sparsity of the data, certain constraints are imposed. Additionally, we present
an optimization algorithm in the form of a tensor multiplicative updates
method, which relies on the Einstein product. To guarantee a minimum number of
iterations for the convergence of the proposed algorithm, we employ the Reduced
Rank Extrapolation (RRE) and the Topological Extrapolation Transformation
Algorithm (TEA). The efficacy of the proposed model is demonstrated through
tests conducted on Hyperspectral Images (HI) for denoising, as well as for
Hyperspectral Image Linear Unmixing. Numerical experiments are provided to
substantiate the effectiveness of the proposed model for both synthetic and
real data.
","Anas El Hachimi, Khalide Jbilou, Ahmed Ratnani",Ahmed Ratnani,2024-06-17T12:36:43Z
"Dual-stage Hyperspectral Image Classification Model with Spectral
  Supertoken","  Hyperspectral image classification, a task that assigns pre-defined classes
to each pixel in a hyperspectral image of remote sensing scenes, often faces
challenges due to the neglect of correlations between spectrally similar
pixels. This oversight can lead to inaccurate edge definitions and difficulties
in managing minor spectral variations in contiguous areas. To address these
issues, we introduce the novel Dual-stage Spectral Supertoken Classifier
(DSTC), inspired by superpixel concepts. DSTC employs spectrum-derivative-based
pixel clustering to group pixels with similar spectral characteristics into
spectral supertokens. By projecting the classification of these tokens onto the
image space, we achieve pixel-level results that maintain regional
classification consistency and precise boundary. Moreover, recognizing the
diversity within tokens, we propose a class-proportion-based soft label. This
label adaptively assigns weights to different categories based on their
prevalence, effectively managing data distribution imbalances and enhancing
classification performance. Comprehensive experiments on WHU-OHS, IP, KSC, and
UP datasets corroborate the robust classification capabilities of DSTC and the
effectiveness of its individual components. Code will be publicly available at
https://github.com/laprf/DSTC.
","Peifu Liu, Tingfa Xu, Jie Wang, Huan Chen, Huiyan Bai, Jianan Li",Jianan Li,2024-07-10T01:58:30Z
"HyCoT: Hyperspectral Compression Transformer with an Efficient Training
  Strategy","  The development of learning-based hyperspectral image (HSI) compression
models has recently attracted significant interest. Existing models
predominantly utilize convolutional filters, which capture only local
dependencies. Furthermore, they often incur high training costs and exhibit
substantial computational complexity. To address these limitations, in this
paper we propose Hyperspectral Compression Transformer (HyCoT) that is a
transformer-based autoencoder for pixelwise HSI compression. Additionally, we
introduce an efficient training strategy to accelerate the training process.
Experimental results on the HySpecNet-11k dataset demonstrate that HyCoT
surpasses the state-of-the-art across various compression ratios by over 1 dB
with significantly reduced computational requirements. Our code and pre-trained
weights are publicly available at https://git.tu-berlin.de/rsim/hycot .
","Martin Hermann Paul Fuchs, Behnood Rasti, Begüm Demir",Begüm Demir,2024-08-16T12:27:46Z
Unrolling Plug-and-Play Network for Hyperspectral Unmixing,"  Deep learning based unmixing methods have received great attention in recent
years and achieve remarkable performance. These methods employ a data-driven
approach to extract structure features from hyperspectral image, however, they
tend to be less physical interpretable. Conventional unmixing methods are with
much more interpretability, whereas they require manually designing
regularization and choosing penalty parameters. To overcome these limitations,
we propose a novel unmixing method by unrolling the plug-and-play unmixing
algorithm to conduct the deep architecture. Our method integrates both inner
and outer priors. The carefully designed unfolding deep architecture is used to
learn the spectral and spatial information from the hyperspectral image, which
we refer to as inner priors. Additionally, our approach incorporates deep
denoisers that have been pretrained on a large volume of image data to leverage
the outer priors. Secondly, we design a dynamic convolution to model the
multiscale information. Different scales are fused using an attention module.
Experimental results of both synthetic and real datasets demonstrate that our
method outperforms compared methods.
","Min Zhao, Linruize Tang, Jie Chen",Jie Chen,2024-09-07T05:44:37Z
"HSR-KAN: Efficient Hyperspectral Image Super-Resolution via
  Kolmogorov-Arnold Networks","  Hyperspectral images (HSIs) have great potential in various visual tasks due
to their rich spectral information. However, obtaining high-resolution
hyperspectral images remains challenging due to limitations of physical
imaging. Inspired by Kolmogorov-Arnold Networks (KANs), we propose an efficient
HSI super-resolution (HSI-SR) model to fuse a low-resolution HSI (LR-HSI) and a
high-resolution multispectral image (HR-MSI), yielding a high-resolution HSI
(HR-HSI). To achieve the effective integration of spatial information from
HR-MSI, we design a fusion module based on KANs, called KAN-Fusion. Further
inspired by the channel attention mechanism, we design a spectral channel
attention module called KAN Channel Attention Block (KAN-CAB) for post-fusion
feature extraction. As a channel attention module integrated with KANs, KAN-CAB
not only enhances the fine-grained adjustment ability of deep networks,
enabling networks to accurately simulate details of spectral sequences and
spatial textures, but also effectively avoid Curse of Dimensionality (COD).
Extensive experiments show that, compared to current state-of-the-art (SOTA)
HSI-SR methods, proposed HSR-KAN achieves the best performance in terms of both
qualitative and quantitative assessments. Our code is available at:
https://github.com/Baisonm-Li/HSR-KAN.
","Baisong Li, Xingwang Wang, Haixiao Xu",Haixiao Xu,2024-08-24T02:51:51Z
"AMBER -- Advanced SegFormer for Multi-Band Image Segmentation: an
  application to Hyperspectral Imaging","  Deep learning has revolutionized the field of hyperspectral image (HSI)
analysis, enabling the extraction of complex and hierarchical features. While
convolutional neural networks (CNNs) have been the backbone of HSI
classification, their limitations in capturing global contextual features have
led to the exploration of Vision Transformers (ViTs). This paper introduces
AMBER, an advanced SegFormer specifically designed for multi-band image
segmentation. AMBER enhances the original SegFormer by incorporating
three-dimensional convolutions to handle hyperspectral data. Our experiments,
conducted on the Indian Pines, Pavia University, and PRISMA datasets, show that
AMBER outperforms traditional CNN-based methods in terms of Overall Accuracy,
Kappa coefficient, and Average Accuracy on the first two datasets, and achieves
state-of-the-art performance on the PRISMA dataset.
","Andrea Dosi, Massimo Brescia, Stefano Cavuoti, Mariarca D'Aniello, Michele Delli Veneri, Carlo Donadio, Adriano Ettari, Giuseppe Longo, Alvi Rownok, Luca Sannino, Maria Zampella",Maria Zampella,2024-09-14T09:34:05Z
"Hyperspectral fluorescence imaging using a high-speed silicon
  photomultiplier array","  High-speed multiplex imaging of fluorescent probes is limited by a
combination of spectral resolution, sensitivity, high cost and low light
throughput of detectors, and filters. In this work, we present a hyperspectral
detection system based on a silicon photomultiplier array that enables
high-speed, high-light throughput hyperspectral imaging at low cost. We
demonstrate 16 spectral channel imaging at 50 MP/s (800M spectra per second)
with a conventional two photon microscope combined with a generalized spectral
unmixing model that enables extraction of spectrally overlapping fluorophores.
We show that the high spectral resolution combined with high throughput enables
the multiplexing of multiple contrast agents over large areas and the detection
of subtle spectral shifts associated with molecular binding. Silicon
photomultiplier arrays may be a promising method to extend multiplex
fluorescence imaging in a variety of scenarios.
","Chi Z. Huang, Vincent D. Ching-Roa, Connor M. Heckman, Sherrif F. Ibrahim, Michael G. Giacomelli",Michael G. Giacomelli,2024-10-11T16:01:16Z
"Advancements in Ship Detection: Comparative Analysis of Optical and
  Hyperspectral Sensors","  In marine surveillance, applications span military and civilian domains,
including ship detection, marine traffic control, and disaster management.
Optical and hyperspectral satellites are key for this purpose. This paper
focuses on ship detection and classification techniques, particularly comparing
optical and hyperspectral remote sensing approaches. It presents a
comprehensive analysis of these technologies, covering feature extraction,
methodologies, and their suitability for different missions. The study
highlights the importance of selecting the right sensor aligned with mission
objectives and conditions, aiming to improve detection accuracy through
integrated strategies. The paper examines the strengths and limitations of both
technologies in various maritime applications, enhancing understanding of their
usability in different operational scenarios.
","Alyazia Al Shamsi, Alavikunhu Panthakkan, Saeed Al Mansoori, Hussain Al Ahmad",Hussain Al Ahmad,2024-10-11T19:11:35Z
"Band selection with Higher Order Multivariate Cumulants for small target
  detection in hyperspectral images","  In the small target detection problem a pattern to be located is on the order
of magnitude less numerous than other patterns present in the dataset. This
applies both to the case of supervised detection, where the known template is
expected to match in just a few areas and unsupervised anomaly detection, as
anomalies are rare by definition. This problem is frequently related to the
imaging applications, i.e. detection within the scene acquired by a camera. To
maximize available data about the scene, hyperspectral cameras are used; at
each pixel, they record spectral data in hundreds of narrow bands.
  The typical feature of hyperspectral imaging is that characteristic
properties of target materials are visible in the small number of bands, where
light of certain wavelength interacts with characteristic molecules. A
target-independent band selection method based on statistical principles is a
versatile tool for solving this problem in different practical applications.
  Combination of a regular background and a rare standing out anomaly will
produce a distortion in the joint distribution of hyperspectral pixels. Higher
Order Cumulants Tensors are a natural `window' into this distribution, allowing
to measure properties and suggest candidate bands for removal. While there have
been attempts at producing band selection algorithms based on the 3 rd
cumulant's tensor i.e. the joint skewness, the literature lacks a systematic
analysis of how the order of the cumulant tensor used affects effectiveness of
band selection in detection applications. In this paper we present an analysis
of a general algorithm for band selection based on higher order cumulants. We
discuss its usability related to the observed breaking points in performance,
depending both on method order and the desired number of bands. Finally we
perform experiments and evaluate these methods in a hyperspectral detection
scenario.
","Przemysław Głomb, Krzysztof Domino, Michał Romaszewski, Michał Cholewa",Michał Cholewa,2018-08-10T12:50:52Z
"Constrained Nonnegative Matrix Factorization for Blind Hyperspectral
  Unmixing incorporating Endmember Independence","  Hyperspectral unmixing (HU) has become an important technique in exploiting
hyperspectral data since it decomposes a mixed pixel into a collection of
endmembers weighted by fractional abundances. The endmembers of a hyperspectral
image (HSI) are more likely to be generated by independent sources and be mixed
in a macroscopic degree before arriving at the sensor element of the imaging
spectrometer as mixed spectra. Over the past few decades, many attempts have
focused on imposing auxiliary constraints on the conventional nonnegative
matrix factorization (NMF) framework in order to effectively unmix these mixed
spectra. As a promising step toward finding an optimum constraint to extract
endmembers, this paper presents a novel blind HU algorithm, referred to as
Kurtosis-based Smooth Nonnegative Matrix Factorization (KbSNMF) which
incorporates a novel constraint based on the statistical independence of the
probability density functions of endmember spectra. Imposing this constraint on
the conventional NMF framework promotes the extraction of independent
endmembers while further enhancing the parts-based representation of data.
Experiments conducted on diverse synthetic HSI datasets (with numerous numbers
of endmembers, spectral bands, pixels, and noise levels) and three standard
real HSI datasets demonstrate the validity of the proposed KbSNMF algorithm
compared to several state-of-the-art NMF-based HU baselines. The proposed
algorithm exhibits superior performance especially in terms of extracting
endmember spectra from hyperspectral data; therefore, it could uplift the
performance of recent deep learning HU methods which utilize the endmember
spectra as supervisory input data for abundance extraction.
","E. M. M. B. Ekanayake, H. M. H. K. Weerasooriya, D. Y. L. Ranasinghe, S. Herath, B. Rathnayake, G. M. R. I. Godaliyadda, M. P. B. Ekanayake, H. M. V. R. Herath",H. M. V. R. Herath,2020-03-02T17:20:04Z
"Plant species richness prediction from DESIS hyperspectral data: A
  comparison study on feature extraction procedures and regression models","  The diversity of terrestrial vascular plants plays a key role in maintaining
the stability and productivity of ecosystems. Monitoring species compositional
diversity across large spatial scales is challenging and time consuming. The
advanced spectral and spatial specification of the recently launched DESIS (the
DLR Earth Sensing Imaging Spectrometer) instrument provides a unique
opportunity to test the potential for monitoring plant species diversity with
spaceborne hyperspectral data. This study provides a quantitative assessment on
the ability of DESIS hyperspectral data for predicting plant species richness
in two different habitat types in southeast Australia. Spectral features were
first extracted from the DESIS spectra, then regressed against on-ground
estimates of plant species richness, with a two-fold cross validation scheme to
assess the predictive performance. We tested and compared the effectiveness of
Principal Component Analysis (PCA), Canonical Correlation Analysis (CCA), and
Partial Least Squares analysis (PLS) for feature extraction, and Kernel Ridge
Regression (KRR), Gaussian Process Regression (GPR), Random Forest Regression
(RFR) for species richness prediction. The best prediction results were r=0.76
and RMSE=5.89 for the Southern Tablelands region, and r=0.68 and RMSE=5.95 for
the Snowy Mountains region. Relative importance analysis for the DESIS spectral
bands showed that the red-edge, red, and blue spectral regions were more
important for predicting plant species richness than the green bands and the
near-infrared bands beyond red-edge. We also found that the DESIS hyperspectral
data performed better than Sentinel-2 multispectral data in the prediction of
plant species richness. Our results provide a quantitative reference for future
studies exploring the potential of spaceborne hyperspectral data for plant
biodiversity mapping.
","Yiqing Guo, Karel Mokany, Cindy Ong, Peyman Moghadam, Simon Ferrier, Shaun R. Levick",Shaun R. Levick,2023-01-05T05:33:56Z
"Implicit Neural Feature Fusion Function for Multispectral and
  Hyperspectral Image Fusion","  Multispectral and Hyperspectral Image Fusion (MHIF) is a practical task that
aims to fuse a high-resolution multispectral image (HR-MSI) and a
low-resolution hyperspectral image (LR-HSI) of the same scene to obtain a
high-resolution hyperspectral image (HR-HSI). Benefiting from powerful
inductive bias capability, CNN-based methods have achieved great success in the
MHIF task. However, they lack certain interpretability and require convolution
structures be stacked to enhance performance. Recently, Implicit Neural
Representation (INR) has achieved good performance and interpretability in 2D
tasks due to its ability to locally interpolate samples and utilize multimodal
content such as pixels and coordinates. Although INR-based approaches show
promise, they require extra construction of high-frequency information
(\emph{e.g.,} positional encoding). In this paper, inspired by previous work of
MHIF task, we realize that HR-MSI could serve as a high-frequency detail
auxiliary input, leading us to propose a novel INR-based hyperspectral fusion
function named Implicit Neural Feature Fusion Function (INF). As an elaborate
structure, it solves the MHIF task and addresses deficiencies in the INR-based
approaches. Specifically, our INF designs a Dual High-Frequency Fusion (DHFF)
structure that obtains high-frequency information twice from HR-MSI and LR-HSI,
then subtly fuses them with coordinate information. Moreover, the proposed INF
incorporates a parameter-free method named INR with cosine similarity (INR-CS)
that uses cosine similarity to generate local weights through feature vectors.
Based on INF, we construct an Implicit Neural Fusion Network (INFN) that
achieves state-of-the-art performance for MHIF tasks of two public datasets,
\emph{i.e.,} CAVE and Harvard. The code will soon be made available on GitHub.
","ShangQi Deng, RuoCheng Wu, Liang-Jian Deng, Ran Ran, Gemine Vivone",Gemine Vivone,2023-07-14T11:59:47Z
"SUSHI: An algorithm for source separation of hyperspectral images with
  non-stationary spectral variation","  Hyperspectral images are data cubes with two spatial dimensions and a third
spectral dimension, providing a spectrum for each pixel, and thus allow the
mapping of extended sources' physical properties. In this article, we present
the Semi-blind Unmixing with Sparsity for Hyperspectral Images (SUSHI), an
algorithm for non-stationary unmixing of hyperspectral images with spatial
regularization of spectral parameters. The method allows for the disentangling
of physical components without the assumption of a unique spectrum for each
component. Thus, unlike most source separation methods used in astrophysics,
all physical components obtained by SUSHI vary in spectral shape and in
amplitude across the data cube.
  Non-stationary source separation is an ill-posed inverse problem that needs
to be constrained. We achieve this by training a spectral model and applying a
spatial regularization constraint on its parameters. For the spectral model, we
used an Interpolatory Auto-Encoder, a generative model that can be trained with
limited samples. For spatial regularization, we applied a sparsity constraint
on the wavelet transform of the model parameter maps.
  We applied SUSHI to a toy model meant to resemble supernova remnants in X-ray
astrophysics, though the method may be used on any extended source with any
hyperspectral instrument. We compared this result to the one obtained by a
classic 1D fit on each individual pixel. We find that SUSHI obtains more
accurate results, particularly when it comes to reconstructing physical
parameters. We applied SUSHI to real X-ray data from the supernova remnant
Cassiopeia A and to the Crab Nebula. The results obtained are realistic and in
accordance with past findings but have a much better spatial resolution. Thanks
to spatial regularization, SUSHI can obtain reliable physical parameters at
fine scales that are out of reach for pixel-by-pixel methods.
","Julia Lascar, Jérôme Bobin, Fabio Acero",Fabio Acero,2024-04-04T14:44:15Z
"Beyond the Visible: Jointly Attending to Spectral and Spatial Dimensions
  with HSI-Diffusion for the FINCH Spacecraft","  Satellite remote sensing missions have gained popularity over the past
fifteen years due to their ability to cover large swaths of land at regular
intervals, making them ideal for monitoring environmental trends. The FINCH
mission, a 3U+ CubeSat equipped with a hyperspectral camera, aims to monitor
crop residue cover in agricultural fields. Although hyperspectral imaging
captures both spectral and spatial information, it is prone to various types of
noise, including random noise, stripe noise, and dead pixels. Effective
denoising of these images is crucial for downstream scientific tasks.
Traditional methods, including hand-crafted techniques encoding strong priors,
learned 2D image denoising methods applied across different hyperspectral
bands, or diffusion generative models applied independently on bands, often
struggle with varying noise strengths across spectral bands, leading to
significant spectral distortion. This paper presents a novel approach to
hyperspectral image denoising using latent diffusion models that integrate
spatial and spectral information. We particularly do so by building a 3D
diffusion model and presenting a 3-stage training approach on real and
synthetically crafted datasets. The proposed method preserves image structure
while reducing noise. Evaluations on both popular hyperspectral denoising
datasets and synthetically crafted datasets for the FINCH mission demonstrate
the effectiveness of this approach.
","Ian Vyse, Rishit Dagli, Dav Vrat Chadha, John P. Ma, Hector Chen, Isha Ruparelia, Prithvi Seran, Matthew Xie, Eesa Aamer, Aidan Armstrong, Naveen Black, Ben Borstein, Kevin Caldwell, Orrin Dahanaggamaarachchi, Joe Dai, Abeer Fatima, Stephanie Lu, Maxime Michet, Anoushka Paul, Carrie Ann Po, Shivesh Prakash, Noa Prosser, Riddhiman Roy, Mirai Shinjo, Iliya Shofman, Coby Silayan, Reid Sox-Harris, Shuhan Zheng, Khang Nguyen",Khang Nguyen,2024-06-15T19:34:18Z
"HAMSTER: Hyperspectral Albedo Maps dataset with high Spatial and
  TEmporal Resolution","  Surface albedo is an important parameter in radiative transfer simulations of
the Earth's system, as it is fundamental to correctly calculate the energy
budget of the planet. The Moderate Resolution Imaging Spectroradiometer (MODIS)
instruments on NASA's Terra and Aqua satellites continuously monitor daily and
yearly changes in reflection at the planetary surface. The MODIS Surface
Reflectance black-sky albedo dataset (MCD43D, version 6.1) gives detailed
albedo maps in seven spectral bands in the visible and near-infrared range.
These albedo maps allow us to classify different Lambertian surface types and
their seasonal and yearly variability and change, albeit only in seven spectral
bands. However, a complete set of albedo maps covering the entire wavelength
range is required to simulate radiance spectra, and to correctly retrieve
atmospheric and cloud properties from Earth's remote sensing. We use a
Principal Component Analysis (PCA) regression algorithm to generate
hyperspectral albedo maps of Earth. Combining different datasets of
hyperspectral reflectance laboratory measurements for various dry soils,
vegetation surfaces, and mixtures of both, we reconstruct the albedo maps in
the entire wavelength range from 400 to 2500~nm. The PCA method is trained with
a 10-years average of MODIS data for each day of the year. We obtain
hyperspectral albedo maps with a spatial resolution of 0.05{\deg} in latitude
and longitude, a spectral resolution of 10~nm, and a temporal resolution of
1~day. Using the hyperspectral albedo maps, we estimate the spectral profiles
of different land surfaces, such as forests, deserts, cities and icy surfaces,
and study their seasonal variability. These albedo maps shall enable to refine
calculations of Earth's energy budget, its seasonal variability, and improve
climate simulations.
","Giulia Roccetti, Luca Bugliaro, Felix Gödde, Claudia Emde, Ulrich Hamann, Mihail Manev, Michael Sterzik, Cedric Wehrum",Cedric Wehrum,2024-07-25T13:26:50Z
"Dimensionality Reduction and Classification feature using Mutual
  Information applied to Hyperspectral Images : A Filter strategy based
  algorithm","  Hyperspectral images (HIS) classification is a high technical remote sensing
tool. The goal is to reproduce a thematic map that will be compared with a
reference ground truth map (GT), constructed by expecting the region. The HIS
contains more than a hundred bidirectional measures, called bands (or simply
images), of the same region. They are taken at juxtaposed frequencies.
Unfortunately, some bands contain redundant information, others are affected by
the noise, and the high dimensionality of features made the accuracy of
classification lower. The problematic is how to find the good bands to classify
the pixels of regions. Some methods use Mutual Information (MI) and threshold,
to select relevant bands, without treatment of redundancy. Others control and
eliminate redundancy by selecting the band top ranking the MI, and if its
neighbors have sensibly the same MI with the GT, they will be considered
redundant and so discarded. This is the most inconvenient of this method,
because this avoids the advantage of hyperspectral images: some precious
information can be discarded. In this paper we'll accept the useful redundancy.
A band contains useful redundancy if it contributes to produce an estimated
reference map that has higher MI with the GT.nTo control redundancy, we
introduce a complementary threshold added to last value of MI. This process is
a Filter strategy; it gets a better performance of classification accuracy and
not expensive, but less preferment than Wrapper strategy.
","ELkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine",Driss Aboutajdine,2012-09-28T23:03:00Z
"Band Selection and Classification of Hyperspectral Images using Mutual
  Information: An algorithm based on minimizing the error probability using the
  inequality of Fano","  Hyperspectral image is a substitution of more than a hundred images, called
bands, of the same region. They are taken at juxtaposed frequencies. The
reference image of the region is called Ground Truth map (GT). the problematic
is how to find the good bands to classify the pixels of regions; because the
bands can be not only redundant, but a source of confusion, and decreasing so
the accuracy of classification. Some methods use Mutual Information (MI) and
threshold, to select relevant bands. Recently there's an algorithm selection
based on mutual information, using bandwidth rejection and a threshold to
control and eliminate redundancy. The band top ranking the MI is selected, and
if its neighbors have sensibly the same MI with the GT, they will be considered
redundant and so discarded. This is the most inconvenient of this method,
because this avoids the advantage of hyperspectral images: some precious
information can be discarded. In this paper we'll make difference between
useful and useless redundancy. A band contains useful redundancy if it
contributes to decreasing error probability. According to this scheme, we
introduce new algorithm using also mutual information, but it retains only the
bands minimizing the error probability of classification. To control
redundancy, we introduce a complementary threshold. So the good band candidate
must contribute to decrease the last error probability augmented by the
threshold. This process is a wrapper strategy; it gets high performance of
classification accuracy but it is expensive than filter strategy.
","Elkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine",Driss Aboutajdine,2012-09-28T23:36:26Z
"Application of Symmetric Uncertainty and Mutual Information to
  Dimensionality Reduction and Classification of Hyperspectral Images","  Remote sensing is a technology to acquire data for disatant substances,
necessary to construct a model knowledge for applications as classification.
Recently Hyperspectral Images (HSI) becomes a high technical tool that the main
goal is to classify the point of a region. The HIS is more than a hundred
bidirectional measures, called bands (or simply images), of the same region
called Ground Truth Map (GT). But some bands are not relevant because they are
affected by different atmospheric effects; others contain redundant
information; and high dimensionality of HSI features make the accuracy of
classification lower. All these bands can be important for some applications;
but for the classification a small subset of these is relevant. The problematic
related to HSI is the dimensionality reduction. Many studies use mutual
information (MI) to select the relevant bands. Others studies use the MI
normalized forms, like Symmetric Uncertainty, in medical imagery applications.
In this paper we introduce an algorithm based also on MI to select relevant
bands and it apply the Symmetric Uncertainty coefficient to control redundancy
and increase the accuracy of classification. This algorithm is feature
selection tool and a Filter strategy. We establish this study on HSI AVIRIS
92AV3C. This is an effectiveness, and fast scheme to control redundancy.
","ELkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine",Driss Aboutajdine,2012-11-03T14:01:29Z
"Hierarchical Clustering of Hyperspectral Images using Rank-Two
  Nonnegative Matrix Factorization","  In this paper, we design a hierarchical clustering algorithm for
high-resolution hyperspectral images. At the core of the algorithm, a new
rank-two nonnegative matrix factorizations (NMF) algorithm is used to split the
clusters, which is motivated by convex geometry concepts. The method starts
with a single cluster containing all pixels, and, at each step, (i) selects a
cluster in such a way that the error at the next step is minimized, and (ii)
splits the selected cluster into two disjoint clusters using rank-two NMF in
such a way that the clusters are well balanced and stable. The proposed method
can also be used as an endmember extraction algorithm in the presence of pure
pixels. The effectiveness of this approach is illustrated on several synthetic
and real-world hyperspectral images, and shown to outperform standard
clustering techniques such as k-means, spherical k-means and standard NMF.
","Nicolas Gillis, Da Kuang, Haesun Park",Haesun Park,2013-09-14T09:54:59Z
"Hyperspectral image superresolution: An edge-preserving convex
  formulation","  Hyperspectral remote sensing images (HSIs) are characterized by having a low
spatial resolution and a high spectral resolution, whereas multispectral images
(MSIs) are characterized by low spectral and high spatial resolutions. These
complementary characteristics have stimulated active research in the inference
of images with high spatial and spectral resolutions from HSI-MSI pairs.
  In this paper, we formulate this data fusion problem as the minimization of a
convex objective function containing two data-fitting terms and an
edge-preserving regularizer. The data-fitting terms are quadratic and account
for blur, different spatial resolutions, and additive noise; the regularizer, a
form of vector Total Variation, promotes aligned discontinuities across the
reconstructed hyperspectral bands.
  The optimization described above is rather hard, owing to its
non-diagonalizable linear operators, to the non-quadratic and non-smooth nature
of the regularizer, and to the very large size of the image to be inferred. We
tackle these difficulties by tailoring the Split Augmented Lagrangian Shrinkage
Algorithm (SALSA)---an instance of the Alternating Direction Method of
Multipliers (ADMM)---to this optimization problem. By using a convenient
variable splitting and by exploiting the fact that HSIs generally ""live"" in a
low-dimensional subspace, we obtain an effective algorithm that yields
state-of-the-art results, as illustrated by experiments.
","Miguel Simões, José Bioucas-Dias, Luis B. Almeida, Jocelyn Chanussot",Jocelyn Chanussot,2014-03-31T17:18:48Z
"Kernel Nonnegative Matrix Factorization Without the Curse of the
  Pre-image - Application to Unmixing Hyperspectral Images","  The nonnegative matrix factorization (NMF) is widely used in signal and image
processing, including bio-informatics, blind source separation and
hyperspectral image analysis in remote sensing. A great challenge arises when
dealing with a nonlinear formulation of the NMF. Within the framework of kernel
machines, the models suggested in the literature do not allow the
representation of the factorization matrices, which is a fallout of the curse
of the pre-image. In this paper, we propose a novel kernel-based model for the
NMF that does not suffer from the pre-image problem, by investigating the
estimation of the factorization matrices directly in the input space. For
different kernel functions, we describe two schemes for iterative algorithms:
an additive update rule based on a gradient descent scheme and a multiplicative
update rule in the same spirit as in the Lee and Seung algorithm. Within the
proposed framework, we develop several extensions to incorporate constraints,
including sparseness, smoothness, and spatial regularization with a
total-variation-like penalty. The effectiveness of the proposed method is
demonstrated with the problem of unmixing hyperspectral images, using
well-known real images and results with state-of-the-art techniques.
","Fei Zhu, Paul Honeine, Maya Kallas",Maya Kallas,2014-07-16T18:46:41Z
"Self-Dictionary Sparse Regression for Hyperspectral Unmixing: Greedy
  Pursuit and Pure Pixel Search are Related","  This paper considers a recently emerged hyperspectral unmixing formulation
based on sparse regression of a self-dictionary multiple measurement vector
(SD-MMV) model, wherein the measured hyperspectral pixels are used as the
dictionary. Operating under the pure pixel assumption, this SD-MMV formalism is
special in that it allows simultaneous identification of the endmember spectral
signatures and the number of endmembers. Previous SD-MMV studies mainly focus
on convex relaxations. In this study, we explore the alternative of greedy
pursuit, which generally provides efficient and simple algorithms. In
particular, we design a greedy SD-MMV algorithm using simultaneous orthogonal
matching pursuit. Intriguingly, the proposed greedy algorithm is shown to be
closely related to some existing pure pixel search algorithms, especially, the
successive projection algorithm (SPA). Thus, a link between SD-MMV and pure
pixel search is revealed. We then perform exact recovery analyses, and prove
that the proposed greedy algorithm is robust to noise---including its
identification of the (unknown) number of endmembers---under a sufficiently low
noise level. The identification performance of the proposed greedy algorithm is
demonstrated through both synthetic and real-data experiments.
","Xiao Fu, Wing-Kin Ma, Tsung-Han Chan, José M. Bioucas-Dias",José M. Bioucas-Dias,2014-09-15T16:48:31Z
"Task-Driven Dictionary Learning for Hyperspectral Image Classification
  with Structured Sparsity Constraints","  Sparse representation models a signal as a linear combination of a small
number of dictionary atoms. As a generative model, it requires the dictionary
to be highly redundant in order to ensure both a stable high sparsity level and
a low reconstruction error for the signal. However, in practice, this
requirement is usually impaired by the lack of labelled training samples.
Fortunately, previous research has shown that the requirement for a redundant
dictionary can be less rigorous if simultaneous sparse approximation is
employed, which can be carried out by enforcing various structured sparsity
constraints on the sparse codes of the neighboring pixels. In addition,
numerous works have shown that applying a variety of dictionary learning
methods for the sparse representation model can also improve the classification
performance. In this paper, we highlight the task-driven dictionary learning
algorithm, which is a general framework for the supervised dictionary learning
method. We propose to enforce structured sparsity priors on the task-driven
dictionary learning method in order to improve the performance of the
hyperspectral classification. Our approach is able to benefit from both the
advantages of the simultaneous sparse representation and those of the
supervised dictionary learning. We enforce two different structured sparsity
priors, the joint and Laplacian sparsity, on the task-driven dictionary
learning method and provide the details of the corresponding optimization
algorithms. Experiments on numerous popular hyperspectral images demonstrate
that the classification performance of our approach is superior to sparse
representation classifier with structured priors or the task-driven dictionary
learning method.
","Xiaoxia Sun, Nasser M. Nasrabadi, Trac D. Tran",Trac D. Tran,2015-02-03T12:24:40Z
"Nonparametric Detection of Nonlinearly Mixed Pixels and Endmember
  Estimation in Hyperspectral Images","  Mixing phenomena in hyperspectral images depend on a variety of factors such
as the resolution of observation devices, the properties of materials, and how
these materials interact with incident light in the scene. Different parametric
and nonparametric models have been considered to address hyperspectral unmixing
problems. The simplest one is the linear mixing model. Nevertheless, it has
been recognized that mixing phenomena can also be nonlinear. The corresponding
nonlinear analysis techniques are necessarily more challenging and complex than
those employed for linear unmixing. Within this context, it makes sense to
detect the nonlinearly mixed pixels in an image prior to its analysis, and then
employ the simplest possible unmixing technique to analyze each pixel. In this
paper, we propose a technique for detecting nonlinearly mixed pixels. The
detection approach is based on the comparison of the reconstruction errors
using both a Gaussian process regression model and a linear regression model.
The two errors are combined into a detection statistics for which a probability
density function can be reasonably approximated. We also propose an iterative
endmember extraction algorithm to be employed in combination with the detection
algorithm. The proposed Detect-then-Unmix strategy, which consists of
extracting endmembers, detecting nonlinearly mixed pixels and unmixing, is
tested with synthetic and real images.
","Tales Imbiriba, José Carlos Moreira Bermudez, Cédric Richard, Jean-Yves Tourneret",Jean-Yves Tourneret,2015-03-18T18:20:24Z
"Simultaneously sparse and low-rank abundance matrix estimation for
  hyperspectral image unmixing","  In a plethora of applications dealing with inverse problems, e.g. in image
processing, social networks, compressive sensing, biological data processing
etc., the signal of interest is known to be structured in several ways at the
same time. This premise has recently guided the research to the innovative and
meaningful idea of imposing multiple constraints on the parameters involved in
the problem under study. For instance, when dealing with problems whose
parameters form sparse and low-rank matrices, the adoption of suitably combined
constraints imposing sparsity and low-rankness, is expected to yield
substantially enhanced estimation results. In this paper, we address the
spectral unmixing problem in hyperspectral images. Specifically, two novel
unmixing algorithms are introduced, in an attempt to exploit both spatial
correlation and sparse representation of pixels lying in homogeneous regions of
hyperspectral images. To this end, a novel convex mixed penalty term is first
defined consisting of the sum of the weighted $\ell_1$ and the weighted nuclear
norm of the abundance matrix corresponding to a small area of the image
determined by a sliding square window. This penalty term is then used to
regularize a conventional quadratic cost function and impose simultaneously
sparsity and row-rankness on the abundance matrix. The resulting regularized
cost function is minimized by a) an incremental proximal sparse and low-rank
unmixing algorithm and b) an algorithm based on the alternating minimization
method of multipliers (ADMM). The effectiveness of the proposed algorithms is
illustrated in experiments conducted both on simulated and real data.
","Paris Giampouras, Konstantinos Themelis, Athanasios Rontogiannis, Konstantinos Koutroumbas",Konstantinos Koutroumbas,2015-04-07T08:23:45Z
"A Fast Hyperplane-Based Minimum-Volume Enclosing Simplex Algorithm for
  Blind Hyperspectral Unmixing","  Hyperspectral unmixing (HU) is a crucial signal processing procedure to
identify the underlying materials (or endmembers) and their corresponding
proportions (or abundances) from an observed hyperspectral scene. A well-known
blind HU criterion, advocated by Craig in early 1990's, considers the vertices
of the minimum-volume enclosing simplex of the data cloud as good endmember
estimates, and it has been empirically and theoretically found effective even
in the scenario of no pure pixels. However, such kind of algorithms may suffer
from heavy simplex volume computations in numerical optimization, etc. In this
work, without involving any simplex volume computations, by exploiting a convex
geometry fact that a simplest simplex of N vertices can be defined by N
associated hyperplanes, we propose a fast blind HU algorithm, for which each of
the N hyperplanes associated with the Craig's simplex of N vertices is
constructed from N-1 affinely independent data pixels, together with an
endmember identifiability analysis for its performance support. Without
resorting to numerical optimization, the devised algorithm searches for the
N(N-1) active data pixels via simple linear algebraic computations, accounting
for its computational efficiency. Monte Carlo simulations and real data
experiments are provided to demonstrate its superior efficacy over some
benchmark Craig-criterion-based algorithms in both computational efficiency and
estimation accuracy.
","Chia-Hsiang Lin, Chong-Yung Chi, Yu-Hsiang Wang, Tsung-Han Chan",Tsung-Han Chan,2015-10-29T21:41:26Z
"Probe-based Rapid Hybrid Hyperspectral and Tissue Surface Imaging Aided
  by Fully Convolutional Networks","  Tissue surface shape and reflectance spectra provide rich intra-operative
information useful in surgical guidance. We propose a hybrid system which
displays an endoscopic image with a fast joint inspection of tissue surface
shape using structured light (SL) and hyperspectral imaging (HSI). For SL a
miniature fibre probe is used to project a coloured spot pattern onto the
tissue surface. In HSI mode standard endoscopic illumination is used, with the
fibre probe collecting reflected light and encoding the spatial information
into a linear format that can be imaged onto the slit of a spectrograph.
Correspondence between the arrangement of fibres at the distal and proximal
ends of the bundle was found using spectral encoding. Then during pattern
decoding, a fully convolutional network (FCN) was used for spot detection,
followed by a matching propagation algorithm for spot identification. This
method enabled fast reconstruction (12 frames per second) using a GPU. The
hyperspectral image was combined with the white light image and the
reconstructed surface, showing the spectral information of different areas.
Validation of this system using phantom and ex vivo experiments has been
demonstrated.
","Jianyu Lin, Neil T. Clancy, Xueqing Sun, Ji Qi, Mirek Janatka, Danail Stoyanov, Daniel S. Elson",Daniel S. Elson,2016-06-15T14:00:07Z
"Inertia-Constrained Pixel-by-Pixel Nonnegative Matrix Factorisation: a
  Hyperspectral Unmixing Method Dealing with Intra-class Variability","  Blind source separation is a common processing tool to analyse the
constitution of pixels of hyperspectral images. Such methods usually suppose
that pure pixel spectra (endmembers) are the same in all the image for each
class of materials. In the framework of remote sensing, such an assumption is
no more valid in the presence of intra-class variabilities due to illumination
conditions, weathering, slight variations of the pure materials, etc... In this
paper, we first describe the results of investigations highlighting intra-class
variability measured in real images. Considering these results, a new
formulation of the linear mixing model is presented leading to two new methods.
Unconstrained Pixel-by-pixel NMF (UP-NMF) is a new blind source separation
method based on the assumption of a linear mixing model, which can deal with
intra-class variability. To overcome UP-NMF limitations an extended method is
proposed, named Inertia-constrained Pixel-by-pixel NMF (IP-NMF). For each
sensed spectrum, these extended versions of NMF extract a corresponding set of
source spectra. A constraint is set to limit the spreading of each source's
estimates in IP-NMF. The methods are tested on a semi-synthetic data set built
with spectra extracted from a real hyperspectral image and then numerically
mixed. We thus demonstrate the interest of our methods for realistic source
variabilities. Finally, IP-NMF is tested on a real data set and it is shown to
yield better performance than state of the art methods.
","Charlotte Revel, Yannick Deville, Véronique Achard, Xavier Briottet",Xavier Briottet,2017-02-24T15:43:10Z
Bayesian Nonparametric Unmixing of Hyperspectral Images,"  Hyperspectral imaging is an important tool in remote sensing, allowing for
accurate analysis of vast areas. Due to a low spatial resolution, a pixel of a
hyperspectral image rarely represents a single material, but rather a mixture
of different spectra. HSU aims at estimating the pure spectra present in the
scene of interest, referred to as endmembers, and their fractions in each
pixel, referred to as abundances. Today, many HSU algorithms have been
proposed, based either on a geometrical or statistical model. While most
methods assume that the number of endmembers present in the scene is known,
there is only little work about estimating this number from the observed data.
In this work, we propose a Bayesian nonparametric framework that jointly
estimates the number of endmembers, the endmembers itself, and their
abundances, by making use of the Indian Buffet Process as a prior for the
endmembers. Simulation results and experiments on real data demonstrate the
effectiveness of the proposed algorithm, yielding results comparable with
state-of-the-art methods while being able to reliably infer the number of
endmembers. In scenarios with strong noise, where other algorithms provide only
poor results, the proposed approach tends to overestimate the number of
endmembers slightly. The additional endmembers, however, often simply represent
noisy replicas of present endmembers and could easily be merged in a
post-processing step.
","Jürgen Hahn, Abdelhak M. Zoubir",Abdelhak M. Zoubir,2017-02-26T09:10:45Z
"EndNet: Sparse AutoEncoder Network for Endmember Extraction and
  Hyperspectral Unmixing","  Data acquired from multi-channel sensors is a highly valuable asset to
interpret the environment for a variety of remote sensing applications.
However, low spatial resolution is a critical limitation for previous sensors
and the constituent materials of a scene can be mixed in different fractions
due to their spatial interactions. Spectral unmixing is a technique that allows
us to obtain the material spectral signatures and their fractions from
hyperspectral data. In this paper, we propose a novel endmember extraction and
hyperspectral unmixing scheme, so called \textit{EndNet}, that is based on a
two-staged autoencoder network. This well-known structure is completely
enhanced and restructured by introducing additional layers and a projection
metric (i.e., spectral angle distance (SAD) instead of inner product) to
achieve an optimum solution. Moreover, we present a novel loss function that is
composed of a Kullback-Leibler divergence term with SAD similarity and
additional penalty terms to improve the sparsity of the estimates. These
modifications enable us to set the common properties of endmembers such as
non-linearity and sparsity for autoencoder networks. Lastly, due to the
stochastic-gradient based approach, the method is scalable for large-scale data
and it can be accelerated on Graphical Processing Units (GPUs). To demonstrate
the superiority of our proposed method, we conduct extensive experiments on
several well-known datasets. The results confirm that the proposed method
considerably improves the performance compared to the state-of-the-art
techniques in literature.
","Savas Ozkan, Berk Kaya, Gozde Bozdagi Akar",Gozde Bozdagi Akar,2017-08-06T14:21:32Z
Incremental Import Vector Machines for Classifying Hyperspectral Data,"  In this paper we propose an incremental learning strategy for import vector
machines (IVM), which is a sparse kernel logistic regression approach. We use
the procedure for the concept of self-training for sequential classification of
hyperspectral data. The strategy comprises the inclusion of new training
samples to increase the classification accuracy and the deletion of
non-informative samples to be memory- and runtime-efficient. Moreover, we
update the parameters in the incremental IVM model without re-training from
scratch. Therefore, the incremental classifier is able to deal with large data
sets. The performance of the IVM in comparison to support vector machines (SVM)
is evaluated in terms of accuracy and experiments are conducted to assess the
potential of the probabilistic outputs of the IVM. Experimental results
demonstrate that the IVM and SVM perform similar in terms of classification
accuracy. However, the number of import vectors is significantly lower when
compared to the number of support vectors and thus, the computation time during
classification can be decreased. Moreover, the probabilities provided by IVM
are more reliable, when compared to the probabilistic information, derived from
an SVM's output. In addition, the proposed self-training strategy can increase
the classification accuracy. Overall, the IVM and the its incremental version
is worthwhile for the classification of hyperspectral data.
","Ribana Roscher, Björn Waske, Wolfgang Förstner",Wolfgang Förstner,2017-08-20T13:59:00Z
"An Augmented Linear Mixing Model to Address Spectral Variability for
  Hyperspectral Unmixing","  Hyperspectral imagery collected from airborne or satellite sources inevitably
suffers from spectral variability, making it difficult for spectral unmixing to
accurately estimate abundance maps. The classical unmixing model, the linear
mixing model (LMM), generally fails to handle this sticky issue effectively. To
this end, we propose a novel spectral mixture model, called the augmented
linear mixing model (ALMM), to address spectral variability by applying a
data-driven learning strategy in inverse problems of hyperspectral unmixing.
The proposed approach models the main spectral variability (i.e., scaling
factors) generated by variations in illumination or typography separately by
means of the endmember dictionary. It then models other spectral variabilities
caused by environmental conditions (e.g., local temperature and humidity,
atmospheric effects) and instrumental configurations (e.g., sensor noise), as
well as material nonlinear mixing effects, by introducing a spectral
variability dictionary. To effectively run the data-driven learning strategy,
we also propose a reasonable prior knowledge for the spectral variability
dictionary, whose atoms are assumed to be low-coherent with spectral signatures
of endmembers, which leads to a well-known low coherence dictionary learning
problem. Thus, a dictionary learning technique is embedded in the framework of
spectral unmixing so that the algorithm can learn the spectral variability
dictionary and estimate the abundance maps simultaneously. Extensive
experiments on synthetic and real datasets are performed to demonstrate the
superiority and effectiveness of the proposed method in comparison with
previous state-of-the-art methods.
","Danfeng Hong, Naoto Yokoya, Jocelyn Chanussot, Xiao Xiang Zhu",Xiao Xiang Zhu,2018-10-29T08:35:42Z
"Learnable Manifold Alignment (LeMA) : A Semi-supervised Cross-modality
  Learning Framework for Land Cover and Land Use Classification","  In this paper, we aim at tackling a general but interesting cross-modality
feature learning question in remote sensing community --- can a limited amount
of highly-discrimin-ative (e.g., hyperspectral) training data improve the
performance of a classification task using a large amount of
poorly-discriminative (e.g., multispectral) data? Traditional semi-supervised
manifold alignment methods do not perform sufficiently well for such problems,
since the hyperspectral data is very expensive to be largely collected in a
trade-off between time and efficiency, compared to the multispectral data. To
this end, we propose a novel semi-supervised cross-modality learning framework,
called learnable manifold alignment (LeMA). LeMA learns a joint graph structure
directly from the data instead of using a given fixed graph defined by a
Gaussian kernel function. With the learned graph, we can further capture the
data distribution by graph-based label propagation, which enables finding a
more accurate decision boundary. Additionally, an optimization strategy based
on the alternating direction method of multipliers (ADMM) is designed to solve
the proposed model. Extensive experiments on two hyperspectral-multispectral
datasets demonstrate the superiority and effectiveness of the proposed method
in comparison with several state-of-the-art methods.
","Danfeng Hong, Naoto Yokoya, Nan Ge, Jocelyn Chanussot, Xiao Xiang Zhu",Xiao Xiang Zhu,2019-01-09T17:22:36Z
"HybridSN: Exploring 3D-2D CNN Feature Hierarchy for Hyperspectral Image
  Classification","  Hyperspectral image (HSI) classification is widely used for the analysis of
remotely sensed images. Hyperspectral imagery includes varying bands of images.
Convolutional Neural Network (CNN) is one of the most frequently used deep
learning based methods for visual data processing. The use of CNN for HSI
classification is also visible in recent works. These approaches are mostly
based on 2D CNN. Whereas, the HSI classification performance is highly
dependent on both spatial and spectral information. Very few methods have
utilized the 3D CNN because of increased computational complexity. This letter
proposes a Hybrid Spectral Convolutional Neural Network (HybridSN) for HSI
classification. Basically, the HybridSN is a spectral-spatial 3D-CNN followed
by spatial 2D-CNN. The 3D-CNN facilitates the joint spatial-spectral feature
representation from a stack of spectral bands. The 2D-CNN on top of the 3D-CNN
further learns more abstract level spatial representation. Moreover, the use of
hybrid CNNs reduces the complexity of the model compared to 3D-CNN alone. To
test the performance of this hybrid approach, very rigorous HSI classification
experiments are performed over Indian Pines, Pavia University and Salinas Scene
remote sensing datasets. The results are compared with the state-of-the-art
hand-crafted as well as end-to-end deep learning based methods. A very
satisfactory performance is obtained using the proposed HybridSN for HSI
classification. The source code can be found at
\url{https://github.com/gokriznastic/HybridSN}.
","Swalpa Kumar Roy, Gopal Krishna, Shiv Ram Dubey, Bidyut B. Chaudhuri",Bidyut B. Chaudhuri,2019-02-18T18:14:26Z
"Estimating Chlorophyll a Concentrations of Several Inland Waters with
  Hyperspectral Data and Machine Learning Models","  Water is a key component of life, the natural environment and human health.
For monitoring the conditions of a water body, the chlorophyll a concentration
can serve as a proxy for nutrients and oxygen supply. In situ measurements of
water quality parameters are often time-consuming, expensive and limited in
areal validity. Therefore, we apply remote sensing techniques. During field
campaigns, we collected hyperspectral data with a spectrometer and in situ
measured chlorophyll a concentrations of 13 inland water bodies with different
spectral characteristics. One objective of this study is to estimate
chlorophyll a concentrations of these inland waters by applying three machine
learning regression models: Random Forest, Support Vector Machine and an
Artificial Neural Network. Additionally, we simulate four different
hyperspectral resolutions of the spectrometer data to investigate the effects
on the estimation performance. Furthermore, the application of first order
derivatives of the spectra is evaluated in turn to the regression performance.
This study reveals the potential of combining machine learning approaches and
remote sensing data for inland waters. Each machine learning model achieves an
R2-score between 80 % to 90 % for the regression on chlorophyll a
concentrations. The random forest model benefits clearly from the applied
derivatives of the spectra. In further studies, we will focus on the
application of machine learning models on spectral satellite data to enhance
the area-wide estimation of chlorophyll a concentration for inland waters.
","Philipp M. Maier, Sina Keller",Sina Keller,2019-04-03T15:16:36Z
"BS-Nets: An End-to-End Framework For Band Selection of Hyperspectral
  Image","  Hyperspectral image (HSI) consists of hundreds of continuous narrow bands
with high spectral correlation, which would lead to the so-called Hughes
phenomenon and the high computational cost in processing. Band selection has
been proven effective in avoiding such problems by removing the redundant
bands. However, many of existing band selection methods separately estimate the
significance for every single band and cannot fully consider the nonlinear and
global interaction between spectral bands. In this paper, by assuming that a
complete HSI can be reconstructed from its few informative bands, we propose a
general band selection framework, Band Selection Network (termed as BS-Net).
The framework consists of a band attention module (BAM), which aims to
explicitly model the nonlinear inter-dependencies between spectral bands, and a
reconstruction network (RecNet), which is used to restore the original HSI cube
from the learned informative bands, resulting in a flexible architecture. The
resulting framework is end-to-end trainable, making it easier to train from
scratch and to combine with existing networks. We implement two BS-Nets
respectively using fully connected networks (BS-Net-FC) and convolutional
neural networks (BS-Net-Conv), and compare the results with many existing band
selection approaches for three real hyperspectral images, demonstrating that
the proposed BS-Nets can accurately select informative band subset with less
redundancy and achieve significantly better classification performance with an
acceptable time cost.
","Yaoming Cai, Xiaobo Liu, Zhihua Cai",Zhihua Cai,2019-04-17T13:41:38Z
"Hyperspectral Unmixing via Deep Autoencoder Networks for a Generalized
  Linear-Mixture/Nonlinear-Fluctuation Model","  Spectral unmixing is an important task in hyperspectral image processing for
separating the mixed spectral data pertaining to various materials observed
individual pixels. Recently, nonlinear spectral unmixing has received
particular attention because a linear mixture is not appropriate under many
conditions. However, existing nonlinear unmixing approaches are often based on
specific assumptions regarding the inherent nonlinearity, and they can be
ineffective when applied to conditions deviating from the original assumptions.
Therefore, these approaches are not well suited to scenes with unknown
nonlinearity characteristics. This paper presents an unsupervised nonlinear
spectral unmixing method based on a deep autoencoder network that applies to a
generalized linear-mixture/nonlinear fluctuation model, consisting of a linear
mixture component and an additive nonlinear mixture component that depends on
both endmembers and abundances. The proposed approach benefits from the
universal modeling ability of deep neural networks to learn the inherent
nonlinearity of the nonlinear mixture component from the data itself via the
autoencoder network, rather than relying on an assumed form. Extensive
experiments with numerically synthetic, labeled laboratory-created data and
real airborne data, illustrate the generality and effectiveness of this
approach compared with state-of-the-art methods.
","Min Zhao, Mou Wang, Jie Chen, Susanto Rahardja",Susanto Rahardja,2019-04-30T02:12:00Z
"Hyperspectral Super-Resolution via Global-Local Low-Rank Matrix
  Estimation","  Hyperspectral super-resolution (HSR) is a problem that aims to estimate an
image of high spectral and spatial resolutions from a pair of co-registered
multispectral (MS) and hyperspectral (HS) images, which have coarser spectral
and spatial resolutions, respectively. In this paper we pursue a low-rank
matrix estimation approach for HSR. We assume that the spectral-spatial
matrices associated with the whole image and the local areas of the image have
low-rank structures. The local low-rank assumption, in particular, has the aim
of providing a more flexible model for accounting for local variation effects
due to endmember variability. We formulate the HSR problem as a global-local
rank-regularized least-squares problem. By leveraging on the recent advances in
non-convex large-scale optimization, namely, the smooth Schatten-p
approximation and the accelerated majorization-minimization method, we develop
an efficient algorithm for the global-local low-rank problem. Numerical
experiments on synthetic, semi-real and real data show that the proposed
algorithm outperforms a number of benchmark algorithms in terms of recovery
performance.
","Ruiyuan Wu, Wing-Kin Ma, Xiao Fu, Qiang Li",Qiang Li,2019-07-02T03:46:02Z
"A Hyperspectral Microscope based on an Ultrastable Common-Path
  Interferometer","  We introduce a wide field hyperspectral microscope using the
Fourier-transform approach. The interferometer is based on the
Translating-Wedge-Based Identical Pulses eNcoding System (TWINS) [Opt. Lett.
37, 3027 (2012)], a common-path birefringent interferometer which combines
compactness, intrinsic interferometric delay precision, long-term stability and
insensitivity to vibrations. We describe three different implementations of our
system: two prototypes designed to test different optical schemes and an add-on
for a commercial microscope. We show high-quality spectral microscopy of the
fluorescence from stained cells and powders of inorganic pigments,
demonstrating that the device is suited to biology and materials science. We
demonstrate the acquisition of a 1Mpixel hyperspectral image in 75 seconds in
the spectral range from 400 to 1100 nm. We also introduce an acquisition method
which synthesizes a tunable spectral filter, providing band-passed images by
the measurement of only two maps.
","A. Candeo, B. E. Nogueira de Faria, M. Erreni, G. Valentini, A. Bassi, A. M. de Paula, G. Cerullo, C. Manzoni",C. Manzoni,2019-09-24T10:25:35Z
"Multi-Level Graph Convolutional Network with Automatic Graph Learning
  for Hyperspectral Image Classification","  Nowadays, deep learning methods, especially the Graph Convolutional Network
(GCN), have shown impressive performance in hyperspectral image (HSI)
classification. However, the current GCN-based methods treat graph construction
and image classification as two separate tasks, which often results in
suboptimal performance. Another defect of these methods is that they mainly
focus on modeling the local pairwise importance between graph nodes while lack
the capability to capture the global contextual information of HSI. In this
paper, we propose a Multi-level GCN with Automatic Graph Learning method
(MGCN-AGL) for HSI classification, which can automatically learn the graph
information at both local and global levels. By employing attention mechanism
to characterize the importance among spatially neighboring regions, the most
relevant information can be adaptively incorporated to make decisions, which
helps encode the spatial context to form the graph information at local level.
Moreover, we utilize multiple pathways for local-level graph convolution, in
order to leverage the merits from the diverse spatial context of HSI and to
enhance the expressive power of the generated representations. To reconstruct
the global contextual relations, our MGCN-AGL encodes the long range
dependencies among image regions based on the expressive representations that
have been produced at local level. Then inference can be performed along the
reconstructed graph edges connecting faraway regions. Finally, the multi-level
information is adaptively fused to generate the network output. In this means,
the graph learning and image classification can be integrated into a unified
framework and benefit each other. Extensive experiments have been conducted on
three real-world hyperspectral datasets, which are shown to outperform the
state-of-the-art methods.
","Sheng Wan, Chen Gong, Shirui Pan, Jie Yang, Jian Yang",Jian Yang,2020-09-19T09:26:20Z
"Ensemble Hyperspectral Band Selection for Detecting Nitrogen Status in
  Grape Leaves","  The large data size and dimensionality of hyperspectral data demands complex
processing and data analysis. Multispectral data do not suffer the same
limitations, but are normally restricted to blue, green, red, red edge, and
near infrared bands. This study aimed to identify the optimal set of spectral
bands for nitrogen detection in grape leaves using ensemble feature selection
on hyperspectral data from over 3,000 leaves from 150 Flame Seedless table
grapevines. Six machine learning base rankers were included in the ensemble:
random forest, LASSO, SelectKBest, ReliefF, SVM-RFE, and chaotic crow search
algorithm (CCSA). The pipeline identified less than 0.45% of the bands as most
informative about grape nitrogen status. The selected violet, yellow-orange,
and shortwave infrared bands lie outside of the typical blue, green, red, red
edge, and near infrared bands of commercial multispectral cameras, so the
potential improvement in remote sensing of nitrogen in grapevines brought forth
by a customized multispectral sensor centered at the selected bands is
promising and worth further investigation. The proposed pipeline may also be
used for application-specific multispectral sensor design in domains other than
agriculture.
","Ryan Omidi, Ali Moghimi, Alireza Pourreza, Mohamed El-Hadedy, Anas Salah Eddin",Anas Salah Eddin,2020-10-08T19:09:10Z
Hyperspectral interference tomography of nacre,"  Structural characterization of biologically formed materials is essential for
understanding biological phenomena and their environment, and generating new
bio-inspired engineering concepts. For example, nacre -- formed by mollusks in
the ocean -- encodes local environmental conditions throughout its formation
and has exceptional strength due to its nanoscale brick-and-mortar structure.
This layered structure, comprising transparent aragonite tablets bonded with an
ultra-thin organic polymer, also results in stunning interference colors.
Existing methods of structural characterization of nacre rely on some form of
cross-sectional analysis, such as scanning electron microscopy or
polarization-dependent imaging contrast (PIC) mapping. However, these
techniques are destructive and too time- and resource-intensive to analyze
large sample areas. Here we present an all-optical, rapid, and non-destructive
imaging technique -- hyperspectral interference tomography (HIT) -- to
spatially map the structural parameters of nacre and other disordered layered
materials. We combined hyperspectral imaging with optical-interference modeling
to infer the mean tablet thickness and disordering of nacre layers across
entire mollusk shells at various stages of development, observing a previously
unknown relationship between the growth of the mollusk and tablet thickness.
Our rapid, inexpensive, and nondestructive method can be readily applied to
in-field studies.
","Jad Salman, Cayla A. Stifler, Alireza Shahsafi, Chang-Yu Sun, Steve Weibel, Michel Frising, Bryan E. Rubio-Perez, Yuzhe Xiao, Christopher Draves, Raymond A. Wambold, Zhaoning Yu, Daniel C. Bradley, Gabor Kemeny, Pupa U. P. A. Gilbert, Mikhail A. Kats",Mikhail A. Kats,2020-10-16T05:15:14Z
"Multimodal Remote Sensing Benchmark Datasets for Land Cover
  Classification with A Shared and Specific Feature Learning Model","  As remote sensing (RS) data obtained from different sensors become available
largely and openly, multimodal data processing and analysis techniques have
been garnering increasing interest in the RS and geoscience community. However,
due to the gap between different modalities in terms of imaging sensors,
resolutions, and contents, embedding their complementary information into a
consistent, compact, accurate, and discriminative representation, to a great
extent, remains challenging. To this end, we propose a shared and specific
feature learning (S2FL) model. S2FL is capable of decomposing multimodal RS
data into modality-shared and modality-specific components, enabling the
information blending of multi-modalities more effectively, particularly for
heterogeneous data sources. Moreover, to better assess multimodal baselines and
the newly-proposed S2FL model, three multimodal RS benchmark datasets, i.e.,
Houston2013 -- hyperspectral and multispectral data, Berlin -- hyperspectral
and synthetic aperture radar (SAR) data, Augsburg -- hyperspectral, SAR, and
digital surface model (DSM) data, are released and used for land cover
classification. Extensive experiments conducted on the three datasets
demonstrate the superiority and advancement of our S2FL model in the task of
land cover classification in comparison with previously-proposed
state-of-the-art baselines. Furthermore, the baseline codes and datasets used
in this paper will be made available freely at
https://github.com/danfenghong/ISPRS_S2FL.
","Danfeng Hong, Jingliang Hu, Jing Yao, Jocelyn Chanussot, Xiao Xiang Zhu",Xiao Xiang Zhu,2021-05-21T08:14:21Z
"Sparse Linear Spectral Unmixing of Hyperspectral images using
  Expectation-Propagation","  This paper presents a novel Bayesian approach for hyperspectral image
unmixing. The observed pixels are modeled by a linear combination of material
signatures weighted by their corresponding abundances. A spike-and-slab
abundance prior is adopted to promote sparse mixtures and an Ising prior model
is used to capture spatial correlation of the mixture support across pixels. We
approximate the posterior distribution of the abundances using the
expectation-propagation (EP) method. We show that it can significantly reduce
the computational complexity of the unmixing stage and meanwhile provide
uncertainty measures, compared to expensive Monte Carlo strategies
traditionally considered for uncertainty quantification. Moreover, many
variational parameters within each EP factor can be updated in a parallel
manner, which enables mapping of efficient algorithmic architectures based on
graphics processing units (GPU). Under the same approximate Bayesian framework,
we then extend the proposed algorithm to semi-supervised unmixing, whereby the
abundances are viewed as latent variables and the expectation-maximization (EM)
algorithm is used to refine the endmember matrix. Experimental results on
synthetic data and real hyperspectral data illustrate the benefits of the
proposed framework over state-of-art linear unmixing methods.
","Zeng Li, Yoann Altmann, Jie Chen, Stephen Mclaughlin, Susanto Rahardja",Susanto Rahardja,2021-06-18T08:14:41Z
"High Performance Hyperspectral Image Classification using Graphics
  Processing Units","  Real-time remote sensing applications like search and rescue missions,
military target detection, environmental monitoring, hazard prevention and
other time-critical applications require onboard real time processing
capabilities or autonomous decision making. Some unmanned remote systems like
satellites are physically remote from their operators, and all control of the
spacecraft and data returned by the spacecraft must be transmitted over a
wireless radio link. This link may not be available for extended periods when
the satellite is out of line of sight of its ground station. Therefore,
lightweight, small size and low power consumption hardware is essential for
onboard real time processing systems. With increasing dimensionality, size and
resolution of recent hyperspectral imaging sensors, additional challenges are
posed upon remote sensing processing systems and more capable computing
architectures are needed. Graphical Processing Units (GPUs) emerged as
promising architecture for light weight high performance computing that can
address these computational requirements for onboard systems. The goal of this
study is to build high performance methods for onboard hyperspectral analysis.
We propose accelerated methods for the well-known recursive hierarchical
segmentation (RHSEG) clustering method, using GPUs, hybrid multicore CPU with a
GPU and hybrid multi-core CPU/GPU clusters. RHSEG is a method developed by the
National Aeronautics and Space Administration (NASA), which is designed to
provide rich classification information with several output levels. The
achieved speedups by parallel solutions compared to CPU sequential
implementations are 21x for parallel single GPU and 240x for hybrid multi-node
computer clusters with 16 computing nodes. The energy consumption is reduced to
74% using a single GPU compared to the equivalent parallel CPU cluster.
",Mahmoud Hossam,Mahmoud Hossam,2021-05-30T09:26:03Z
"Generalized Unsupervised Clustering of Hyperspectral Images of
  Geological Targets in the Near Infrared","  The application of infrared hyperspectral imagery to geological problems is
becoming more popular as data become more accessible and cost-effective.
Clustering and classifying spectrally similar materials is often a first step
in applications ranging from economic mineral exploration on Earth to planetary
exploration on Mars. Semi-manual classification guided by expertly developed
spectral parameters can be time consuming and biased, while supervised methods
require abundant labeled data and can be difficult to generalize. Here we
develop a fully unsupervised workflow for feature extraction and clustering
informed by both expert spectral geologist input and quantitative metrics. Our
pipeline uses a lightweight autoencoder followed by Gaussian mixture modeling
to map the spectral diversity within any image. We validate the performance of
our pipeline at submillimeter-scale with expert-labelled data from the Oman
ophiolite drill core and evaluate performance at meters-scale with partially
classified orbital data of Jezero Crater on Mars (the landing site for the
Perseverance rover). We additionally examine the effects of various
preprocessing techniques used in traditional analysis of hyperspectral imagery.
This pipeline provides a fast and accurate clustering map of similar geological
materials and consistently identifies and separates major mineral classes in
both laboratory imagery and remote sensing imagery. We refer to our pipeline as
""Generalized Pipeline for Spectroscopic Unsupervised clustering of Minerals
(GyPSUM).""
","Angela F. Gao, Brandon Rasmussen, Peter Kulits, Eva L. Scheller, Rebecca Greenberger, Bethany L. Ehlmann",Bethany L. Ehlmann,2021-06-24T21:05:10Z
"Ill-posed Surface Emissivity Retrieval from Multi-Geometry Hyperspectral
  Images using a Hybrid Deep Neural Network","  Atmospheric correction is a fundamental task in remote sensing because
observations are taken either of the atmosphere or looking through the
atmosphere. Atmospheric correction errors can significantly alter the spectral
signature of the observations, and lead to invalid classifications or target
detection. This is even more crucial when working with hyperspectral data,
where a precise measurement of spectral properties is required.
State-of-the-art physics-based atmospheric correction approaches require
extensive prior knowledge about sensor characteristics, collection geometry,
and environmental characteristics of the scene being collected. These
approaches are computationally expensive, prone to inaccuracy due to lack of
sufficient environmental and collection information, and often impossible for
real-time applications. In this paper, a geometry-dependent hybrid neural
network is proposed for automatic atmospheric correction using multi-scan
hyperspectral data collected from different geometries. The proposed network
can characterize the atmosphere without any additional meteorological data. A
grid-search method is also proposed to solve the temperature emissivity
separation problem. Results show that the proposed network has the capacity to
accurately characterize the atmosphere and estimate target emissivity spectra
with a Mean Absolute Error (MAE) under 0.02 for 29 different materials. This
solution can lead to accurate atmospheric correction to improve target
detection for real time applications.
","Fangcao Xu, Jian Sun, Guido Cervone, Mark Salvador",Mark Salvador,2021-07-09T18:59:58Z
"A Novel CropdocNet for Automated Potato Late Blight Disease Detection
  from the Unmanned Aerial Vehicle-based Hyperspectral Imagery","  Late blight disease is one of the most destructive diseases in potato crop,
leading to serious yield losses globally. Accurate diagnosis of the disease at
early stage is critical for precision disease control and management. Current
farm practices in crop disease diagnosis are based on manual visual inspection,
which is costly, time consuming, subject to individual bias. Recent advances in
imaging sensors (e.g. RGB, multiple spectral and hyperspectral cameras), remote
sensing and machine learning offer the opportunity to address this challenge.
Particularly, hyperspectral imagery (HSI) combining with machine learning/deep
learning approaches is preferable for accurately identifying specific plant
diseases because the HSI consists of a wide range of high-quality reflectance
information beyond human vision, capable of capturing both spectral-spatial
information. The proposed method considers the potential disease specific
reflectance radiation variance caused by the canopy structural diversity,
introduces the multiple capsule layers to model the hierarchical structure of
the spectral-spatial disease attributes with the encapsulated features to
represent the various classes and the rotation invariance of the disease
attributes in the feature space. We have evaluated the proposed method with the
real UAV-based HSI data under the controlled field conditions. The
effectiveness of the hierarchical features has been quantitatively assessed and
compared with the existing representative machine learning/deep learning
methods. The experiment results show that the proposed model significantly
improves the accuracy performance when considering hierarchical-structure of
spectral-spatial features, comparing to the existing methods only using
spectral, or spatial or spectral-spatial features without consider
hierarchical-structure of spectral-spatial features.
","Yue Shi, Liangxiu Han, Anthony Kleerekoper, Sheng Chang, Tongle Hu",Tongle Hu,2021-07-28T11:18:48Z
"Conditional Random Field and Deep Feature Learning for Hyperspectral
  Image Segmentation","  Image segmentation is considered to be one of the critical tasks in
hyperspectral remote sensing image processing. Recently, convolutional neural
network (CNN) has established itself as a powerful model in segmentation and
classification by demonstrating excellent performances. The use of a graphical
model such as a conditional random field (CRF) contributes further in capturing
contextual information and thus improving the segmentation performance. In this
paper, we propose a method to segment hyperspectral images by considering both
spectral and spatial information via a combined framework consisting of CNN and
CRF. We use multiple spectral cubes to learn deep features using CNN, and then
formulate deep CRF with CNN-based unary and pairwise potential functions to
effectively extract the semantic correlations between patches consisting of
three-dimensional data cubes. Effective piecewise training is applied in order
to avoid the computationally expensive iterative CRF inference. Furthermore, we
introduce a deep deconvolution network that improves the segmentation masks. We
also introduce a new dataset and experimented our proposed method on it along
with several widely adopted benchmark datasets to evaluate the effectiveness of
our method. By comparing our results with those from several state-of-the-art
models, we show the promising potential of our method.
","Fahim Irfan Alam, Jun Zhou, Alan Wee-Chung Liew, Xiuping Jia, Jocelyn Chanussot, Yongsheng Gao",Yongsheng Gao,2017-11-13T09:18:25Z
"Unsupervised Sparse Dirichlet-Net for Hyperspectral Image
  Super-Resolution","  In many computer vision applications, obtaining images of high resolution in
both the spatial and spectral domains are equally important. However, due to
hardware limitations, one can only expect to acquire images of high resolution
in either the spatial or spectral domains. This paper focuses on hyperspectral
image super-resolution (HSI-SR), where a hyperspectral image (HSI) with low
spatial resolution (LR) but high spectral resolution is fused with a
multispectral image (MSI) with high spatial resolution (HR) but low spectral
resolution to obtain HR HSI. Existing deep learning-based solutions are all
supervised that would need a large training set and the availability of HR HSI,
which is unrealistic. Here, we make the first attempt to solving the HSI-SR
problem using an unsupervised encoder-decoder architecture that carries the
following uniquenesses. First, it is composed of two encoder-decoder networks,
coupled through a shared decoder, in order to preserve the rich spectral
information from the HSI network. Second, the network encourages the
representations from both modalities to follow a sparse Dirichlet distribution
which naturally incorporates the two physical constraints of HSI and MSI.
Third, the angular difference between representations are minimized in order to
reduce the spectral distortion. We refer to the proposed architecture as
unsupervised Sparse Dirichlet-Net, or uSDN. Extensive experimental results
demonstrate the superior performance of uSDN as compared to the
state-of-the-art.
","Ying Qu, Hairong Qi, Chiman Kwan",Chiman Kwan,2018-04-13T17:17:05Z
Hyperspectral Super-Resolution: A Coupled Tensor Factorization Approach,"  Hyperspectral super-resolution refers to the problem of fusing a
hyperspectral image (HSI) and a multispectral image (MSI) to produce a
super-resolution image (SRI) that has fine spatial and spectral resolution.
State-of-the-art methods approach the problem via low-rank matrix
approximations to the matricized HSI and MSI. These methods are effective to
some extent, but a number of challenges remain. First, HSIs and MSIs are
naturally third-order tensors (data ""cubes"") and thus matricization is prone to
loss of structural information--which could degrade performance. Second, it is
unclear whether or not these low-rank matrix-based fusion strategies can
guarantee identifiability or exact recovery of the SRI. However,
identifiability plays a pivotal role in estimation problems and usually has a
significant impact on performance in practice. Third, the majority of the
existing methods assume that there are known (or easily estimated) degradation
operators applied to the SRI to form the corresponding HSI and MSI--which is
hardly the case in practice. In this work, we propose to tackle the
super-resolution problem from a tensor perspective. Specifically, we utilize
the multidimensional structure of the HSI and MSI to propose a coupled tensor
factorization framework that can effectively overcome the aforementioned
issues. The proposed approach guarantees the identifiability of the SRI under
mild and realistic conditions. Furthermore, it works with little knowledge of
the degradation operators, which is clearly an advantage over the existing
methods. Semi-real numerical experiments are included to show the effectiveness
of the proposed approach.
","Charilaos I. Kanatsoulis, Xiao Fu, Nicholas D. Sidiropoulos, Wing-Kin Ma",Wing-Kin Ma,2018-04-15T05:53:24Z
"Randomized ICA and LDA Dimensionality Reduction Methods for
  Hyperspectral Image Classification","  Dimensionality reduction is an important step in processing the hyperspectral
images (HSI) to overcome the curse of dimensionality problem. Linear
dimensionality reduction methods such as Independent component analysis (ICA)
and Linear discriminant analysis (LDA) are commonly employed to reduce the
dimensionality of HSI. These methods fail to capture non-linear dependency in
the HSI data, as data lies in the nonlinear manifold. To handle this, nonlinear
transformation techniques based on kernel methods were introduced for
dimensionality reduction of HSI. However, the kernel methods involve cubic
computational complexity while computing the kernel matrix, and thus its
potential cannot be explored when the number of pixels (samples) are large. In
literature a fewer number of pixels are randomly selected to partial to
overcome this issue, however this sub-optimal strategy might neglect important
information in the HSI. In this paper, we propose randomized solutions to the
ICA and LDA dimensionality reduction methods using Random Fourier features, and
we label them as RFFICA and RFFLDA. Our proposed method overcomes the
scalability issue and to handle the non-linearities present in the data more
efficiently. Experiments conducted with two real-world hyperspectral datasets
demonstrates that our proposed randomized methods outperform the conventional
kernel ICA and kernel LDA in terms overall, per-class accuracies and
computational time.
","Chippy Jayaprakash, Bharath Bhushan Damodaran, Sowmya V, K P Soman",K P Soman,2018-04-19T19:36:08Z
"Locality and Structure Regularized Low Rank Representation for
  Hyperspectral Image Classification","  Hyperspectral image (HSI) classification, which aims to assign an accurate
label for hyperspectral pixels, has drawn great interest in recent years.
Although low rank representation (LRR) has been used to classify HSI, its
ability to segment each class from the whole HSI data has not been exploited
fully yet. LRR has a good capacity to capture the underlying lowdimensional
subspaces embedded in original data. However, there are still two drawbacks for
LRR. First, LRR does not consider the local geometric structure within data,
which makes the local correlation among neighboring data easily ignored.
Second, the representation obtained by solving LRR is not discriminative enough
to separate different data. In this paper, a novel locality and structure
regularized low rank representation (LSLRR) model is proposed for HSI
classification. To overcome the above limitations, we present locality
constraint criterion (LCC) and structure preserving strategy (SPS) to improve
the classical LRR. Specifically, we introduce a new distance metric, which
combines both spatial and spectral features, to explore the local similarity of
pixels. Thus, the global and local structures of HSI data can be exploited
sufficiently. Besides, we propose a structure constraint to make the
representation have a near block-diagonal structure. This helps to determine
the final classification labels directly. Extensive experiments have been
conducted on three popular HSI datasets. And the experimental results
demonstrate that the proposed LSLRR outperforms other state-of-the-art methods.
","Qi Wang, Xiange He, Xuelong Li",Xuelong Li,2019-05-07T12:05:52Z
"Spatial-Spectral Feature Extraction via Deep ConvLSTM Neural Networks
  for Hyperspectral Image Classification","  In recent years, deep learning has presented a great advance in hyperspectral
image (HSI) classification. Particularly, long short-term memory (LSTM), as a
special deep learning structure, has shown great ability in modeling long-term
dependencies in the time dimension of video or the spectral dimension of HSIs.
However, the loss of spatial information makes it quite difficult to obtain the
better performance. In order to address this problem, two novel deep models are
proposed to extract more discriminative spatial-spectral features by exploiting
the Convolutional LSTM (ConvLSTM). By taking the data patch in a local sliding
window as the input of each memory cell band by band, the 2-D extended
architecture of LSTM is considered for building the spatial-spectral ConvLSTM
2-D Neural Network (SSCL2DNN) to model long-range dependencies in the spectral
domain. To better preserve the intrinsic structure information of the
hyperspectral data, the spatial-spectral ConvLSTM 3-D Neural Network (SSCL3DNN)
is proposed by extending LSTM to 3-D version for further improving the
classification performance. The experiments, conducted on three commonly used
HSI data sets, demonstrate that the proposed deep models have certain
competitive advantages and can provide better classification performance than
other state-of-the-art approaches.
","Wen-Shuai Hu, Heng-Chao Li, Lei Pan, Wei Li, Ran Tao, Qian Du",Qian Du,2019-05-09T12:43:11Z
"Collection of micromirror-modulated light in the single-pixel broadband
  hyperspectral microscope","  Digital micromirror device (DMD) serves in a significant part of
computational optical setups as a means of encoding an image by the desired
pattern. The most prominent is its usage in the so-called single-pixel camera
experiment. This experiment often requires an efficient and homogenous
collection of light from a relatively large chip on a small area of an optical
fiber or spectrometer slit. Moreover, this effort is complicated by the fact
that the DMD acts as a diffractive element, which causes severe spectral
inhomogeneities in the light collection. We studied the effect of light
diffraction via a whiskbroom hyperspectral camera in a broad spectral range.
Based on the knowledge, we designed a variety of different approaches to light
collection. We mapped the efficiency and spectral homogeneity of each of the
configuration - namely its ability to couple the light into commercially
available fiber spectrometers working in the visible and IR range (up to 2500
nm). We found the integrating spheres to provide homogeneous light collection,
which, however, suffers from very low efficiency. The best compromise between
the performance parameters was provided by a combination of an engineered
diffuser with an off-axis parabolic mirror. We used this configuration to
create a computational microscope able to carry out hyperspectral imaging of a
sample in a broad spectral range (400-2500 nm). We see such a setup as an ideal
tool to carry out spectrally-resolved transmission microscopy in a broad
spectral range.
","Lukas Klein, Karel Zidek",Karel Zidek,2020-01-20T10:44:48Z
Classification of Hyperspectral and LiDAR Data Using Coupled CNNs,"  In this paper, we propose an efficient and effective framework to fuse
hyperspectral and Light Detection And Ranging (LiDAR) data using two coupled
convolutional neural networks (CNNs). One CNN is designed to learn
spectral-spatial features from hyperspectral data, and the other one is used to
capture the elevation information from LiDAR data. Both of them consist of
three convolutional layers, and the last two convolutional layers are coupled
together via a parameter sharing strategy. In the fusion phase, feature-level
and decision-level fusion methods are simultaneously used to integrate these
heterogeneous features sufficiently. For the feature-level fusion, three
different fusion strategies are evaluated, including the concatenation
strategy, the maximization strategy, and the summation strategy. For the
decision-level fusion, a weighted summation strategy is adopted, where the
weights are determined by the classification accuracy of each output. The
proposed model is evaluated on an urban data set acquired over Houston, USA,
and a rural one captured over Trento, Italy. On the Houston data, our model can
achieve a new record overall accuracy of 96.03%. On the Trento data, it
achieves an overall accuracy of 99.12%. These results sufficiently certify the
effectiveness of our proposed model.
","Renlong Hang, Zhu Li, Pedram Ghamisi, Danfeng Hong, Guiyu Xia, Qingshan Liu",Qingshan Liu,2020-02-04T06:23:36Z
"Hierarchical Regression Network for Spectral Reconstruction from RGB
  Images","  Capturing visual image with a hyperspectral camera has been successfully
applied to many areas due to its narrow-band imaging technology. Hyperspectral
reconstruction from RGB images denotes a reverse process of hyperspectral
imaging by discovering an inverse response function. Current works mainly map
RGB images directly to corresponding spectrum but do not consider context
information explicitly. Moreover, the use of encoder-decoder pair in current
algorithms leads to loss of information. To address these problems, we propose
a 4-level Hierarchical Regression Network (HRNet) with PixelShuffle layer as
inter-level interaction. Furthermore, we adopt a residual dense block to remove
artifacts of real world RGB images and a residual global block to build
attention mechanism for enlarging perceptive field. We evaluate proposed HRNet
with other architectures and techniques by participating in NTIRE 2020
Challenge on Spectral Reconstruction from RGB Images. The HRNet is the winning
method of track 2 - real world images and ranks 3rd on track 1 - clean images.
Please visit the project web page
https://github.com/zhaoyuzhi/Hierarchical-Regression-Network-for-Spectral-Reconstruction-from-RGB-Images
to try our codes and pre-trained models.
","Yuzhi Zhao, Lai-Man Po, Qiong Yan, Wei Liu, Tingyu Lin",Tingyu Lin,2020-05-10T16:06:11Z
"Restoring the night sky darkness at Observatorio del Teide: First
  application of the model Illumina version 2","  The propagation of artificial light into real environments is complex. To
perform its numerical modelling with accuracy one must consider hyperspectral
properties of the lighting devices and their geographic positions, the
hyperspectral properties of the ground reflectance, the size and distribution
of small-scale obstacles, the blocking effect of topography, the lamps angular
photometry and the atmospheric transfer function (aerosols and molecules). A
detailed radiative transfer model can be used to evaluate how a particular
change in the lighting infrastructure may affect the sky radiance.
  In this paper, we use the new version (v2) of the Illumina model to evaluate
a night sky restoration plan for the Teide Observatory located on the island of
Tenerife, Spain. In the past decades, the sky darkness was severely degraded by
growing light pollution on the Tenerife Island. In this work, we use the
contribution maps giving the effect of each pixel of the territory to the
artificial sky radiance. We exploit the hyperspectral capabilities of Illumina
v2 and show how the contribution maps can be integrated over regions or
municipalities according to the Johnson-Cousins photometric bands spectral
sensitivities. The sky brightness reductions per municipality after a complete
shutdown and a conversion to Light-Emitting Diodes are calculated in the
Johnson-Cousins B, V, R bands. We found that the conversion of the lighting
infrastructure of Tenerife with LED (1800K and 2700K), according to the
conversion strategy in force, would result in a zenith V band sky brightness
reduction of about 0.3 mag arcsec-2.
","Martin Aubé, Alexandre Simoneau, Casiana Munoz-Tunon, Javier Diaz-Castro, Miquel Serra-Ricart",Miquel Serra-Ricart,2020-05-28T17:20:47Z
"Hyperspectral Super-Resolution via Interpretable Block-Term Tensor
  Modeling","  This work revisits coupled tensor decomposition (CTD)-based hyperspectral
super-resolution (HSR). HSR aims at fusing a pair of hyperspectral and
multispectral images to recover a super-resolution image (SRI). The vast
majority of the HSR approaches take a low-rank matrix recovery perspective. The
challenge is that theoretical guarantees for recovering the SRI using low-rank
matrix models are either elusive or derived under stringent conditions. A
couple of recent CTD-based methods ensure recoverability for the SRI under
relatively mild conditions, leveraging on algebraic properties of the canonical
polyadic decomposition (CPD) and the Tucker decomposition models, respectively.
However, the latent factors of both the CPD and Tucker models have no physical
interpretations in the context of spectral image analysis, which makes
incorporating prior information challenging---but using priors is often
essential for enhancing performance in noisy environments. This work employs an
idea that models spectral images as tensors following the block-term
decomposition model with multilinear rank-$(L_r, L_r, 1)$ terms (i.e., the LL1
model) and formulates the HSR problem as a coupled LL1 tensor decomposition
problem. Similar to the existing CTD approaches, recoverability of the SRI is
shown under mild conditions. More importantly, the latent factors of the LL1
model can be interpreted as the key constituents of spectral images, i.e., the
endmembers' spectral signatures and abundance maps. This connection allows us
to easily incorporate prior information for performance enhancement. A flexible
algorithmic framework that can work with a series of structural information is
proposed to take advantage of the model interpretability. The effectiveness is
showcased using simulated and real data.
","Meng Ding, Xiao Fu, Ting-Zhu Huang, Jun Wang, Xi-Le Zhao",Xi-Le Zhao,2020-06-18T03:05:01Z
"Exploring Cross-Domain Pretrained Model for Hyperspectral Image
  Classification","  A pretrain-finetune strategy is widely used to reduce the overfitting that
can occur when data is insufficient for CNN training. First few layers of a CNN
pretrained on a large-scale RGB dataset are capable of acquiring general image
characteristics which are remarkably effective in tasks targeted for different
RGB datasets. However, when it comes down to hyperspectral domain where each
domain has its unique spectral properties, the pretrain-finetune strategy no
longer can be deployed in a conventional way while presenting three major
issues: 1) inconsistent spectral characteristics among the domains (e.g.,
frequency range), 2) inconsistent number of data channels among the domains,
and 3) absence of large-scale hyperspectral dataset.
  We seek to train a universal cross-domain model which can later be deployed
for various spectral domains. To achieve, we physically furnish multiple inlets
to the model while having a universal portion which is designed to handle the
inconsistent spectral characteristics among different domains. Note that only
the universal portion is used in the finetune process. This approach naturally
enables the learning of our model on multiple domains simultaneously which acts
as an effective workaround for the issue of the absence of large-scale dataset.
  We have carried out a study to extensively compare models that were trained
using cross-domain approach with ones trained from scratch. Our approach was
found to be superior both in accuracy and in training efficiency. In addition,
we have verified that our approach effectively reduces the overfitting issue,
enabling us to deepen the model up to 13 layers (from 9) without compromising
the accuracy.
","Hyungtae Lee, Sungmin Eum, Heesung Kwon",Heesung Kwon,2022-04-07T01:09:42Z
"GAF-NAU: Gramian Angular Field encoded Neighborhood Attention U-Net for
  Pixel-Wise Hyperspectral Image Classification","  Hyperspectral image (HSI) classification is the most vibrant area of research
in the hyperspectral community due to the rich spectral information contained
in HSI can greatly aid in identifying objects of interest. However, inherent
non-linearity between materials and the corresponding spectral profiles brings
two major challenges in HSI classification: interclass similarity and
intraclass variability. Many advanced deep learning methods have attempted to
address these issues from the perspective of a region/patch-based approach,
instead of a pixel-based alternate. However, the patch-based approaches
hypothesize that neighborhood pixels of a target pixel in a fixed spatial
window belong to the same class. And this assumption is not always true. To
address this problem, we herein propose a new deep learning architecture,
namely Gramian Angular Field encoded Neighborhood Attention U-Net (GAF-NAU),
for pixel-based HSI classification. The proposed method does not require
regions or patches centered around a raw target pixel to perform 2D-CNN based
classification, instead, our approach transforms 1D pixel vector in HSI into 2D
angular feature space using Gramian Angular Field (GAF) and then embed it to a
new neighborhood attention network to suppress irrelevant angular feature while
emphasizing on pertinent features useful for HSI classification task.
Evaluation results on three publicly available HSI datasets demonstrate the
superior performance of the proposed model.
","Sidike Paheding, Abel A. Reyes, Anush Kasaragod, Thomas Oommen",Thomas Oommen,2022-04-21T13:45:18Z
Weighted Low-rank Tensor Recovery for Hyperspectral Image Restoration,"  Hyperspectral imaging, providing abundant spatial and spectral information
simultaneously, has attracted a lot of interest in recent years. Unfortunately,
due to the hardware limitations, the hyperspectral image (HSI) is vulnerable to
various degradations, such noises (random noise, HSI denoising), blurs
(Gaussian and uniform blur, HSI deblurring), and down-sampled (both spectral
and spatial downsample, HSI super-resolution). Previous HSI restoration methods
are designed for one specific task only. Besides, most of them start from the
1-D vector or 2-D matrix models and cannot fully exploit the structurally
spectral-spatial correlation in 3-D HSI. To overcome these limitations, in this
work, we propose a unified low-rank tensor recovery model for comprehensive HSI
restoration tasks, in which non-local similarity between spectral-spatial cubic
and spectral correlation are simultaneously captured by 3-order tensors.
Further, to improve the capability and flexibility, we formulate it as a
weighted low-rank tensor recovery (WLRTR) model by treating the singular values
differently, and study its analytical solution. We also consider the exclusive
stripe noise in HSI as the gross error by extending WLRTR to robust principal
component analysis (WLRTR-RPCA). Extensive experiments demonstrate the proposed
WLRTR models consistently outperform state-of-the-arts in typical low level
vision HSI tasks, including denoising, destriping, deblurring and
super-resolution.
","Yi Chang, Luxin Yan, Houzhang Fang, Sheng Zhong, Zhijun Zhang",Zhijun Zhang,2017-09-01T07:58:34Z
"A Tutorial on Modeling and Inference in Undirected Graphical Models for
  Hyperspectral Image Analysis","  Undirected graphical models have been successfully used to jointly model the
spatial and the spectral dependencies in earth observing hyperspectral images.
They produce less noisy, smooth, and spatially coherent land cover maps and
give top accuracies on many datasets. Moreover, they can easily be combined
with other state-of-the-art approaches, such as deep learning. This has made
them an essential tool for remote sensing researchers and practitioners.
However, graphical models have not been easily accessible to the larger remote
sensing community as they are not discussed in standard remote sensing
textbooks and not included in the popular remote sensing software and
toolboxes. In this tutorial, we provide a theoretical introduction to Markov
random fields and conditional random fields based spatial-spectral
classification for land cover mapping along with a detailed step-by-step
practical guide on applying these methods using freely available software.
Furthermore, the discussed methods are benchmarked on four public hyperspectral
datasets for a fair comparison among themselves and easy comparison with the
vast number of methods in literature which use the same datasets. The source
code necessary to reproduce all the results in the paper is published on-line
to make it easier for the readers to apply these techniques to different remote
sensing problems.
","Utsav B. Gewali, Sildomar T. Monteiro",Sildomar T. Monteiro,2018-01-25T03:44:43Z
"A CNN-based Spatial Feature Fusion Algorithm for Hyperspectral Imagery
  Classification","  The shortage of training samples remains one of the main obstacles in
applying the artificial neural networks (ANN) to the hyperspectral images
classification. To fuse the spatial and spectral information, pixel patches are
often utilized to train a model, which may further aggregate this problem. In
the existing works, an ANN model supervised by center-loss (ANNC) was
introduced. Training merely with spectral information, the ANNC yields
discriminative spectral features suitable for the subsequent classification
tasks. In this paper, a CNN-based spatial feature fusion (CSFF) algorithm is
proposed, which allows a smart fusion of the spatial information to the
spectral features extracted by ANNC. As a critical part of CSFF, a CNN-based
discriminant model is introduced to estimate whether two paring pixels belong
to the same class. At the testing stage, by applying the discriminant model to
the pixel-pairs generated by the test pixel and its neighbors, the local
structure is estimated and represented as a customized convolutional kernel.
The spectral-spatial feature is obtained by a convolutional operation between
the estimated kernel and the corresponding spectral features within a
neighborhood. At last, the label of the test pixel is predicted by classifying
the resulting spectral-spatial feature. Without increasing the number of
training samples or involving pixel patches at the training stage, the CSFF
framework achieves the state-of-the-art by declining $20\%-50\%$ classification
failures in experiments on three well-known hyperspectral images.
","Alan J. X. Guo, Fei Zhu",Fei Zhu,2018-01-31T08:57:10Z
"Differentiable Programming for Hyperspectral Unmixing using a
  Physics-based Dispersion Model","  Hyperspectral unmixing is an important remote sensing task with applications
including material identification and analysis. Characteristic spectral
features make many pure materials identifiable from their visible-to-infrared
spectra, but quantifying their presence within a mixture is a challenging task
due to nonlinearities and factors of variation. In this paper, spectral
variation is considered from a physics-based approach and incorporated into an
end-to-end spectral unmixing algorithm via differentiable programming. The
dispersion model is introduced to simulate realistic spectral variation, and an
efficient method to fit the parameters is presented. Then, this dispersion
model is utilized as a generative model within an analysis-by-synthesis
spectral unmixing algorithm. Further, a technique for inverse rendering using a
convolutional neural network to predict parameters of the generative model is
introduced to enhance performance and speed when training data is available.
Results achieve state-of-the-art on both infrared and visible-to-near-infrared
(VNIR) datasets, and show promise for the synergy between physics-based models
and deep learning in hyperspectral unmixing in the future.
","John Janiczek, Parth Thaker, Gautam Dasarathy, Christopher S. Edwards, Philip Christensen, Suren Jayasuriya",Suren Jayasuriya,2020-07-12T14:16:35Z
"Fast Hyperspectral Image Recovery via Non-iterative Fusion of
  Dual-Camera Compressive Hyperspectral Imaging","  Coded aperture snapshot spectral imaging (CASSI) is a promising technique to
capture the three-dimensional hyperspectral image (HSI) using a single coded
two-dimensional (2D) measurement, in which algorithms are used to perform the
inverse problem. Due to the ill-posed nature, various regularizers have been
exploited to reconstruct the 3D data from the 2D measurement. Unfortunately,
the accuracy and computational complexity are unsatisfied. One feasible
solution is to utilize additional information such as the RGB measurement in
CASSI. Considering the combined CASSI and RGB measurement, in this paper, we
propose a new fusion model for the HSI reconstruction. We investigate the
spectral low-rank property of HSI composed of a spectral basis and spatial
coefficients. Specifically, the RGB measurement is utilized to estimate the
coefficients, meanwhile the CASSI measurement is adopted to provide the
orthogonal spectral basis. We further propose a patch processing strategy to
enhance the spectral low-rank property of HSI. The proposed model neither
requires non-local processing or iteration, nor the spectral sensing matrix of
the RGB detector. Extensive experiments on both simulated and real HSI dataset
demonstrate that our proposed method outperforms previous state-of-the-art not
only in quality but also speeds up the reconstruction more than 5000 times.
","Wei He, Naoto Yokoya, Xin Yuan",Xin Yuan,2020-12-30T10:29:32Z
"Ensemble and Random Collaborative Representation-Based Anomaly Detector
  for Hyperspectral Imagery","  In recent years, hyperspectral anomaly detection (HAD) has become an active
topic and plays a significant role in military and civilian fields. As a
classic HAD method, the collaboration representation-based detector (CRD) has
attracted extensive attention and in-depth research. Despite the good
performance of the CRD method, its computational cost mainly arising from the
sliding dual window strategy is too high for wide applications. Moreover, it
takes multiple repeated tests to determine the size of the dual window, which
needs to be reset once the dataset changes and cannot be identified in advance
with prior knowledge. To alleviate this problem, we proposed a novel ensemble
and random collaborative representation-based detector (ERCRD) for HAD, which
comprises two closely related stages. Firstly, we process the random
sub-sampling on CRD (RCRD) to gain several detection results instead of the
sliding dual window strategy, which significantly reduces the computational
complexity and makes it more feasible in practical applications. Secondly,
ensemble learning is employed to refine the multiple results of RCRD, which act
as various ""experts"" providing abundant complementary information to better
target different anomalies. Such two stages form an organic and theoretical
detector, which can not only improve the accuracy and stability of HAD methods
but also enhance its generalization ability. Experiments on four real
hyperspectral datasets exhibit the accuracy and efficiency of this proposed
ERCRD method compared with ten state-of-the-art HAD methods.
","Rong Wang, Yihang Lu, Qianrong Zhang, Feiping Nie, Zhen Wang, Xuelong Li",Xuelong Li,2021-01-06T11:23:51Z
"Hyperspectral Pigment Analysis of Cultural Heritage Artifacts Using the
  Opaque Form of Kubelka-Munk Theory","  Kubelka-Munk (K-M) theory has been successfully used to estimate pigment
concentrations in the pigment mixtures of modern paintings in spectral imagery.
In this study the single-constant K-M theory has been utilized for the
classification of green pigments in the Selden Map of China, a navigational map
of the South China Sea likely created in the early seventeenth century.
Hyperspectral data of the map was collected at the Bodleian Library, University
of Oxford, and can be used to estimate the pigment diversity, and spatial
distribution, within the map. This work seeks to assess the utility of
analyzing the data in the K/S space from Kubelka-Munk theory, as opposed to the
traditional reflectance domain. We estimate the dimensionality of the data and
extract endmembers in the reflectance domain. Then we perform linear unmixing
to estimate abundances in the K/S space, and following Bai, et al. (2017), we
perform a classification in the abundance space. Finally, due to the lack of
ground truth labels, the classification accuracy was estimated by computing the
mean spectrum of each class as the representative signature of that class, and
calculating the root mean squared error with all the pixels in that class to
create a spatial representation of the error. This highlights both the
magnitude of, and any spatial pattern in, the errors, indicating if a
particular pigment is not well modeled in this approach.
","Abu Md Niamul Taufique, David W. Messinger",David W. Messinger,2021-04-11T00:22:37Z
"Semi-supervised Superpixel-based Multi-Feature Graph Learning for
  Hyperspectral Image Data","  Graphs naturally lend themselves to model the complexities of Hyperspectral
Image (HSI) data as well as to serve as semi-supervised classifiers by
propagating given labels among nearest neighbours. In this work, we present a
novel framework for the classification of HSI data in light of a very limited
amount of labelled data, inspired by multi-view graph learning and graph signal
processing. Given an a priori superpixel-segmented hyperspectral image, we seek
a robust and efficient graph construction and label propagation method to
conduct semi-supervised learning (SSL). Since the graph is paramount to the
success of the subsequent classification task, particularly in light of the
intrinsic complexity of HSI data, we consider the problem of finding the
optimal graph to model such data. Our contribution is two-fold: firstly, we
propose a multi-stage edge-efficient semi-supervised graph learning framework
for HSI data which exploits given label information through pseudo-label
features embedded in the graph construction. Secondly, we examine and enhance
the contribution of multiple superpixel features embedded in the graph on the
basis of pseudo-labels in an extension of the previous framework, which is less
reliant on excessive parameter tuning. Ultimately, we demonstrate the
superiority of our approaches in comparison with state-of-the-art methods
through extensive numerical experiments.
","Madeleine Kotzagiannidis, Carola-Bibiane Schönlieb",Carola-Bibiane Schönlieb,2021-04-27T15:36:26Z
"MSHCNet: Multi-Stream Hybridized Convolutional Networks with Mixed
  Statistics in Euclidean/Non-Euclidean Spaces and Its Application to
  Hyperspectral Image Classification","  It is well known that hyperspectral images (HSI) contain rich
spatial-spectral contextual information, and how to effectively combine both
spectral and spatial information using DNN for HSI classification has become a
new research hotspot. Compared with CNN with square kernels, GCN have exhibited
exciting potential to model spatial contextual structure and conduct flexible
convolution on arbitrarily irregular image regions. However, current GCN only
using first-order spectral-spatial signatures can result in boundary blurring
and isolated misclassification. To address these, we first designed the
graph-based second-order pooling (GSOP) operation to obtain contextual nodes
information in non-Euclidean space for GCN. Further, we proposed a novel
multi-stream hybridized convolutional network (MSHCNet) with combination of
first and second order statistics in Euclidean/non-Euclidean spaces to learn
and fuse multi-view complementary information to segment HSIs. Specifically,
our MSHCNet adopted four parallel streams, which contained G-stream, utilizing
the irregular correlation between adjacent land covers in terms of first-order
graph in non-Euclidean space; C-stream, adopting convolution operator to learn
regular spatial-spectral features in Euclidean space; N-stream, combining first
and second order features to learn representative and discriminative regular
spatial-spectral features of Euclidean space; S-stream, using GSOP to capture
boundary correlations and obtain graph representations from all nodes in graphs
of non-Euclidean space. Besides, these feature representations learned from
four different streams were fused to integrate the multi-view complementary
information for HSI classification. Finally, we evaluated our proposed MSHCNet
on three hyperspectral datasets, and experimental results demonstrated that our
method significantly outperformed state-of-the-art eight methods.
","Shuang He, Haitong Tang, Xia Lu, Hongjie Yan, Nizhuan Wang",Nizhuan Wang,2021-10-07T11:35:40Z
"Autonomous Investigations over WS$_2$ and Au{111} with Scanning Probe
  Microscopy","  Individual atomic defects in 2D materials impact their macroscopic
functionality. Correlating the interplay is challenging, however, intelligent
hyperspectral scanning tunneling spectroscopy (STS) mapping provides a feasible
solution to this technically difficult and time consuming problem. Here, dense
spectroscopic volume is collected autonomously via Gaussian process regression,
where convolutional neural networks are used in tandem for spectral
identification. Acquired data enable defect segmentation, and a workflow is
provided for machine-driven decision making during experimentation with
capability for user customization. We provide a means towards autonomous
experimentation for the benefit of both enhanced reproducibility and
user-accessibility. Hyperspectral investigations on WS$_2$ sulfur vacancy sites
are explored, which is combined with local density of states confirmation on
the Au{111} herringbone reconstruction. Chalcogen vacancies, pristine WS$_2$,
Au face-centered cubic, and Au hexagonal close packed regions are examined and
detected by machine learning methods to demonstrate the potential of artificial
intelligence for hyperspectral STS mapping.
","John C. Thomas, Antonio Rossi, Darian Smalley, Luca Francaviglia, Zhuohang Yu, Tianyi Zhang, Shalini Kumari, Joshua A. Robinson, Mauricio Terrones, Masahiro Ishigami, Eli Rotenberg, Edward S. Barnard, Archana Raja, Ed Wong, D. Frank Ogletree, Marcus M. Noack, Alexander Weber-Bargioni",Alexander Weber-Bargioni,2021-10-07T11:43:45Z
Spectral Variability Augmented Sparse Unmixing of Hyperspectral Images,"  Spectral unmixing (SU) expresses the mixed pixels existed in hyperspectral
images as the product of endmember and abundance, which has been widely used in
hyperspectral imagery analysis. However, the influence of light, acquisition
conditions and the inherent properties of materials, results in that the
identified endmembers can vary spectrally within a given image (construed as
spectral variability). To address this issue, recent methods usually use a
priori obtained spectral library to represent multiple characteristic spectra
of the same object, but few of them extracted the spectral variability
explicitly. In this paper, a spectral variability augmented sparse unmixing
model (SVASU) is proposed, in which the spectral variability is extracted for
the first time. The variable spectra are divided into two parts of intrinsic
spectrum and spectral variability for spectral reconstruction, and modeled
synchronously in the SU model adding the regular terms restricting the sparsity
of abundance and the generalization of the variability coefficient. It is noted
that the spectral variability library and the intrinsic spectral library are
all constructed from the In-situ observed image. Experimental results over both
synthetic and real-world data sets demonstrate that the augmented decomposition
by spectral variability significantly improves the unmixing performance than
the decomposition only by spectral library, as well as compared to
state-of-the-art algorithms.
","Ge Zhang, Shaohui Mei, Mingyang Ma, Yan Feng, Qian Du",Qian Du,2021-10-19T05:25:30Z
"Learning A 3D-CNN and Transformer Prior for Hyperspectral Image
  Super-Resolution","  To solve the ill-posed problem of hyperspectral image super-resolution
(HSISR), an usually method is to use the prior information of the hyperspectral
images (HSIs) as a regularization term to constrain the objective function.
Model-based methods using hand-crafted priors cannot fully characterize the
properties of HSIs. Learning-based methods usually use a convolutional neural
network (CNN) to learn the implicit priors of HSIs. However, the learning
ability of CNN is limited, it only considers the spatial characteristics of the
HSIs and ignores the spectral characteristics, and convolution is not effective
for long-range dependency modeling. There is still a lot of room for
improvement. In this paper, we propose a novel HSISR method that uses
Transformer instead of CNN to learn the prior of HSIs. Specifically, we first
use the proximal gradient algorithm to solve the HSISR model, and then use an
unfolding network to simulate the iterative solution processes. The
self-attention layer of Transformer makes it have the ability of spatial global
interaction. In addition, we add 3D-CNN behind the Transformer layers to better
explore the spatio-spectral correlation of HSIs. Both quantitative and visual
results on two widely used HSI datasets and the real-world dataset demonstrate
that the proposed method achieves a considerable gain compared to all the
mainstream algorithms including the most competitive conventional methods and
the recently proposed deep learning-based methods.
","Qing Ma, Junjun Jiang, Xianming Liu, Jiayi Ma",Jiayi Ma,2021-11-27T15:38:57Z
"Multiscale Convolutional Transformer with Center Mask Pretraining for
  Hyperspectral Image Classification","  Hyperspectral images (HSI) not only have a broad macroscopic field of view
but also contain rich spectral information, and the types of surface objects
can be identified through spectral information, which is one of the main
applications in hyperspectral image related research.In recent years, more and
more deep learning methods have been proposed, among which convolutional neural
networks (CNN) are the most influential. However, CNN-based methods are
difficult to capture long-range dependencies, and also require a large amount
of labeled data for model training.Besides, most of the self-supervised
training methods in the field of HSI classification are based on the
reconstruction of input samples, and it is difficult to achieve effective use
of unlabeled samples. To address the shortcomings of CNN networks, we propose a
noval multi-scale convolutional embedding module for HSI to realize effective
extraction of spatial-spectral information, which can be better combined with
Transformer network.In order to make more efficient use of unlabeled data, we
propose a new self-supervised pretask. Similar to Mask autoencoder, but our
pre-training method only masks the corresponding token of the central pixel in
the encoder, and inputs the remaining token into the decoder to reconstruct the
spectral information of the central pixel.Such a pretask can better model the
relationship between the central feature and the domain feature, and obtain
more stable training results.
","Sen Jia, Yifan Wang",Yifan Wang,2022-03-09T14:42:26Z
"Nonnegative-Constrained Joint Collaborative Representation with Union
  Dictionary for Hyperspectral Anomaly Detection","  Recently, many collaborative representation-based (CR) algorithms have been
proposed for hyperspectral anomaly detection. CR-based detectors approximate
the image by a linear combination of background dictionaries and the
coefficient matrix, and derive the detection map by utilizing recovery
residuals. However, these CR-based detectors are often established on the
premise of precise background features and strong image representation, which
are very difficult to obtain. In addition, pursuing the coefficient matrix
reinforced by the general $l_2$-min is very time consuming. To address these
issues, a nonnegative-constrained joint collaborative representation model is
proposed in this paper for the hyperspectral anomaly detection task. To extract
reliable samples, a union dictionary consisting of background and anomaly
sub-dictionaries is designed, where the background sub-dictionary is obtained
at the superpixel level and the anomaly sub-dictionary is extracted by the
pre-detection process. And the coefficient matrix is jointly optimized by the
Frobenius norm regularization with a nonnegative constraint and a sum-to-one
constraint. After the optimization process, the abnormal information is finally
derived by calculating the residuals that exclude the assumed background
information. To conduct comparable experiments, the proposed
nonnegative-constrained joint collaborative representation (NJCR) model and its
kernel version (KNJCR) are tested in four HSI data sets and achieve superior
results compared with other state-of-the-art detectors.
","Shizhen Chang, Pedram Ghamisi",Pedram Ghamisi,2022-03-18T16:02:27Z
"Connections between Deep Equilibrium and Sparse Representation Models
  with Application to Hyperspectral Image Denoising","  In this study, the problem of computing a sparse representation of
multi-dimensional visual data is considered. In general, such data e.g.,
hyperspectral images, color images or video data consists of signals that
exhibit strong local dependencies. A new computationally efficient sparse
coding optimization problem is derived by employing regularization terms that
are adapted to the properties of the signals of interest. Exploiting the merits
of the learnable regularization techniques, a neural network is employed to act
as structure prior and reveal the underlying signal dependencies. To solve the
optimization problem Deep unrolling and Deep equilibrium based algorithms are
developed, forming highly interpretable and concise deep-learning-based
architectures, that process the input dataset in a block-by-block fashion.
Extensive simulation results, in the context of hyperspectral image denoising,
are provided, which demonstrate that the proposed algorithms outperform
significantly other sparse coding approaches and exhibit superior performance
against recent state-of-the-art deep-learning-based denoising models. In a
wider perspective, our work provides a unique bridge between a classic
approach, that is the sparse representation theory, and modern representation
tools that are based on deep learning modeling.
","Alexandros Gkillas, Dimitris Ampeliotis, Kostas Berberidis",Kostas Berberidis,2022-03-29T21:00:39Z
"Fast and Structured Block-Term Tensor Decomposition For Hyperspectral
  Unmixing","  The block-term tensor decomposition model with multilinear rank-$(L_r,L_r,1)$
terms (or, the ""LL1 tensor decomposition"" in short) offers a valuable
alternative for hyperspectral unmixing (HU) under the linear mixture model.
Particularly, the LL1 decomposition ensures the endmember/abundance
identifiability in scenarios where such guarantees are not supported by the
classic matrix factorization (MF) approaches. However, existing LL1-based HU
algorithms use a three-factor parameterization of the tensor (i.e., the
hyperspectral image cube), which leads to a number of challenges including high
per-iteration complexity, slow convergence, and difficulties in incorporating
structural prior information. This work puts forth an LL1 tensor
decomposition-based HU algorithm that uses a constrained two-factor
re-parameterization of the tensor data. As a consequence, a two-block
alternating gradient projection (GP)-based LL1 algorithm is proposed for HU.
With carefully designed projection solvers, the GP algorithm enjoys a
relatively low per-iteration complexity. Like in MF-based HU, the factors under
our parameterization correspond to the endmembers and abundances. Thus, the
proposed framework is natural to incorporate physics-motivated priors that
arise in HU. The proposed algorithm often attains orders-of-magnitude speedup
and substantial HU performance gains compared to the existing three-factor
parameterization-based HU algorithms.
","Meng Ding, Xiao Fu, Xi-Le Zhao",Xi-Le Zhao,2022-05-08T06:58:06Z
Deep Learning of Radiative Atmospheric Transfer with an Autoencoder,"  As electro-optical energy from the sun propagates through the atmosphere it
is affected by radiative transfer effects including absorption, emission, and
scattering. Modeling these affects is essential for scientific remote sensing
measurements of the earth and atmosphere. For example, hyperspectral imagery is
a form of digital imagery collected with many, often hundreds, of wavelengths
of light in pixel. The amount of light measured at the sensor is the result of
emitted sunlight, atmospheric radiative transfer, and the reflectance off the
materials on the ground, all of which vary per wavelength resulting from
multiple physical phenomena. Therefore measurements of the ground spectra or
atmospheric constituents requires separating these different contributions per
wavelength. In this paper, we create an autoencoder similar to denoising
autoencoders treating the atmospheric affects as 'noise' and ground reflectance
as truth per spectrum. We generate hundreds of thousands of training samples by
taking random samples of spectra from laboratory measurements and adding
atmospheric affects using physics-based modelling via MODTRAN
(http://modtran.spectral.com/modtran\_home) by varying atmospheric inputs. This
process ideally could create an autoencoder that would separate atmospheric
effects and ground reflectance in hyperspectral imagery, a process called
atmospheric compensation which is difficult and time-consuming requiring a
combination of heuristic approximations, estimates of physical quantities, and
physical modelling. While the accuracy of our method is not as good as other
methods in the field, this an important first step in applying the growing
field of deep learning of physical principles to atmospheric compensation in
hyperspectral imagery and remote sensing.
","Abigail Basener, Bill Basener",Bill Basener,2022-07-21T17:50:57Z
Low-Light Hyperspectral Image Enhancement,"  Due to inadequate energy captured by the hyperspectral camera sensor in poor
illumination conditions, low-light hyperspectral images (HSIs) usually suffer
from low visibility, spectral distortion, and various noises. A range of HSI
restoration methods have been developed, yet their effectiveness in enhancing
low-light HSIs is constrained. This work focuses on the low-light HSI
enhancement task, which aims to reveal the spatial-spectral information hidden
in darkened areas. To facilitate the development of low-light HSI processing,
we collect a low-light HSI (LHSI) dataset of both indoor and outdoor scenes.
Based on Laplacian pyramid decomposition and reconstruction, we developed an
end-to-end data-driven low-light HSI enhancement (HSIE) approach trained on the
LHSI dataset. With the observation that illumination is related to the
low-frequency component of HSI, while textural details are closely correlated
to the high-frequency component, the proposed HSIE is designed to have two
branches. The illumination enhancement branch is adopted to enlighten the
low-frequency component with reduced resolution. The high-frequency refinement
branch is utilized for refining the high-frequency component via a predicted
mask. In addition, to improve information flow and boost performance, we
introduce an effective channel attention block (CAB) with residual dense
connection, which served as the basic block of the illumination enhancement
branch. The effectiveness and efficiency of HSIE both in quantitative
assessment measures and visual effects are demonstrated by experimental results
on the LHSI dataset. According to the classification performance on the remote
sensing Indian Pines dataset, downstream tasks benefit from the enhanced HSI.
Datasets and codes are available:
\href{https://github.com/guanguanboy/HSIE}{https://github.com/guanguanboy/HSIE}.
","Xuelong Li, Guanlin Li, Bin Zhao",Bin Zhao,2022-08-05T08:45:52Z
"Hyperspectral Image Reconstruction from Multispectral Images Using
  Non-Local Filtering","  Using light spectra is an essential element in many applications, for
example, in material classification. Often this information is acquired by
using a hyperspectral camera. Unfortunately, these cameras have some major
disadvantages like not being able to record videos. Therefore, multispectral
cameras with wide-band filters are used, which are much cheaper and are often
able to capture videos. However, using multispectral cameras requires an
additional reconstruction step to yield spectral information. Usually, this
reconstruction step has to be done in the presence of imaging noise, which
degrades the reconstructed spectra severely. Typically, same or similar pixels
are found across the image with the advantage of having independent noise. In
contrast to state-of-the-art spectral reconstruction methods which only exploit
neighboring pixels by block-based processing, this paper introduces non-local
filtering in spectral reconstruction. First, a block-matching procedure finds
similar non-local multispectral blocks. Thereafter, the hyperspectral pixels
are reconstructed by filtering the matched multispectral pixels collaboratively
using a reconstruction Wiener filter. The proposed novel procedure even works
under very strong noise. The method is able to lower the spectral angle up to
18% and increase the peak signal-to-noise-ratio up to 1.1dB in noisy scenarios
compared to state-of-the-art methods. Moreover, the visual results are much
more appealing.
","Frank Sippel, Jürgen Seiler, André Kaup",André Kaup,2022-09-16T12:29:39Z
"Shared Manifold Learning Using a Triplet Network for Multiple Sensor
  Translation and Fusion with Missing Data","  Heterogeneous data fusion can enhance the robustness and accuracy of an
algorithm on a given task. However, due to the difference in various
modalities, aligning the sensors and embedding their information into
discriminative and compact representations is challenging. In this paper, we
propose a Contrastive learning based MultiModal Alignment Network (CoMMANet) to
align data from different sensors into a shared and discriminative manifold
where class information is preserved. The proposed architecture uses a
multimodal triplet autoencoder to cluster the latent space in such a way that
samples of the same classes from each heterogeneous modality are mapped close
to each other. Since all the modalities exist in a shared manifold, a unified
classification framework is proposed. The resulting latent space
representations are fused to perform more robust and accurate classification.
In a missing sensor scenario, the latent space of one sensor is easily and
efficiently predicted using another sensor's latent space, thereby allowing
sensor translation. We conducted extensive experiments on a manually labeled
multimodal dataset containing hyperspectral data from AVIRIS-NG and NEON, and
LiDAR (light detection and ranging) data from NEON. Lastly, the model is
validated on two benchmark datasets: Berlin Dataset (hyperspectral and
synthetic aperture radar) and MUUFL Gulfport Dataset (hyperspectral and LiDAR).
A comparison made with other methods demonstrates the superiority of this
method. We achieved a mean overall accuracy of 94.3% on the MUUFL dataset and
the best overall accuracy of 71.26% on the Berlin dataset, which is better than
other state-of-the-art approaches.
","Aditya Dutt, Alina Zare, Paul Gader",Paul Gader,2022-10-25T20:22:09Z
Hyperspectral Demosaicing of Snapshot Camera Images Using Deep Learning,"  Spectral imaging technologies have rapidly evolved during the past decades.
The recent development of single-camera-one-shot techniques for hyperspectral
imaging allows multiple spectral bands to be captured simultaneously (3x3, 4x4
or 5x5 mosaic), opening up a wide range of applications. Examples include
intraoperative imaging, agricultural field inspection and food quality
assessment. To capture images across a wide spectrum range, i.e. to achieve
high spectral resolution, the sensor design sacrifices spatial resolution. With
increasing mosaic size, this effect becomes increasingly detrimental.
Furthermore, demosaicing is challenging. Without incorporating edge, shape, and
object information during interpolation, chromatic artifacts are likely to
appear in the obtained images. Recent approaches use neural networks for
demosaicing, enabling direct information extraction from image data. However,
obtaining training data for these approaches poses a challenge as well. This
work proposes a parallel neural network based demosaicing procedure trained on
a new ground truth dataset captured in a controlled environment by a
hyperspectral snapshot camera with a 4x4 mosaic pattern. The dataset is a
combination of real captured scenes with images from publicly available data
adapted to the 4x4 mosaic pattern. To obtain real world ground-truth data, we
performed multiple camera captures with 1-pixel shifts in order to compose the
entire data cube. Experiments show that the proposed network outperforms
state-of-art networks.
","Eric L. Wisotzky, Charul Daudkhane, Anna Hilsmann, Peter Eisert",Peter Eisert,2022-11-21T11:55:05Z
Multiple Sub-Pixel Target Detection for Hyperspectral Imaging Systems,"  Hyperspectral target detection is a task of primary importance in remote
sensing since it allows identification, location, and discrimination of target
features. To this end, the reflectance maps, which contain the spectral
signatures and related abundances of the materials in the observed scene, are
often used. However, due to the low spatial resolution of most hyperspectral
sensors, targets occupy a fraction of the pixel and, hence, the spectra of
different sub-pixel targets (including the background spectrum) are mixed
together within the same pixel. To solve this issue, in this paper, we adopt a
generalized replacement model accounting for multiple sub-pixel target spectra
and formulate the detection problem at hand as a binary hypothesis test where
under the alternative hypothesis the target is modeled in terms of a linear
combination of endmembers whose coefficients also account for the presence of
the background. Then, we devise detection architectures based upon the
generalized likelihood ratio test where the unknown parameters are suitably
estimated through procedures inspired by the maximum likelihood approach. The
performances of the proposed decision schemes are evaluated by means of both
synthetic as well as real data and compared with an analogous counterpart by
showing the effectiveness of the proposed procedure.
","Pia Addabbo, Nicomino Fiscante, Gaetano Giunta, Danilo Orlando, Giuseppe Ricci, Silvia Liberata Ullo",Silvia Liberata Ullo,2023-01-16T09:08:05Z
"Training Methods of Multi-label Prediction Classifiers for Hyperspectral
  Remote Sensing Images","  With their combined spectral depth and geometric resolution, hyperspectral
remote sensing images embed a wealth of complex, non-linear information that
challenges traditional computer vision techniques. Yet, deep learning methods
known for their representation learning capabilities prove more suitable for
handling such complexities. Unlike applications that focus on single-label,
pixel-level classification methods for hyperspectral remote sensing images, we
propose a multi-label, patch-level classification method based on a
two-component deep-learning network. We use patches of reduced spatial
dimension and a complete spectral depth extracted from the remote sensing
images. Additionally, we investigate three training schemes for our network:
Iterative, Joint, and Cascade. Experiments suggest that the Joint scheme is the
best-performing scheme; however, its application requires an expensive search
for the best weight combination of the loss constituents. The Iterative scheme
enables the sharing of features between the two parts of the network at the
early stages of training. It performs better on complex data with multi-labels.
Further experiments showed that methods designed with different architectures
performed well when trained on patches extracted and labeled according to our
sampling method.
","Salma Haidar, José Oramas",José Oramas,2023-01-17T13:30:03Z
"Dynamical Hyperspectral Unmixing with Variational Recurrent Neural
  Networks","  Multitemporal hyperspectral unmixing (MTHU) is a fundamental tool in the
analysis of hyperspectral image sequences. It reveals the dynamical evolution
of the materials (endmembers) and of their proportions (abundances) in a given
scene. However, adequately accounting for the spatial and temporal variability
of the endmembers in MTHU is challenging, and has not been fully addressed so
far in unsupervised frameworks. In this work, we propose an unsupervised MTHU
algorithm based on variational recurrent neural networks. First, a stochastic
model is proposed to represent both the dynamical evolution of the endmembers
and their abundances, as well as the mixing process. Moreover, a new model
based on a low-dimensional parametrization is used to represent spatial and
temporal endmember variability, significantly reducing the amount of variables
to be estimated. We propose to formulate MTHU as a Bayesian inference problem.
However, the solution to this problem does not have an analytical solution due
to the nonlinearity and non-Gaussianity of the model. Thus, we propose a
solution based on deep variational inference, in which the posterior
distribution of the estimated abundances and endmembers is represented by using
a combination of recurrent neural networks and a physically motivated model.
The parameters of the model are learned using stochastic backpropagation.
Experimental results show that the proposed method outperforms state of the art
MTHU algorithms.
","Ricardo Augusto Borsoi, Tales Imbiriba, Pau Closas",Pau Closas,2023-03-19T04:51:34Z
MSFA-Frequency-Aware Transformer for Hyperspectral Images Demosaicing,"  Hyperspectral imaging systems that use multispectral filter arrays (MSFA)
capture only one spectral component in each pixel. Hyperspectral demosaicing is
used to recover the non-measured components. While deep learning methods have
shown promise in this area, they still suffer from several challenges,
including limited modeling of non-local dependencies, lack of consideration of
the periodic MSFA pattern that could be linked to periodic artifacts, and
difficulty in recovering high-frequency details. To address these challenges,
this paper proposes a novel de-mosaicing framework, the MSFA-frequency-aware
Transformer network (FDM-Net). FDM-Net integrates a novel MSFA-frequency-aware
multi-head self-attention mechanism (MaFormer) and a filter-based Fourier
zero-padding method to reconstruct high pass components with greater difficulty
and low pass components with relative ease, separately. The advantage of
Maformer is that it can leverage the MSFA information and non-local
dependencies present in the data. Additionally, we introduce a joint spatial
and frequency loss to transfer MSFA information and enhance training on
frequency components that are hard to recover. Our experimental results
demonstrate that FDM-Net outperforms state-of-the-art methods with 6dB PSNR,
and reconstructs high-fidelity details successfully.
","Haijin Zeng, Kai Feng, Shaoguang Huang, Jiezhang Cao, Yongyong Chen, Hongyan Zhang, Hiep Luong, Wilfried Philips",Wilfried Philips,2023-03-23T16:27:30Z
Multi-scale Adaptive Fusion Network for Hyperspectral Image Denoising,"  Removing the noise and improving the visual quality of hyperspectral images
(HSIs) is challenging in academia and industry. Great efforts have been made to
leverage local, global or spectral context information for HSI denoising.
However, existing methods still have limitations in feature interaction
exploitation among multiple scales and rich spectral structure preservation. In
view of this, we propose a novel solution to investigate the HSI denoising
using a Multi-scale Adaptive Fusion Network (MAFNet), which can learn the
complex nonlinear mapping between clean and noisy HSI. Two key components
contribute to improving the hyperspectral image denoising: A progressively
multiscale information aggregation network and a co-attention fusion module.
Specifically, we first generate a set of multiscale images and feed them into a
coarse-fusion network to exploit the contextual texture correlation.
Thereafter, a fine fusion network is followed to exchange the information
across the parallel multiscale subnetworks. Furthermore, we design a
co-attention fusion module to adaptively emphasize informative features from
different scales, and thereby enhance the discriminative learning capability
for denoising. Extensive experiments on synthetic and real HSI datasets
demonstrate that the proposed MAFNet has achieved better denoising performance
than other state-of-the-art techniques. Our codes are available at
\verb'https://github.com/summitgao/MAFNet'.
","Haodong Pan, Feng Gao, Junyu Dong, Qian Du",Qian Du,2023-04-19T02:00:21Z
"Degradation-Noise-Aware Deep Unfolding Transformer for Hyperspectral
  Image Denoising","  Hyperspectral imaging (HI) has emerged as a powerful tool in diverse fields
such as medical diagnosis, industrial inspection, and agriculture, owing to its
ability to detect subtle differences in physical properties through high
spectral resolution. However, hyperspectral images (HSIs) are often quite noisy
because of narrow band spectral filtering. To reduce the noise in HSI data
cubes, both model-driven and learning-based denoising algorithms have been
proposed. However, model-based approaches rely on hand-crafted priors and
hyperparameters, while learning-based methods are incapable of estimating the
inherent degradation patterns and noise distributions in the imaging procedure,
which could inform supervised learning. Secondly, learning-based algorithms
predominantly rely on CNN and fail to capture long-range dependencies,
resulting in limited interpretability. This paper proposes a
Degradation-Noise-Aware Unfolding Network (DNA-Net) that addresses these
issues. Firstly, DNA-Net models sparse noise, Gaussian noise, and explicitly
represent image prior using transformer. Then the model is unfolded into an
end-to-end network, the hyperparameters within the model are estimated from the
noisy HSI and degradation model and utilizes them to control each iteration.
Additionally, we introduce a novel U-Shaped Local-Non-local-Spectral
Transformer (U-LNSA) that captures spectral correlation, local contents, and
non-local dependencies simultaneously. By integrating U-LNSA into DNA-Net, we
present the first Transformer-based deep unfolding HSI denoising method.
Experimental results show that DNA-Net outperforms state-of-the-art methods,
and the modeling of noise distributions helps in cases with heavy noise.
","Haijin Zeng, Jiezhang Cao, Kai Feng, Shaoguang Huang, Hongyan Zhang, Hiep Luong, Wilfried Philips",Wilfried Philips,2023-05-06T13:28:20Z
"Hyperspectral photoluminescence and reflectance microscopy of 2D
  materials","  Optical micro-spectroscopy is an invaluable tool for studying and
characterizing samples ranging from classical semiconductors to low-dimensional
materials and heterostructures. To date, most implementations are based on
point-scanning techniques, which are flexible and reliable, but slow. Here, we
describe a setup for highly parallel acquisition of hyperspectral reflection
and photoluminescence microscope images using a push-broom technique. Spatial
as well as spectral distortions are characterized and their digital corrections
are presented. We demonstrate close-to diffraction-limited spatial imaging
performance and a spectral resolution limited by the spectrograph. The
capabilities of the setup are demonstrated by recording a hyperspectral
photoluminescence map of a CVD-grown MoSe$_2$-WSe$_2$ lateral heterostructure,
from which we extract the luminescence energies, intensities and peak widths
across the interface.
","David Tebbe, Marc Schütte, Baisali Kundu, Bernd Beschoten, Prasana K. Sahoo, Lutz Waldecker",Lutz Waldecker,2023-05-11T16:23:07Z
"Generative Adversarial Networks for Spatio-Spectral Compression of
  Hyperspectral Images","  The development of deep learning-based models for the compression of
hyperspectral images (HSIs) has recently attracted great attention in remote
sensing due to the sharp growing of hyperspectral data archives. Most of the
existing models achieve either spectral or spatial compression, and do not
jointly consider the spatio-spectral redundancies present in HSIs. To address
this problem, in this paper we focus our attention on the High Fidelity
Compression (HiFiC) model (which is proven to be highly effective for spatial
compression problems) and adapt it to perform spatio-spectral compression of
HSIs. In detail, we introduce two new models: i) HiFiC using Squeeze and
Excitation (SE) blocks (denoted as HiFiC$_{SE}$); and ii) HiFiC with 3D
convolutions (denoted as HiFiC$_{3D}$) in the framework of compression of HSIs.
We analyze the effectiveness of HiFiC$_{SE}$ and HiFiC$_{3D}$ in compressing
the spatio-spectral redundancies with channel attention and inter-dependency
analysis. Experimental results show the efficacy of the proposed models in
performing spatio-spectral compression, while reconstructing images at reduced
bitrates with higher reconstruction quality. The code of the proposed models is
publicly available at https://git.tu-berlin.de/rsim/HSI-SSC .
","Martin Hermann Paul Fuchs, Akshara Preethy Byju, Alisa Walda, Behnood Rasti, Begüm Demir",Begüm Demir,2023-05-15T10:23:14Z
"Unsupervised Hyperspectral and Multispectral Images Fusion Based on the
  Cycle Consistency","  Hyperspectral images (HSI) with abundant spectral information reflected
materials property usually perform low spatial resolution due to the hardware
limits. Meanwhile, multispectral images (MSI), e.g., RGB images, have a high
spatial resolution but deficient spectral signatures. Hyperspectral and
multispectral image fusion can be cost-effective and efficient for acquiring
both high spatial resolution and high spectral resolution images. Many of the
conventional HSI and MSI fusion algorithms rely on known spatial degradation
parameters, i.e., point spread function, spectral degradation parameters,
spectral response function, or both of them. Another class of deep
learning-based models relies on the ground truth of high spatial resolution HSI
and needs large amounts of paired training images when working in a supervised
manner. Both of these models are limited in practical fusion scenarios. In this
paper, we propose an unsupervised HSI and MSI fusion model based on the cycle
consistency, called CycFusion. The CycFusion learns the domain transformation
between low spatial resolution HSI (LrHSI) and high spatial resolution MSI
(HrMSI), and the desired high spatial resolution HSI (HrHSI) are considered to
be intermediate feature maps in the transformation networks. The CycFusion can
be trained with the objective functions of marginal matching in single
transform and cycle consistency in double transforms. Moreover, the estimated
PSF and SRF are embedded in the model as the pre-training weights, which
further enhances the practicality of our proposed model. Experiments conducted
on several datasets show that our proposed model outperforms all compared
unsupervised fusion methods. The codes of this paper will be available at this
address: https: //github.com/shuaikaishi/CycFusion for reproducibility.
","Shuaikai Shi, Lijun Zhang, Yoann Altmann, Jie Chen",Jie Chen,2023-07-07T06:47:15Z
"Hyperspectral and Multispectral Image Fusion Using the Conditional
  Denoising Diffusion Probabilistic Model","  Hyperspectral images (HSI) have a large amount of spectral information
reflecting the characteristics of matter, while their spatial resolution is low
due to the limitations of imaging technology. Complementary to this are
multispectral images (MSI), e.g., RGB images, with high spatial resolution but
insufficient spectral bands. Hyperspectral and multispectral image fusion is a
technique for acquiring ideal images that have both high spatial and high
spectral resolution cost-effectively. Many existing HSI and MSI fusion
algorithms rely on known imaging degradation models, which are often not
available in practice. In this paper, we propose a deep fusion method based on
the conditional denoising diffusion probabilistic model, called DDPM-Fus.
Specifically, the DDPM-Fus contains the forward diffusion process which
gradually adds Gaussian noise to the high spatial resolution HSI (HrHSI) and
another reverse denoising process which learns to predict the desired HrHSI
from its noisy version conditioning on the corresponding high spatial
resolution MSI (HrMSI) and low spatial resolution HSI (LrHSI). Once the
training is completes, the proposed DDPM-Fus implements the reverse process on
the test HrMSI and LrHSI to generate the fused HrHSI. Experiments conducted on
one indoor and two remote sensing datasets show the superiority of the proposed
model when compared with other advanced deep learningbased fusion methods. The
codes of this work will be opensourced at this address:
https://github.com/shuaikaishi/DDPMFus for reproducibility.
","Shuaikai Shi, Lijun Zhang, Jie Chen",Jie Chen,2023-07-07T07:08:52Z
"BSDM: Background Suppression Diffusion Model for Hyperspectral Anomaly
  Detection","  Hyperspectral anomaly detection (HAD) is widely used in Earth observation and
deep space exploration. A major challenge for HAD is the complex background of
the input hyperspectral images (HSIs), resulting in anomalies confused in the
background. On the other hand, the lack of labeled samples for HSIs leads to
poor generalization of existing HAD methods. This paper starts the first
attempt to study a new and generalizable background learning problem without
labeled samples. We present a novel solution BSDM (background suppression
diffusion model) for HAD, which can simultaneously learn latent background
distributions and generalize to different datasets for suppressing complex
background. It is featured in three aspects: (1) For the complex background of
HSIs, we design pseudo background noise and learn the potential background
distribution in it with a diffusion model (DM). (2) For the generalizability
problem, we apply a statistical offset module so that the BSDM adapts to
datasets of different domains without labeling samples. (3) For achieving
background suppression, we innovatively improve the inference process of DM by
feeding the original HSIs into the denoising network, which removes the
background as noise. Our work paves a new background suppression way for HAD
that can improve HAD performance without the prerequisite of manually labeled
data. Assessments and generalization experiments of four HAD methods on several
real HSI datasets demonstrate the above three unique properties of the proposed
method. The code is available at https://github.com/majitao-xd/BSDM-HAD.
","Jitao Ma, Weiying Xie, Yunsong Li, Leyuan Fang",Leyuan Fang,2023-07-19T09:45:06Z
"End-to-end Hyperspectral Image Change Detection Network Based on Band
  Selection","  For hyperspectral image change detection (HSI-CD), one key challenge is to
reduce band redundancy, as only a few bands are crucial for change detection
while other bands may be adverse to it. However, most existing HSI-CD methods
directly extract change feature from full-dimensional HSIs, suffering from a
degradation of feature discrimination. To address this issue, we propose an
end-to-end hyperspectral image change detection network with band selection
(ECDBS), which effectively retains the critical bands to promote change
detection. The main ingredients of the network are a deep learning based band
selection module and cascading band-specific spatial attention (BSA) blocks.
The band selection module can be seamlessly integrated with subsequent CD
models for joint optimization and end-to-end reasoning, rather than as a step
separate from change detection. The BSA block extracts features from each band
using a tailored strategy. Unlike the typically used feature extraction
strategy that uniformly processes all bands, the BSA blocks considers the
differences in feature distributions among widely spaced bands, thereupon
extracting more sufficient change feature. Experimental evaluations conducted
on three widely used HSI-CD datasets demonstrate the effectiveness and
superiority of our proposed method over other state-of-the-art techniques.
","Qingren Yao, Yuan Zhou, Chang Tang, Wei Xiang",Wei Xiang,2023-07-23T13:50:41Z
"ESSAformer: Efficient Transformer for Hyperspectral Image
  Super-resolution","  Single hyperspectral image super-resolution (single-HSI-SR) aims to restore a
high-resolution hyperspectral image from a low-resolution observation. However,
the prevailing CNN-based approaches have shown limitations in building
long-range dependencies and capturing interaction information between spectral
features. This results in inadequate utilization of spectral information and
artifacts after upsampling. To address this issue, we propose ESSAformer, an
ESSA attention-embedded Transformer network for single-HSI-SR with an iterative
refining structure. Specifically, we first introduce a robust and
spectral-friendly similarity metric, \ie, the spectral correlation coefficient
of the spectrum (SCC), to replace the original attention matrix and
incorporates inductive biases into the model to facilitate training. Built upon
it, we further utilize the kernelizable attention technique with theoretical
support to form a novel efficient SCC-kernel-based self-attention (ESSA) and
reduce attention computation to linear complexity. ESSA enlarges the receptive
field for features after upsampling without bringing much computation and
allows the model to effectively utilize spatial-spectral information from
different scales, resulting in the generation of more natural high-resolution
images. Without the need for pretraining on large-scale datasets, our
experiments demonstrate ESSA's effectiveness in both visual quality and
quantitative results.
","Mingjin Zhang, Chi Zhang, Qiming Zhang, Jie Guo, Xinbo Gao, Jing Zhang",Jing Zhang,2023-07-26T07:45:14Z
"Absorption-Based, Passive Range Imaging from Hyperspectral Thermal
  Measurements","  Passive hyperspectral long-wave infrared measurements are remarkably
informative about the surroundings, such as remote object material composition,
temperature, and range; and air temperature and gas concentrations. Remote
object material and temperature determine the spectrum of thermal radiance, and
range, air temperature, and gas concentrations determine how this spectrum is
modified by propagation to the sensor. We computationally separate these
phenomena, introducing a novel passive range imaging method based on
atmospheric absorption of ambient thermal radiance. Previously demonstrated
passive absorption-based ranging methods assume hot and highly emitting
objects. However, the temperature variation in natural scenes is usually low,
making range imaging challenging. Our method benefits from explicit
consideration of air emission and parametric modeling of atmospheric
absorption. To mitigate noise in low-contrast scenarios, we jointly estimate
range and intrinsic object properties by exploiting a variety of absorption
lines spread over the infrared spectrum. Along with Monte Carlo simulations
that demonstrate the importance of regularization, temperature differentials,
and availability of many spectral bands, we apply this method to long-wave
infrared (8--13 $\mu$m) hyperspectral image data acquired from natural scenes
with no active illumination. Range features from 15m to 150m are recovered,
with good qualitative match to unaligned lidar data.
","Unay Dorken Gallastegi, Hoover Rueda-Chacon, Martin J. Stevens, Vivek K Goyal",Vivek K Goyal,2023-08-10T18:35:22Z
"Systematic reduction of Hyperspectral Images for high-throughput Plastic
  Characterization","  Hyperspectral Imaging (HSI) combines microscopy and spectroscopy to assess
the spatial distribution of spectroscopically active compounds in objects, and
has diverse applications in food quality control, pharmaceutical processes, and
waste sorting. However, due to the large size of HSI datasets, it can be
challenging to analyze and store them within a reasonable digital
infrastructure, especially in waste sorting where speed and data storage
resources are limited. Additionally, as with most spectroscopic data, there is
significant redundancy, making pixel and variable selection crucial for
retaining chemical information. Recent high-tech developments in chemometrics
enable automated and evidence-based data reduction, which can substantially
enhance the speed and performance of Non-Negative Matrix Factorization (NMF), a
widely used algorithm for chemical resolution of HSI data. By recovering the
pure contribution maps and spectral profiles of distributed compounds, NMF can
provide evidence-based sorting decisions for efficient waste management. To
improve the quality and efficiency of data analysis on hyperspectral imaging
(HSI) data, we apply a convex-hull method to select essential pixels and
wavelengths and remove uninformative and redundant information. This process
minimizes computational strain and effectively eliminates highly mixed pixels.
By reducing data redundancy, data investigation and analysis become more
straightforward, as demonstrated in both simulated and real HSI data for
plastic sorting.
","Mahdiyeh Ghaffari, Mickey C. J. Lukkien, Nematollah Omidikia, Gerjen H. Tinnevelt, Marcel C. P. van Eijk, Jeroen J. Jansen",Jeroen J. Jansen,2023-08-28T11:38:08Z
Domain Adaptation for Satellite-Borne Hyperspectral Cloud Detection,"  The advent of satellite-borne machine learning hardware accelerators has
enabled the on-board processing of payload data using machine learning
techniques such as convolutional neural networks (CNN). A notable example is
using a CNN to detect the presence of clouds in hyperspectral data captured on
Earth observation (EO) missions, whereby only clear sky data is downlinked to
conserve bandwidth. However, prior to deployment, new missions that employ new
sensors will not have enough representative datasets to train a CNN model,
while a model trained solely on data from previous missions will underperform
when deployed to process the data on the new missions. This underperformance
stems from the domain gap, i.e., differences in the underlying distributions of
the data generated by the different sensors in previous and future missions. In
this paper, we address the domain gap problem in the context of on-board
hyperspectral cloud detection. Our main contributions lie in formulating new
domain adaptation tasks that are motivated by a concrete EO mission, developing
a novel algorithm for bandwidth-efficient supervised domain adaptation, and
demonstrating test-time adaptation algorithms on space deployable neural
network accelerators. Our contributions enable minimal data transmission to be
invoked (e.g., only 1% of the weights in ResNet50) to achieve domain
adaptation, thereby allowing more sophisticated CNN models to be deployed and
updated on satellites without being hampered by domain gap and bandwidth
limitations.
","Andrew Du, Anh-Dzung Doan, Yee Wei Law, Tat-Jun Chin",Tat-Jun Chin,2023-09-05T11:43:18Z
"A Multisensor Hyperspectral Benchmark Dataset For Unmixing of Intimate
  Mixtures","  Optical hyperspectral cameras capture the spectral reflectance of materials.
Since many materials behave as heterogeneous intimate mixtures with which each
photon interacts differently, the relationship between spectral reflectance and
material composition is very complex. Quantitative validation of spectral
unmixing algorithms requires high-quality ground truth fractional abundance
data, which are very difficult to obtain. In this work, we generated a
comprehensive laboratory ground truth dataset of intimately mixed mineral
powders. For this, five clay powders (Kaolin, Roof clay, Red clay, mixed clay,
and Calcium hydroxide) were mixed homogeneously to prepare 325 samples of 60
binary, 150 ternary, 100 quaternary, and 15 quinary mixtures. Thirteen
different hyperspectral sensors have been used to acquire the reflectance
spectra of these mixtures in the visible, near, short, mid, and long-wavelength
infrared regions (350-15385) nm. {\color{black} Overlaps in wavelength regions
due to the operational ranges of each sensor} and variations in acquisition
conditions {\color{black} resulted in} a large amount of spectral variability.
Ground truth composition is given by construction, but to verify that the
generated samples are sufficiently homogeneous, XRD and XRF elemental analysis
is performed. We believe these data will be beneficial for validating advanced
methods for nonlinear unmixing and material composition estimation, including
studying spectral variability and training supervised unmixing approaches. The
datasets can be downloaded from the following link:
https://github.com/VisionlabUA/Multisensor_datasets.
","Bikram Koirala, Behnood Rasti, Zakaria Bnoulkacem, Andrea de Lima Ribeiro, Yuleika Madriz, Erik Herrmann, Arthur Gestels, Thomas De Kerf, Sandra Lorenz, Margret Fuchs, Koen Janssens, Gunther Steenackers, Richard Gloaguen, Paul Scheunders",Paul Scheunders,2023-08-30T11:48:36Z
"Mono/Multi-material Characterization Using Hyperspectral Images and
  Multi-Block Non-Negative Matrix Factorization","  Plastic sorting is a very essential step in waste management, especially due
to the presence of multilayer plastics. These monomaterial and multimaterial
plastics are widely employed to enhance the functional properties of packaging,
combining beneficial properties in thickness, mechanical strength, and heat
tolerance. However, materials containing multiple polymer species need to be
pretreated before they can be recycled as monomaterials and therefore should
not end up in monomaterial streams. Industry 4.0 has significantly improved
materials sorting of plastic packaging in speed and accuracy compared to manual
sorting, specifically through Near Infrared Hyperspectral Imaging (NIRHSI) that
provides an automated, fast, and accurate material characterization, without
sample preparation. Identification of multimaterials with HSI however requires
novel dedicated approaches for chemical pattern recognition. Non negative
Matrix Factorization, NMF, is widely used for the chemical resolution of
hyperspectral images. Chemically relevant model constraints may make it
specifically valuable to identify multilayer plastics through HSI.
Specifically, Multi Block Non Negative Matrix Factorization (MBNMF) with
correspondence among different chemical species constraint may be used to
evaluate the presence or absence of particular polymer species. To translate
the MBNMF model into an evidence based sorting decision, we extended the model
with an F test to distinguish between monomaterial and multimaterial objects.
The benefits of our new approach, MBNMF, were illustrated by the identification
of several plastic waste objects.
","Mahdiyeh Ghaffari, Gerjen H. Tinnevelt, Marcel C. P. van Eijk, Stanislav Podchezertsev, Geert J. Postma, Jeroen J. Jansen",Jeroen J. Jansen,2023-08-15T10:00:53Z
"One-dimensional convolutional neural network model for breast cancer
  subtypes classification and biochemical content evaluation using micro-FTIR
  hyperspectral images","  Breast cancer treatment still remains a challenge, where molecular subtypes
classification plays a crucial role in selecting appropriate and specific
therapy. The four subtypes are Luminal A (LA), Luminal B (LB), HER2 subtype,
and Triple-Negative Breast Cancer (TNBC). Immunohistochemistry is the
gold-standard evaluation, although interobserver variations are reported and
molecular signatures identification is time-consuming. Fourier transform
infrared micro-spectroscopy with machine learning approaches have been used to
evaluate cancer samples, presenting biochemical-related explainability.
However, this explainability is harder when using deep learning. This study
created a 1D deep learning tool for breast cancer subtype evaluation and
biochemical contribution. Sixty hyperspectral images were acquired from a human
breast cancer microarray. K-Means clustering was applied to select tissue and
paraffin spectra. CaReNet-V1, a novel 1D convolutional neural network, was
developed to classify breast cancer (CA) and adjacent tissue (AT), and
molecular subtypes. A 1D adaptation of Grad-CAM was applied to assess the
biochemical impact to the classifications. CaReNet-V1 effectively classified CA
and AT (test accuracy of 0.89), as well as HER2 and TNBC subtypes (0.83 and
0.86), with greater difficulty for LA and LB (0.74 and 0.68). The model enabled
the evaluation of the most contributing wavenumbers to the predictions,
providing a direct relationship with the biochemical content. Therefore,
CaReNet-V1 and hyperspectral images is a potential approach for breast cancer
biopsies assessment, providing additional information to the pathology report.
Biochemical content impact feature may be used for other studies, such as
treatment efficacy evaluation and development new diagnostics and therapeutic
methods.
","Matheus del-Valle, Emerson Soares Bernardes, Denise Maria Zezell",Denise Maria Zezell,2023-10-23T16:58:34Z
"Towards Machine Learning-based Quantitative Hyperspectral Image Guidance
  for Brain Tumor Resection","  Complete resection of malignant gliomas is hampered by the difficulty in
distinguishing tumor cells at the infiltration zone. Fluorescence guidance with
5-ALA assists in reaching this goal. Using hyperspectral imaging, previous work
characterized five fluorophores' emission spectra in most human brain tumors.
In this paper, the effectiveness of these five spectra was explored for
different tumor and tissue classification tasks in 184 patients (891
hyperspectral measurements) harboring low- (n=30) and high-grade gliomas
(n=115), non-glial primary brain tumors (n=19), radiation necrosis (n=2),
miscellaneous (n=10) and metastases (n=8). Four machine learning models were
trained to classify tumor type, grade, glioma margins and IDH mutation. Using
random forests and multi-layer perceptrons, the classifiers achieved average
test accuracies of 84-87%, 96%, 86%, and 93% respectively. All five fluorophore
abundances varied between tumor margin types and tumor grades (p < 0.01). For
tissue type, at least four of the five fluorophore abundances were found to be
significantly different (p < 0.01) between all classes. These results
demonstrate the fluorophores' differing abundances in different tissue classes,
as well as the value of the five fluorophores as potential optical biomarkers,
opening new opportunities for intraoperative classification systems in
fluorescence-guided neurosurgery.
","David Black, Declan Byrne, Anna Walke, Sidong Liu, Antonio Di leva, Sadahiro Kaneko, Walter Stummer, Septimiu Salcudean, Eric Suero Molina",Eric Suero Molina,2023-11-17T04:15:27Z
"Broadband dual-comb hyperspectral imaging and adaptable spectroscopy
  with programmable frequency combs","  We explore the advantages of a free-form dual-comb spectroscopy (DCS)
platform based on time-programmable frequency combs for real-time, penalty-free
apodized scanning. In traditional DCS, the fundamental spectral resolution,
which equals the comb repetition rate, can be excessively fine for many
applications. While the fine resolution is not itself problematic, it comes
with the penalty of excess acquisition time. Post-processing apodization
(windowing) can be applied to tailor the resolution to the sample, but only
with a deadtime penalty proportional to the degree of apodization. The excess
acquisition time remains. With free-form DCS, this deadtime is avoided by
programming a real-time apodization pattern that dynamically reverses the pulse
periods between the dual frequency combs. In this way, one can tailor the
spectrometer's resolution and update rate to different applications without
penalty. We show operation of a free-form DCS system where the spectral
resolution is varied from the intrinsic fine resolution of 160 MHz up to 822
GHz by applying tailored real-time apodization. Because there is no deadtime
penalty, the spectral signal-to-noise ratio increases linearly with resolution
by 5000x over this range, as opposed to the square root increase observed for
postprocessing apodization in traditional DCS. We explore the flexibility to
change resolution and update rate to perform hyperspectral imaging at slow
camera frame rates, where the penalty-free apodization allows for optimal use
of each frame. We obtain dual-comb hyperspectral movies at a 20 Hz spectrum
update rate with broad optical spectral coverage of over 10 THz.
","Fabrizio R. Giorgetta, Jean-Daniel Deschênes, Richard L. Lieber, Ian Coddington, Nathan R. Newbury, Esther Baumann",Esther Baumann,2023-11-17T16:31:42Z
"Spectrum-driven Mixed-frequency Network for Hyperspectral Salient Object
  Detection","  Hyperspectral salient object detection (HSOD) aims to detect spectrally
salient objects in hyperspectral images (HSIs). However, existing methods
inadequately utilize spectral information by either converting HSIs into
false-color images or converging neural networks with clustering. We propose a
novel approach that fully leverages the spectral characteristics by extracting
two distinct frequency components from the spectrum: low-frequency Spectral
Saliency and high-frequency Spectral Edge. The Spectral Saliency approximates
the region of salient objects, while the Spectral Edge captures edge
information of salient objects. These two complementary components, crucial for
HSOD, are derived by computing from the inter-layer spectral angular distance
of the Gaussian pyramid and the intra-neighborhood spectral angular gradients,
respectively. To effectively utilize this dual-frequency information, we
introduce a novel lightweight Spectrum-driven Mixed-frequency Network (SMN).
SMN incorporates two parameter-free plug-and-play operators, namely Spectral
Saliency Generator and Spectral Edge Operator, to extract the Spectral Saliency
and Spectral Edge components from the input HSI independently. Subsequently,
the Mixed-frequency Attention module, comprised of two frequency-dependent
heads, intelligently combines the embedded features of edge and saliency
information, resulting in a mixed-frequency feature representation.
Furthermore, a saliency-edge-aware decoder progressively scales up the
mixed-frequency feature while preserving rich detail and saliency information
for accurate salient object prediction. Extensive experiments conducted on the
HS-SOD benchmark and our custom dataset HSOD-BIT demonstrate that our SMN
outperforms state-of-the-art methods regarding HSOD performance. Code and
dataset will be available at https://github.com/laprf/SMN.
","Peifu Liu, Tingfa Xu, Huan Chen, Shiyun Zhou, Haolin Qin, Jianan Li",Jianan Li,2023-12-02T08:05:45Z
"Exploring Hyperspectral Anomaly Detection with Human Vision: A Small
  Target Aware Detector","  Hyperspectral anomaly detection (HAD) aims to localize pixel points whose
spectral features differ from the background. HAD is essential in scenarios of
unknown or camouflaged target features, such as water quality monitoring, crop
growth monitoring and camouflaged target detection, where prior information of
targets is difficult to obtain. Existing HAD methods aim to objectively detect
and distinguish background and anomalous spectra, which can be achieved almost
effortlessly by human perception. However, the underlying processes of human
visual perception are thought to be quite complex. In this paper, we analyze
hyperspectral image (HSI) features under human visual perception, and transfer
the solution process of HAD to the more robust feature space for the first
time. Specifically, we propose a small target aware detector (STAD), which
introduces saliency maps to capture HSI features closer to human visual
perception. STAD not only extracts more anomalous representations, but also
reduces the impact of low-confidence regions through a proposed small target
filter (STF). Furthermore, considering the possibility of HAD algorithms being
applied to edge devices, we propose a full connected network to convolutional
network knowledge distillation strategy. It can learn the spectral and spatial
features of the HSI while lightening the network. We train the network on the
HAD100 training set and validate the proposed method on the HAD100 test set.
Our method provides a new solution space for HAD that is closer to human visual
perception with high confidence. Sufficient experiments on real HSI with
multiple method comparisons demonstrate the excellent performance and unique
potential of the proposed method. The code is available at
https://github.com/majitao-xd/STAD-HAD.
","Jitao Ma, Weiying Xie, Yunsong Li",Yunsong Li,2024-01-02T08:28:38Z
"Quick unsupervised hyperspectral dimensionality reduction for earth
  observation: a comparison","  Dimensionality reduction can be applied to hyperspectral images so that the
most useful data can be extracted and processed more quickly. This is critical
in any situation in which data volume exceeds the capacity of the computational
resources, particularly in the case of remote sensing platforms (e.g., drones,
satellites), but also in the case of multi-year datasets. Moreover, the
computational strategies of unsupervised dimensionality reduction often provide
the basis for more complicated supervised techniques. Seven unsupervised
dimensionality reduction algorithms are tested on hyperspectral data from the
HYPSO-1 earth observation satellite. Each particular algorithm is chosen to be
representative of a broader collection. The experiments probe the computational
complexity, reconstruction accuracy, signal clarity, sensitivity to artifacts,
and effects on target detection and classification of the different algorithms.
No algorithm consistently outperformed the others across all tests, but some
general trends regarding the characteristics of the algorithms did emerge. With
half a million pixels, computational time requirements of the methods varied by
5 orders of magnitude, and the reconstruction error varied by about 3 orders of
magnitude. A relationship between mutual information and artifact
susceptibility was suggested by the tests. The relative performance of the
algorithms differed significantly between the target detection and
classification tests. Overall, these experiments both show the power of
dimensionality reduction and give guidance regarding how to evaluate a
technique prior to incorporating it into a processing pipeline.
","Daniela Lupu, Joseph L. Garrett, Tor Arne Johansen, Milica Orlandic, Ion Necoara",Ion Necoara,2024-02-26T13:43:43Z
"SSF-Net: Spatial-Spectral Fusion Network with Spectral Angle Awareness
  for Hyperspectral Object Tracking","  Hyperspectral video (HSV) offers valuable spatial, spectral, and temporal
information simultaneously, making it highly suitable for handling challenges
such as background clutter and visual similarity in object tracking. However,
existing methods primarily focus on band regrouping and rely on RGB trackers
for feature extraction, resulting in limited exploration of spectral
information and difficulties in achieving complementary representations of
object features. In this paper, a spatial-spectral fusion network with spectral
angle awareness (SST-Net) is proposed for hyperspectral (HS) object tracking.
Firstly, to address the issue of insufficient spectral feature extraction in
existing networks, a spatial-spectral feature backbone ($S^2$FB) is designed.
With the spatial and spectral extraction branch, a joint representation of
texture and spectrum is obtained. Secondly, a spectral attention fusion module
(SAFM) is presented to capture the intra- and inter-modality correlation to
obtain the fused features from the HS and RGB modalities. It can incorporate
the visual information into the HS spectral context to form a robust
representation. Thirdly, to ensure a more accurate response of the tracker to
the object position, a spectral angle awareness module (SAAM) investigates the
region-level spectral similarity between the template and search images during
the prediction stage. Furthermore, we develop a novel spectral angle awareness
loss (SAAL) to offer guidance for the SAAM based on similar regions. Finally,
to obtain the robust tracking results, a weighted prediction method is
considered to combine the HS and RGB predicted motions of objects to leverage
the strengths of each modality. Extensive experiments on the HOTC dataset
demonstrate the effectiveness of the proposed SSF-Net, compared with
state-of-the-art trackers.
","Hanzheng Wang, Wei Li, Xiang-Gen Xia, Qian Du, Jing Tian",Jing Tian,2024-03-09T09:37:13Z
"Deep Learning for In-Orbit Cloud Segmentation and Classification in
  Hyperspectral Satellite Data","  This article explores the latest Convolutional Neural Networks (CNNs) for
cloud detection aboard hyperspectral satellites. The performance of the latest
1D CNN (1D-Justo-LiuNet) and two recent 2D CNNs (nnU-net and
2D-Justo-UNet-Simple) for cloud segmentation and classification is assessed.
Evaluation criteria include precision and computational efficiency for in-orbit
deployment. Experiments utilize NASA's EO-1 Hyperion data, with varying
spectral channel numbers after Principal Component Analysis. Results indicate
that 1D-Justo-LiuNet achieves the highest accuracy, outperforming 2D CNNs,
while maintaining compactness with larger spectral channel sets, albeit with
increased inference times. However, the performance of 1D CNN degrades with
significant channel reduction. In this context, the 2D-Justo-UNet-Simple offers
the best balance for in-orbit deployment, considering precision, memory, and
time costs. While nnU-net is suitable for on-ground processing, deployment of
lightweight 1D-Justo-LiuNet is recommended for high-precision applications.
Alternatively, lightweight 2D-Justo-UNet-Simple is recommended for balanced
costs between timing and precision in orbit.
","Daniel Kovac, Jan Mucha, Jon Alvarez Justo, Jiri Mekyska, Zoltan Galaz, Krystof Novotny, Radoslav Pitonak, Jan Knezik, Jonas Herec, Tor Arne Johansen",Tor Arne Johansen,2024-03-13T16:58:37Z
"Efficient and Accurate Hyperspectral Image Demosaicing with Neural
  Network Architectures","  Neural network architectures for image demosaicing have been become more and
more complex. This results in long training periods of such deep networks and
the size of the networks is huge. These two factors prevent practical
implementation and usage of the networks in real-time platforms, which
generally only have limited resources. This study investigates the
effectiveness of neural network architectures in hyperspectral image
demosaicing. We introduce a range of network models and modifications, and
compare them with classical interpolation methods and existing reference
network approaches. The aim is to identify robust and efficient performing
network architectures. Our evaluation is conducted on two datasets,
""SimpleData"" and ""SimRealData,"" representing different degrees of realism in
multispectral filter array (MSFA) data. The results indicate that our networks
outperform or match reference models in both datasets demonstrating exceptional
performance. Notably, our approach focuses on achieving correct spectral
reconstruction rather than just visual appeal, and this emphasis is supported
by quantitative and qualitative assessments. Furthermore, our findings suggest
that efficient demosaicing solutions, which require fewer parameters, are
essential for practical applications. This research contributes valuable
insights into hyperspectral imaging and its potential applications in various
fields, including medical imaging.
","Eric L. Wisotzky, Lara Wallburg, Anna Hilsmann, Peter Eisert, Thomas Wittenberg, Stephan Göb",Stephan Göb,2023-12-21T08:02:49Z
"Spatio-Spectral Structure Tensor Total Variation for Hyperspectral Image
  Denoising and Destriping","  This paper proposes a novel regularization method, named Spatio-Spectral
Structure Tensor Total Variation (S3TTV), for denoising and destriping of
hyperspectral (HS) images. HS images are inevitably contaminated by various
types of noise, during acquisition process, due to the measurement equipment
and the environment. For HS image denoising and destriping tasks,
Spatio-Spectral Total Variation (SSTV), defined using second-order
spatio-spectral differences, is widely known as a powerful regularization
approach that models the underlying spatio-spectral properties. However, since
SSTV refers only to adjacent pixels/bands, semi-local spatial structures are
not preserved during denoising process. To address this problem, we newly
design S3TTV, defined by the sum of the nuclear norms of matrices consisting of
second-order spatio-spectral differences in small spectral blocks (we call
these matrices as spatio-spectral structure tensors). The proposed
regularization method simultaneously models the spatial piecewise-smoothness,
the spatial similarity between adjacent bands, and the spectral correlation
across all bands in small spectral blocks, leading to effective noise removal
while preserving the semi-local spatial structures. Furthermore, we formulate
the HS image denoising and destriping problem as a convex optimization problem
involving S3TTV and develop an algorithm based on a preconditioned primal-dual
splitting method to solve this problem efficiently. Finally, we demonstrate the
effectiveness of S3TTV by comparing it with existing methods, including
state-of-the-art ones through denoising and destriping experiments.
","Shingo Takemoto, Shunsuke Ono",Shunsuke Ono,2024-04-04T09:22:18Z
"3DSS-Mamba: 3D-Spectral-Spatial Mamba for Hyperspectral Image
  Classification","  Hyperspectral image (HSI) classification constitutes the fundamental research
in remote sensing fields. Convolutional Neural Networks (CNNs) and Transformers
have demonstrated impressive capability in capturing spectral-spatial
contextual dependencies. However, these architectures suffer from limited
receptive fields and quadratic computational complexity, respectively.
Fortunately, recent Mamba architectures built upon the State Space Model
integrate the advantages of long-range sequence modeling and linear
computational efficiency, exhibiting substantial potential in low-dimensional
scenarios. Motivated by this, we propose a novel 3D-Spectral-Spatial Mamba
(3DSS-Mamba) framework for HSI classification, allowing for global
spectral-spatial relationship modeling with greater computational efficiency.
Technically, a spectral-spatial token generation (SSTG) module is designed to
convert the HSI cube into a set of 3D spectral-spatial tokens. To overcome the
limitations of traditional Mamba, which is confined to modeling causal
sequences and inadaptable to high-dimensional scenarios, a 3D-Spectral-Spatial
Selective Scanning (3DSS) mechanism is introduced, which performs pixel-wise
selective scanning on 3D hyperspectral tokens along the spectral and spatial
dimensions. Five scanning routes are constructed to investigate the impact of
dimension prioritization. The 3DSS scanning mechanism combined with
conventional mapping operations forms the 3D-spectral-spatial mamba block
(3DMB), enabling the extraction of global spectral-spatial semantic
representations. Experimental results and analysis demonstrate that the
proposed method outperforms the state-of-the-art methods on HSI classification
benchmarks.
","Yan He, Bing Tu, Bo Liu, Jun Li, Antonio Plaza",Antonio Plaza,2024-05-21T04:10:26Z
"Hyperspectral Pansharpening: Critical Review, Tools and Future
  Perspectives","  Hyperspectral pansharpening consists of fusing a high-resolution panchromatic
band and a low-resolution hyperspectral image to obtain a new image with high
resolution in both the spatial and spectral domains. These remote sensing
products are valuable for a wide range of applications, driving ever growing
research efforts. Nonetheless, results still do not meet application demands.
In part, this comes from the technical complexity of the task: compared to
multispectral pansharpening, many more bands are involved, in a spectral range
only partially covered by the panchromatic component and with overwhelming
noise. However, another major limiting factor is the absence of a comprehensive
framework for the rapid development and accurate evaluation of new methods.
This paper attempts to address this issue.
  We started by designing a dataset large and diverse enough to allow reliable
training (for data-driven methods) and testing of new methods. Then, we
selected a set of state-of-the-art methods, following different approaches,
characterized by promising performance, and reimplemented them in a single
PyTorch framework. Finally, we carried out a critical comparative analysis of
all methods, using the most accredited quality indicators. The analysis
highlights the main limitations of current solutions in terms of
spectral/spatial quality and computational efficiency, and suggests promising
research directions.
  To ensure full reproducibility of the results and support future research,
the framework (including codes, evaluation procedures and links to the dataset)
is shared on https://github.com/matciotola/hyperspectral_pansharpening_toolbox,
as a single Python-based reference benchmark toolbox.
","Matteo Ciotola, Giuseppe Guarino, Gemine Vivone, Giovanni Poggi, Jocelyn Chanussot, Antonio Plaza, Giuseppe Scarpa",Giuseppe Scarpa,2024-07-01T15:10:50Z
"Mid-Infrared Hyperspectral Microscopy with Broadband 1-GHz Dual
  Frequency Combs","  Mid-infrared microscopy is an important tool for biological analyses,
allowing a direct probe of molecular bonds in their low energy landscape. In
addition to the label-free extraction of spectroscopic information, the
application of broadband sources can provide a third dimension of chemical
specificity. However, to enable widespread deployment, mid-infrared microscopy
platforms need to be compact and robust while offering high speed, broad
bandwidth and high signal-to-noise ratio (SNR). In this study, we
experimentally showcase the integration of a broadband, high-repetition-rate
dual-comb spectrometer (DCS) in the mid-infrared range with a scanning
microscope. We employ a set of 1-GHz mid-infrared frequency combs,
demonstrating their capability for high-speed and broadband hyperspectral
imaging of polymers and ovarian tissue. The system covers 1000
$\mathrm{cm^{-1}}$ at $\mathrm{\nu_c=2941 \; cm^{-1}}$ with 12.86 kHz spectra
acquisition rate and 5 $\mathrm{\mu m}$ spatial resolution. Taken together, our
experiments and analysis elucidate the trade-off between bandwidth and speed in
DCS as it relates to microscopy. This provides a roadmap for the future
advancement and application of high-repetition-rate DCS hyperspectral imaging.
","Peter Chang, Ragib Ishrak, Nazanin Hoghooghi, Scott Egbert, Daniel Lesko, Stephanie Swartz, Jens Biegert, Gregory B. Rieker, Rohith Reddy, Scott A. Diddams",Scott A. Diddams,2024-07-02T06:11:32Z
"Analytical Aberration Theory for Plane-symmetric Optical Systems and its
  Application in the Analysis of Distortion in Freeform Spectrometers","  The recent history of optical design saw a progressive trend of also
designing without rotational symmetry, especially spectrometers due to the use
of reflective and diffractive elements in their designs. A freeform
hyperspectral imager design in CubeSat format is presented in this work, which
has large deviation from rotational symmetry. Based on a generalization of
paraxial optics and wavefront aberration expansion applicable to
plane-symmetric systems, in this dissertation we derived the aberration
coefficients of aberration types in the third group for plane-symmetric systems
that include the second order effects of the light beam footprint on optical
surfaces. We also expanded the theory to include the contributions from
freeform surfaces and induced aberrations. For the application to
plane-symmetric spectrometers, the aberration coefficients related to
distortion are of special interest. Comparisons between the distortion results
predicted by the aberration coefficients and simulated from real raytracing
show good consistency in example systems of a Dyson spectrometer and freeform
spectrometers that share the three-mirror double-pass structure, which is
similar to the spectrometer component of the hyperspectral imager we designed.
In comparison to real raytracing, results of the theory applied to the
spectrometer of the hyperspectral imager we designed show the limits of the
theory that is limited to the third group of aberrations, while in this design,
high-order groups also significantly contribute. In all cases, the analytical
formulae of the aberration coefficients contain the information on surface
contributions, induced aberrations, and the relation between the aberration
behavior and system parameters, which provide valuable insights in the analysis
of plane-symmetric systems.
",Yuxuan Liu,Yuxuan Liu,2024-07-08T23:22:51Z
"UnmixingSR: Material-aware Network with Unsupervised Unmixing as
  Auxiliary Task for Hyperspectral Image Super-resolution","  Deep learning-based (DL-based) hyperspectral image (HIS) super-resolution
(SR) methods have achieved remarkable performance and attracted attention in
industry and academia. Nonetheless, most current methods explored and learned
the mapping relationship between low-resolution (LR) and high-resolution (HR)
HSIs, leading to the side effect of increasing unreliability and irrationality
in solving the ill-posed SR problem. We find, quite interestingly, LR imaging
is similar to the mixed pixel phenomenon. A single photodetector in sensor
arrays receives the reflectance signals reflected by a number of classes,
resulting in low spatial resolution and mixed pixel problems. Inspired by this
observation, this paper proposes a component-aware HSI SR network called
UnmixingSR, in which the unsupervised HU as an auxiliary task is used to
perceive the material components of HSIs. We regard HU as an auxiliary task and
incorporate it into the HSI SR process by exploring the constraints between LR
and HR abundances. Instead of only learning the mapping relationship between LR
and HR HSIs, we leverage the bond between LR abundances and HR abundances to
boost the stability of our method in solving SR problems. Moreover, the
proposed unmixing process can be embedded into existing deep SR models as a
plug-in-play auxiliary task. Experimental results on hyperspectral experiments
show that unmixing process as an auxiliary task incorporated into the SR
problem is feasible and rational, achieving outstanding performance. The code
is available at
",Yang Yu,Yang Yu,2024-07-09T03:41:02Z
"GraphMamba: An Efficient Graph Structure Learning Vision Mamba for
  Hyperspectral Image Classification","  Efficient extraction of spectral sequences and geospatial information has
always been a hot topic in hyperspectral image classification. In terms of
spectral sequence feature capture, RNN and Transformer have become mainstream
classification frameworks due to their long-range feature capture capabilities.
In terms of spatial information aggregation, CNN enhances the receptive field
to retain integrated spatial information as much as possible. However, the
spectral feature-capturing architectures exhibit low computational efficiency,
and CNNs lack the flexibility to perceive spatial contextual information. To
address these issues, this paper proposes GraphMamba--an efficient graph
structure learning vision Mamba classification framework that fully considers
HSI characteristics to achieve deep spatial-spectral information mining.
Specifically, we propose a novel hyperspectral visual GraphMamba processing
paradigm (HVGM) that preserves spatial-spectral features by constructing
spatial-spectral cubes and utilizes linear spectral encoding to enhance the
operability of subsequent tasks. The core components of GraphMamba include the
HyperMamba module for improving computational efficiency and the SpectralGCN
module for adaptive spatial context awareness. The HyperMamba mitigates clutter
interference by employing the global mask (GM) and introduces a parallel
training inference architecture to alleviate computational bottlenecks. The
SpatialGCN incorporates weighted multi-hop aggregation (WMA) spatial encoding
to focus on highly correlated spatial structural features, thus flexibly
aggregating contextual information while mitigating spatial noise interference.
Extensive experiments were conducted on three different scales of real HSI
datasets, and compared with the state-of-the-art classification frameworks,
GraphMamba achieved optimal performance.
","Aitao Yang, Min Li, Yao Ding, Leyuan Fang, Yaoming Cai, Yujie He",Yujie He,2024-07-11T07:56:08Z
"Using $k$-means to sort spectra: electronic order mapping from scanning
  tunneling spectroscopy measurements","  Hyperspectral imaging techniques have a unique ability to probe the
inhomogeneity of material properties whether driven by compositional variation
or other forms of phase segregation. In the doped cuprates, iridates, and
related materials, scanning tunneling microscopy/spectroscopy (STM/STS)
measurements have found the emergence of pseudogap 'puddles' from the
macroscopically Mott insulating phase with increased doping. However,
categorizing this hyperspectral data by electronic order is not trivial, and
has often been done with ad hoc methods. In this paper we demonstrate the
utility of $k$-means, a simple and easy-to-use unsupervised clustering method,
as a tool for classifying heterogeneous scanning tunneling spectroscopy data by
electronic order for Rh-doped Sr$_2$IrO$_{4}$, a cuprate-like material. Applied
to STM data acquired within the Mott phase, $k$-means successfully identified
areas of Mott order and of pseudogap order. The unsupervised nature of
$k$-means limits avenues for bias, and provides clustered spectral shapes
without a priori knowledge of the physics. Additionally, we demonstrate
successful use of $k$-means as a preprocessing tool to constrain
phenomenological function fitting. Clustering the data allows us to reduce the
fitting parameter space, limiting over-fitting. We suggest $k$-means as a fast,
simple model for processing hyperspectral data on materials of mixed electronic
order.
","V. King, Seokhwan Choi, Dong Chen, Brandon Stuart, Jisun Kim, Mohamed Oudah, Jimin Kim, B. J. Kim, D. A. Bonn, S. A. Burke",S. A. Burke,2024-08-13T02:10:11Z
"A novel approach to combine spatial and spectral information from
  hyperspectral images","  This article proposes a generic framework to process jointly the spatial and
spectral information of hyperspectral images. First, sub-images are extracted.
Then each of these sub-images follows two parallel workflows, one dedicated to
the extraction of spatial features and the other dedicated to the extraction of
spectral features. Finally, the extracted features are merged, producing as
many scores as sub-images. Two applications are proposed, illustrating
different spatial and spectral processing methods. The first one is related to
the characterization of a teak wood disk, in an unsupervised way. It implements
tensors of structure for the spatial branch, simple averaging for the spectral
branch and multi-block principal component analysis for the fusion process. The
second application is related to the early detection of apple scab on leaves.
It implements co-occurrence matrices for the spatial branch, singular value
decomposition for the spectral branch and multiblock partial least squares
discriminant analysis for the fusion process. Both applications demonstrate the
interest of the proposed method for the extraction of relevant spatial and
spectral information and show how promising this new approach is for
hyperspectral imaging processing.
","Belal Gaci, Florent Abdelghafour, Maxime Ryckewaert, Sílvia Mas Garcia, Marine Louargant, Florence Verpont, Yohana Laloum, Ryad Bendoula, Gilles Chaix, Jean-Michel Roger",Jean-Michel Roger,2024-08-21T08:37:46Z
"Self-supervised Fusarium Head Blight Detection with Hyperspectral Image
  and Feature Mining","  Fusarium Head Blight (FHB) is a serious fungal disease affecting wheat
(including durum), barley, oats, other small cereal grains, and corn. Effective
monitoring and accurate detection of FHB are crucial to ensuring stable and
reliable food security. Traditionally, trained agronomists and surveyors
perform manual identification, a method that is labor-intensive, impractical,
and challenging to scale. With the advancement of deep learning and
Hyper-spectral Imaging (HSI) and Remote Sensing (RS) technologies, employing
deep learning, particularly Convolutional Neural Networks (CNNs), has emerged
as a promising solution. Notably, wheat infected with serious FHB may exhibit
significant differences on the spectral compared to mild FHB one, which is
particularly advantageous for hyperspectral image-based methods. In this study,
we propose a self-unsupervised classification method based on HSI endmember
extraction strategy and top-K bands selection, designed to analyze material
signatures in HSIs to derive discriminative feature representations. This
approach does not require expensive device or complicate algorithm design,
making it more suitable for practical uses. Our method has been effectively
validated in the Beyond Visible Spectrum: AI for Agriculture Challenge 2024.
The source code is easy to reproduce and available at
{https://github.com/VanLinLin/Automated-Crop-Disease-Diagnosis-from-Hyperspectral-Imagery-3rd}.
","Yu-Fan Lin, Ching-Heng Cheng, Bo-Cheng Qiu, Cheng-Jun Kang, Chia-Ming Lee, Chih-Chung Hsu",Chih-Chung Hsu,2024-08-31T09:09:02Z
Deep intra-operative illumination calibration of hyperspectral cameras,"  Hyperspectral imaging (HSI) is emerging as a promising novel imaging modality
with various potential surgical applications. Currently available cameras,
however, suffer from poor integration into the clinical workflow because they
require the lights to be switched off, or the camera to be manually
recalibrated as soon as lighting conditions change. Given this critical
bottleneck, the contribution of this paper is threefold: (1) We demonstrate
that dynamically changing lighting conditions in the operating room
dramatically affect the performance of HSI applications, namely physiological
parameter estimation, and surgical scene segmentation. (2) We propose a novel
learning-based approach to automatically recalibrating hyperspectral images
during surgery and show that it is sufficiently accurate to replace the tedious
process of white reference-based recalibration. (3) Based on a total of 742 HSI
cubes from a phantom, porcine models, and rats we show that our recalibration
method not only outperforms previously proposed methods, but also generalizes
across species, lighting conditions, and image processing tasks. Due to its
simple workflow integration as well as high accuracy, speed, and generalization
capabilities, our method could evolve as a central component in clinical
surgical HSI.
","Alexander Baumann, Leonardo Ayala, Alexander Studier-Fischer, Jan Sellner, Berkin Özdemir, Karl-Friedrich Kowalewski, Slobodan Ilic, Silvia Seidlitz, Lena Maier-Hein",Lena Maier-Hein,2024-09-11T08:30:03Z
"IGroupSS-Mamba: Interval Group Spatial-Spectral Mamba for Hyperspectral
  Image Classification","  Hyperspectral image (HSI) classification has garnered substantial attention
in remote sensing fields. Recent Mamba architectures built upon the Selective
State Space Models (S6) have demonstrated enormous potential in long-range
sequence modeling. However, the high dimensionality of hyperspectral data and
information redundancy pose challenges to the application of Mamba in HSI
classification, suffering from suboptimal performance and computational
efficiency. In light of this, this paper investigates a lightweight Interval
Group Spatial-Spectral Mamba framework (IGroupSS-Mamba) for HSI classification,
which allows for multi-directional and multi-scale global spatial-spectral
information extraction in a grouping and hierarchical manner. Technically, an
Interval Group S6 Mechanism (IGSM) is developed as the core component, which
partitions high-dimensional features into multiple non-overlapping groups at
intervals, and then integrates a unidirectional S6 for each group with a
specific scanning direction to achieve non-redundant sequence modeling.
Compared to conventional applying multi-directional scanning to all bands, this
grouping strategy leverages the complementary strengths of different scanning
directions while decreasing computational costs. To adequately capture the
spatial-spectral contextual information, an Interval Group Spatial-Spectral
Block (IGSSB) is introduced, in which two IGSM-based spatial and spectral
operators are cascaded to characterize the global spatial-spectral relationship
along the spatial and spectral dimensions, respectively. IGroupSS-Mamba is
constructed as a hierarchical structure stacked by multiple IGSSB blocks,
integrating a pixel aggregation-based downsampling strategy for multiscale
spatial-spectral semantic learning from shallow to deep stages. Extensive
experiments demonstrate that IGroupSS-Mamba outperforms the state-of-the-art
methods.
","Yan He, Bing Tu, Puzhao Jiang, Bo Liu, Jun Li, Antonio Plaza",Antonio Plaza,2024-10-07T14:55:50Z
"HyperspectralViTs: General Hyperspectral Models for On-board Remote
  Sensing","  On-board processing of hyperspectral data with machine learning models would
enable unprecedented amount of autonomy for a wide range of tasks, for example
methane detection or mineral identification. This can enable early warning
system and could allow new capabilities such as automated scheduling across
constellations of satellites. Classical methods suffer from high false positive
rates and previous deep learning models exhibit prohibitive computational
requirements. We propose fast and accurate machine learning architectures which
support end-to-end training with data of high spectral dimension without
relying on hand-crafted products or spectral band compression preprocessing. We
evaluate our models on two tasks related to hyperspectral data processing. With
our proposed general architectures, we improve the F1 score of the previous
methane detection state-of-the-art models by 27% on a newly created synthetic
dataset and by 13% on the previously released large benchmark dataset. We also
demonstrate that training models on the synthetic dataset improves performance
of models finetuned on the dataset of real events by 6.9% in F1 score in
contrast with training from scratch. On a newly created dataset for mineral
identification, our models provide 3.5% improvement in the F1 score in contrast
to the default versions of the models. With our proposed models we improve the
inference speed by 85% in contrast to previous classical and deep learning
approaches by removing the dependency on classically computed features. With
our architecture, one capture from the EMIT sensor can be processed within 30
seconds on realistic proxy of the ION-SCV 004 satellite.
","Vít Růžička, Andrew Markham",Andrew Markham,2024-10-22T17:59:55Z
"Hyperspectral Imaging-Based Perception in Autonomous Driving Scenarios:
  Benchmarking Baseline Semantic Segmentation Models","  Hyperspectral Imaging (HSI) is known for its advantages over traditional RGB
imaging in remote sensing, agriculture, and medicine. Recently, it has gained
attention for enhancing Advanced Driving Assistance Systems (ADAS) perception.
Several HSI datasets such as HyKo, HSI-Drive, HSI-Road, and Hyperspectral City
have been made available. However, a comprehensive evaluation of semantic
segmentation models (SSM) using these datasets is lacking. To address this gap,
we evaluated the available annotated HSI datasets on four deep learning-based
baseline SSMs: DeepLab v3+, HRNet, PSPNet, and U-Net, along with its two
variants: Coordinate Attention (UNet-CA) and Convolutional Block-Attention
Module (UNet-CBAM). The original model architectures were adapted to handle the
varying spatial and spectral dimensions of the datasets. These baseline SSMs
were trained using a class-weighted loss function for individual HSI datasets
and evaluated using mean-based metrics such as intersection over union (IoU),
recall, precision, F1 score, specificity, and accuracy. Our results indicate
that UNet-CBAM, which extracts channel-wise features, outperforms other SSMs
and shows potential to leverage spectral information for enhanced semantic
segmentation. This study establishes a baseline SSM benchmark on available
annotated datasets for future evaluation of HSI-based ADAS perception. However,
limitations of current HSI datasets, such as limited dataset size, high class
imbalance, and lack of fine-grained annotations, remain significant constraints
for developing robust SSMs for ADAS applications.
","Imad Ali Shah, Jiarong Li, Martin Glavin, Edward Jones, Enda Ward, Brian Deegan",Brian Deegan,2024-10-29T14:54:13Z
"The Matsu Wheel: A Cloud-based Framework for Efficient Analysis and
  Reanalysis of Earth Satellite Imagery","  Project Matsu is a collaboration between the Open Commons Consortium and NASA
focused on developing open source technology for the cloud-based processing of
Earth satellite imagery. A particular focus is the development of applications
for detecting fires and floods to help support natural disaster detection and
relief. Project Matsu has developed an open source cloud-based infrastructure
to process, analyze, and reanalyze large collections of hyperspectral satellite
image data using OpenStack, Hadoop, MapReduce, Storm and related technologies.
  We describe a framework for efficient analysis of large amounts of data
called the Matsu ""Wheel."" The Matsu Wheel is currently used to process incoming
hyperspectral satellite data produced daily by NASA's Earth Observing-1 (EO-1)
satellite. The framework is designed to be able to support scanning queries
using cloud computing applications, such as Hadoop and Accumulo. A scanning
query processes all, or most of the data, in a database or data repository.
  We also describe our preliminary Wheel analytics, including an anomaly
detector for rare spectral signatures or thermal anomalies in hyperspectral
data and a land cover classifier that can be used for water and flood
detection. Each of these analytics can generate visual reports accessible via
the web for the public and interested decision makers. The resultant products
of the analytics are also made accessible through an Open Geospatial Compliant
(OGC)-compliant Web Map Service (WMS) for further distribution. The Matsu Wheel
allows many shared data services to be performed together to efficiently use
resources for processing hyperspectral satellite image data and other, e.g.,
large environmental datasets that may be analyzed for many purposes.
","Maria T Patterson, Nikolas Anderson, Collin Bennett, Jacob Bruggemann, Robert Grossman, Matthew Handy, Vuong Ly, Dan Mandl, Shane Pederson, Jim Pivarski, Ray Powell, Jonathan Spring, Walt Wells",Walt Wells,2016-02-22T18:51:14Z
"Effective training of deep convolutional neural networks for
  hyperspectral image classification through artificial labeling","  Hyperspectral imaging is a rich source of data, allowing for multitude of
effective applications. However, such imaging remains challenging because of
large data dimension and, typically, small pool of available training examples.
While deep learning approaches have been shown to be successful in providing
effective classification solutions, especially for high dimensional problems,
unfortunately they work best with a lot of labelled examples available. To
alleviate the second requirement for a particular dataset the transfer learning
approach can be used: first the network is pre-trained on some dataset with
large amount of training labels available, then the actual dataset is used to
fine-tune the network. This strategy is not straightforward to apply with
hyperspectral images, as it is often the case that only one particular image of
some type or characteristic is available. In this paper, we propose and
investigate a simple and effective strategy of transfer learning that uses
unsupervised pre-training step without label information. This approach can be
applied to many of the hyperspectral classification problems. Performed
experiments show that it is very effective at improving the classification
accuracy without being restricted to a particular image type or neural network
architecture. The experiments were carried out on several deep neural network
architectures and various sizes of labeled training sets. The greatest
improvement in overall accuracy on the Indian Pines and Pavia University
datasets is over 21 and 13 percentage points, respectively. An additional
advantage of the proposed approach is the unsupervised nature of the
pre-training step, which can be done immediately after image acquisition,
without the need of the potentially costly expert's time.
","Wojciech Masarczyk, Przemysław Głomb, Bartosz Grabowski, Mateusz Ostaszewski",Mateusz Ostaszewski,2019-09-12T08:47:21Z
Spectral unmixing for exoplanet direct detection in hyperspectral data,"  The direct detection of exoplanets with high-contrast instruments can be
boosted with high spectral resolution. For integral field spectrographs
yielding hyperspectral data, this means that the field of view consists of
diffracted starlight spectra and a spatially localized planet. Analysis usually
relies on cross-correlation with theoretical spectra. In a purely blind-search
context, this supervised strategy can be biased with model mismatch and/or be
computationally inefficient. Using an approach that is inspired by the
remote-sensing community, we aim to propose an alternative to cross-correlation
that is fully data-driven, which decomposes the data into a set of individual
spectra and their corresponding spatial distributions. This strategy is called
spectral unmixing. We used an orthogonal subspace projection to identify the
most distinct spectra in the field of view. Their spatial distribution maps
were then obtained by inverting the data. These spectra were then used to break
the original hyperspectral images into their corresponding spatial distribution
maps via non-negative least squares. The performance of our method was
evaluated and compared with a cross-correlation using simulated hyperspectral
data with medium resolution from the ELT/HARMONI integral field spectrograph.
We show that spectral unmixing effectively leads to a planet detection solely
based on spectral dissimilarities at significantly reduced computational cost.
The extracted spectrum holds significant signatures of the planet while being
not perfectly separated from residual starlight. The sensitivity of the
supervised cross-correlation is three to four times higher than with
unsupervised spectral unmixing, the gap is biased toward the former because the
injected and correlated spectrum match perfectly. The algorithm was furthermore
vetted on real data obtained with VLT/SINFONI of the beta Pictoris system.
","Julien Rameau, Jocelyn Chanussot, Alexis Carlotti, Mickael Bonnefoy, Philippe Delorme",Philippe Delorme,2021-05-11T12:21:48Z
"A graph cut approach to 3D tree delineation, using integrated airborne
  LiDAR and hyperspectral imagery","  Recognising individual trees within remotely sensed imagery has important
applications in forest ecology and management. Several algorithms for tree
delineation have been suggested, mostly based on locating local maxima or
inverted basins in raster canopy height models (CHMs) derived from Light
Detection And Ranging (LiDAR) data or photographs. However, these algorithms
often lead to inaccurate estimates of forest stand characteristics due to the
limited information content of raster CHMs. Here we develop a 3D tree
delineation method which uses graph cut to delineate trees from the full 3D
LiDAR point cloud, and also makes use of any optical imagery available
(hyperspectral imagery in our case). First, conventional methods are used to
locate local maxima in the CHM and generate an initial map of trees. Second, a
graph is built from the LiDAR point cloud, fused with the hyperspectral data.
For computational efficiency, the feature space of hyperspectral imagery is
reduced using robust PCA. Third, a multi-class normalised cut is applied to the
graph, using the initial map of trees to constrain the number of clusters and
their locations. Finally, recursive normalised cut is used to subdivide, if
necessary, each of the clusters identified by the initial analysis. We call
this approach Multiclass Cut followed by Recursive Cut (MCRC). The
effectiveness of MCRC was tested using three datasets: i) NewFor, ii) a
coniferous forest in the Italian Alps, and iii) a deciduous woodland in the UK.
The performance of MCRC was usually superior to that of other delineation
methods, and was further improved by including high-resolution optical imagery.
Since MCRC delineates the entire LiDAR point cloud in 3D, it allows individual
crown characteristics to be measured. By making full use of the data available,
graph cut has the potential to considerably improve the accuracy of tree
delineation.
","Juheon Lee, David Coomes, Carola-Bibiane Schonlieb, Xiaohao Cai, Jan Lellmann, Michele Dalponte, Yadvinder Malhi, Nathalie Butt, Mike Morecroft",Mike Morecroft,2017-01-24T02:41:30Z
"Spectral-spatial classification of hyperspectral images: three tricks
  and a new supervised learning setting","  Spectral-spatial classification of hyperspectral images has been the subject
of many studies in recent years. In the presence of only very few labeled
pixels, this task becomes challenging. In this paper we address the following
two research questions: 1) Can a simple neural network with just a single
hidden layer achieve state of the art performance in the presence of few
labeled pixels? 2) How is the performance of hyperspectral image classification
methods affected when using disjoint train and test sets? We give a positive
answer to the first question by using three tricks within a very basic shallow
Convolutional Neural Network (CNN) architecture: a tailored loss function, and
smooth- and label-based data augmentation. The tailored loss function enforces
that neighborhood wavelengths have similar contributions to the features
generated during training. A new label-based technique here proposed favors
selection of pixels in smaller classes, which is beneficial in the presence of
very few labeled pixels and skewed class distributions. To address the second
question, we introduce a new sampling procedure to generate disjoint train and
test set. Then the train set is used to obtain the CNN model, which is then
applied to pixels in the test set to estimate their labels. We assess the
efficacy of the simple neural network method on five publicly available
hyperspectral images. On these images our method significantly outperforms
considered baselines. Notably, with just 1% of labeled pixels per class, on
these datasets our method achieves an accuracy that goes from 86.42%
(challenging dataset) to 99.52% (easy dataset). Furthermore we show that the
simple neural network method improves over other baselines in the new
challenging supervised setting. Our analysis substantiates the highly
beneficial effect of using the entire image (so train and test data) for
constructing a model.
","Jacopo Acquarelli, Elena Marchiori, Lutgarde M. C. Buydens, Thanh Tran, Twan van Laarhoven",Twan van Laarhoven,2017-11-15T12:02:57Z
Deep Learning for Hyperspectral Image Classification: An Overview,"  Hyperspectral image (HSI) classification has become a hot topic in the field
of remote sensing. In general, the complex characteristics of hyperspectral
data make the accurate classification of such data challenging for traditional
machine learning methods. In addition, hyperspectral imaging often deals with
an inherently nonlinear relation between the captured spectral information and
the corresponding materials. In recent years, deep learning has been recognized
as a powerful feature-extraction tool to effectively address nonlinear problems
and widely used in a number of image processing tasks. Motivated by those
successful applications, deep learning has also been introduced to classify
HSIs and demonstrated good performance. This survey paper presents a systematic
review of deep learning-based HSI classification literatures and compares
several strategies for this topic. Specifically, we first summarize the main
challenges of HSI classification which cannot be effectively overcome by
traditional machine learning methods, and also introduce the advantages of deep
learning to handle these problems. Then, we build a framework which divides the
corresponding works into spectral-feature networks, spatial-feature networks,
and spectral-spatial-feature networks to systematically review the recent
achievements in deep learning-based HSI classification. In addition,
considering the fact that available training samples in the remote sensing
field are usually very limited and training deep networks require a large
number of samples, we include some strategies to improve classification
performance, which can provide some guidelines for future studies on this
topic. Finally, several representative deep learning-based classification
methods are conducted on real HSIs in our experiments.
","Shutao Li, Weiwei Song, Leyuan Fang, Yushi Chen, Pedram Ghamisi, Jón Atli Benediktsson",Jón Atli Benediktsson,2019-10-26T11:50:27Z
"Spectral Variability in Hyperspectral Data Unmixing: A Comprehensive
  Review","  The spectral signatures of the materials contained in hyperspectral images,
also called endmembers (EM), can be significantly affected by variations in
atmospheric, illumination or environmental conditions typically occurring
within an image. Traditional spectral unmixing (SU) algorithms neglect the
spectral variability of the endmembers, what propagates significant mismodeling
errors throughout the whole unmixing process and compromises the quality of its
results. Therefore, large efforts have been recently dedicated to mitigate the
effects of spectral variability in SU. This resulted in the development of
algorithms that incorporate different strategies to allow the EMs to vary
within a hyperspectral image, using, for instance, sets of spectral signatures
known a priori, Bayesian, parametric, or local EM models. Each of these
approaches has different characteristics and underlying motivations. This paper
presents a comprehensive literature review contextualizing both classic and
recent approaches to solve this problem. We give a detailed evaluation of the
sources of spectral variability and their effect in image spectra. Furthermore,
we propose a new taxonomy that organizes existing works according to a
practitioner's point of view, based on the necessary amount of supervision and
on the computational cost they require. We also review methods used to
construct spectral libraries (which are required by many SU techniques) based
on the observed hyperspectral image, as well as algorithms for library
augmentation and reduction. Finally, we conclude the paper with some
discussions and an outline of possible future directions for the field.
","Ricardo Augusto Borsoi, Tales Imbiriba, José Carlos Moreira Bermudez, Cédric Richard, Jocelyn Chanussot, Lucas Drumetz, Jean-Yves Tourneret, Alina Zare, Christian Jutten",Christian Jutten,2020-01-21T01:49:51Z
"In-field early disease recognition of potato late blight based on deep
  learning and proximal hyperspectral imaging","  Effective early detection of potato late blight (PLB) is an essential aspect
of potato cultivation. However, it is a challenge to detect late blight at an
early stage in fields with conventional imaging approaches because of the lack
of visual cues displayed at the canopy level. Hyperspectral imaging can,
capture spectral signals from a wide range of wavelengths also outside the
visual wavelengths. In this context, we propose a deep learning classification
architecture for hyperspectral images by combining 2D convolutional neural
network (2D-CNN) and 3D-CNN with deep cooperative attention networks
(PLB-2D-3D-A). First, 2D-CNN and 3D-CNN are used to extract rich spectral space
features, and then the attention mechanism AttentionBlock and SE-ResNet are
used to emphasize the salient features in the feature maps and increase the
generalization ability of the model. The dataset is built with 15,360 images
(64x64x204), cropped from 240 raw images captured in an experimental field with
over 20 potato genotypes. The accuracy in the test dataset of 2000 images
reached 0.739 in the full band and 0.790 in the specific bands (492nm, 519nm,
560nm, 592nm, 717nm and 765nm). This study shows an encouraging result for
early detection of PLB with deep learning and proximal hyperspectral imaging.
","Chao Qi, Murilo Sandroni, Jesper Cairo Westergaard, Ea Høegh Riis Sundmark, Merethe Bagge, Erik Alexandersson, Junfeng Gao",Junfeng Gao,2021-11-23T21:12:27Z
S^2-Transformer for Mask-Aware Hyperspectral Image Reconstruction,"  The technology of hyperspectral imaging (HSI) records the visual information
upon long-range-distributed spectral wavelengths. A representative
hyperspectral image acquisition procedure conducts a 3D-to-2D encoding by the
coded aperture snapshot spectral imager (CASSI) and requires a software decoder
for the 3D signal reconstruction. By observing this physical encoding
procedure, two major challenges stand in the way of a high-fidelity
reconstruction. (i) To obtain 2D measurements, CASSI dislocates multiple
channels by disperser-titling and squeezes them onto the same spatial region,
yielding an entangled data loss. (ii) The physical coded aperture leads to a
masked data loss by selectively blocking the pixel-wise light exposure. To
tackle these challenges, we propose a spatial-spectral (S^2-) Transformer
network with a mask-aware learning strategy. First, we simultaneously leverage
spatial and spectral attention modeling to disentangle the blended information
in the 2D measurement along both two dimensions. A series of Transformer
structures are systematically designed to fully investigate the spatial and
spectral informative properties of the hyperspectral data. Second, the masked
pixels will induce higher prediction difficulty and should be treated
differently from unmasked ones. Thereby, we adaptively prioritize the loss
penalty attributing to the mask structure by inferring the pixel-wise
reconstruction difficulty upon the mask-encoded prediction. We theoretically
discusses the distinct convergence tendencies between masked/unmasked regions
of the proposed learning strategy. Extensive experiments demonstrates that the
proposed method achieves superior reconstruction performance. Additionally, we
empirically elaborate the behaviour of spatial and spectral attentions under
the proposed architecture, and comprehensively examine the impact of the
mask-aware learning.
","Jiamian Wang, Kunpeng Li, Yulun Zhang, Xin Yuan, Zhiqiang Tao",Zhiqiang Tao,2022-09-24T19:26:46Z
"Evaluation of the potential of Near Infrared Hyperspectral Imaging for
  monitoring the invasive brown marmorated stink bug","  The brown marmorated stink bug (BMSB), Halyomorpha halys, is an invasive
insect pest of global importance that damages several crops, compromising
agri-food production. Field monitoring procedures are fundamental to perform
risk assessment operations, in order to promptly face crop infestations and
avoid economical losses. To improve pest management, spectral cameras mounted
on Unmanned Aerial Vehicles (UAVs) and other Internet of Things (IoT) devices,
such as smart traps or unmanned ground vehicles, could be used as an innovative
technology allowing fast, efficient and real-time monitoring of insect
infestations. The present study consists in a preliminary evaluation at the
laboratory level of Near Infrared Hyperspectral Imaging (NIR-HSI) as a possible
technology to detect BMSB specimens on different vegetal backgrounds,
overcoming the problem of BMSB mimicry. Hyperspectral images of BMSB were
acquired in the 980-1660 nm range, considering different vegetal backgrounds
selected to mimic a real field application scene. Classification models were
obtained following two different chemometric approaches. The first approach was
focused on modelling spectral information and selecting relevant spectral
regions for discrimination by means of sparse-based variable selection coupled
with Soft Partial Least Squares Discriminant Analysis (s-Soft PLS-DA)
classification algorithm. The second approach was based on modelling spatial
and spectral features contained in the hyperspectral images using Convolutional
Neural Networks (CNN). Finally, to further improve BMSB detection ability, the
two strategies were merged, considering only the spectral regions selected by
s-Soft PLS-DA for CNN modelling.
","Veronica Ferrari, Rosalba Calvini, Bas Boom, Camilla Menozzi, Aravind Krishnaswamy Rangarajan, Lara Maistrello, Peter Offermans, Alessandro Ulrici",Alessandro Ulrici,2023-01-19T11:37:20Z
"A comprehensive review of 3D convolutional neural network-based
  classification techniques of diseased and defective crops using non-UAV-based
  hyperspectral images","  Hyperspectral imaging (HSI) is a non-destructive and contactless technology
that provides valuable information about the structure and composition of an
object. It can capture detailed information about the chemical and physical
properties of agricultural crops. Due to its wide spectral range, compared with
multispectral- or RGB-based imaging methods, HSI can be a more effective tool
for monitoring crop health and productivity. With the advent of this imaging
tool in agrotechnology, researchers can more accurately address issues related
to the detection of diseased and defective crops in the agriculture industry.
This allows to implement the most suitable and accurate farming solutions, such
as irrigation and fertilization before crops enter a damaged and
difficult-to-recover phase of growth in the field. While HSI provides valuable
insights into the object under investigation, the limited number of HSI
datasets for crop evaluation presently poses a bottleneck. Dealing with the
curse of dimensionality presents another challenge due to the abundance of
spectral and spatial information in each hyperspectral cube. State-of-the-art
methods based on 1D- and 2D-CNNs struggle to efficiently extract spectral and
spatial information. On the other hand, 3D-CNN-based models have shown
significant promise in achieving better classification and detection results by
leveraging spectral and spatial features simultaneously. Despite the apparent
benefits of 3D-CNN-based models, their usage for classification purposes in
this area of research has remained limited. This paper seeks to address this
gap by reviewing 3D-CNN-based architectures and the typical deep learning
pipeline, including preprocessing and visualization of results, for the
classification of hyperspectral images of diseased and defective crops.
Furthermore, we discuss open research areas and challenges when utilizing
3D-CNNs with HSI data.
","Nooshin Noshiri, Michael A. Beck, Christopher P. Bidinosti, Christopher J. Henry",Christopher J. Henry,2023-06-15T18:02:53Z
"A Comprehensive Survey for Hyperspectral Image Classification: The
  Evolution from Conventional to Transformers","  Hyperspectral Image Classification (HSC) is a challenging task due to the
high dimensionality and complex nature of Hyperspectral (HS) data. Traditional
Machine Learning approaches while effective, face challenges in real-world data
due to varying optimal feature sets, subjectivity in human-driven design,
biases, and limitations. Traditional approaches encounter the curse of
dimensionality, struggle with feature selection and extraction, lack spatial
information consideration, exhibit limited robustness to noise, face
scalability issues, and may not adapt well to complex data distributions. In
recent years, DL techniques have emerged as powerful tools for addressing these
challenges. This survey provides a comprehensive overview of the current trends
and future prospects in HSC, focusing on the advancements from DL models to the
emerging use of Transformers. We review the key concepts, methodologies, and
state-of-the-art approaches in DL for HSC. We explore the potential of
Transformer-based models in HSC, outlining their benefits and challenges. We
also delve into emerging trends in HSC, as well as thorough discussions on
Explainable AI and Interoperability concepts along with Diffusion Models (image
denoising, feature extraction, and image fusion). Additionally, we address
several open challenges and research questions pertinent to HSC. Comprehensive
experimental results have been undertaken using three HS datasets to verify the
efficacy of various conventional DL models and Transformers. Finally, we
outline future research directions and potential applications that can further
enhance the accuracy and efficiency of HSC. The Source code is available at
\url{https://github.com/mahmad00/Conventional-to-Transformer-for-Hyperspectral-Image-Classification-Survey-2024}.
","Muhammad Ahmad, Salvatore Distifano, Adil Mehmood Khan, Manuel Mazzara, Chenyu Li, Jing Yao, Hao Li, Jagannath Aryal, Gemine Vivone, Danfeng Hong",Danfeng Hong,2024-04-23T12:00:20Z
"A digital instrument simulator to optimize the development of
  hyperspectral systems: application for intraoperative functional brain
  mapping","  Intraoperative optical imaging is a localization technique for the functional
areas of the human brain cortex during neurosurgical procedures. These areas
can be assessed by monitoring cerebral hemodynamics and metabolism. A robust
quantification of these biomarkers is complicated to perform during
neurosurgery due to the critical context of the operating room. In actual
devices, the inhomogeneities of the optical properties of exposed brain cortex
are poorly taken into consideration, which introduce quantification errors of
biomarkers of brain functionality. Moreover, the choice of the best spectral
configuration is still based on an empirical approach.
  We propose a digital instrument simulator to optimize the development of
hyperspectral systems. This simulator can provide a realistic modelling of the
cerebral cortex and the identification of the optimal wavelengths to monitor
cerebral hemodynamics (oxygenated and deoxygenated hemoglobin) and metabolism
(oxidized state of cytochromes b, c and cytochrome-c-oxidase).
  The digital instrument allows the modelling of intensity maps collected by a
camera sensor as well as images of pathlength to take into account the
inhomogeneities of the optical properties. The optimization procedure helps to
identify the best wavelength combination of 18 wavelengths that reduce the
quantification errors in HbO2, Hb, oxCCO of 61%, 29% and 82% compared to the
gold standard of 121 wavelengths between 780 and 900 nm. The optimization
procedure does not help to resolve changes in cytochrome b and c in a
significant way but help to better resolve oxCCO changes.
  We proposed a digital instrument simulator to optimize the development of
hyperspectral systems for intraoperative brain mapping studies. This digital
instrument simulator and this optimization framework could be used to optimize
the design of hyperspectral imaging devices.
","Charly Caredda, Frédéric Lange, Luca Giannoni, Ivan Ezhov, Thiébaud Picart, Jacques Guyotat, Ilias Tachtsidis, Bruno Montcel",Bruno Montcel,2024-06-03T11:30:56Z
"Best of both worlds: Fusing hyperspectral data from two generations of
  spectro-imagers for X-ray astrophysics","  With the launch of the X-Ray Imaging and Spectroscopy Mission (XRISM) and the
advent of microcalorimeter detectors, X-ray astrophysics is entering in a new
era of spatially resolved high resolution spectroscopy. But while this new
generation of X-ray telescopes have much finer spectral resolutions than their
predecessors (e.g. XMM-Newton, Chandra), they also have coarser spatial
resolutions, leading to problematic cross-pixel contamination. This issue is
currently a critical limitation for the study of extended sources such as
galaxy clusters of supernova remnants. To increase the scientific output of
XRISM's hyperspectral data, we propose to fuse it with XMM-Newton data, and
seek to obtain a cube with the best spatial and spectral resolution of both
generations. This is the aim of hyperspectral fusion. In this article, we have
implemented an algorithm that jointly deconvolves the spatial response of XRISM
and the spectral response of XMM-Newton. To do so, we construct a forward model
adapted for instrumental systematic degradations and Poisson noise, then tackle
hyperspectral fusion as a regularized inverse problem. We test three methods of
regularization: low rank approximation with Sobolev regularization; low rank
approximation with 2D wavelet sparsity ; and 2D-1D wavelet sparsity. We test
our method on toy models constructed from hydrodynamic simulations of supernova
remnants. We find that our method reconstructs the ground truth well even when
the toy model is complex. For the regularization term, we find that while the
low rank approximation worked well as a spectral denoiser in models with less
spectral variability, it introduced a bias in models with more spectral
variability, in which case the 2D-1D wavelet sparsity regularization worked
best. After demonstrating a proof of concept in this article, we aim to apply
this method to real X-ray astrophysical data in the near future.
","Julia Lascar, Jérôme Bobin, Fabio Acero",Fabio Acero,2024-07-22T13:58:08Z
"Alternating Direction Algorithms for Constrained Sparse Regression:
  Application to Hyperspectral Unmixing","  Convex optimization problems are common in hyperspectral unmixing. Examples
include: the constrained least squares (CLS) and the fully constrained least
squares (FCLS) problems, which are used to compute the fractional abundances in
linear mixtures of known spectra; the constrained basis pursuit (CBP) problem,
which is used to find sparse (i.e., with a small number of non-zero terms)
linear mixtures of spectra from large libraries; the constrained basis pursuit
denoising (CBPDN) problem, which is a generalization of BP that admits modeling
errors. In this paper, we introduce two new algorithms to efficiently solve
these optimization problems, based on the alternating direction method of
multipliers, a method from the augmented Lagrangian family. The algorithms are
termed SUnSAL (sparse unmixing by variable splitting and augmented Lagrangian)
and C-SUnSAL (constrained SUnSAL). C-SUnSAL solves the CBP and CBPDN problems,
while SUnSAL solves CLS and FCLS, as well as a more general version thereof,
called constrained sparse regression (CSR). C-SUnSAL and SUnSAL are shown to
outperform off-the-shelf methods in terms of speed and accuracy.
","José M. Bioucas-Dias, Mário A. T. Figueiredo",Mário A. T. Figueiredo,2010-02-24T11:46:14Z
"High resolution cathodoluminescence hyperspectral imaging of surface
  features in InGaN/GaN multiple quantum well structures","  InGaN/GaN multiple quantum wells (MQWs) have been studied by using
cathodoluminescence hyperspectral imaging with high spatial resolution.
Variations in peak emission energies and intensities across trench-like
features and V-pits on the surface of the MQWs are investigated. The MQW
emission from the region inside trench-like features is red-shifted by
approximately 45 meV and more intense than the surrounding planar regions of
the sample, whereas emission from the V-pits is blue-shifted by about 20 meV
and relatively weaker. By employing this technique to the studied
nanostructures it is possible to investigate energy and intensity shifts on a
10 nm length scale.
","Jochen Bruckbauer, Paul R. Edwards, Tao Wang, Robert W. Martin",Robert W. Martin,2011-02-09T11:08:20Z
"Nonlinear spectral unmixing of hyperspectral images using Gaussian
  processes","  This paper presents an unsupervised algorithm for nonlinear unmixing of
hyperspectral images. The proposed model assumes that the pixel reflectances
result from a nonlinear function of the abundance vectors associated with the
pure spectral components. We assume that the spectral signatures of the pure
components and the nonlinear function are unknown. The first step of the
proposed method consists of the Bayesian estimation of the abundance vectors
for all the image pixels and the nonlinear function relating the abundance
vectors to the observations. The endmembers are subsequently estimated using
Gaussian process regression. The performance of the unmixing strategy is
evaluated with simulations conducted on synthetic and real data.
","Yoann Altmann, Nicolas Dobigeon, Steve McLaughlin, Jean-Yves Tourneret",Jean-Yves Tourneret,2012-07-23T16:51:10Z
Coherent Raman spectro-imaging with laser frequency combs,"  Optical spectroscopy and imaging of microscopic samples have opened up a wide
range of applications throughout the physical, chemical, and biological
sciences. High chemical specificity may be achieved by directly interrogating
the fundamental or low-lying vibrational energy levels of the compound
molecules. Amongst the available prevailing label-free techniques, coherent
Raman scattering has the distinguishing features of high spatial resolution
down to 200 nm and three-dimensional sectioning. However, combining fast
imaging speed and identification of multiple - and possibly unexpected-
compounds remains challenging: existing high spectral resolution schemes
require long measurement times to achieve broad spectral spans. Here we
overcome this difficulty and introduce a novel concept of coherent anti-Stokes
Raman scattering (CARS) spectro-imaging with two laser frequency combs. We
illustrate the power of our technique with high resolution (4 cm-1) Raman
spectra spanning more than 1200 cm-1 recorded within less than 15 microseconds.
Furthermore, hyperspectral images combining high spectral (10 cm-1) and spatial
(2 micrometers) resolutions are acquired at a rate of 50 pixels per second.
Real-time multiplex accessing of hyperspectral images may dramatically expand
the range of applications of nonlinear microscopy.
","Takuro Ideguchi, Simon Holzner, Birgitta Bernhardt, Guy Guelachvili, Nathalie Picqué, Theodor W. Hänsch",Theodor W. Hänsch,2013-02-11T08:31:49Z
Nonlinear unmixing of hyperspectral images: models and algorithms,"  When considering the problem of unmixing hyperspectral images, most of the
literature in the geoscience and image processing areas relies on the widely
used linear mixing model (LMM). However, the LMM may be not valid and other
nonlinear models need to be considered, for instance, when there are
multi-scattering effects or intimate interactions. Consequently, over the last
few years, several significant contributions have been proposed to overcome the
limitations inherent in the LMM. In this paper, we present an overview of
recent advances in nonlinear unmixing modeling.
","Nicolas Dobigeon, Jean-Yves Tourneret, Cédric Richard, José C. M. Bermudez, Stephen McLaughlin, Alfred O. Hero",Alfred O. Hero,2013-04-06T10:21:56Z
Hyperspectral fluorescence microscopy based on Compressive Sampling,"  The mathematical theory of compressed sensing (CS) asserts that one can
acquire signals from measurements whose rate is much lower than the total
bandwidth. Whereas the CS theory is now well developed, challenges concerning
hardware implementations of CS-based acquisition devices-especially in
optics-have only started being addressed. This paper presents an implementation
of compressive sensing in fluorescence microscopy and its applications to
biomedical imaging. Our CS microscope combines a dynamic structured wide-field
illumination and a fast and sensitive single-point fluorescence detection to
enable reconstructions of images of fluorescent beads, cells, and tissues with
undersampling ratios (between the number of pixels and number of measurements)
up to 32. We further demonstrate a hyperspectral mode and record images with
128 spectral channels and undersampling ratios up to 64, illustrating the
potential benefits of CS acquisition for higher-dimensional signals, which
typically exhibits extreme redundancy. Altogether, our results emphasize the
interest of CS schemes for acquisition at a significantly reduced rate and
point to some remaining challenges for CS fluorescence microscopy.
","Makhlad Chahid, Jerome Bobin, Hamed Shams Mousavi, Emmanuel Candes, Maxime Dahan, Vincent Studer",Vincent Studer,2013-07-17T13:17:43Z
Bayesian Fusion of Multi-Band Images,"  In this paper, a Bayesian fusion technique for remotely sensed multi-band
images is presented. The observed images are related to the high spectral and
high spatial resolution image to be recovered through physical degradations,
e.g., spatial and spectral blurring and/or subsampling defined by the sensor
characteristics. The fusion problem is formulated within a Bayesian estimation
framework. An appropriate prior distribution exploiting geometrical
consideration is introduced. To compute the Bayesian estimator of the scene of
interest from its posterior distribution, a Markov chain Monte Carlo algorithm
is designed to generate samples asymptotically distributed according to the
target distribution. To efficiently sample from this high-dimension
distribution, a Hamiltonian Monte Carlo step is introduced in the Gibbs
sampling strategy. The efficiency of the proposed fusion method is evaluated
with respect to several state-of-the-art fusion techniques. In particular, low
spatial resolution hyperspectral and multispectral images are fused to produce
a high spatial resolution hyperspectral image.
","Qi Wei, Nicolas Dobigeon, Jean-Yves Tourneret",Jean-Yves Tourneret,2013-07-23T09:44:36Z
"Semidefinite Programming Based Preconditioning for More Robust
  Near-Separable Nonnegative Matrix Factorization","  Nonnegative matrix factorization (NMF) under the separability assumption can
provably be solved efficiently, even in the presence of noise, and has been
shown to be a powerful technique in document classification and hyperspectral
unmixing. This problem is referred to as near-separable NMF and requires that
there exists a cone spanned by a small subset of the columns of the input
nonnegative matrix approximately containing all columns. In this paper, we
propose a preconditioning based on semidefinite programming making the input
matrix well-conditioned. This in turn can improve significantly the performance
of near-separable NMF algorithms which is illustrated on the popular successive
projection algorithm (SPA). The new preconditioned SPA is provably more robust
to noise, and outperforms SPA on several synthetic data sets. We also show how
an active-set method allow us to apply the preconditioning on large-scale
real-world hyperspectral images.
","Nicolas Gillis, Stephen A. Vavasis",Stephen A. Vavasis,2013-10-08T20:30:38Z
"A comparison of nonlinear mixing models for vegetated areas using
  simulated and real hyperspectral data","  Spectral unmixing is a crucial processing step when analyzing hyperspectral
data. In such analysis, most of the work in the literature relies on the widely
acknowledged linear mixing model to describe the observed pixels.
Unfortunately, this model has been shown to be of limited interest for specific
scenes, in particular when acquired over vegetated areas. Consequently, in the
past few years, several nonlinear mixing models have been introduced to take
nonlinear effects into account while performing spectral unmixing. These models
have been proposed empirically, however without any thorough validation. In
this paper, the authors take advantage of two sets of real and physical-based
simulated data to validate the accuracy of various nonlinear models in
vegetated areas. These physics-based and analysis models, and their
corresponding unmixing algorithms, are evaluated with respect to their ability
of fitting the measured spectra and of providing an accurate estimation of the
abundance coefficients, considered as the spatial distribution of the materials
in each pixel.
","Nicolas Dobigeon, Laurent Tits, Ben Somers, Yoann Altmann, Pol Coppin",Pol Coppin,2013-12-04T18:31:28Z
"Structured Priors for Sparse-Representation-Based Hyperspectral Image
  Classification","  Pixel-wise classification, where each pixel is assigned to a predefined
class, is one of the most important procedures in hyperspectral image (HSI)
analysis. By representing a test pixel as a linear combination of a small
subset of labeled pixels, a sparse representation classifier (SRC) gives rather
plausible results compared with that of traditional classifiers such as the
support vector machine (SVM). Recently, by incorporating additional structured
sparsity priors, the second generation SRCs have appeared in the literature and
are reported to further improve the performance of HSI. These priors are based
on exploiting the spatial dependencies between the neighboring pixels, the
inherent structure of the dictionary, or both. In this paper, we review and
compare several structured priors for sparse-representation-based HSI
classification. We also propose a new structured prior called the low rank
group prior, which can be considered as a modification of the low rank prior.
Furthermore, we will investigate how different structured priors improve the
result for the HSI classification.
","Xiaoxia Sun, Qing Qu, Nasser M. Nasrabadi, Trac D. Tran",Trac D. Tran,2014-01-16T03:21:26Z
"Hyperspectral imaging spectroscopy of a Mars analogue environment at the
  North Pole Dome, Pilbara Craton, Western Australia","  A visible and near infrared (VNIR) to shortwave infrared (SWIR) hyperspectral
dataset of the Early Archaean North Pole Dome, Pilbara Craton, Western
Australia, has been analysed for indications of hydrothermal alteration.
Occurrence maps of hydrothermal alteration minerals were produced. It was found
that using a spatial resolution on the ground of approximately 5 m and spectral
coverage from 0.4 to 2.5 mm was sufficient to delineate several hydrothermal
alteration zones and associated veins, including phyllic, serpentinitic and
chloritic alteration. These results suggest this level of spectral and spatial
resolution would be ideal for localising shallow epithermal activity, should
such activity have existed, on the surface of Mars.
","Adrian J. Brown, Malcolm Walter, Thomas Cudahy",Thomas Cudahy,2014-01-21T07:20:14Z
"Nonlinear hyperspectral unmixing with robust nonnegative matrix
  factorization","  This paper introduces a robust mixing model to describe hyperspectral data
resulting from the mixture of several pure spectral signatures. This new model
not only generalizes the commonly used linear mixing model, but also allows for
possible nonlinear effects to be easily handled, relying on mild assumptions
regarding these nonlinearities. The standard nonnegativity and sum-to-one
constraints inherent to spectral unmixing are coupled with a group-sparse
constraint imposed on the nonlinearity component. This results in a new form of
robust nonnegative matrix factorization. The data fidelity term is expressed as
a beta-divergence, a continuous family of dissimilarity measures that takes the
squared Euclidean distance and the generalized Kullback-Leibler divergence as
special cases. The penalized objective is minimized with a block-coordinate
descent that involves majorization-minimization updates. Simulation results
obtained on synthetic and real data show that the proposed strategy competes
with state-of-the-art linear and nonlinear unmixing methods.
","Cédric Févotte, Nicolas Dobigeon",Nicolas Dobigeon,2014-01-22T13:04:16Z
"Minerals detection for hyperspectral images using adapted linear
  unmixing: LinMin","  Minerals detection over large volume of spectra is the challenge addressed by
current hyperspectral imaging spectrometer in Planetary Science. Instruments
such OMEGA (Mars Express), CRISM (Mars Reconnaissance Orbiter), M^{3}
(Chandrayaan-1), VIRTIS (Rosetta) and many more, have been producing very large
datasets since one decade. We propose here a fast supervised detection
algorithm called LinMin, in the framework of linear unmixing, with innovative
arrangement in order to treat non-linear cases due to radiative transfer in
both atmosphere and surface. We use reference laboratory and synthetic spectral
library. Additional spectra are used in order to mimic the effect of Martian
aerosols, grain size, and observation geometry discrepancies between reference
and observed spectra. The proposed algorithm estimates the uncertainty on
mixing coefficient from the uncertainty of observed spectra. Both numerical and
observational tests validate the approach. Fast parallel implementation of the
best algorithm (IPLS) on Graphics Processing Units (GPU) allows to
significantly reduce the computation cost by a factor of 40.
","Schmidt Frederic, Legendre Maxime, Le Mouelic Stephane",Le Mouelic Stephane,2014-02-11T15:15:20Z
Compressive Hyperspectral Imaging Using Progressive Total Variation,"  Compressed Sensing (CS) is suitable for remote acquisition of hyperspectral
images for earth observation, since it could exploit the strong spatial and
spectral correlations, llowing to simplify the architecture of the onboard
sensors. Solutions proposed so far tend to decouple spatial and spectral
dimensions to reduce the complexity of the reconstruction, not taking into
account that onboard sensors progressively acquire spectral rows rather than
acquiring spectral channels. For this reason, we propose a novel progressive CS
architecture based on separate sensing of spectral rows and joint
reconstruction employing Total Variation. Experimental results run on raw
AVIRIS and AIRS images confirm the validity of the proposed system.
","Simeon Kamdem Kuiteing, Giulio Coluccia, Alessandro Barducci, Mauro Barni, Enrico Magli",Enrico Magli,2014-03-07T09:44:34Z
"Time-Encoded Raman: Fiber-based, hyperspectral, broadband stimulated
  Raman microscopy","  Raman sensing and Raman microscopy are amongst the most specific optical
technologies to identify the chemical compounds of unknown samples, and to
enable label-free biomedical imaging with molecular contrast. However, the high
cost and complexity, low speed, and incomplete spectral information provided by
current technology are major challenges preventing more widespread application
of Raman systems. To overcome these limitations, we developed a new method for
stimulated Raman spectroscopy and Raman imaging using continuous wave (CW),
rapidly wavelength swept lasers. Our all-fiber, time-encoded Raman (TICO-Raman)
setup uses a Fourier Domain Mode Locked (FDML) laser source to achieve a unique
combination of high speed, broad spectral coverage (750 cm-1 - 3150 cm-1) and
high resolution (0.5 cm-1). The Raman information is directly encoded and
acquired in time. We demonstrate quantitative chemical analysis of a solvent
mixture and hyperspectral Raman microscopy with molecular contrast of plant
cells.
","Sebastian Karpf, Matthias Eibl, Wolfgang Wieser, Thomas Klein, Robert Huber",Robert Huber,2014-05-16T14:29:48Z
"Unsupervised Unmixing of Hyperspectral Images Accounting for Endmember
  Variability","  This paper presents an unsupervised Bayesian algorithm for hyperspectral
image unmixing accounting for endmember variability. The pixels are modeled by
a linear combination of endmembers weighted by their corresponding abundances.
However, the endmembers are assumed random to take into account their
variability in the image. An additive noise is also considered in the proposed
model generalizing the normal compositional model. The proposed algorithm
exploits the whole image to provide spectral and spatial information. It
estimates both the mean and the covariance matrix of each endmember in the
image. This allows the behavior of each material to be analyzed and its
variability to be quantified in the scene. A spatial segmentation is also
obtained based on the estimated abundances. In order to estimate the parameters
associated with the proposed Bayesian model, we propose to use a Hamiltonian
Monte Carlo algorithm. The performance of the resulting unmixing strategy is
evaluated via simulations conducted on both synthetic and real data.
","Abderrahim Halimi, Nicolas Dobigeon, Jean-Yves Tourneret",Jean-Yves Tourneret,2014-06-19T15:06:02Z
"Identifiability of the Simplex Volume Minimization Criterion for Blind
  Hyperspectral Unmixing: The No Pure-Pixel Case","  In blind hyperspectral unmixing (HU), the pure-pixel assumption is well-known
to be powerful in enabling simple and effective blind HU solutions. However,
the pure-pixel assumption is not always satisfied in an exact sense, especially
for scenarios where pixels are heavily mixed. In the no pure-pixel case, a good
blind HU approach to consider is the minimum volume enclosing simplex (MVES).
Empirical experience has suggested that MVES algorithms can perform well
without pure pixels, although it was not totally clear why this is true from a
theoretical viewpoint. This paper aims to address the latter issue. We develop
an analysis framework wherein the perfect endmember identifiability of MVES is
studied under the noiseless case. We prove that MVES is indeed robust against
lack of pure pixels, as long as the pixels do not get too heavily mixed and too
asymmetrically spread. The theoretical results are verified by numerical
simulations.
","Chia-Hsiang Lin, Wing-Kin Ma, Wei-Chiang Li, Chong-Yung Chi, ArulMurugan Ambikapathi",ArulMurugan Ambikapathi,2014-06-20T03:54:19Z
"Hyperspectral and Multispectral Image Fusion based on a Sparse
  Representation","  This paper presents a variational based approach to fusing hyperspectral and
multispectral images. The fusion process is formulated as an inverse problem
whose solution is the target image assumed to live in a much lower dimensional
subspace. A sparse regularization term is carefully designed, relying on a
decomposition of the scene on a set of dictionaries. The dictionary atoms and
the corresponding supports of active coding coefficients are learned from the
observed images. Then, conditionally on these dictionaries and supports, the
fusion problem is solved via alternating optimization with respect to the
target image (using the alternating direction method of multipliers) and the
coding coefficients. Simulation results demonstrate the efficiency of the
proposed algorithm when compared with the state-of-the-art fusion methods.
","Qi Wei, José Bioucas-Dias, Nicolas Dobigeon, Jean-Yves Tourneret",Jean-Yves Tourneret,2014-09-19T17:07:53Z
"HyperSpectral classification with adaptively weighted L1-norm
  regularization and spatial postprocessing","  Sparse regression methods have been proven effective in a wide range of
signal processing problems such as image compression, speech coding, channel
equalization, linear regression and classification. In this paper a new convex
method of hyperspectral image classification is developed based on the sparse
unmixing algorithm SUnSAL for which a pixel adaptive L1-norm regularization
term is introduced. To further enhance class separability, the algorithm is
kernelized using an RBF kernel and the final results are improved by a
combination of spatial pre and post-processing operations. It is shown that the
proposed method is competitive with state of the art algorithms such as SVM-CK,
KSOMP-CK and KSSP-CK.
",Victor Stefan Aldea,Victor Stefan Aldea,2014-12-08T18:14:04Z
"Bayesian nonlinear hyperspectral unmixing with spatial residual
  component analysis","  This paper presents a new Bayesian model and algorithm for nonlinear unmixing
of hyperspectral images. The model proposed represents the pixel reflectances
as linear combinations of the endmembers, corrupted by nonlinear (with respect
to the endmembers) terms and additive Gaussian noise. Prior knowledge about the
problem is embedded in a hierarchical model that describes the dependence
structure between the model parameters and their constraints. In particular, a
gamma Markov random field is used to model the joint distribution of the
nonlinear terms, which are expected to exhibit significant spatial
correlations. An adaptive Markov chain Monte Carlo algorithm is then proposed
to compute the Bayesian estimates of interest and perform Bayesian inference.
This algorithm is equipped with a stochastic optimisation adaptation mechanism
that automatically adjusts the parameters of the gamma Markov random field by
maximum marginal likelihood estimation. Finally, the proposed methodology is
demonstrated through a series of experiments with comparisons using synthetic
and real data and with competing state-of-the-art approaches.
","Yoann Altmann, Marcelo Pereyra, Stephen McLaughlin",Stephen McLaughlin,2014-12-15T17:14:48Z
Classification of Hyperspectral Imagery on Embedded Grassmannians,"  We propose an approach for capturing the signal variability in hyperspectral
imagery using the framework of the Grassmann manifold. Labeled points from each
class are sampled and used to form abstract points on the Grassmannian. The
resulting points on the Grassmannian have representations as orthonormal
matrices and as such do not reside in Euclidean space in the usual sense. There
are a variety of metrics which allow us to determine a distance matrices that
can be used to realize the Grassmannian as an embedding in Euclidean space. We
illustrate that we can achieve an approximately isometric embedding of the
Grassmann manifold using the chordal metric while this is not the case with
geodesic distances. However, non-isometric embeddings generated by using a
pseudometric on the Grassmannian lead to the best classification results. We
observe that as the dimension of the Grassmannian grows, the accuracy of the
classification grows to 100% on two illustrative examples. We also observe a
decrease in classification rates if the dimension of the points on the
Grassmannian is too large for the dimension of the Euclidean space. We use
sparse support vector machines to perform additional model reduction. The
resulting classifier selects a subset of dimensions of the embedding without
loss in classification performance.
","Sofya Chepushtanova, Michael Kirby",Michael Kirby,2015-02-03T18:17:13Z
"Hyperspectral unmixing with spectral variability using a perturbed
  linear mixing model","  Given a mixed hyperspectral data set, linear unmixing aims at estimating the
reference spectral signatures composing the data - referred to as endmembers -
their abundance fractions and their number. In practice, the identified
endmembers can vary spectrally within a given image and can thus be construed
as variable instances of reference endmembers. Ignoring this variability
induces estimation errors that are propagated into the unmixing procedure. To
address this issue, endmember variability estimation consists of estimating the
reference spectral signatures from which the estimated endmembers have been
derived as well as their variability with respect to these references. This
paper introduces a new linear mixing model that explicitly accounts for spatial
and spectral endmember variabilities. The parameters of this model can be
estimated using an optimization algorithm based on the alternating direction
method of multipliers. The performance of the proposed unmixing method is
evaluated on synthetic and real data. A comparison with state-of-the-art
algorithms designed to model and estimate endmember variability allows the
interest of the proposed unmixing solution to be appreciated.
","Pierre-Antoine Thouvenin, Nicolas Dobigeon, Jean-Yves Tourneret",Jean-Yves Tourneret,2015-02-04T17:22:08Z
"Band selection in RKHS for fast nonlinear unmixing of hyperspectral
  images","  The profusion of spectral bands generated by the acquisition process of
hyperspectral images generally leads to high computational costs. Such
difficulties arise in particular with nonlinear unmixing methods, which are
naturally more complex than linear ones. This complexity, associated with the
high redundancy of information within the complete set of bands, make the
search of band selection algorithms relevant. With this work, we propose a band
selection strategy in reproducing kernel Hilbert spaces that allows to
drastically reduce the processing time required by nonlinear unmixing
techniques. Simulation results show a complexity reduction of two orders of
magnitude without compromising unmixing performance.
","T. Imbiriba, J. C. M. Bermudez, C. Richard, J. -Y. Tourneret",J. -Y. Tourneret,2015-03-06T21:20:15Z
Radiative transfer model for contaminated rough slabs,"  We present a semi-analytical model to simulate bidirectional reflectance
distribution function (BRDF) spectra of a rough slab layer containing
impurities. This model has been optimized for fast computation in order to
analyze hyperspectral data. We designed it for planetary surfaces ices studies
but it could be used for other purposes. It estimates the bidirectional
reflectance of a rough slab of material containing inclusions, overlaying an
optically thick media (semi-infinite media or stratified media, for instance
granular material). The inclusions are supposed to be close to spherical, and
of any type of other material than the ice matrix. It can be any type of other
ice, mineral or even bubbles, defined by their optical constants. We suppose a
low roughness and we consider the geometrical optics conditions. This model is
thus applicable for inclusions larger than the considered wavelength. The
scattering on the inclusions is assumed to be isotropic. This model has a fast
computation implementation and thus is suitable for high resolution
hyperspectral data analysis.
","François Andrieu, Sylvain Douté, Frédéric Schmidt, Bernard Schmitt",Bernard Schmitt,2015-06-10T07:31:31Z
Approximate Message Passing in Coded Aperture Snapshot Spectral Imaging,"  We consider a compressive hyperspectral imaging reconstruction problem, where
three-dimensional spatio-spectral information about a scene is sensed by a
coded aperture snapshot spectral imager (CASSI). The approximate message
passing (AMP) framework is utilized to reconstruct hyperspectral images from
CASSI measurements, and an adaptive Wiener filter is employed as a
three-dimensional image denoiser within AMP. We call our algorithm
""AMP-3D-Wiener."" The simulation results show that AMP-3D-Wiener outperforms
existing widely-used algorithms such as gradient projection for sparse
reconstruction (GPSR) and two-step iterative shrinkage/thresholding (TwIST)
given the same amount of runtime. Moreover, in contrast to GPSR and TwIST,
AMP-3D-Wiener need not tune any parameters, which simplifies the reconstruction
process.
","Jin Tan, Yanting Ma, Hoover Rueda, Dror Baron, Gonzalo Arce",Gonzalo Arce,2015-09-08T16:08:21Z
"High Dimensional Data Modeling Techniques for Detection of Chemical
  Plumes and Anomalies in Hyperspectral Images and Movies","  We briefly review recent progress in techniques for modeling and analyzing
hyperspectral images and movies, in particular for detecting plumes of both
known and unknown chemicals. For detecting chemicals of known spectrum, we
extend the technique of using a single subspace for modeling the background to
a ""mixture of subspaces"" model to tackle more complicated background.
Furthermore, we use partial least squares regression on a resampled training
set to boost performance. For the detection of unknown chemicals we view the
problem as an anomaly detection problem, and use novel estimators with
low-sampled complexity for intrinsically low-dimensional data in
high-dimensions that enable us to model the ""normal"" spectra and detect
anomalies. We apply these algorithms to benchmark data sets made available by
the Automated Target Detection program co-funded by NSF, DTRA and NGA, and
compare, when applicable, to current state-of-the-art algorithms, with
favorable results.
"," Yi,  Wang, Guangliang Chen, Mauro Maggioni",Mauro Maggioni,2015-09-24T19:59:46Z
Estimating Target Signatures with Diverse Density,"  Hyperspectral target detection algorithms rely on knowing the desired target
signature in advance. However, obtaining an effective target signature can be
difficult; signatures obtained from laboratory measurements or
hand-spectrometers in the field may not transfer to airborne imagery
effectively. One approach to dealing with this difficulty is to learn an
effective target signature from training data. An approach for learning target
signatures from training data is presented. The proposed approach addresses
uncertainty and imprecision in groundtruth in the training data using a
multiple instance learning, diverse density (DD) based objective function.
After learning the target signature given data with uncertain and imprecise
groundtruth, target detection can be applied on test data. Results are shown on
simulated and real data.
","Taylor Glenn, Alina Zare",Alina Zare,2015-10-30T18:26:51Z
"Technical Report: Band selection for nonlinear unmixing of hyperspectral
  images as a maximal clique problem","  Kernel-based nonlinear mixing models have been applied to unmix spectral
information of hyperspectral images when the type of mixing occurring in the
scene is too complex or unknown. Such methods, however, usually require the
inversion of matrices of sizes equal to the number of spectral bands. Reducing
the computational load of these methods remains a challenge in large scale
applications. This paper proposes a centralized method for band selection (BS)
in the reproducing kernel Hilbert space (RKHS). It is based upon the coherence
criterion, which sets the largest value allowed for correlations between the
basis kernel functions characterizing the unmixing model. We show that the
proposed BS approach is equivalent to solving a maximum clique problem (MCP),
that is, searching for the biggest complete subgraph in a graph. Furthermore,
we devise a strategy for selecting the coherence threshold and the Gaussian
kernel bandwidth using coherence bounds for linearly independent bases.
Simulation results illustrate the efficiency of the proposed method.
","Tales Imbiriba, José Carlos Moreira Bermudez, Cédric Richard",Cédric Richard,2016-03-01T20:08:51Z
"On distances, paths and connections for hyperspectral image segmentation","  The present paper introduces the $\eta$ and {\eta} connections in order to
add regional information on $\lambda$-flat zones, which only take into account
a local information. A top-down approach is considered. First $\lambda$-flat
zones are built in a way leading to a sub-segmentation. Then a finer
segmentation is obtained by computing $\eta$-bounded regions and $\mu$-geodesic
balls inside the $\lambda$-flat zones. The proposed algorithms for the
construction of new partitions are based on queues with an ordered selection of
seeds using the cumulative distance. $\eta$-bounded regions offers a control on
the variations of amplitude in the class from a point, called center, and
$\mu$-geodesic balls controls the ""size"" of the class. These results are
applied to hyperspectral images.
","Guillaume Noyel, Jesus Angulo, Dominique Jeulin",Dominique Jeulin,2016-02-02T09:17:06Z
"Application of the Second-Order Statistics for Estimation of the Pure
  Spectra of Individual Components from the Visible Hyperspectral Images of
  Their Mixture","  The second-order statistics (SOS) can be applied in estimation of the pure
spectra of chemical components from the spectrum of their mixture, when SOS
seems to be good at estimation of spectral patterns, but their peak directions
are opposite in some cases. In this paper, one method for judgment of the peak
direction of the pure spectra was proposed, where the base line of the pure
spectra was drawn by using their histograms and the peak directions were chosen
so as to make all of the pure spectra located upwards over the base line.
Results of the SOS analysis on the visible hyperspectral images of the mixture
composed of two or three chemical components showed that the present method
offered the reasonable shape and direction of the pure spectra of its
components.
","Sung-Ho Jong, Yong-U Ri, Kye-Ryong Sin",Kye-Ryong Sin,2016-04-12T01:23:40Z
"Unsupervised Nonlinear Spectral Unmixing based on a Multilinear Mixing
  Model","  In the community of remote sensing, nonlinear mixing models have recently
received particular attention in hyperspectral image processing. In this paper,
we present a novel nonlinear spectral unmixing method following the recent
multilinear mixing model of [1], which includes an infinite number of terms
related to interactions between different endmembers. The proposed unmixing
method is unsupervised in the sense that the endmembers are estimated jointly
with the abundances and other parameters of interest, i.e., the transition
probability of undergoing further interactions. Non-negativity and sum-to one
constraints are imposed on abundances while only nonnegativity is considered
for endmembers. The resulting unmixing problem is formulated as a constrained
nonlinear optimization problem, which is solved by a block coordinate descent
strategy, consisting of updating the endmembers, abundances and transition
probability iteratively. The proposed method is evaluated and compared with
linear unmixing methods for synthetic and real hyperspectral datasets acquired
by the AVIRIS sensor. The advantage of using non-linear unmixing as opposed to
linear unmixing is clearly shown in these examples.
","Qi Wei, Marcus Chen, Jean-Yves Tourneret, Simon Godsill",Simon Godsill,2016-04-14T20:09:22Z
"Unsupervised Classification in Hyperspectral Imagery with Nonlocal Total
  Variation and Primal-Dual Hybrid Gradient Algorithm","  In this paper, a graph-based nonlocal total variation method (NLTV) is
proposed for unsupervised classification of hyperspectral images (HSI). The
variational problem is solved by the primal-dual hybrid gradient (PDHG)
algorithm. By squaring the labeling function and using a stable simplex
clustering routine, an unsupervised clustering method with random
initialization can be implemented. The effectiveness of this proposed algorithm
is illustrated on both synthetic and real-world HSI, and numerical results show
that the proposed algorithm outperforms other standard unsupervised clustering
methods such as spherical K-means, nonnegative matrix factorization (NMF), and
the graph-based Merriman-Bence-Osher (MBO) scheme.
","Wei Zhu, Victoria Chayes, Alexandre Tiard, Stephanie Sanchez, Devin Dahlberg, Andrea L. Bertozzi, Stanley Osher, Dominique Zosso, Da Kuang",Da Kuang,2016-04-27T19:11:10Z
"Fast Hyperspectral Unmixing in Presence of Nonlinearity or Mismodelling
  Effects","  This paper presents two novel hyperspectral mixture models and associated
unmixing algorithms. The two models assume a linear mixing model corrupted by
an additive term whose expression can be adapted to account for multiple
scattering nonlinearities (NL), or mismodelling effects (ME). The NL model
generalizes bilinear models by taking into account higher order interaction
terms. The ME model accounts for different effects such as endmember
variability or the presence of outliers. The abundance and residual parameters
of these models are estimated by considering a convex formulation suitable for
fast estimation algorithms. This formulation accounts for constraints such as
the sum-to-one and non-negativity of the abundances, the non-negativity of the
nonlinearity coefficients, the spectral smoothness of the ME terms and the
spatial sparseness of the residuals. The resulting convex problem is solved
using the alternating direction method of multipliers (ADMM) whose convergence
is ensured theoretically. The proposed mixture models and their unmixing
algorithms are validated on both synthetic and real images showing competitive
results regarding the quality of the inference and the computational complexity
when compared to the state-of-the-art algorithms.
","Abderrahim Halimi, Jose Bioucas-Dias, Nicolas Dobigeon, Gerald S. Buller, Steve McLaughlin",Steve McLaughlin,2016-07-18T21:39:00Z
A regularized tri-linear approach for optical interferometric imaging,"  In the context of optical interferometry, only undersampled power spectrum
and bispectrum data are accessible. It poses an ill-posed inverse problem for
image recovery. Recently, a tri-linear model was proposed for monochromatic
imaging, leading to an alternated minimization problem. In that work, only a
positivity constraint was considered, and the problem was solved by an
approximated Gauss-Seidel method. In this paper, we propose to improve the
approach on three fundamental aspects. Firstly, we define the estimated image
as a solution of a regularized minimization problem, promoting sparsity in a
fixed dictionary using either an $\ell_1$ or a weighted-$\ell_1$ regularization
term. Secondly, we solve the resultant non-convex minimization problem using a
block-coordinate forward-backward algorithm. This algorithm is able to deal
both with smooth and non-smooth functions, and benefits from convergence
guarantees even in a non-convex context. Finally, we generalize our model and
algorithm to the hyperspectral case, promoting a joint sparsity prior through
an $\ell_{2,1}$ regularization term. We present simulation results, both for
monochromatic and hyperspectral cases, to validate the proposed approach.
","Jasleen Birdi, Audrey Repetti, Yves Wiaux",Yves Wiaux,2016-09-02T11:04:23Z
Multitask Learning of Vegetation Biochemistry from Hyperspectral Data,"  Statistical models have been successful in accurately estimating the
biochemical contents of vegetation from the reflectance spectra. However, their
performance deteriorates when there is a scarcity of sizable amount of ground
truth data for modeling the complex non-linear relationship occurring between
the spectrum and the biochemical quantity. We propose a novel Gaussian process
based multitask learning method for improving the prediction of a biochemical
through the transfer of knowledge from the learned models for predicting
related biochemicals. This method is most advantageous when there are few
ground truth data for the biochemical of interest, but plenty of ground truth
data for related biochemicals. The proposed multitask Gaussian process
hypothesizes that the inter-relationship between the biochemical quantities is
better modeled by using a combination of two or more covariance functions and
inter-task correlation matrices. In the experiments, our method outperformed
the current methods on two real-world datasets.
","Utsav B. Gewali, Sildomar T. Monteiro",Sildomar T. Monteiro,2016-10-22T01:52:12Z
"Hyperspectral Image Classification with Markov Random Fields and a
  Convolutional Neural Network","  This paper presents a new supervised classification algorithm for remotely
sensed hyperspectral image (HSI) which integrates spectral and spatial
information in a unified Bayesian framework. First, we formulate the HSI
classification problem from a Bayesian perspective. Then, we adopt a
convolutional neural network (CNN) to learn the posterior class distributions
using a patch-wise training strategy to better use the spatial information.
Next, spatial information is further considered by placing a spatial smoothness
prior on the labels. Finally, we iteratively update the CNN parameters using
stochastic gradient decent (SGD) and update the class labels of all pixel
vectors using an alpha-expansion min-cut-based algorithm. Compared with other
state-of-the-art methods, the proposed classification method achieves better
performance on one synthetic dataset and two benchmark HSI datasets in a number
of experimental settings.
","Xiangyong Cao, Feng Zhou, Lin Xu, Deyu Meng, Zongben Xu, John Paisley",John Paisley,2017-05-01T22:15:11Z
"Speckle-based hyperspectral imaging combining multiple scattering and
  compressive sensing in nanowire mats","  Encoding of spectral information onto monochrome imaging cameras is of
interest for wavelength multiplexing and hyperspectral imaging applications.
Here, the complex spatio-spectral response of a disordered material is used to
demonstrate retrieval of a number of discrete wavelengths over a wide spectral
range. Strong, diffuse light scattering in a semiconductor nanowire mat is used
to achieve a highly compact spectrometer of micrometer thickness, transforming
different wavelengths into distinct speckle patterns with nanometer
sensitivity. Spatial multiplexing is achieved through the use of a microlens
array, allowing simultaneous imaging of many speckles, ultimately limited by
the size of the diffuse spot area. The performance of different information
retrieval algorithms is compared. A compressive sensing algorithm exhibits
efficient reconstruction capability in noisy environments and with only a few
measurements.
","Rebecca French, Sylvain Gigan, Otto L. Muskens",Otto L. Muskens,2017-05-08T17:48:49Z
"Rigid-layer Raman-active modes in $N$-layer Transition Metal
  Dichalcogenides: interlayer force constants and hyperspectral Raman imaging","  We report a comparative study of rigid layer Raman-active modes in $N$-layer
transition metal dichalcogenides. Trigonal prismatic (2Hc, such as MoSe$_2$,
MoTe$_2$, WS$_2$, WSe$_2$) and distorted octahedral (1T', such as ReS$_2$ and
ReSe$_2$) phases are considered. The Raman-active in-plane interlayer shear
modes and out-of-plane interlayer breathing modes appear as well-defined
features with wavenumbers in the range 0-40~cm$^{-1}$. These rigid layer modes
are well-described by an elementary linear chain model from which the
interlayer force constants are readily extracted. Remarkably, these force
constants are all found to be of the same order of magnitude. Finally, we show
that the prominent interlayer shear and breathing mode features allow
high-precision hyperspectral Raman imaging of $N-$layer domains within a given
transition metal dichalcogenide flake.
","Guillaume Froehlicher, Etienne Lorchat, Olivia Zill, Michelangelo Romeo, Stéphane Berciaud",Stéphane Berciaud,2017-08-04T21:16:02Z
"Shapelet-based Sparse Representation for Landcover Classification of
  Hyperspectral Images","  This paper presents a sparse representation-based classification approach
with a novel dictionary construction procedure. By using the constructed
dictionary sophisticated prior knowledge about the spatial nature of the image
can be integrated. The approach is based on the assumption that each image
patch can be factorized into characteristic spatial patterns, also called
shapelets, and patch-specific spectral information. A set of shapelets is
learned in an unsupervised way and spectral information are embodied by
training samples. A combination of shapelets and spectral information are
represented in an undercomplete spatial-spectral dictionary for each individual
patch, where the elements of the dictionary are linearly combined to a sparse
representation of the patch. The patch-based classification is obtained by
means of the representation error. Experiments are conducted on three
well-known hyperspectral image datasets. They illustrate that our proposed
approach shows superior results in comparison to sparse representation-based
classifiers that use only limited spatial information and behaves competitively
with or better than state-of-the-art classifiers utilizing spatial information
and kernelized sparse representation-based classifiers.
","Ribana Roscher, Björn Waske",Björn Waske,2017-08-20T14:36:11Z
"Using Spatial Correlation in Semi-Supervised Hyperspectral Unmixing
  under Polynomial Post-nonlinear Mixing Model","  This paper presents a semi-supervised hyperspectral unmixing solution that
integrate the spatial information in the abundance estimation procedure. The
proposed method is applied on a nonlinear model based on polynomial
postnonlinear mixing model where characterizes each pixel reflections composed
of nonlinear function of pure spectral signatures added by noise. We
partitioned the image to classes where contains similar materials so share the
same abundance vector. The spatial correlation between pixels belonging to each
class is modelled by Markov Random Field. A Bayesian framework is proposed to
estimate the classes and corresponding abundance vectors alternatively. We
proposed sparse Dirichlet prior for abundance vector that made it possible to
use this algorithm in semi-supervised scenario where the exact involved
materials are unknown. In this approach, we just need to have a large library
of pure spectral signatures including the desired materials. An MCMC algorithm
is used to estimate the abundance vector based on generated samples. The result
of implementation on simulated data shows the prominence of proposed approach.
","Fahime Amiri, Mohammad Hossein. Kahaei",Mohammad Hossein. Kahaei,2018-03-02T14:54:03Z
"Alternatives for Generating a Reduced Basis to Solve the Hyperspectral
  Diffuse Optical Tomography Model","  The Reduced Basis Method (RBM) is a model reduction technique used to solve
parametric PDEs that relies upon a basis set of solutions to the PDE at
specific parameter values. To generate this reduced basis, the set of a small
number of parameter values must be strategically chosen. We apply a Metropolis
algorithm and a gradient algorithm to find the set of parameters and compare
them to the standard greedy algorithm most commonly used in the RBM. We test
our methods by using the RBM to solve a simplified version of the governing
partial differential equation for hyperspectral diffuse optical tomography
(hyDOT). The governing equation for hyDOT is an elliptic PDE parameterized by
the wavelength of the laser source. For this one-dimensional problem, we find
that both the Metropolis and gradient algorithms are potentially superior
alternatives to the greedy algorithm in that they generate a reduced basis
which produces solutions with a smaller relative error with respect to
solutions found using the finite element method and in less time.
","Rachel Grotheer, Thilo Strauss, Phil Gralla, Taufiquar Khan",Taufiquar Khan,2018-03-02T17:00:51Z
"Polariton hyperspectral imaging of two-dimensional semiconductor
  crystals","  Atomically thin crystals of transition metal dichalcogenides (TMDs) host
excitons with strong binding energies and sizable light-matter interactions.
Coupled to optical cavities, monolayer TMDs routinely reach the regime of
strong light-matter coupling, where excitons and photons admix coherently to
form quasiparticles known as polaritons up to room temperature. Here, we
explore the two-dimensional nature of TMD polaritons with cavity-assisted
hyperspectral imaging. Using extended WS$_2$ monolayers, we establish the
regime of strong coupling with a scanning microcavity to map out polariton
properties and correlate their spatial features with intrinsic and extrinsic
effects. We find a high level of homogeneity, and show that polariton splitting
variations are correlated with intrinsic exciton properties such as oscillator
strength and linewidth. Moreover, we observe a deviation from thermal
equilibrium in the resonant polariton population, which we ascribe to
non-perturbative polariton-phonon coupling. Our measurements reveal a
promisingly consistent polariton landscape, and highlight the importance of
phonons for future polaritonic devices.
","Christian Gebhardt, Michael Förg, Hisato Yamaguchi, Ismail Bilgin, Aditya D. Mohite, Christopher Gies, Malte Hartmann, Matthias Florian, Theodor W. Hänsch, Alexander Högele, David Hunger",David Hunger,2018-03-23T08:52:27Z
"Multi-Resolution Multi-Modal Sensor Fusion For Remote Sensing Data With
  Label Uncertainty","  In remote sensing, each sensor can provide complementary or reinforcing
information. It is valuable to fuse outputs from multiple sensors to boost
overall performance. Previous supervised fusion methods often require accurate
labels for each pixel in the training data. However, in many remote sensing
applications, pixel-level labels are difficult or infeasible to obtain. In
addition, outputs from multiple sensors often have different resolution or
modalities. For example, rasterized hyperspectral imagery presents data in a
pixel grid while airborne Light Detection and Ranging (LiDAR) generates dense
three-dimensional (3D) point clouds. It is often difficult to directly fuse
such multi-modal, multi-resolution data. To address these challenges, we
present a novel Multiple Instance Multi-Resolution Fusion (MIMRF) framework
that can fuse multi-resolution and multi-modal sensor outputs while learning
from automatically-generated, imprecisely-labeled data. Experiments were
conducted on the MUUFL Gulfport hyperspectral and LiDAR data set and a
remotely-sensed soybean and weed data set. Results show improved, consistent
performance on scene understanding and agricultural applications when compared
to traditional fusion methods.
","Xiaoxiao Du, Alina Zare",Alina Zare,2018-05-02T17:51:13Z
"Maize Haploid Identification via LSTM-CNN and Hyperspectral Imaging
  Technology","  Accurate and fast identification of seed cultivars is crucial to plant
breeding, with accelerating breeding of new products and increasing its
quality. In our study, the first attempt to design a high-accurate
identification model of maize haploid seeds from diploid ones based on optimum
waveband selection of the LSTM-CNN algorithm is realized via deep learning and
hyperspectral imaging technology, with accuracy reaching 97% in the determining
optimum waveband of 1367.6-1526.4nm. The verification of testing another
cultivar achieved an accuracy of 93% in the same waveband. The model collected
images of 256 wavebands of seeds in the spectral region of 862.9-1704.2nm. The
high-noise waveband intervals were found and deleted by the LSTM. The
optimum-data waveband intervals were determined by CNN's waveband-based
detection. The optimum sample set for network training only accounted for 1/5
of total sample data. The accuracy was significantly higher than the
full-waveband modeling or modeling of any other wavebands. Our study
demonstrates that the proposed model has outstanding effect on maize haploid
identification and it could be generalized to some extent.
","Xuan-Yu Wang, Wen-Xuan Liao, Dong An, Yao-Guang Wei",Yao-Guang Wei,2018-05-23T13:01:15Z
Comparison of VCA and GAEE algorithms for Endmember Extraction,"  Endmember Extraction is a critical step in hyperspectral image analysis and
classification. It is an useful method to decompose a mixed spectrum into a
collection of spectra and their corresponding proportions. In this paper, we
solve a linear endmember extraction problem as an evolutionary optimization
task, maximizing the Simplex Volume in the endmember space. We propose a
standard genetic algorithm and a variation with In Vitro Fertilization module
(IVFm) to find the best solutions and compare the results with the state-of-art
Vertex Component Analysis (VCA) method and the traditional algorithms Pixel
Purity Index (PPI) and N-FINDR. The experimental results on real and synthetic
hyperspectral data confirms the overcome in performance and accuracy of the
proposed approaches over the mentioned algorithms.
","Douglas Winston. R. S., Gustavo T. Laureano, Celso G. Camilo Jr",Celso G. Camilo Jr,2018-05-27T15:53:10Z
"Tensor Alignment Based Domain Adaptation for Hyperspectral Image
  Classification","  This paper presents a tensor alignment (TA) based domain adaptation method
for hyperspectral image (HSI) classification. To be specific, HSIs in both
domains are first segmented into superpixels and tensors of both domains are
constructed to include neighboring samples from single superpixel. Then we
consider the subspace invariance between two domains as projection matrices and
original tensors are projected as core tensors with lower dimensions into the
invariant tensor subspace by applying Tucker decomposition. To preserve
geometric information in original tensors, we employ a manifold regularization
term for core tensors into the decomposition progress. The projection matrices
and core tensors are solved in an alternating optimization manner and the
convergence of TA algorithm is analyzed. In addition, a post-processing
strategy is defined via pure samples extraction for each superpixel to further
improve classification performance. Experimental results on four real HSIs
demonstrate that the proposed method can achieve better performance compared
with the state-of-the-art subspace learning methods when a limited amount of
source labeled samples are available.
","Yao Qin, Lorenzo Bruzzone, Biao Li",Biao Li,2018-08-29T12:51:59Z
"Super-Resolution for Hyperspectral and Multispectral Image Fusion
  Accounting for Seasonal Spectral Variability","  Image fusion combines data from different heterogeneous sources to obtain
more precise information about an underlying scene. Hyperspectral-multispectral
(HS-MS) image fusion is currently attracting great interest in remote sensing
since it allows the generation of high spatial resolution HS images,
circumventing the main limitation of this imaging modality. Existing HS-MS
fusion algorithms, however, neglect the spectral variability often existing
between images acquired at different time instants. This time difference causes
variations in spectral signatures of the underlying constituent materials due
to different acquisition and seasonal conditions. This paper introduces a novel
HS-MS image fusion strategy that combines an unmixing-based formulation with an
explicit parametric model for typical spectral variability between the two
images. Simulations with synthetic and real data show that the proposed
strategy leads to a significant performance improvement under spectral
variability and state-of-the-art performance otherwise.
","Ricardo Augusto Borsoi, Tales Imbiriba, José Carlos Moreira Bermudez",José Carlos Moreira Bermudez,2018-08-30T00:32:37Z
"Compressive Hyperspectral Imaging: Fourier Transform Interferometry
  meets Single Pixel Camera","  This paper introduces a single-pixel HyperSpectral (HS) imaging framework
based on Fourier Transform Interferometry (FTI). By combining a space-time
coding of the light illumination with partial interferometric observations of a
collimated light beam (observed by a single pixel), our system benefits from
(i) reduced measurement rate and light-exposure of the observed object compared
to common (Nyquist) FTI imagers, and (ii) high spectral resolution as desirable
in, e.g., Fluorescence Spectroscopy (FS). From the principles of compressive
sensing with multilevel sampling, our method leverages the sparsity ""in level""
of FS data, both in the spectral and the spatial domains. This allows us to
optimize the space-time light coding using time-modulated Hadamard patterns. We
confirm the effectiveness of our approach by a few numerical experiments.
","Amirafshar Moshtaghpour, José M. Bioucas-Dias, Laurent Jacques",Laurent Jacques,2018-09-04T13:40:39Z
"Modified Diversity of Class Probability Estimation Co-training for
  Hyperspectral Image Classification","  Due to the limited amount and imbalanced classes of labeled training data,
the conventional supervised learning can not ensure the discrimination of the
learned feature for hyperspectral image (HSI) classification. In this paper, we
propose a modified diversity of class probability estimation (MDCPE) with two
deep neural networks to learn spectral-spatial feature for HSI classification.
In co-training phase, recurrent neural network (RNN) and convolutional neural
network (CNN) are utilized as two learners to extract features from labeled and
unlabeled data. Based on the extracted features, MDCPE selects most credible
samples to update initial labeled data by combining k-means clustering with the
traditional diversity of class probability estimation (DCPE) co-training. In
this way, MDCPE can keep new labeled data class-balanced and extract
discriminative features for both the minority and majority classes. During
testing process, classification results are acquired by co-decision of the two
learners. Experimental results demonstrate that the proposed semi-supervised
co-training method can make full use of unlabeled information to enhance
generality of the learners and achieve favorable accuracies on all three widely
used data sets: Salinas, Pavia University and Pavia Center.
","Yan Ju, Lingling Li, Licheng Jiao, Zhongle Ren, Biao Hou, Shuyuan Yang",Shuyuan Yang,2018-09-05T11:12:48Z
"Hybrid Noise Removal in Hyperspectral Imagery With a Spatial-Spectral
  Gradient Network","  The existence of hybrid noise in hyperspectral images (HSIs) severely
degrades the data quality, reduces the interpretation accuracy of HSIs, and
restricts the subsequent HSIs applications. In this paper, the spatial-spectral
gradient network (SSGN) is presented for mixed noise removal in HSIs. The
proposed method employs a spatial-spectral gradient learning strategy, in
consideration of the unique spatial structure directionality of sparse noise
and spectral differences with additional complementary information for better
extracting intrinsic and deep features of HSIs. Based on a fully cascaded
multi-scale convolutional network, SSGN can simultaneously deal with the
different types of noise in different HSIs or spectra by the use of the same
model. The simulated and real-data experiments undertaken in this study
confirmed that the proposed SSGN performs better at mixed noise removal than
the other state-of-the-art HSI denoising algorithms, in evaluation indices,
visual assessments, and time consumption.
","Qiang Zhang, Qiangqiang Yuan, Jie Li, Xinxin Liu, Huanfeng Shen, Liangpei Zhang",Liangpei Zhang,2018-10-01T00:52:34Z
3D Terrain Segmentation in the SWIR Spectrum,"  We focus on the automatic 3D terrain segmentation problem using hyperspectral
shortwave IR (HS-SWIR) imagery and 3D Digital Elevation Models (DEM). The
datasets were independently collected, and metadata for the HS-SWIR dataset are
unavailable. We explore an overall slope of the SWIR spectrum that correlates
with the presence of moisture in soil to propose a band ratio test to be used
as a proxy for soil moisture content to distinguish two broad classes of
objects: live vegetation from impermeable manmade surface. We show that image
based localization techniques combined with the Optimal Randomized RANdom
Sample Consensus (RANSAC) algorithm achieve precise spatial matches between
HS-SWIR data of a portion of downtown Los Angeles (LA (USA)) and the Visible
image of a geo-registered 3D DEM, covering a wider-area of LA. Our
spectral-elevation rule based approach yields an overall accuracy of 97.7%,
segmenting the object classes into buildings, houses, trees, grass, and
roads/parking lots.
","Dalton Rosario, Anthony Ortiz, Olac Fuentes",Olac Fuentes,2018-10-27T17:59:26Z
"Shorten Spatial-spectral RNN with Parallel-GRU for Hyperspectral Image
  Classification","  Convolutional neural networks (CNNs) attained a good performance in
hyperspectral sensing image (HSI) classification, but CNNs consider spectra as
orderless vectors. Therefore, considering the spectra as sequences, recurrent
neural networks (RNNs) have been applied in HSI classification, for RNNs is
skilled at dealing with sequential data. However, for a long-sequence task,
RNNs is difficult for training and not as effective as we expected. Besides,
spatial contextual features are not considered in RNNs. In this study, we
propose a Shorten Spatial-spectral RNN with Parallel-GRU (St-SS-pGRU) for HSI
classification. A shorten RNN is more efficient and easier for training than
band-by-band RNN. By combining converlusion layer, the St-SSpGRU model
considers not only spectral but also spatial feature, which results in a better
performance. An architecture named parallel-GRU is also proposed and applied in
St-SS-pGRU. With this architecture, the model gets a better performance and is
more robust.
",Haowen Luo,Haowen Luo,2018-10-30T07:57:27Z
"Band Selection from Hyperspectral Images Using Attention-based
  Convolutional Neural Networks","  This paper introduces new attention-based convolutional neural networks for
selecting bands from hyperspectral images. The proposed approach re-uses
convolutional activations at different depths, identifying the most informative
regions of the spectrum with the help of gating mechanisms. Our attention
techniques are modular and easy to implement, and they can be seamlessly
trained end-to-end using gradient descent. Our rigorous experiments showed that
deep models equipped with the attention mechanism deliver high-quality
classification, and repeatedly identify significant bands in the training data,
permitting the creation of refined and extremely compact sets that retain the
most meaningful features.
","Pablo Ribalta Lorenzo, Lukasz Tulczyjew, Michal Marcinkiewicz, Jakub Nalepa",Jakub Nalepa,2018-10-24T19:32:48Z
"Non-local Meets Global: An Integrated Paradigm for Hyperspectral
  Denoising","  Non-local low-rank tensor approximation has been developed as a
state-of-the-art method for hyperspectral image (HSI) denoising. Unfortunately,
with more spectral bands for HSI, while the running time of these methods
significantly increases, their denoising performance benefits little. In this
paper, we claim that the HSI underlines a global spectral low-rank subspace,
and the spectral subspaces of each full band patch groups should underlie this
global low-rank subspace. This motivates us to propose a unified
spatial-spectral paradigm for HSI denoising. As the new model is hard to
optimize, we further propose an efficient algorithm for optimization, which is
motivated by alternating minimization. This is done by first learning a
low-dimensional projection and the related reduced image from the noisy HSI.
Then, the non-local low-rank denoising and iterative regularization are
developed to refine the reduced image and projection, respectively. Finally,
experiments on synthetic and both real datasets demonstrate the superiority
against the other state-of-the-arts HSI denoising methods.
","Wei He, Quanming Yao, Chao Li, Naoto Yokoya, Qibin Zhao",Qibin Zhao,2018-12-11T07:26:07Z
"Spatial-Spectral Regularized Local Scaling Cut for Dimensionality
  Reduction in Hyperspectral Image Classification","  Dimensionality reduction (DR) methods have attracted extensive attention to
provide discriminative information and reduce the computational burden of the
hyperspectral image (HSI) classification. However, the DR methods face many
challenges due to limited training samples with high dimensional spectra. To
address this issue, a graph-based spatial and spectral regularized local
scaling cut (SSRLSC) for DR of HSI data is proposed. The underlying idea of the
proposed method is to utilize the information from both the spectral and
spatial domains to achieve better classification accuracy than its spectral
domain counterpart. In SSRLSC, a guided filter is initially used to smoothen
and homogenize the pixels of the HSI data in order to preserve the pixel
consistency. This is followed by generation of between-class and within-class
dissimilarity matrices in both spectral and spatial domains by regularized
local scaling cut (RLSC) and neighboring pixel local scaling cut (NPLSC)
respectively. Finally, we obtain the projection matrix by optimizing the
updated spatial-spectral between-class and total-class dissimilarity. The
effectiveness of the proposed DR algorithm is illustrated with two popular
real-world HSI datasets.
","Ramanarayan Mohanty, S L Happy, Aurobinda Routray",Aurobinda Routray,2018-12-07T04:13:31Z
"Improved Hyperspectral Unmixing With Endmember Variability Parametrized
  Using an Interpolated Scaling Tensor","  Endmember (EM) variability has an important impact on the performance of
hyperspectral image (HI) analysis algorithms. Recently, extended linear mixing
models have been proposed to account for EM variability in the spectral
unmixing (SU) problem. The direct use of these models has led to severely
ill-posed optimization problems. Different regularization strategies have been
considered to deal with this issue, but none so far has consistently exploited
the information provided by the existence of multiple pure pixels often present
in HIs. In this work, we propose to break the SU problem into a sequence of two
problems. First, we use pure pixel information to estimate an interpolated
tensor of scaling factors representing spectral variability. This is done by
considering the spectral variability to be a smooth function over the HI and
confining the energy of the scaling tensor to a low-rank structure. Afterwards,
we solve a matrix-factorization problem to estimate the fractional abundances
using the variability scaling factors estimated in the previous step, what
leads to a significantly more well-posed problem. Simulation swith synthetic
and real data attest the effectiveness of the proposed strategy.
","Ricardo Augusto Borsoi, Tales Imbiriba, José Carlos Moreira Bermudez",José Carlos Moreira Bermudez,2019-01-02T17:51:12Z
"Semi-supervised Learning with Graphs: Covariance Based Superpixels For
  Hyperspectral Image Classification","  In this paper, we present a graph-based semi-supervised framework for
hyperspectral image classification. We first introduce a novel superpixel
algorithm based on the spectral covariance matrix representation of pixels to
provide a better representation of our data. We then construct a superpixel
graph, based on carefully considered feature vectors, before performing
classification. We demonstrate, through a set of experimental results using two
benchmarking datasets, that our approach outperforms three state-of-the-art
classification frameworks, especially when an extremely small amount of
labelled data is used.
","Philip Sellars, Angelica Aviles-Rivero, Nicolas Papadakis, David Coomes, Anita Faul, Carola-Bibane Schönlieb",Carola-Bibane Schönlieb,2019-01-14T11:18:27Z
"Soil Texture Classification with 1D Convolutional Neural Networks based
  on Hyperspectral Data","  Soil texture is important for many environmental processes. In this paper, we
study the classification of soil texture based on hyperspectral data. We
develop and implement three 1-dimensional (1D) convolutional neural networks
(CNN): the LucasCNN, the LucasResNet which contains an identity block as
residual network, and the LucasCoordConv with an additional coordinates layer.
Furthermore, we modify two existing 1D CNN approaches for the presented
classification task. The code of all five CNN approaches is available on GitHub
(Riese, 2019). We evaluate the performance of the CNN approaches and compare
them to a random forest classifier. Thereby, we rely on the freely available
LUCAS topsoil dataset. The CNN approach with the least depth turns out to be
the best performing classifier. The LucasCoordConv achieves the best
performance regarding the average accuracy. In future work, we can further
enhance the introduced LucasCNN, LucasResNet and LucasCoordConv and include
additional variables of the rich LUCAS dataset.
","Felix M. Riese, Sina Keller",Sina Keller,2019-01-15T14:29:04Z
Fast High-Dimensional Kernel Filtering,"  The bilateral and nonlocal means filters are instances of kernel-based
filters that are popularly used in image processing. It was recently shown that
fast and accurate bilateral filtering of grayscale images can be performed
using a low-rank approximation of the kernel matrix. More specifically, based
on the eigendecomposition of the kernel matrix, the overall filtering was
approximated using spatial convolutions, for which efficient algorithms are
available. Unfortunately, this technique cannot be scaled to high-dimensional
data such as color and hyperspectral images. This is simply because one needs
to compute/store a large matrix and perform its eigendecomposition in this
case. We show how this problem can be solved using the Nystr\""om method, which
is generally used for approximating the eigendecomposition of large matrices.
The resulting algorithm can also be used for nonlocal means filtering. We
demonstrate the effectiveness of our proposal for bilateral and nonlocal means
filtering of color and hyperspectral images. In particular, our method is shown
to be competitive with state-of-the-art fast algorithms, and moreover it comes
with a theoretical guarantee on the approximation error.
","Pravin Nair, Kunal N. Chaudhury",Kunal N. Chaudhury,2019-01-18T07:24:28Z
Spectral-Spatial Diffusion Geometry for Hyperspectral Image Clustering,"  An unsupervised learning algorithm to cluster hyperspectral image (HSI) data
is proposed that exploits spatially-regularized random walks. Markov diffusions
are defined on the space of HSI spectra with transitions constrained to near
spatial neighbors. The explicit incorporation of spatial regularity into the
diffusion construction leads to smoother random processes that are more adapted
for unsupervised machine learning than those based on spectra alone. The
regularized diffusion process is subsequently used to embed the
high-dimensional HSI into a lower dimensional space through diffusion
distances. Cluster modes are computed using density estimation and diffusion
distances, and all other points are labeled according to these modes. The
proposed method has low computational complexity and performs competitively
against state-of-the-art HSI clustering algorithms on real data. In particular,
the proposed spatial regularization confers an empirical advantage over
non-regularized methods.
","James M. Murphy, Mauro Maggioni",Mauro Maggioni,2019-02-08T13:28:30Z
"Blind Hyperspectral-Multispectral Image Fusion via Graph Laplacian
  Regularization","  Fusing a low-resolution hyperspectral image (HSI) and a high-resolution
multispectral image (MSI) of the same scene leads to a super-resolution image
(SRI), which is information rich spatially and spectrally. In this paper, we
super-resolve the HSI using the graph Laplacian defined on the MSI. Unlike many
existing works, we don't assume prior knowledge about the spatial degradation
from SRI to HSI, nor a perfectly aligned HSI and MSI pair. Our algorithm
progressively alternates between finding the blur kernel and fusing HSI with
MSI, generating accurate estimations of the blur kernel and the SRI at
convergence. Experiments on various datasets demonstrate the advantages of the
proposed algorithm in the quality of fusion and its capability in dealing with
unknown spatial degradation.
","Chandrajit Bajaj, Tianming Wang",Tianming Wang,2019-02-21T19:27:59Z
"A Dictionary-Based Generalization of Robust PCA with Applications to
  Target Localization in Hyperspectral Imaging","  We consider the decomposition of a data matrix assumed to be a superposition
of a low-rank matrix and a component which is sparse in a known dictionary,
using a convex demixing method. We consider two sparsity structures for the
sparse factor of the dictionary sparse component, namely entry-wise and
column-wise sparsity, and provide a unified analysis, encompassing both
undercomplete and the overcomplete dictionary cases, to show that the
constituent matrices can be successfully recovered under some relatively mild
conditions on incoherence, sparsity, and rank. We leverage these results to
localize targets of interest in a hyperspectral (HS) image based on their
spectral signature(s) using the a priori known characteristic spectral
responses of the target. We corroborate our theoretical results and analyze
target localization performance of our approach via experimental evaluations
and comparisons to related techniques.
","Sirisha Rambhatla, Xingguo Li, Jineng Ren, Jarvis Haupt",Jarvis Haupt,2019-02-21T23:26:35Z
"Cascaded Recurrent Neural Networks for Hyperspectral Image
  Classification","  By considering the spectral signature as a sequence, recurrent neural
networks (RNNs) have been successfully used to learn discriminative features
from hyperspectral images (HSIs) recently. However, most of these models only
input the whole spectral bands into RNNs directly, which may not fully explore
the specific properties of HSIs. In this paper, we propose a cascaded RNN model
using gated recurrent units (GRUs) to explore the redundant and complementary
information of HSIs. It mainly consists of two RNN layers. The first RNN layer
is used to eliminate redundant information between adjacent spectral bands,
while the second RNN layer aims to learn the complementary information from
non-adjacent spectral bands. To improve the discriminative ability of the
learned features, we design two strategies for the proposed model. Besides,
considering the rich spatial information contained in HSIs, we further extend
the proposed model to its spectral-spatial counterpart by incorporating some
convolutional layers. To test the effectiveness of our proposed models, we
conduct experiments on two widely used HSIs. The experimental results show that
our proposed models can achieve better results than the compared models.
","Renlong Hang, Qingshan Liu, Danfeng Hong, Pedram Ghamisi",Pedram Ghamisi,2019-02-28T01:29:59Z
1D-Convolutional Capsule Network for Hyperspectral Image Classification,"  Recently, convolutional neural networks (CNNs) have achieved excellent
performances in many computer vision tasks. Specifically, for hyperspectral
images (HSIs) classification, CNNs often require very complex structure due to
the high dimension of HSIs. The complex structure of CNNs results in
prohibitive training efforts. Moreover, the common situation in HSIs
classification task is the lack of labeled samples, which results in accuracy
deterioration of CNNs. In this work, we develop an easy-to-implement capsule
network to alleviate the aforementioned problems, i.e., 1D-convolution capsule
network (1D-ConvCapsNet). Firstly, 1D-ConvCapsNet separately extracts spatial
and spectral information on spatial and spectral domains, which is more
lightweight than 3D-convolution due to fewer parameters. Secondly,
1D-ConvCapsNet utilizes the capsule-wise constraint window method to reduce
parameter amount and computational complexity of conventional capsule network.
Finally, 1D-ConvCapsNet obtains accurate predictions with respect to input
samples via dynamic routing. The effectiveness of the 1D-ConvCapsNet is
verified by three representative HSI datasets. Experimental results demonstrate
that 1D-ConvCapsNet is superior to state-of-the-art methods in both the
accuracy and training effort.
","Haitao Zhang, Lingguo Meng, Xian Wei, Xiaoliang Tang, Xuan Tang, Xingping Wang, Bo Jin, Wei Yao",Wei Yao,2019-03-23T15:22:49Z
Hyperspectral Camera Selection for Interventional Health-care,"  Hyperspectral imaging (HSI) is an emerging modality in health-care
applications for disease diagnosis, tissue assessment and image-guided surgery.
Tissue reflectances captured by a HSI camera encode physiological properties
including oxygenation and blood volume fraction. Optimal camera properties such
as filter responses depend crucially on the application, and choosing a
suitable HSI camera for a research project and/or a clinical problem is not
straightforward. We propose a generic framework for quantitative and
application-specific performance assessment of HSI cameras and optical
subsystem without the need for any physical setup. Based on user input about
the camera characteristics and properties of the target domain, our framework
quantifies the performance of the given camera configuration using large
amounts of simulated data and a user-defined metric. The application of the
framework to commercial camera selection and band selection in the context of
oxygenation monitoring in interventional health-care demonstrates its
integration into the design work-flow of an engineer. The advantage of being
able to test the desired configuration without the need for purchasing
expensive components may save system engineers valuable resources.
","Anant S. Vemuri, Sebastian Wirkert, Lena Maier-Hein",Lena Maier-Hein,2019-04-04T09:41:53Z
"Deep Learning Enabled Real Time Speckle Recognition and Hyperspectral
  Imaging using a Multimode Fiber Array","  We demonstrate the use of deep learning for fast spectral deconstruction of
speckle patterns. The artificial neural network can be effectively trained
using numerically constructed multispectral datasets taken from a measured
spectral transmission matrix. Optimized neural networks trained on these
datasets achieve reliable reconstruction of both discrete and continuous
spectra from a monochromatic camera image. Deep learning is compared to
analytical inversion methods as well as to a compressive sensing algorithm and
shows favourable characteristics both in the oversampling and in the sparse
undersampling (compressive) regimes. The deep learning approach offers
significant advantages in robustness to drift or noise and in reconstruction
speed. In a proof-of-principle demonstrator we achieve real time recovery of
hyperspectral information using a multi-core, multi-mode fiber array as a
random scattering medium.
","Ulas Kürüm, P. R. Wiecha, Rebecca French, Otto L. Muskens",Otto L. Muskens,2019-04-07T08:47:37Z
"Active Multi-Kernel Domain Adaptation for Hyperspectral Image
  Classification","  Recent years have witnessed the quick progress of the hyperspectral images
(HSI) classification. Most of existing studies either heavily rely on the
expensive label information using the supervised learning or can hardly exploit
the discriminative information borrowed from related domains. To address this
issues, in this paper we show a novel framework addressing HSI classification
based on the domain adaptation (DA) with active learning (AL). The main idea of
our method is to retrain the multi-kernel classifier by utilizing the available
labeled samples from source domain, and adding minimum number of the most
informative samples with active queries in the target domain. The proposed
method adaptively combines multiple kernels, forming a DA classifier that
minimizes the bias between the source and target domains. Further equipped with
the nested actively updating process, it sequentially expands the training set
and gradually converges to a satisfying level of classification performance. We
study this active adaptation framework with the Margin Sampling (MS) strategy
in the HSI classification task. Our experimental results on two popular HSI
datasets demonstrate its effectiveness.
","Cheng Deng, Xianglong Liu, Chao Li, Dacheng Tao",Dacheng Tao,2019-04-10T14:07:25Z
"Performance of Kriging Based Soft Classification on WiFS/IRS- 1D image
  using Ground Hyperspectral Signatures","  Hard and soft classification techniques are the conventional ways of image
classification on satellite data. These classifiers have number of drawbacks.
Firstly, these approaches are inappropriate for mixed pixels. Secondly, these
approaches do not consider spatial variability. Kriging based soft classifier
(KBSC) is a non-parametric geostatistical method. It exploits the spatial
variability of the classes within the image. This letter compares the
performance of KBSC with other conventional hard/soft classification
techniques. The satellite data used in this study is the Wide Field Sensor
(WiFS) from the Indian Remote Sensing Satellite -1D (IRS-1D). The ground
hyperspectral signatures acquired from the agricultural fields by a hand held
spectroradiometer are used to detect subpixel targets from the satellite
images. Two measures of closeness have been used for accuracy assessment of the
KBSC to that of the conventional classifications. The results prove that the
KBSC is statistically more accurate than the other conventional techniques.
","Sumanta Kumar Das, Randhir Singh",Randhir Singh,2019-04-25T11:08:43Z
"Non-myopic Planetary Exploration Combining In Situ and Remote
  Measurements","  Remote sensing can provide crucial information for planetary rovers. However,
they must validate these orbital observations with in situ measurements.
Typically, this involves validating hyperspectral data using a spectrometer
on-board the field robot. In order to achieve this, the robot must visit
sampling locations that jointly improve a model of the environment while
satisfying sampling constraints. However, current planners follow sub-optimal
greedy strategies that are not scalable to larger regions. We demonstrate how
the problem can be effectively defined in an MDP framework and propose a
planning algorithm based on Monte Carlo Tree Search, which is devoid of the
common drawbacks of existing planners and also provides superior performance.
We evaluate our approach using hyperspectral imagery of a well-studied geologic
site in Cuprite, Nevada.
","Suhit Kodgule, Alberto Candela, David Wettergreen",David Wettergreen,2019-04-28T03:59:01Z
Optimal Clustering Framework for Hyperspectral Band Selection,"  Band selection, by choosing a set of representative bands in hyperspectral
image (HSI), is an effective method to reduce the redundant information without
compromising the original contents. Recently, various unsupervised band
selection methods have been proposed, but most of them are based on
approximation algorithms which can only obtain suboptimal solutions toward a
specific objective function. This paper focuses on clustering-based band
selection, and proposes a new framework to solve the above dilemma, claiming
the following contributions: 1) An optimal clustering framework (OCF), which
can obtain the optimal clustering result for a particular form of objective
function under a reasonable constraint. 2) A rank on clusters strategy (RCS),
which provides an effective criterion to select bands on existing clustering
structure. 3) An automatic method to determine the number of the required
bands, which can better evaluate the distinctive information produced by
certain number of bands. In experiments, the proposed algorithm is compared to
some state-of-the-art competitors. According to the experimental results, the
proposed algorithm is robust and significantly outperform the other methods on
various data sets.
","Qi Wang, Fahong Zhang, Xuelong Li",Xuelong Li,2019-04-30T03:26:44Z
"Pixel DAG-Recurrent Neural Network for Spectral-Spatial Hyperspectral
  Image Classification","  Exploiting rich spatial and spectral features contributes to improve the
classification accuracy of hyperspectral images (HSIs). In this paper, based on
the mechanism of the population receptive field (pRF) in human visual cortex,
we further utilize the spatial correlation of pixels in images and propose
pixel directed acyclic graph recurrent neural network (Pixel DAG-RNN) to
extract and apply spectral-spatial features for HSIs classification. In our
model, an undirected cyclic graph (UCG) is used to represent the relevance
connectivity of pixels in an image patch, and four DAGs are used to approximate
the spatial relationship of UCGs. In order to avoid overfitting, weight sharing
and dropout are adopted. The higher classification performance of our model on
HSIs classification has been verified by experiments on three benchmark data
sets.
","Xiufang Li, Qigong Sun, Lingling Li, Zhongle Ren, Fang Liu, Licheng Jiao",Licheng Jiao,2019-06-09T09:40:55Z
"Convolution Based Spectral Partitioning Architecture for Hyperspectral
  Image Classification","  Hyperspectral images (HSIs) can distinguish materials with high number of
spectral bands, which is widely adopted in remote sensing applications and
benefits in high accuracy land cover classifications. However, HSIs processing
are tangled with the problem of high dimensionality and limited amount of
labelled data. To address these challenges, this paper proposes a deep learning
architecture using three dimensional convolutional neural networks with
spectral partitioning to perform effective feature extraction. We conduct
experiments using Indian Pines and Salinas scenes acquired by NASA Airborne
Visible/Infra-Red Imaging Spectrometer. In comparison to prior results, our
architecture shows competitive performance for classification results over
current methods.
","Ringo S. W. Chu, Ho-Cheung Ng, Xiwei Wang, Wayne Luk",Wayne Luk,2019-06-27T22:06:15Z
"High-throughput Onboard Hyperspectral Image Compression with
  Ground-based CNN Reconstruction","  Compression of hyperspectral images onboard of spacecrafts is a tradeoff
between the limited computational resources and the ever-growing spatial and
spectral resolution of the optical instruments. As such, it requires
low-complexity algorithms with good rate-distortion performance and high
throughput. In recent years, the Consultative Committee for Space Data Systems
(CCSDS) has focused on lossless and near-lossless compression approaches based
on predictive coding, resulting in the recently published CCSDS 123.0-B-2
recommended standard. While the in-loop reconstruction of quantized prediction
residuals provides excellent rate-distortion performance for the near-lossless
operating mode, it significantly constrains the achievable throughput due to
data dependencies. In this paper, we study the performance of a faster method
based on prequantization of the image followed by a lossless predictive
compressor. While this is well known to be suboptimal, one can exploit powerful
signal models to reconstruct the image at the ground segment, recovering part
of the suboptimality. In particular, we show that convolutional neural networks
can be used for this task and that they can recover the whole SNR drop incurred
at a bitrate of 2 bits per pixel.
","Diego Valsesia, Enrico Magli",Enrico Magli,2019-07-05T17:59:25Z
"Multiscale Principle of Relevant Information for Hyperspectral Image
  Classification","  This paper proposes a novel architecture, termed multiscale principle of
relevant information (MPRI), to learn discriminative spectral-spatial features
for hyperspectral image (HSI) classification. MPRI inherits the merits of the
principle of relevant information (PRI) to effectively extract multiscale
information embedded in the given data, and also takes advantage of the
multilayer structure to learn representations in a coarse-to-fine manner.
Specifically, MPRI performs spectral-spatial pixel characterization (using PRI)
and feature dimensionality reduction (using regularized linear discriminant
analysis) iteratively and successively. Extensive experiments on three
benchmark data sets demonstrate that MPRI outperforms existing state-of-the-art
methods (including deep learning based ones) qualitatively and quantitatively,
especially in the scenario of limited training samples. Code of MPRI is
available at \url{http://bit.ly/MPRI_HSI}.
","Yantao Wei, Shujian Yu, Luis Sanchez Giraldo, Jose C. Principe",Jose C. Principe,2019-07-13T07:29:42Z
"FeatureExplorer: Interactive Feature Selection and Exploration of
  Regression Models for Hyperspectral Images","  Feature selection is used in machine learning to improve predictions,
decrease computation time, reduce noise, and tune models based on limited
sample data. In this article, we present FeatureExplorer, a visual analytics
system that supports the dynamic evaluation of regression models and importance
of feature subsets through the interactive selection of features in
high-dimensional feature spaces typical of hyperspectral images. The
interactive system allows users to iteratively refine and diagnose the model by
selecting features based on their domain knowledge, interchangeable
(correlated) features, feature importance, and the resulting model performance.
","Jieqiong Zhao, Morteza Karimzadeh, Ali Masjedi, Taojun Wang, Xiwen Zhang, Melba M. Crawford, David S. Ebert",David S. Ebert,2019-08-02T00:50:04Z
Successive Projection Algorithm Robust to Outliers,"  The successive projection algorithm (SPA) is a fast algorithm to tackle
separable nonnegative matrix factorization (NMF). Given a nonnegative data
matrix $X$, SPA identifies an index set $\mathcal{K}$ such that there exists a
nonnegative matrix $H$ with $X \approx X(:,\mathcal{K})H$. SPA has been
successfully used as a pure-pixel search algorithm in hyperspectral unmixing
and for anchor word selection in document classification. Moreover, SPA is
provably robust in low-noise settings. The main drawbacks of SPA are that it is
not robust to outliers and does not take the data fitting term into account
when selecting the indices in $\mathcal{K}$. In this paper, we propose a new
SPA variant, dubbed Robust SPA (RSPA), that is robust to outliers while still
being provably robust in low-noise settings, and that takes into account the
reconstruction error for selecting the indices in $\mathcal{K}$. We illustrate
the effectiveness of RSPA on synthetic data sets and hyperspectral images.
",Nicolas Gillis,Nicolas Gillis,2019-08-12T12:21:50Z
"A Convolutional Neural Network with Mapping Layers for Hyperspectral
  Image Classification","  In this paper, we propose a convolutional neural network with mapping layers
(MCNN) for hyperspectral image (HSI) classification. The proposed mapping
layers map the input patch into a low dimensional subspace by multilinear
algebra. We use our mapping layers to reduce the spectral and spatial
redundancy and maintain most energy of the input. The feature extracted by our
mapping layers can also reduce the number of following convolutional layers for
feature extraction. Our MCNN architecture avoids the declining accuracy with
increasing layers phenomenon of deep learning models for HSI classification and
also saves the training time for its effective mapping layers. Furthermore, we
impose the 3-D convolutional kernel on convolutional layer to extract the
spectral-spatial features for HSI. We tested our MCNN on three datasets of
Indian Pines, University of Pavia and Salinas, and we achieved the
classification accuracy of 98.3%, 99.5% and 99.3%, respectively. Experimental
results demonstrate that the proposed MCNN can significantly improve the
classification accuracy and save much time consumption.
","Rui Li, Zhibin Pan, Yang Wang, Ping Wang",Ping Wang,2019-08-26T08:42:26Z
"All-optical continuous tuning of phase-change plasmonic metasurfaces for
  multispectral thermal imaging","  Actively tunable, narrowband spectral filtering across arbitrary optical
wavebands is highly desirable in a plethora of applications, from chemical
sensing, hyperspectral imaging to infrared astronomy. Yet, the ability to
actively reconfigure the optical properties of a solid-state narrowband filter
remains elusive. Existing solutions require either moving parts, have slow
response times or provide limited spectral coverage. Here, we demonstrate a
continuously tunable, spectrally-agnostic, all-solid-state, narrowband
phase-change metasurface filter based on a GeSbTe (GST)-embedded plasmonic
nanohole array. The passband of the presented tunable filter is ~74 nm with
~70% transmittance and operates across 3 - 5 $\mu$m; the thermal imaging
waveband. Continuous, reconfigurable tuning is achieved by exploiting
intermediate GST phases via optical switching with a single nanosecond laser
pulse and material stability is verified through multiple switching cycles. We
further demonstrate multispectral thermal imaging in the mid-wave infrared
using our phase-change metasurfaces. Our results pave the way for highly
functional, reduced power, compact hyperspectral imaging systems and optical
filters.
","Matthew N. Julian, Calum Williams, Stephen Borg, Scott Bartram, Hyun Jung Kim",Hyun Jung Kim,2019-12-17T15:38:29Z
"Learning Shared Cross-modality Representation Using Multispectral-LiDAR
  and Hyperspectral Data","  Due to the ever-growing diversity of the data source, multi-modality feature
learning has attracted more and more attention. However, most of these methods
are designed by jointly learning feature representation from multi-modalities
that exist in both training and test sets, yet they are less investigated in
absence of certain modality in the test phase. To this end, in this letter, we
propose to learn a shared feature space across multi-modalities in the training
process. By this way, the out-of-sample from any of multi-modalities can be
directly projected onto the learned space for a more effective cross-modality
representation. More significantly, the shared space is regarded as a latent
subspace in our proposed method, which connects the original multi-modal
samples with label information to further improve the feature discrimination.
Experiments are conducted on the multispectral-Lidar and hyperspectral dataset
provided by the 2018 IEEE GRSS Data Fusion Contest to demonstrate the
effectiveness and superiority of the proposed method in comparison with several
popular baselines.
","Danfeng Hong, Jocelyn Chanussot, Naoto Yokoya, Jian Kang, Xiao Xiang Zhu",Xiao Xiang Zhu,2019-12-18T19:06:50Z
"ADRN: Attention-based Deep Residual Network for Hyperspectral Image
  Denoising","  Hyperspectral image (HSI) denoising is of crucial importance for many
subsequent applications, such as HSI classification and interpretation. In this
paper, we propose an attention-based deep residual network to directly learn a
mapping from noisy HSI to the clean one. To jointly utilize the
spatial-spectral information, the current band and its $K$ adjacent bands are
simultaneously exploited as the input. Then, we adopt convolution layer with
different filter sizes to fuse the multi-scale feature, and use shortcut
connection to incorporate the multi-level information for better noise removal.
In addition, the channel attention mechanism is employed to make the network
concentrate on the most relevant auxiliary information and features that are
beneficial to the denoising process best. To ease the training procedure, we
reconstruct the output through a residual mode rather than a straightforward
prediction. Experimental results demonstrate that our proposed ADRN scheme
outperforms the state-of-the-art methods both in quantitative and visual
evaluations.
","Yongsen Zhao, Deming Zhai, Junjun Jiang, Xianming Liu",Xianming Liu,2020-03-04T08:36:27Z
3D Quasi-Recurrent Neural Network for Hyperspectral Image Denoising,"  In this paper, we propose an alternating directional 3D quasi-recurrent
neural network for hyperspectral image (HSI) denoising, which can effectively
embed the domain knowledge -- structural spatio-spectral correlation and global
correlation along spectrum. Specifically, 3D convolution is utilized to extract
structural spatio-spectral correlation in an HSI, while a quasi-recurrent
pooling function is employed to capture the global correlation along spectrum.
Moreover, alternating directional structure is introduced to eliminate the
causal dependency with no additional computation cost. The proposed model is
capable of modeling spatio-spectral dependency while preserving the flexibility
towards HSIs with arbitrary number of bands. Extensive experiments on HSI
denoising demonstrate significant improvement over state-of-the-arts under
various noise settings, in terms of both restoration accuracy and computation
time. Our code is available at https://github.com/Vandermode/QRNN3D.
","Kaixuan Wei, Ying Fu, Hua Huang",Hua Huang,2020-03-10T06:14:53Z
"Fully reversible neural networks for large-scale surface and sub-surface
  characterization via remote sensing","  The large spatial/frequency scale of hyperspectral and airborne magnetic and
gravitational data causes memory issues when using convolutional neural
networks for (sub-) surface characterization. Recently developed fully
reversible networks can mostly avoid memory limitations by virtue of having a
low and fixed memory requirement for storing network states, as opposed to the
typical linear memory growth with depth. Fully reversible networks enable the
training of deep neural networks that take in entire data volumes, and create
semantic segmentations in one go. This approach avoids the need to work in
small patches or map a data patch to the class of just the central pixel. The
cross-entropy loss function requires small modifications to work in conjunction
with a fully reversible network and learn from sparsely sampled labels without
ever seeing fully labeled ground truth. We show examples from land-use change
detection from hyperspectral time-lapse data, and regional aquifer mapping from
airborne geophysical and geological data.
","Bas Peters, Eldad Haber, Keegan Lensink",Keegan Lensink,2020-03-16T23:54:22Z
"Sub-pixel detection in hyperspectral imaging with elliptically contoured
  $t$-distributed background","  Detection of a target with known spectral signature when this target may
occupy only a fraction of the pixel is an important issue in hyperspectral
imaging. We recently derived the generalized likelihood ratio test (GLRT) for
such sub-pixel targets, either for the so-called replacement model where the
presence of a target induces a decrease of the background power, due to the sum
of abundances equal to one, or for a mixed model which alleviates some of the
limitations of the replacement model. In both cases, the background was assumed
to be Gaussian distributed. The aim of this short communication is to extend
these detectors to the broader class of elliptically contoured distributions,
more precisely matrix-variate $t$-distributions with unknown mean and
covariance matrix. We show that the generalized likelihood ratio tests in the
$t$-distributed case coincide with their Gaussian counterparts, which confers
the latter an increased generality for application. The performance as well as
the robustness of these detectors are evaluated through numerical simulations.
","Olivier Besson, François Vincent",François Vincent,2020-03-26T07:49:38Z
"Multivariate analysis of Brillouin imaging data by supervised and
  unsupervised learning","  Brillouin imaging relies on the reliable extraction of subtle spectral
information from hyperspectral datasets. To date, the mainstream practice has
been using line fitting of spectral features to retrieve the average peak shift
and linewidth parameters. Good results, however, depend heavily on sufficient
SNR and may not be applicable in complex samples that consist of spectral
mixtures. In this work, we thus propose the use of various multivariate
algorithms that can be used to perform supervised or unsupervised analysis of
the hyperspectral data, with which we explore advanced image analysis
applications, namely unmixing, classification and segmentation in a phantom and
live cells. The resulting images are shown to provide more contrast and detail,
and obtained on a timescale $10^2$ faster than fitting. The estimated spectral
parameters are consistent with those calculated from pure fitting.
","YuChen Xiang, Kai Ling C. Seow, Carl Paterson, Peter Török",Peter Török,2020-09-15T17:01:10Z
"Mixture of Spectral Generative Adversarial Networks for Imbalanced
  Hyperspectral Image Classification","  We propose a three-player spectral generative adversarial network (GAN)
architecture to afford GAN with the ability to manage minority classes under
imbalance conditions. A class-dependent mixture generator spectral GAN (MGSGAN)
has been developed to force generated samples remain within the domain of the
actual distribution of the data. MGSGAN is able to generate minority classes
even when the imbalance ratio of majority to minority classes is high. A
classifier based on lower features is adopted with a sequential discriminator
to form a three-player GAN game. The generator networks perform data
augmentation to improve the classifier's performance. The proposed method has
been validated through two hyperspectral images datasets and compared with
state-of-the-art methods under two class-imbalance settings corresponding to
real data distributions.
","Tanmoy Dam, Sreenatha G. Anavatti, Hussein A. Abbass",Hussein A. Abbass,2020-09-28T03:09:20Z
"Spectral Response Function Guided Deep Optimization-driven Network for
  Spectral Super-resolution","  Hyperspectral images are crucial for many research works. Spectral
super-resolution (SSR) is a method used to obtain high spatial resolution (HR)
hyperspectral images from HR multispectral images. Traditional SSR methods
include model-driven algorithms and deep learning. By unfolding a variational
method, this paper proposes an optimization-driven convolutional neural network
(CNN) with a deep spatial-spectral prior, resulting in physically interpretable
networks. Unlike the fully data-driven CNN, auxiliary spectral response
function (SRF) is utilized to guide CNNs to group the bands with spectral
relevance. In addition, the channel attention module (CAM) and reformulated
spectral angle mapper loss function are applied to achieve an effective
reconstruction model. Finally, experiments on two types of datasets, including
natural and remote sensing images, demonstrate the spectral enhancement effect
of the proposed method. And the classification results on the remote sensing
dataset also verified the validity of the information enhanced by the proposed
method.
","Jiang He, Jie Li, Qiangqiang Yuan, Huanfeng Shen, Liangpei Zhang",Liangpei Zhang,2020-11-19T07:52:45Z
Learning to Enhance Visual Quality via Hyperspectral Domain Mapping,"  Deep learning based methods have achieved remarkable success in image
restoration and enhancement, but most such methods rely on RGB input images.
These methods fail to take into account the rich spectral distribution of
natural images. We propose a deep architecture, SpecNet, which computes
spectral profile to estimate pixel-wise dynamic range adjustment of a given
image. First, we employ an unpaired cycle-consistent framework to generate
hyperspectral images (HSI) from low-light input images. HSI is further used to
generate a normal light image of the same scene. We incorporate a
self-supervision and a spectral profile regularization network to infer a
plausible HSI from an RGB image. We evaluate the benefits of optimizing the
spectral profile for real and fake images in low-light conditions on the LOL
Dataset.
","Harsh Sinha, Aditya Mehta, Murari Mandal, Pratik Narang",Pratik Narang,2021-02-10T13:27:34Z
"Subspace-Based Feature Fusion From Hyperspectral And Multispectral Image
  For Land Cover Classification","  In remote sensing, hyperspectral (HS) and multispectral (MS) image fusion
have emerged as a synthesis tool to improve the data set resolution. However,
conventional image fusion methods typically degrade the performance of the land
cover classification. In this paper, a feature fusion method from HS and MS
images for pixel-based classification is proposed. More precisely, the proposed
method first extracts spatial features from the MS image using morphological
profiles. Then, the feature fusion model assumes that both the extracted
morphological profiles and the HS image can be described as a feature matrix
lying in different subspaces. An algorithm based on combining alternating
optimization (AO) and the alternating direction method of multipliers (ADMM) is
developed to solve efficiently the feature fusion problem. Finally, extensive
simulations were run to evaluate the performance of the proposed feature fusion
approach for two data sets. In general, the proposed approach exhibits a
competitive performance compared to other feature extraction methods.
","Juan Ramírez, Héctor Vargas, José Ignacio Martínez, Henry Arguello",Henry Arguello,2021-02-22T17:59:18Z
Dual-Comb Hyperspectral Digital Holography,"  Holography has always held special appeal, for it is able to record and
display spatial information in three dimensions. Here, we show how to augment
the capabilities of digital holography by using a large number of narrow laser
lines at precisely-defined optical frequencies simultaneously. Using an
interferometer based on two frequency combs of slightly different repetition
frequencies and a lens-less camera sensor, we record time-varying spatial
interference patterns that generate spectral hypercubes of complex holograms,
revealing, for each comb line frequency, amplitudes and phases of scattered
wave-fields. Unlike with previous multi-color holography and low-coherence
holography (including with a frequency comb), the unique synergy of broad
spectral bandwidth and high temporal coherence in dual-comb holography opens up
novel optical diagnostics, such as precise dimensional metrology over large
distances without interferometric phase ambiguity, or hyperspectral
3-dimensional imaging with high spectral resolving power, as we illustrate by
molecule-selective imaging of an absorbing gas.
","Edoardo Vicentini, Zhenhai Wang, Kasper Van Gasse, Theodor W. Hänsch, Nathalie Picqué",Nathalie Picqué,2021-05-02T16:58:53Z
"Spectral-Spatial Global Graph Reasoning for Hyperspectral Image
  Classification","  Convolutional neural networks have been widely applied to hyperspectral image
classification. However, traditional convolutions can not effectively extract
features for objects with irregular distributions. Recent methods attempt to
address this issue by performing graph convolutions on spatial topologies, but
fixed graph structures and local perceptions limit their performances. To
tackle these problems, in this paper, different from previous approaches, we
perform the superpixel generation on intermediate features during network
training to adaptively produce homogeneous regions, obtain graph structures,
and further generate spatial descriptors, which are served as graph nodes.
Besides spatial objects, we also explore the graph relationships between
channels by reasonably aggregating channels to generate spectral descriptors.
The adjacent matrices in these graph convolutions are obtained by considering
the relationships among all descriptors to realize global perceptions. By
combining the extracted spatial and spectral graph features, we finally obtain
a spectral-spatial graph reasoning network (SSGRN). The spatial and spectral
parts of SSGRN are separately called spatial and spectral graph reasoning
subnetworks. Comprehensive experiments on four public datasets demonstrate the
competitiveness of the proposed methods compared with other state-of-the-art
graph convolution-based approaches.
","Di Wang, Bo Du, Liangpei Zhang",Liangpei Zhang,2021-06-26T06:24:51Z
"Evaluating the Usefulness of Unsupervised monitoring in Cultural
  Heritage Monuments","  In this paper, we scrutinize the effectiveness of various clustering
techniques, investigating their applicability in Cultural Heritage monitoring
applications. In the context of this paper, we detect the level of
decomposition and corrosion on the walls of Saint Nicholas fort in Rhodes
utilizing hyperspectral images. A total of 6 different clustering approaches
have been evaluated over a set of 14 different orthorectified hyperspectral
images. Experimental setup in this study involves K-means, Spectral, Meanshift,
DBSCAN, Birch and Optics algorithms. For each of these techniques we evaluate
its performance by the use of performance metrics such as Calinski-Harabasz,
Davies-Bouldin indexes and Silhouette value. In this approach, we evaluate the
outcomes of the clustering methods by comparing them with a set of annotated
images which denotes the ground truth regarding the decomposition and/or
corrosion area of the original images. The results depict that a few clustering
techniques applied on the given dataset succeeded decent accuracy, precision,
recall and f1 scores. Eventually, it was observed that the deterioration was
detected quite accurately.
","Charalampos Zafeiropoulos, Ioannis N. Tzortzis, Ioannis Rallis, Eftychios Protopapadakis, Nikolaos Doulamis, Anastasios Doulamis",Anastasios Doulamis,2021-07-02T10:51:28Z
Rule-Based Classification of Hyperspectral Imaging Data,"  Due to its high spatial and spectral information content, hyperspectral
imaging opens up new possibilities for a better understanding of data and
scenes in a wide variety of applications. An essential part of this process of
understanding is the classification part. In this article we present a general
classification approach based on the shape of spectral signatures. In contrast
to classical classification approaches (e.g. SVM, KNN), not only reflectance
values are considered, but also parameters such as curvature points, curvature
values, and the curvature behavior of spectral signatures are used to develop
shape-describing rules in order to use them for classification by a rule-based
procedure using IF-THEN queries. The flexibility and efficiency of the
methodology is demonstrated using datasets from two different application
fields and leads to convincing results with good performance.
","Songuel Polat, Alain Tremeau, Frank Boochs",Frank Boochs,2021-07-21T10:11:41Z
"Determination of the best optimal estimation parameters for validation
  of infrared hyperspectral sounding retrievals","  The availability of hyperspectral infrared remote sensing instruments, like
AIRS and IASI, on board of Earth observing satellites opens the possibility of
obtaining high vertical resolution atmospheric profiles. We present an
objective and simple technique to derive the parameters used in the optimal
estimation method that retrieve atmospheric states from the spectra. The
retrievals obtained in this way are optimal in the sense of providing the best
possible validation statistics obtained from the difference between retrievals
and a chosen calibration/validation dataset of atmospheric states. This is
demonstrated analytically. To illustrate this result several real world
examples using IASI retrievals fine tuned to ECMWF analyses are shown. The
analytical equations obtained give further insight into the various
contributions to the biases and errors of the retrievals and the consequences
of using other types of fine tuning. Retrievals using IASI show an error of 0.9
to 1.9 K in temperature and below 6.5 K in humidity dew point temperature in
the troposphere on the vertical radiative transfer model pressure grid
(RTIASI-4.1), which has a vertical spacing between 300 and 400 m. The more
accurately the calibration dataset represents the true state of the atmosphere,
the better the retrievals will be when compared to the true states.
",Xavier Calbet,Xavier Calbet,2012-05-14T13:19:31Z
"Compressive hyperspectral imaging via adaptive sampling and dictionary
  learning","  In this paper, we propose a new sampling strategy for hyperspectral signals
that is based on dictionary learning and singular value decomposition (SVD).
Specifically, we first learn a sparsifying dictionary from training spectral
data using dictionary learning. We then perform an SVD on the dictionary and
use the first few left singular vectors as the rows of the measurement matrix
to obtain the compressive measurements for reconstruction. The proposed method
provides significant improvement over the conventional compressive sensing
approaches. The reconstruction performance is further improved by
reconditioning the sensing matrix using matrix balancing. We also demonstrate
that the combination of dictionary learning and SVD is robust by applying them
to different datasets.
","Mingrui Yang, Frank de Hoog, Yuqi Fan, Wen Hu",Wen Hu,2015-12-02T23:13:04Z
"Semi-Supervised Endmember Identification In Nonlinear Spectral Mixtures
  Via Semantic Representation","  This paper proposes a new hyperspectral unmixing method for nonlinearly mixed
hyperspectral data using a semantic representation in a semi-supervised
fashion, assuming the availability of a spectral reference library. Existing
semi-supervised unmixing algorithms select members from an endmember library
that are present at each of the pixels; most such methods assume a linear
mixing model. However, those methods will fail in the presence of nonlinear
mixing among the observed spectra. To address this issue, we develop an
endmember selection method using a recently proposed semantic spectral
representation obtained via non-homogeneous hidden Markov chain (NHMC) model
for a wavelet transform of the spectra. The semantic representation can encode
spectrally discriminative features for any observed spectrum and, therefore,
our proposed method can perform endmember selection without any assumption on
the mixing model. Experimental results show that in the presence of
sufficiently nonlinear mixing our proposed method outperforms dictionary-based
sparse unmixing approaches based on linear models.
","Yuki Itoh, Siwei Feng, Marco F. Duarte, Mario Parente",Mario Parente,2017-01-03T19:59:15Z
"Online characterization of planetary surfaces: PlanetServer, an
  open-source analysis and visualization tool","  The lack of open-source tools for hyperspectral data visualization and
analysiscreates a demand for new tools. In this paper we present the new
PlanetServer,a set of tools comprising a web Geographic Information System
(GIS) and arecently developed Python Application Programming Interface (API)
capableof visualizing and analyzing a wide variety of hyperspectral data from
differentplanetary bodies. Current WebGIS open-source tools are evaluated in
orderto give an overview and contextualize how PlanetServer can help in this
mat-ters. The web client is thoroughly described as well as the datasets
availablein PlanetServer. Also, the Python API is described and exposed the
reason ofits development. Two different examples of mineral characterization of
differenthydrosilicates such as chlorites, prehnites and kaolinites in the Nili
Fossae areaon Mars are presented. As the obtained results show positive outcome
in hyper-spectral analysis and visualization compared to previous literature,
we suggestusing the PlanetServer approach for such investigations.
","R. Marco Figuera, B. Pham Huu, A. P. Rossi, M. Minin, J. Flahaut, A. Halder",A. Halder,2017-01-06T11:40:27Z
Multiple Instance Hybrid Estimator for Learning Target Signatures,"  Signature-based detectors for hyperspectral target detection rely on knowing
the specific target signature in advance. However, target signature are often
difficult or impossible to obtain. Furthermore, common methods for obtaining
target signatures, such as from laboratory measurements or manual selection
from an image scene, usually do not capture the discriminative features of
target class. In this paper, an approach for estimating a discriminative target
signature from imprecise labels is presented. The proposed approach maximizes
the response of the hybrid sub-pixel detector within a multiple instance
learning framework and estimates a set of discriminative target signatures.
After learning target signatures, any signature based detector can then be
applied on test data. Both simulated and real hyperspectral target detection
experiments are shown to illustrate the effectiveness of the method.
","Changzhe Jiao, Alina Zare",Alina Zare,2017-01-09T16:59:01Z
"Low-rank and Sparse NMF for Joint Endmembers' Number Estimation and
  Blind Unmixing of Hyperspectral Images","  Estimation of the number of endmembers existing in a scene constitutes a
critical task in the hyperspectral unmixing process. The accuracy of this
estimate plays a crucial role in subsequent unsupervised unmixing steps i.e.,
the derivation of the spectral signatures of the endmembers (endmembers'
extraction) and the estimation of the abundance fractions of the pixels. A
common practice amply followed in literature is to treat endmembers' number
estimation and unmixing, independently as two separate tasks, providing the
outcome of the former as input to the latter. In this paper, we go beyond this
computationally demanding strategy. More precisely, we set forth a multiple
constrained optimization framework, which encapsulates endmembers' number
estimation and unsupervised unmixing in a single task. This is attained by
suitably formulating the problem via a low-rank and sparse nonnegative matrix
factorization rationale, where low-rankness is promoted with the use of a
sophisticated $\ell_2/\ell_1$ norm penalty term. An alternating proximal
algorithm is then proposed for minimizing the emerging cost function. The
results obtained by simulated and real data experiments verify the
effectiveness of the proposed approach.
","Paris V. Giampouras, Athanasios A. Rontogiannis, Konstantinos D. Koutroumbas",Konstantinos D. Koutroumbas,2017-03-16T18:25:21Z
"Bidirectional-Convolutional LSTM Based Spectral-Spatial Feature Learning
  for Hyperspectral Image Classification","  This paper proposes a novel deep learning framework named
bidirectional-convolutional long short term memory (Bi-CLSTM) network to
automatically learn the spectral-spatial feature from hyperspectral images
(HSIs). In the network, the issue of spectral feature extraction is considered
as a sequence learning problem, and a recurrent connection operator across the
spectral domain is used to address it. Meanwhile, inspired from the widely used
convolutional neural network (CNN), a convolution operator across the spatial
domain is incorporated into the network to extract the spatial feature.
Besides, to sufficiently capture the spectral information, a bidirectional
recurrent connection is proposed. In the classification phase, the learned
features are concatenated into a vector and fed to a softmax classifier via a
fully-connected operator. To validate the effectiveness of the proposed
Bi-CLSTM framework, we compare it with several state-of-the-art methods,
including the CNN framework, on three widely used HSIs. The obtained results
show that Bi-CLSTM can improve the classification performance as compared to
other methods.
","Qingshan Liu, Feng Zhou, Renlong Hang, Xiaotong Yuan",Xiaotong Yuan,2017-03-23T02:50:32Z
Spectral Unmixing with Multiple Dictionaries,"  Spectral unmixing aims at recovering the spectral signatures of materials,
called endmembers, mixed in a hyperspectral or multispectral image, along with
their abundances. A typical assumption is that the image contains one pure
pixel per endmember, in which case spectral unmixing reduces to identifying
these pixels. Many fully automated methods have been proposed in recent years,
but little work has been done to allow users to select areas where pure pixels
are present manually or using a segmentation algorithm. Additionally, in a
non-blind approach, several spectral libraries may be available rather than a
single one, with a fixed number (or an upper or lower bound) of endmembers to
chose from each. In this paper, we propose a multiple-dictionary constrained
low-rank matrix approximation model that address these two problems. We propose
an algorithm to compute this model, dubbed M2PALS, and its performance is
discussed on both synthetic and real hyperspectral images.
","Jeremy E. Cohen, Nicolas Gillis",Nicolas Gillis,2017-11-08T09:42:14Z
"Spectral-Spatial Feature Extraction and Classification by ANN Supervised
  with Center Loss in Hyperspectral Imagery","  In this paper, we propose a spectral-spatial feature extraction and
classification framework based on artificial neuron network (ANN) in the
context of hyperspectral imagery. With limited labeled samples, only spectral
information is exploited for training and spatial context is integrated
posteriorly at the testing stage. Taking advantage of recent advances in face
recognition, a joint supervision symbol that combines softmax loss and center
loss is adopted to train the proposed network, by which intra-class features
are gathered while inter-class variations are enlarged. Based on the learned
architecture, the extracted spectrum-based features are classified by a center
classifier. Moreover, to fuse the spectral and spatial information, an adaptive
spectral-spatial center classifier is developed, where multiscale neighborhoods
are considered simultaneously, and the final label is determined using an
adaptive voting strategy. Finally, experimental results on three well-known
datasets validate the effectiveness of the proposed methods compared with the
state-of-the-art approaches.
","Alan J. X. Guo, Fei Zhu",Fei Zhu,2017-11-20T04:46:45Z
"Sparsity-based Cholesky Factorization and its Application to
  Hyperspectral Anomaly Detection","  Estimating large covariance matrices has been a longstanding important
problem in many applications and has attracted increased attention over several
decades. This paper deals with two methods based on pre-existing works to
impose sparsity on the covariance matrix via its unit lower triangular matrix
(aka Cholesky factor) $\mathbf{T}$. The first method serves to estimate the
entries of $\mathbf{T}$ using the Ordinary Least Squares (OLS), then imposes
sparsity by exploiting some generalized thresholding techniques such as Soft
and Smoothly Clipped Absolute Deviation (SCAD). The second method directly
estimates a sparse version of $\mathbf{T}$ by penalizing the negative normal
log-likelihood with $L_1$ and SCAD penalty functions. The resulting covariance
estimators are always guaranteed to be positive definite. Some Monte-Carlo
simulations as well as experimental data demonstrate the effectiveness of our
estimators for hyperspectral anomaly detection using the Kelly anomaly
detector.
","Ahmad W. Bitar, Jean-Philippe Ovarlez, Loong-Fah Cheong",Loong-Fah Cheong,2017-11-22T11:46:41Z
"Tech Report: A Fast Multiscale Spatial Regularization for Sparse
  Hyperspectral Unmixing","  Sparse hyperspectral unmixing from large spectral libraries has been
considered to circumvent limitations of endmember extraction algorithms in many
applications. This strategy often leads to ill-posed inverse problems, which
can benefit from spatial regularization strategies. While existing spatial
regularization methods improve the problem conditioning and promote piecewise
smooth solutions, they lead to large nonsmooth optimization problems. Thus,
efficiently introducing spatial context in the unmixing problem remains a
challenge, and a necessity for many real world applications. In this paper, a
novel multiscale spatial regularization approach for sparse unmixing is
proposed. The method uses a signal-adaptive spatial multiscale decomposition
based on superpixels to decompose the unmixing problem into two simpler
problems, one in the approximation domain and another in the original domain.
Simulation results using both synthetic and real data indicate that the
proposed method can outperform state-of-the-art Total Variation-based
algorithms with a computation time comparable to that of their unregularized
counterparts.
","Ricardo Augusto Borsoi, Tales Imbiriba, José Carlos Moreira Bermudez, Cédric Richard",Cédric Richard,2017-12-05T17:24:54Z
Image Registration for the Alignment of Digitized Historical Documents,"  In this work, we conducted a survey on different registration algorithms and
investigated their suitability for hyperspectral historical image registration
applications. After the evaluation of different algorithms, we choose an
intensity based registration algorithm with a curved transformation model. For
the transformation model, we select cubic B-splines since they should be
capable to cope with all non-rigid deformations in our hyperspectral images.
From a number of similarity measures, we found that residual complexity and
localized mutual information are well suited for the task at hand. In our
evaluation, both measures show an acceptable performance in handling all
difficulties, e.g., capture range, non-stationary and spatially varying
intensity distortions or multi-modality that occur in our application.
","AmirAbbas Davari, Tobias Lindenberger, Armin Häberle, Vincent Christlein, Andreas Maier, Christian Riess",Christian Riess,2017-12-12T19:41:42Z
Fusing Multiple Multiband Images,"  We consider the problem of fusing an arbitrary number of multiband, i.e.,
panchromatic, multispectral, or hyperspectral, images belonging to the same
scene. We use the well-known forward observation and linear mixture models with
Gaussian perturbations to formulate the maximum-likelihood estimator of the
endmember abundance matrix of the fused image. We calculate the Fisher
information matrix for this estimator and examine the conditions for the
uniqueness of the estimator. We use a vector total-variation penalty term
together with nonnegativity and sum-to-one constraints on the endmember
abundances to regularize the derived maximum-likelihood estimation problem. The
regularization facilitates exploiting the prior knowledge that natural images
are mostly composed of piecewise smooth regions with limited abrupt changes,
i.e., edges, as well as coping with potential ill-posedness of the fusion
problem. We solve the resultant convex optimization problem using the
alternating direction method of multipliers. We utilize the circular
convolution theorem in conjunction with the fast Fourier transform to alleviate
the computational complexity of the proposed algorithm. Experiments with
multiband images constructed from real hyperspectral datasets reveal the
superior performance of the proposed algorithm in comparison with the
state-of-the-art algorithms, which need to be used in tandem to fuse more than
two multiband images.
",Reza Arablouei,Reza Arablouei,2017-12-13T00:09:28Z
Aerial Spectral Super-Resolution using Conditional Adversarial Networks,"  Inferring spectral signatures from ground based natural images has acquired a
lot of interest in applied deep learning. In contrast to the spectra of ground
based images, aerial spectral images have low spatial resolution and suffer
from higher noise interference. In this paper, we train a conditional
adversarial network to learn an inverse mapping from a trichromatic space to 31
spectral bands within 400 to 700 nm. The network is trained on AeroCampus, a
first of its kind aerial hyperspectral dataset. AeroCampus consists of high
spatial resolution color images and low spatial resolution hyperspectral images
(HSI). Color images synthesized from 31 spectral bands are used to train our
network. With a baseline root mean square error of 2.48 on the synthesized RGB
test data, we show that it is possible to generate spectral signatures in
aerial imagery.
","Aneesh Rangnekar, Nilay Mokashi, Emmett Ientilucci, Christopher Kanan, Matthew Hoffman",Matthew Hoffman,2017-12-23T00:21:20Z
"Archetypal Analysis for Sparse Representation-based Hyperspectral
  Sub-pixel Quantification","  The estimation of land cover fractions from remote sensing images is a
frequently used indicator of the environmental quality. This paper focuses on
the quantification of land cover fractions in an urban area of Berlin, Germany,
using simulated hyperspectral EnMAP data with a spatial resolution of
30m$\times$30m. We use constrained sparse representation, where each pixel with
unknown surface characteristics is expressed by a weighted linear combination
of elementary spectra with known land cover class. We automatically determine
the elementary spectra from image reference data using archetypal analysis by
simplex volume maximization, and combine it with reversible jump Markov chain
Monte Carlo method. In our experiments, the estimation of the automatically
derived elementary spectra is compared to the estimation obtained by a manually
designed spectral library by means of reconstruction error, mean absolute error
of the fraction estimates, sum of fractions, $R^2$, and the number of used
elementary spectra. The experiments show that a collection of archetypes can be
an adequate and efficient alternative to the manually designed spectral library
with respect to the mentioned criteria.
","Lukas Drees, Ribana Roscher, Susanne Wenzel",Susanne Wenzel,2018-02-08T11:47:19Z
Endmember Extraction on the Grassmannian,"  Endmember extraction plays a prominent role in a variety of data analysis
problems as endmembers often correspond to data representing the purest or best
representative of some feature. Identifying endmembers then can be useful for
further identification and classification tasks. In settings with
high-dimensional data, such as hyperspectral imagery, it can be useful to
consider endmembers that are subspaces as they are capable of capturing a wider
range of variations of a signature. The endmember extraction problem in this
setting thus translates to finding the vertices of the convex hull of a set of
points on a Grassmannian. In the presence of noise, it can be less clear
whether a point should be considered a vertex. In this paper, we propose an
algorithm to extract endmembers on a Grassmannian, identify subspaces of
interest that lie near the boundary of a convex hull, and demonstrate the use
of the algorithm on a synthetic example and on the 220 spectral band AVIRIS
Indian Pines hyperspectral image.
","Elin Farnell, Henry Kvinge, Michael Kirby, Chris Peterson",Chris Peterson,2018-07-03T23:35:47Z
"A Supervised Geometry-Aware Mapping Approach for Classification of
  Hyperspectral Images","  The lack of proper class discrimination among the Hyperspectral (HS) data
points poses a potential challenge in HS classification. To address this issue,
this paper proposes an optimal geometry-aware transformation for enhancing the
classification accuracy. The underlying idea of this method is to obtain a
linear projection matrix by solving a nonlinear objective function based on the
intrinsic geometrical structure of the data. The objective function is
constructed to quantify the discrimination between the points from dissimilar
classes on the projected data space. Then the obtained projection matrix is
used to linearly map the data to more discriminative space. The effectiveness
of the proposed transformation is illustrated with three benchmark real-world
HS data sets. The experiments reveal that the classification and dimensionality
reduction methods on the projected discriminative space outperform their
counterpart in the original space.
","Ramanarayan Mohanty, S L Happy, Aurobinda Routray",Aurobinda Routray,2018-07-07T15:57:50Z
"A Trace Lasso Regularized L1-norm Graph Cut for Highly Correlated Noisy
  Hyperspectral Image","  This work proposes an adaptive trace lasso regularized L1-norm based graph
cut method for dimensionality reduction of Hyperspectral images, called as
`Trace Lasso-L1 Graph Cut' (TL-L1GC). The underlying idea of this method is to
generate the optimal projection matrix by considering both the sparsity as well
as the correlation of the data samples. The conventional L2-norm used in the
objective function is sensitive to noise and outliers. Therefore, in this work
L1-norm is utilized as a robust alternative to L2-norm. Besides, for further
improvement of the results, we use a penalty function of trace lasso with the
L1GC method. It adaptively balances the L2-norm and L1-norm simultaneously by
considering the data correlation along with the sparsity. We obtain the optimal
projection matrix by maximizing the ratio of between-class dispersion to
within-class dispersion using L1-norm with trace lasso as the penalty.
Furthermore, an iterative procedure for this TL-L1GC method is proposed to
solve the optimization function. The effectiveness of this proposed method is
evaluated on two benchmark HSI datasets.
","Ramanarayan Mohanty, S L Happy, Nilesh Suthar, Aurobinda Routray",Aurobinda Routray,2018-07-22T07:44:56Z
"Programmable Spectrometry -- Per-pixel Classification of Materials using
  Learned Spectral Filters","  Many materials have distinct spectral profiles. This facilitates estimation
of the material composition of a scene at each pixel by first acquiring its
hyperspectral image, and subsequently filtering it using a bank of spectral
profiles. This process is inherently wasteful since only a set of linear
projections of the acquired measurements contribute to the classification task.
We propose a novel programmable camera that is capable of producing images of a
scene with an arbitrary spectral filter. We use this camera to optically
implement the spectral filtering of the scene's hyperspectral image with the
bank of spectral profiles needed to perform per-pixel material classification.
This provides gains both in terms of acquisition speed --- since only the
relevant measurements are acquired --- and in signal-to-noise ratio --- since
we invariably avoid narrowband filters that are light inefficient. Given
training data, we use a range of classical and modern techniques including SVMs
and neural networks to identify the bank of spectral profiles that facilitate
material classification. We verify the method in simulations on standard
datasets as well as real data using a lab prototype of the camera.
","Vishwanath Saragadam, Aswin C. Sankaranarayanan",Aswin C. Sankaranarayanan,2019-05-13T00:20:31Z
Hyperspectral Image Classification Based on Adaptive Sparse Deep Network,"  Sparse model is widely used in hyperspectral image classification.However,
different of sparsity and regularization parameters has great influence on the
classification results.In this paper, a novel adaptive sparse deep network
based on deep architecture is proposed, which can construct the optimal sparse
representation and regularization parameters by deep network.Firstly, a data
flow graph is designed to represent each update iteration based on Alternating
Direction Method of Multipliers (ADMM) algorithm.Forward network and
Back-Propagation network are deduced.All parameters are updated by gradient
descent in Back-Propagation.Then we proposed an Adaptive Sparse Deep
Network.Comparing with several traditional classifiers or other algorithm for
sparse model, experiment results indicate that our method achieves great
improvement in HSI classification.
","Jingwen Yan, Zixin Xie, Jingyao Chen, Yinan Liu, Lei Liu",Lei Liu,2019-10-21T14:31:33Z
"Kalman Filtering and Expectation Maximization for Multitemporal Spectral
  Unmixing","  The recent evolution of hyperspectral imaging technology and the
proliferation of new emerging applications presses for the processing of
multiple temporal hyperspectral images. In this work, we propose a novel
spectral unmixing (SU) strategy using physically motivated parametric endmember
representations to account for temporal spectral variability. By representing
the multitemporal mixing process using a state-space formulation, we are able
to exploit the Bayesian filtering machinery to estimate the endmember
variability coefficients. Moreover, by assuming that the temporal variability
of the abundances is small over short intervals, an efficient implementation of
the expectation maximization (EM) algorithm is employed to estimate the
abundances and the other model parameters. Simulation results indicate that the
proposed strategy outperforms state-of-the-art multitemporal SU algorithms.
","Ricardo Augusto Borsoi, Tales Imbiriba, Pau Closas, José Carlos Moreira Bermudez, Cédric Richard",Cédric Richard,2020-01-02T13:12:46Z
"Spectral Pyramid Graph Attention Network for Hyperspectral Image
  Classification","  Convolutional neural networks (CNN) have made significant advances in
hyperspectral image (HSI) classification. However, standard convolutional
kernel neglects the intrinsic connections between data points, resulting in
poor region delineation and small spurious predictions. Furthermore, HSIs have
a unique continuous data distribution along the high dimensional spectrum
domain - much remains to be addressed in characterizing the spectral contexts
considering the prohibitively high dimensionality and improving reasoning
capability in light of the limited amount of labelled data. This paper presents
a novel architecture which explicitly addresses these two issues. Specifically,
we design an architecture to encode the multiple spectral contextual
information in the form of spectral pyramid of multiple embedding spaces. In
each spectral embedding space, we propose graph attention mechanism to
explicitly perform interpretable reasoning in the spatial domain based on the
connection in spectral feature space. Experiments on three HSI datasets
demonstrate that the proposed architecture can significantly improve the
classification accuracy compared with the existing methods.
","Tinghuai Wang, Guangming Wang, Kuan Eeik Tan, Donghui Tan",Donghui Tan,2020-01-20T13:49:43Z
"Generating Natural Adversarial Hyperspectral examples with a modified
  Wasserstein GAN","  Adversarial examples are a hot topic due to their abilities to fool a
classifier's prediction. There are two strategies to create such examples, one
uses the attacked classifier's gradients, while the other only requires access
to the clas-sifier's prediction. This is particularly appealing when the
classifier is not full known (black box model). In this paper, we present a new
method which is able to generate natural adversarial examples from the true
data following the second paradigm. Based on Generative Adversarial Networks
(GANs) [5], it reweights the true data empirical distribution to encourage the
classifier to generate ad-versarial examples. We provide a proof of concept of
our method by generating adversarial hyperspectral signatures on a remote
sensing dataset.
","Jean-Christophe Burnel, Kilian Fatras, Nicolas Courty",Nicolas Courty,2020-01-27T07:32:46Z
"A CNN With Multi-scale Convolution for Hyperspectral Image
  Classification using Target-Pixel-Orientation scheme","  Recently, CNN is a popular choice to handle the hyperspectral image
classification challenges. In spite of having such large spectral information
in Hyper-Spectral Image(s) (HSI), it creates a curse of dimensionality. Also,
large spatial variability of spectral signature adds more difficulty in
classification problem. Additionally, training a CNN in the end to end fashion
with scarced training examples is another challenging and interesting problem.
In this paper, a novel target-patch-orientation method is proposed to train a
CNN based network. Also, we have introduced a hybrid of 3D-CNN and 2D-CNN based
network architecture to implement band reduction and feature extraction
methods, respectively. Experimental results show that our method outperforms
the accuracies reported in the existing state of the art methods.
","Jayasree Saha, Yuvraj Khanna, Jayanta Mukherjee",Jayanta Mukherjee,2020-01-30T07:45:07Z
"Hyperspectral Classification Based on 3D Asymmetric Inception Network
  with Data Fusion Transfer Learning","  Hyperspectral image(HSI) classification has been improved with convolutional
neural network(CNN) in very recent years. Being different from the RGB
datasets, different HSI datasets are generally captured by various remote
sensors and have different spectral configurations. Moreover, each HSI dataset
only contains very limited training samples and thus it is prone to overfitting
when using deep CNNs. In this paper, we first deliver a 3D asymmetric inception
network, AINet, to overcome the overfitting problem. With the emphasis on
spectral signatures over spatial contexts of HSI data, AINet can convey and
classify the features effectively. In addition, the proposed data fusion
transfer learning strategy is beneficial in boosting the classification
performance. Extensive experiments show that the proposed approach beat all of
the state-of-art methods on several HSI benchmarks, including Pavia University,
Indian Pines and Kennedy Space Center(KSC). Code can be found at:
https://github.com/UniLauX/AINet.
","Haokui Zhang, Yu Liu, Bei Fang, Ying Li, Lingqiao Liu, Ian Reid",Ian Reid,2020-02-11T06:37:34Z
NTIRE 2020 Challenge on Spectral Reconstruction from an RGB Image,"  This paper reviews the second challenge on spectral reconstruction from RGB
images, i.e., the recovery of whole-scene hyperspectral (HS) information from a
3-channel RGB image. As in the previous challenge, two tracks were provided:
(i) a ""Clean"" track where HS images are estimated from noise-free RGBs, the RGB
images are themselves calculated numerically using the ground-truth HS images
and supplied spectral sensitivity functions (ii) a ""Real World"" track,
simulating capture by an uncalibrated and unknown camera, where the HS images
are recovered from noisy JPEG-compressed RGB images. A new, larger-than-ever,
natural hyperspectral image data set is presented, containing a total of 510 HS
images. The Clean and Real World tracks had 103 and 78 registered participants
respectively, with 14 teams competing in the final testing phase. A description
of the proposed methods, alongside their challenge scores and an extensive
evaluation of top performing methods is also provided. They gauge the
state-of-the-art in spectral reconstruction from an RGB image.
","Boaz Arad, Radu Timofte, Ohad Ben-Shahar, Yi-Tun Lin, Graham Finlayson, Shai Givati,  others", others,2020-05-07T12:23:56Z
"Fuzziness-based Spatial-Spectral Class Discriminant Information
  Preserving Active Learning for Hyperspectral Image Classification","  Traditional Active/Self/Interactive Learning for Hyperspectral Image
Classification (HSIC) increases the size of the training set without
considering the class scatters and randomness among the existing and new
samples. Second, very limited research has been carried out on joint
spectral-spatial information and finally, a minor but still worth mentioning is
the stopping criteria which not being much considered by the community.
Therefore, this work proposes a novel fuzziness-based spatial-spectral within
and between for both local and global class discriminant information preserving
(FLG) method. We first investigate a spatial prior fuzziness-based
misclassified sample information. We then compute the total local and global
for both within and between class information and formulate it in a
fine-grained manner. Later this information is fed to a discriminative
objective function to query the heterogeneous samples which eliminate the
randomness among the training samples. Experimental results on benchmark HSI
datasets demonstrate the effectiveness of the FLG method on Generative, Extreme
Learning Machine and Sparse Multinomial Logistic Regression (SMLR)-LORSAL
classifiers.
",Muhammad Ahmad,Muhammad Ahmad,2020-05-28T18:58:11Z
"Integrating global spatial features in CNN based Hyperspectral/SAR
  imagery classification","  The land cover classification has played an important role in remote sensing
because it can intelligently identify things in one huge remote sensing image
to reduce the work of humans. However, a lot of classification methods are
designed based on the pixel feature or limited spatial feature of the remote
sensing image, which limits the classification accuracy and universality of
their methods. This paper proposed a novel method to take into the information
of remote sensing image, i.e., geographic latitude-longitude information. In
addition, a dual-branch convolutional neural network (CNN) classification
method is designed in combination with the global information to mine the pixel
features of the image. Then, the features of the two neural networks are fused
with another fully neural network to realize the classification of remote
sensing images. Finally, two remote sensing images are used to verify the
effectiveness of our method, including hyperspectral imaging (HSI) and
polarimetric synthetic aperture radar (PolSAR) imagery. The result of the
proposed method is superior to the traditional single-channel convolutional
neural network.
","Fan Zhang, MinChao Yan, Chen Hu, Jun Ni, Fei Ma",Fei Ma,2020-05-30T10:00:10Z
"Hyperspectral Image Denoising via Global Spatial-Spectral Total
  Variation Regularized Nonconvex Local Low-Rank Tensor Approximation","  Hyperspectral image (HSI) denoising aims to restore clean HSI from the
noise-contaminated one. Noise contamination can often be caused during data
acquisition and conversion. In this paper, we propose a novel spatial-spectral
total variation (SSTV) regularized nonconvex local low-rank (LR) tensor
approximation method to remove mixed noise in HSIs. From one aspect, the clean
HSI data have its underlying local LR tensor property, even though the real HSI
data may not be globally low-rank due to out-liers and non-Gaussian noise.
According to this fact, we propose a novel tensor $L_{\gamma}$-norm to
formulate the local LR prior. From another aspect, HSIs are assumed to be
piecewisely smooth in the global spatial and spectral domains. Instead of
traditional bandwise total variation, we use the SSTV regularization to
simultaneously consider global spatial structure and spectral correlation of
neighboring bands. Results on simulated and real HSI datasets indicate that the
use of local LR tensor penalty and global SSTV can boost the preserving of
local details and overall structural information in HSIs.
","Haijin Zeng, Xiaozhen Xie, Jifeng Ning",Jifeng Ning,2020-05-30T10:03:39Z
"Correlative infrared optical coherence tomography and hyperspectral
  chemical imaging","  Optical coherence tomography (OCT) is a high-resolution three-dimensional
imaging technique that enables non-destructive measurements of surface and
subsurface microstructures. Recent developments of OCT operating in the
mid-infrared (MIR) range (around 4 {\mu}m) lifted fundamental scattering
limitations and initiated applied material research in formerly inaccessible
fields. The MIR spectral region, however, is also of great interest for
spectroscopy and hyperspectral imaging, which allow highly selective and
sensitive chemical studies of materials. In this contribution, we introduce an
OCT system (dual-band, central wavelengths of 2 {\mu}m m and 4 {\mu}m) combined
with MIR spectroscopy that is implemented as a raster scanning chemical imaging
modality. The fully-integrated and cost-effective optical instrument is based
on a single supercontinuum laser source (emission spectrum spanning from 1.1
{\mu}m to 4.4 {\mu}m). Capabilities of the in-situ correlative measurements are
experimentally demonstrated by obtaining complex multidimensional material
data, comprising morphological and chemical information, from a multi-layered
composite ceramic-polymer specimen.
","Ivan Zorin, Rong Su, Bettina Heise, Bernhard Lendl, Markus Brandstetter",Markus Brandstetter,2020-06-05T07:51:12Z
"Recent Advances and New Guidelines on Hyperspectral and Multispectral
  Image Fusion","  Hyperspectral image (HSI) with high spectral resolution often suffers from
low spatial resolution owing to the limitations of imaging sensors. Image
fusion is an effective and economical way to enhance the spatial resolution of
HSI, which combines HSI with higher spatial resolution multispectral image
(MSI) of the same scenario. In the past years, many HSI and MSI fusion
algorithms are introduced to obtain high-resolution HSI. However, it lacks a
full-scale review for the newly proposed HSI and MSI fusion approaches. To
tackle this problem,this work gives a comprehensive review and new guidelines
for HSI-MSI fusion. According to the characteristics of HSI-MSI fusion methods,
they are categorized as four categories, including pan-sharpening based
approaches, matrix factorization based approaches, tensor representation based
approaches, and deep convolution neural network based approaches. We make a
detailed introduction, discussions, and comparison for the fusion methods in
each category. Additionally, the existing challenges and possible future
directions for the HSI-MSI fusion are presented.
","Renwei Dian, Shutao Li, Bin Sun, Anjing Guo",Anjing Guo,2020-08-08T03:05:46Z
"Evolving Deep Convolutional Neural Networks for Hyperspectral Image
  Denoising","  Hyperspectral images (HSIs) are susceptible to various noise factors leading
to the loss of information, and the noise restricts the subsequent HSIs object
detection and classification tasks. In recent years, learning-based methods
have demonstrated their superior strengths in denoising the HSIs.
Unfortunately, most of the methods are manually designed based on the extensive
expertise that is not necessarily available to the users interested. In this
paper, we propose a novel algorithm to automatically build an optimal
Convolutional Neural Network (CNN) to effectively denoise HSIs. Particularly,
the proposed algorithm focuses on the architectures and the initialization of
the connection weights of the CNN. The experiments of the proposed algorithm
have been well-designed and compared against the state-of-the-art peer
competitors, and the experimental results demonstrate the competitive
performance of the proposed algorithm in terms of the different evaluation
metrics, visual assessments, and the computational complexity.
","Yuqiao Liu, Yanan Sun, Bing Xue, Mengjie Zhang",Mengjie Zhang,2020-08-15T03:04:11Z
"Mapping nanoscale charge states and phase domains with quantitative
  hyperspectral coherent diffractive imaging spectroscopy","  The critical properties of functional materials and nanoscale devices often
originate from the coexistence of different thermodynamic phases and / or
oxidization states, but sample makeup is seldom completely known a priori.
Coherent diffractive imaging (CDI) provides the spatial resolution needed to
observe nanoscale coexistence while returning the full amplitude and phase
information of an object, but to date lacks the spectral information necessary
for composition identification. Here we demonstrate CDI spectroscopy (CDIS),
acquiring images of the prototypical quantum material vanadium oxide across the
vanadium L2,3 and oxygen K X-ray absorption edges with nanometer scale
resolution. Using the hyperspectral X-ray image we show coexistence of multiple
oxidization states and phases in a single sample and extract the full complex
refractive index of V2O5 and the monoclinic insulating and rutile conducting
phases of VO2. These results constrain the role of hidden phases in the
insulator-to-metal transition in VO2.
","Allan S. Johnson, Jordi Valls Conesa, Luciana Vidas, Daniel Perez-Salinas, Christian M. Günther, Bastian Pfau, Kent A. Hallman, Richard F. Haglund Jr, Stefan Eisebitt, Simon Wall",Simon Wall,2020-08-27T08:39:22Z
Snapshot hyperspectral imaging with quantum correlated photons,"  Hyperspectral imaging (HSI) has a wide range of applications from
environmental monitoring to biotechnology. Current snapshot HSI techniques all
require a trade-off between spatial and spectral resolution and are thus unable
to achieve high resolutions in both simultaneously. Additionally, the
techniques are resource inefficient with most of the photons lost through
spectral filtering. Here, we demonstrate a snapshot HSI technique utilizing the
strong spectro-temporal correlations inherent in entangled photons using a
modified quantum ghost spectroscopy system, where the target is directly imaged
with one photon and the spectral information gained through ghost spectroscopy
from the partner photon. As only a few rows of pixels near the edge of the
camera are used for the spectrometer, almost no spatial resolution is
sacrificed for spectral. Also since no spectral filtering is required, all
photons contribute to the HSI process making the technique much more resource
efficient.
","Yingwen Zhang, Duncan England, Benjamin Sussman",Benjamin Sussman,2022-04-12T17:47:59Z
"Unsupervised detection of ash dieback disease (Hymenoscyphus fraxineus)
  using diffusion-based hyperspectral image clustering","  Ash dieback (Hymenoscyphus fraxineus) is an introduced fungal disease that is
causing the widespread death of ash trees across Europe. Remote sensing
hyperspectral images encode rich structure that has been exploited for the
detection of dieback disease in ash trees using supervised machine learning
techniques. However, to understand the state of forest health at
landscape-scale, accurate unsupervised approaches are needed. This article
investigates the use of the unsupervised Diffusion and VCA-Assisted Image
Segmentation (D-VIS) clustering algorithm for the detection of ash dieback
disease in a forest site near Cambridge, United Kingdom. The unsupervised
clustering presented in this work has high overlap with the supervised
classification of previous work on this scene (overall accuracy = 71%). Thus,
unsupervised learning may be used for the remote detection of ash dieback
disease without the need for expert labeling.
","Sam L. Polk, Aland H. Y. Chan, Kangning Cui, Robert J. Plemmons, David A. Coomes, James M. Murphy",James M. Murphy,2022-04-19T17:58:49Z
"Low-rank Meets Sparseness: An Integrated Spatial-Spectral Total
  Variation Approach to Hyperspectral Denoising","  Spatial-Spectral Total Variation (SSTV) can quantify local smoothness of
image structures, so it is widely used in hyperspectral image (HSI) processing
tasks. Essentially, SSTV assumes a sparse structure of gradient maps calculated
along the spatial and spectral directions. In fact, these gradient tensors are
not only sparse, but also (approximately) low-rank under FFT, which we have
verified by numerical tests and theoretical analysis. Based on this fact, we
propose a novel TV regularization to simultaneously characterize the sparsity
and low-rank priors of the gradient map (LRSTV). The new regularization not
only imposes sparsity on the gradient map itself, but also penalize the rank on
the gradient map after Fourier transform along the spectral dimension. It
naturally encodes the sparsity and lowrank priors of the gradient map, and thus
is expected to reflect the inherent structure of the original image more
faithfully. Further, we use LRSTV to replace conventional SSTV and embed it in
the HSI processing model to improve its performance. Experimental results on
multiple public data-sets with heavy mixed noise show that the proposed model
can get 1.5dB improvement of PSNR.
","Haijin Zeng, Shaoguang Huang, Yongyong Chen, Hiep Luong, Wilfried Philips",Wilfried Philips,2022-04-27T12:31:55Z
"Fast and Robust Recursive Algorithms for Separable Nonnegative Matrix
  Factorization","  In this paper, we study the nonnegative matrix factorization problem under
the separability assumption (that is, there exists a cone spanned by a small
subset of the columns of the input nonnegative data matrix containing all
columns), which is equivalent to the hyperspectral unmixing problem under the
linear mixing model and the pure-pixel assumption. We present a family of fast
recursive algorithms, and prove they are robust under any small perturbations
of the input data matrix. This family generalizes several existing
hyperspectral unmixing algorithms and hence provides for the first time a
theoretical justification of their better practical performance.
","Nicolas Gillis, Stephen A. Vavasis",Stephen A. Vavasis,2012-08-06T18:49:07Z
"Compressive Source Separation: Theory and Methods for Hyperspectral
  Imaging","  With the development of numbers of high resolution data acquisition systems
and the global requirement to lower the energy consumption, the development of
efficient sensing techniques becomes critical. Recently, Compressed Sampling
(CS) techniques, which exploit the sparsity of signals, have allowed to
reconstruct signal and images with less measurements than the traditional
Nyquist sensing approach. However, multichannel signals like Hyperspectral
images (HSI) have additional structures, like inter-channel correlations, that
are not taken into account in the classical CS scheme. In this paper we exploit
the linear mixture of sources model, that is the assumption that the
multichannel signal is composed of a linear combination of sources, each of
them having its own spectral signature, and propose new sampling schemes
exploiting this model to considerably decrease the number of measurements
needed for the acquisition and source separation. Moreover, we give theoretical
lower bounds on the number of measurements required to perform reconstruction
of both the multichannel signal and its sources. We also proposed optimization
algorithms and extensive experimentation on our target application which is
HSI, and show that our approach recovers HSI with far less measurements and
computational effort than traditional CS approaches.
","Mohammad Golbabaee, Simon Arberet, Pierre Vandergheynst",Pierre Vandergheynst,2012-08-22T14:24:58Z
Hyperspectral Light Field Stereo Matching,"  In this paper, we describe how scene depth can be extracted using a
hyperspectral light field capture (H-LF) system. Our H-LF system consists of a
5 x 6 array of cameras, with each camera sampling a different narrow band in
the visible spectrum. There are two parts to extracting scene depth. The first
part is our novel cross-spectral pairwise matching technique, which involves a
new spectral-invariant feature descriptor and its companion matching metric we
call bidirectional weighted normalized cross correlation (BWNCC). The second
part, namely, H-LF stereo matching, uses a combination of spectral-dependent
correspondence and defocus cues that rely on BWNCC. These two new cost terms
are integrated into a Markov Random Field (MRF) for disparity estimation.
Experiments on synthetic and real H-LF data show that our approach can produce
high-quality disparity maps. We also show that these results can be used to
produce the complete plenoptic cube in addition to synthesizing all-focus and
defocused color images under different sensor spectral responses.
","Kang Zhu, Yujia Xue, Qiang Fu, Sing Bing Kang, Xilin Chen, Jingyi Yu",Jingyi Yu,2017-09-04T06:36:55Z
"Graph Scaling Cut with L1-Norm for Classification of Hyperspectral
  Images","  In this paper, we propose an L1 normalized graph based dimensionality
reduction method for Hyperspectral images, called as L1-Scaling Cut (L1-SC).
The underlying idea of this method is to generate the optimal projection matrix
by retaining the original distribution of the data. Though L2-norm is generally
preferred for computation, it is sensitive to noise and outliers. However,
L1-norm is robust to them. Therefore, we obtain the optimal projection matrix
by maximizing the ratio of between-class dispersion to within-class dispersion
using L1-norm. Furthermore, an iterative algorithm is described to solve the
optimization problem. The experimental results of the HSI classification
confirm the effectiveness of the proposed L1-SC method on both noisy and
noiseless data.
","Ramanarayan Mohanty, S L Happy, Aurobinda Routray",Aurobinda Routray,2017-09-09T06:51:23Z
Partially Asynchronous Distributed Unmixing of Hyperspectral Images,"  So far, the problem of unmixing large or multitemporal hyperspectral datasets
has been specifically addressed in the remote sensing literature only by a few
dedicated strategies. Among them, some attempts have been made within a
distributed estimation framework, in particular relying on the alternating
direction method of multipliers (ADMM). In this paper, we propose to study the
interest of a partially asynchronous distributed unmixing procedure based on a
recently proposed asynchronous algorithm. Under standard assumptions, the
proposed algorithm inherits its convergence properties from recent
contributions in non-convex optimization, while allowing the problem of
interest to be efficiently addressed. Comparisons with a distributed
synchronous counterpart of the proposed unmixing procedure allow its interest
to be assessed on synthetic and real data. Besides, thanks to its genericity
and flexibility, the procedure investigated in this work can be implemented to
address various matrix factorization problems.
","Pierre-Antoine Thouvenin, Nicolas Dobigeon, Jean-Yves Tourneret",Jean-Yves Tourneret,2017-10-06T20:22:33Z
"Data-driven Feature Sampling for Deep Hyperspectral Classification and
  Segmentation","  The high dimensionality of hyperspectral imaging forces unique challenges in
scope, size and processing requirements. Motivated by the potential for an
in-the-field cell sorting detector, we examine a $\textit{Synechocystis sp.}$
PCC 6803 dataset wherein cells are grown alternatively in nitrogen rich or
deplete cultures. We use deep learning techniques to both successfully classify
cells and generate a mask segmenting the cells/condition from the background.
Further, we use the classification accuracy to guide a data-driven, iterative
feature selection method, allowing the design neural networks requiring 90%
fewer input features with little accuracy degradation.
","William M. Severa, Jerilyn A. Timlin, Suraj Kholwadwala, Conrad D. James, James B. Aimone",James B. Aimone,2017-10-26T22:45:28Z
"Hyperspectral Image Denoising Employing a Spatial-Spectral Deep Residual
  Convolutional Neural Network","  Hyperspectral image (HSI) denoising is a crucial preprocessing procedure to
improve the performance of the subsequent HSI interpretation and applications.
In this paper, a novel deep learning-based method for this task is proposed, by
learning a non-linear end-to-end mapping between the noisy and clean HSIs with
a combined spatial-spectral deep convolutional neural network (HSID-CNN). Both
the spatial and spectral information are simultaneously assigned to the
proposed network. In addition, multi-scale feature extraction and multi-level
feature representation are respectively employed to capture both the
multi-scale spatial-spectral feature and fuse the feature representations with
different levels for the final restoration. The simulated and real-data
experiments demonstrate that the proposed HSID-CNN outperforms many of the
mainstream methods in both the quantitative evaluation indexes, visual effects,
and HSI classification accuracy.
","Qiangqiang Yuan, Qiang Zhang, Jie Li, Huanfeng Shen, Liangpei Zhang",Liangpei Zhang,2018-06-01T04:24:09Z
"Hyperspectral Unmixing by Nuclear Norm Difference Maximization based
  Dictionary Pruning","  Dictionary pruning methods perform unmixing by identifying a smaller subset
of active spectral library elements that can represent the image efficiently as
a linear combination. This paper presents a new nuclear norm difference based
approach for dictionary pruning utilizing the low rank property of
hyperspectral data. The proposed workflow calculates the nuclear norm of
abundance of the original data assuming the whole spectral library as
endmembers. In the next step, the algorithm calculates nuclear norm of
abundance after appending a spectral library element with the data. The
spectral library elements having the maximum difference in the nuclear norm of
the obtained abundance matrices are suitable candidates for being image
endmember. The proposed workflow is verified with a large number of synthetic
data generated by varying condition as well as some real images.
","Samiran Das, Aurobinda Routray, Alok Kanti Deb",Alok Kanti Deb,2018-06-03T20:01:44Z
"Generative Adversarial Networks for Realistic Synthesis of Hyperspectral
  Samples","  This work addresses the scarcity of annotated hyperspectral data required to
train deep neural networks. Especially, we investigate generative adversarial
networks and their application to the synthesis of consistent labeled spectra.
By training such networks on public datasets, we show that these models are not
only able to capture the underlying distribution, but also to generate
genuine-looking and physically plausible spectra. Moreover, we experimentally
validate that the synthetic samples can be used as an effective data
augmentation strategy. We validate our approach on several public
hyper-spectral datasets using a variety of deep classifiers.
","Nicolas Audebert, Bertrand Le Saux, Sébastien Lefèvre",Sébastien Lefèvre,2018-06-07T09:36:12Z
"Imaging Mechanism for Hyperspectral Scanning Probe Microscopy via
  Gaussian Process Modelling","  We investigate the ability to reconstruct and derive spatial structure from
sparsely sampled 3D piezoresponse force microcopy data, captured using the
band-excitation (BE) technique, via Gaussian Process (GP) methods. Even for
weakly informative priors, GP methods allow unambiguous determination of the
characteristic length scales of the imaging process both in spatial and
frequency domains. We further show that BE data set tends to be oversampled,
with ~30% of the original data set sufficient for high-quality reconstruction,
potentially enabling the faster BE imaging. Finally, we discuss how the GP can
be used for automated experimentation in SPM, by combining GP regression with
non-rectangular scans. The full code for GP regression applied to hyperspectral
data is available at https://git.io/JePGr.
","Maxim Ziatdinov, Dohyung Kim, Sabine Neumayer, Rama K. Vasudevan, Liam Collins, Stephen Jesse, Mahshid Ahmadi, Sergei V. Kalinin",Sergei V. Kalinin,2019-11-26T05:28:44Z
Color filter arrays based on dielectric metasurface elements,"  Digital imaging has been steadily improving over the past decades and we are
moving towards a wide use of multi- and hyperspectral cameras. A key component
of such imaging systems are color filter arrays, which define the spectrum of
light detected by each camera pixel. Hence, it is essential to develop a
variable, robust and scalable way for controlling the transmission of light.
Nanostructured surfaces, also known as metasurfaces, offer a promising solution
as their transmission spectra can be controlled by shaping the
wavelength-dependent scattering properties of their constituting elements. Here
we present, metasurfaces based on silicon nanodisks, which provide filter
functions with amplitudes reaching 70-90% of transmission, and well suitable
for RGB and CMY color filter arrays, the initial stage towards the further
development of hyperspectral filters. We suggest and discuss possible ways to
expand the color gamut and improve the color values of such optical filters.
","Jonas Berzins, Fabrizio Silvestri, Giampiero Gerini, Frank Setzpfandt, Thomas Pertsch, Stefan M. B. Bäumer",Stefan M. B. Bäumer,2020-04-14T11:22:45Z
"Light Weight Residual Dense Attention Net for Spectral Reconstruction
  from RGB Images","  Hyperspectral Imaging is the acquisition of spectral and spatial information
of a particular scene. Capturing such information from a specialized
hyperspectral camera remains costly. Reconstructing such information from the
RGB image achieves a better solution in both classification and object
recognition tasks. This work proposes a novel light weight network with very
less number of parameters about 233,059 parameters based on Residual dense
model with attention mechanism to obtain this solution. This network uses
Coordination Convolutional Block to get the spatial information. The weights
from this block are shared by two independent feature extraction mechanisms,
one by dense feature extraction and the other by the multiscale hierarchical
feature extraction. Finally, the features from both the feature extraction
mechanisms are globally fused to produce the 31 spectral bands. The network is
trained with NTIRE 2020 challenge dataset and thus achieved 0.0457 MRAE metric
value with less computational complexity.
","D. Sabari Nathan, K. Uma, D Synthiya Vinothini, B. Sathya Bama, S. M. Md Mansoor Roomi",S. M. Md Mansoor Roomi,2020-04-15T07:58:15Z
A Fast 3D CNN for Hyperspectral Image Classification,"  Hyperspectral imaging (HSI) has been extensively utilized for a number of
real-world applications. HSI classification (HSIC) is a challenging task due to
high inter-class similarity, high intra-class variability, overlapping, and
nested regions. A 2D Convolutional Neural Network (CNN) is a viable approach
whereby HSIC highly depends on both Spectral-Spatial information, therefore, 3D
CNN can be an alternative but highly computational complex due to the volume
and spectral dimensions. Furthermore, these models do not extract quality
feature maps and may underperform over the regions having similar textures.
Therefore, this work proposed a 3D CNN model that utilizes both
spatial-spectral feature maps to attain good performance. In order to achieve
the said performance, the HSI cube is first divided into small overlapping 3D
patches. Later these patches are processed to generate 3D feature maps using a
3D kernel function over multiple contiguous bands that persevere the spectral
information as well. Benchmark HSI datasets (Pavia University, Salinas and
Indian Pines) are considered to validate the performance of our proposed
method. The results are further compared with several state-of-the-art methods.
",Muhammad Ahmad,Muhammad Ahmad,2020-04-29T12:57:36Z
"Illumination invariant hyperspectral image unmixing based on a digital
  surface model","  Although many spectral unmixing models have been developed to address
spectral variability caused by variable incident illuminations, the mechanism
of the spectral variability is still unclear. This paper proposes an unmixing
model, named illumination invariant spectral unmixing (IISU). IISU makes the
first attempt to use the radiance hyperspectral data and a LiDAR-derived
digital surface model (DSM) in order to physically explain variable
illuminations and shadows in the unmixing framework. Incident angles, sky
factors, visibility from the sun derived from the LiDAR-derived DSM support the
explicit explanation of endmember variability in the unmixing process from
radiance perspective. The proposed model was efficiently solved by a
straightforward optimization procedure. The unmixing results showed that the
other state-of-the-art unmixing models did not work well especially in the
shaded pixels. On the other hand, the proposed model estimated more accurate
abundances and shadow compensated reflectance than the existing models.
","Tatsumi Uezato, Naoto Yokoya, Wei He",Wei He,2020-07-23T03:27:02Z
"Superpixel Based Graph Laplacian Regularization for Sparse Hyperspectral
  Unmixing","  An efficient spatial regularization method using superpixel segmentation and
graph Laplacian regularization is proposed for sparse hyperspectral unmixing
method. Since it is likely to find spectrally similar pixels in a homogeneous
region, we use a superpixel segmentation algorithm to extract the homogeneous
regions by considering the image boundaries. We first extract the homogeneous
regions, which are called superpixels, then a weighted graph in each superpixel
is constructed by selecting $K$-nearest pixels in each superpixel. Each node in
the graph represents the spectrum of a pixel and edges connect the similar
pixels inside the superpixel. The spatial similarity is investigated using
graph Laplacian regularization. Sparsity regularization for abundance matrix is
provided using a weighted sparsity promoting norm. Experimental results on
simulated and real data sets show the superiority of the proposed algorithm
over the well-known algorithms in the literature.
",Taner Ince,Taner Ince,2020-07-28T07:30:50Z
"Weakly-supervised Semantic Segmentation in Cityscape via Hyperspectral
  Image","  High-resolution hyperspectral images (HSIs) contain the response of each
pixel in different spectral bands, which can be used to effectively distinguish
various objects in complex scenes. While HSI cameras have become low cost,
algorithms based on it have not been well exploited. In this paper, we focus on
a novel topic, weakly-supervised semantic segmentation in cityscape via HSIs.
It is based on the idea that high-resolution HSIs in city scenes contain rich
spectral information, which can be easily associated to semantics without
manual labeling. Therefore, it enables low cost, highly reliable semantic
segmentation in complex scenes. Specifically, in this paper, we theoretically
analyze the HSIs and introduce a weakly-supervised HSI semantic segmentation
framework, which utilizes spectral information to improve the coarse labels to
a finer degree. The experimental results show that our method can obtain highly
competitive labels and even have higher edge fineness than artificial fine
labels in some classes. At the same time, the results also show that the
refined labels can effectively improve the effect of semantic segmentation. The
combination of HSIs and semantic segmentation proves that HSIs have great
potential in high-level visual tasks.
","Yuxing Huang, Shaodi You, Ying Fu, Qiu Shen",Qiu Shen,2020-12-18T09:29:17Z
"Hyperspectral Image Denoising via Multi-modal and Double-weighted Tensor
  Nuclear Norm","  Hyperspectral images (HSIs) usually suffer from different types of pollution.
This severely reduces the quality of HSIs and limits the accuracy of subsequent
processing tasks. HSI denoising can be modeled as a low-rank tensor denoising
problem. Tensor nuclear norm (TNN) induced by tensor singular value
decomposition plays an important role in this problem. In this letter, we first
reconsider three inconspicuous but crucial phenomenons in TNN. In the Fourier
transform domain of HSIs, different frequency slices (FS) contain different
information; different singular values (SVs) of each FS also represent
different information. The two physical phenomenons lie not only in the
spectral mode but also in the spatial modes. Then based on them, we propose a
multi-modal and double-weighted TNN. It can adaptively shrink the FS and SVs
according to their physical meanings in all modes of HSIs. In the framework of
the alternating direction method of multipliers, we design an effective
alternating iterative strategy to optimize our proposed model. Denoised
experiments on both synthetic and real HSI datasets demonstrate their
superiority against related methods.
","Sheng Liu, Xiaozhen Xie, Wenfeng Kong",Wenfeng Kong,2021-01-19T15:20:38Z
"The M3 project: 1- A global hyperspectral image-cube of the Martian
  surface","  This paper is the first paper of a series that will present the derivation of
the modal mineralogy of Mars (M3 project) at a global scale from the
near-infrared dataset acquired by the imaging spectrometer OMEGA (Observatoire
pour la Min\'eralogie, l'Eau, les Glaces et l'Activit\'e) on board ESA/Mars
Express. The objective is to create and provide a global 3-D image-cube of Mars
at 32px/{\deg} covering most of Mars surface. This product has several
advantages. First, it can be used to instantaneously extract atmospheric- and
aerosol-corrected near-infrared (NIR) spectra from any location on Mars.
Second, several new data maps can be built as discussed here. That includes new
global mineral distributions, quantitative mineral abundance distributions and
maps of Martian surface chemistry (wt % oxide) detailed in a companion paper
(Riu et al., submitted). Here we present the method to derive the global
hyperspectral cube from several hundred millions of spectra. Global maps of
some mafic minerals are then shown, and compared to previous works.
","Lucie Riu, François Poulet, John Carter, Jean-Pierre Bibring, Brigitte Gondet, Mathieu Vincendon",Mathieu Vincendon,2021-01-29T07:48:15Z
"Spatial-spectral Hyperspectral Image Classification via Multiple Random
  Anchor Graphs Ensemble Learning","  Graph-based semi-supervised learning methods, which deal well with the
situation of limited labeled data, have shown dominant performance in practical
applications. However, the high dimensionality of hyperspectral images (HSI)
makes it hard to construct the pairwise adjacent graph. Besides, the fine
spatial features that help improve the discriminability of the model are often
overlooked. To handle the problems, this paper proposes a novel
spatial-spectral HSI classification method via multiple random anchor graphs
ensemble learning (RAGE). Firstly, the local binary pattern is adopted to
extract the more descriptive features on each selected band, which preserves
local structures and subtle changes of a region. Secondly, the adaptive
neighbors assignment is introduced in the construction of anchor graph, to
reduce the computational complexity. Finally, an ensemble model is built by
utilizing multiple anchor graphs, such that the diversity of HSI is learned.
Extensive experiments show that RAGE is competitive against the
state-of-the-art approaches.
","Yanling Miao, Qi Wang, Mulin Chen, Xuelong Li",Xuelong Li,2021-03-25T09:31:41Z
"Disentangled Non-Local Network for Hyperspectral and LiDAR Data
  Classification","  As the ground objects become increasingly complex, the classification results
obtained by single source remote sensing data can hardly meet the application
requirements. In order to tackle this limitation, we propose a simple yet
effective attention fusion model based on Disentangled Non-local (DNL) network
for hyperspectral and LiDAR data joint classification task. In this model,
according to the spectral and spatial characteristics of HSI and LiDAR, a
multiscale module and a convolutional neural network (CNN) are used to capture
the spectral and spatial characteristics respectively. In addition, the
extracted HSI and LiDAR features are fused through some operations to obtain
the feature information more in line with the real situation. Finally, the
above three data are fed into different branches of the DNL module,
respectively. Extensive experiments on Houston dataset show that the proposed
network is superior and more effective compared to several of the most advanced
baselines in HSI and LiDAR joint classification missions.
","Wenxia Liu, Feng Gao, Junyu Dong",Junyu Dong,2021-04-06T06:01:22Z
Hyperspectral Image Denoising Based On Multi-Stream Denoising Network,"  Hyperspectral images (HSIs) have been widely applied in many fields, such as
military, agriculture, and environment monitoring. Nevertheless, HSIs commonly
suffer from various types of noise during acquisition. Therefore, denoising is
critical for HSI analysis and applications. In this paper, we propose a novel
blind denoising method for HSIs based on Multi-Stream Denoising Network
(MSDNet). Our network consists of the noise estimation subnetwork and denoising
subnetwork. In the noise estimation subnetwork, a multiscale fusion module is
designed to capture the noise from different scales. Then, the denoising
subnetwork is utilized to obtain the final denoising image. The proposed MSDNet
can obtain robust noise level estimation, which is capable of improving the
performance of HSI denoising. Extensive experiments on HSI dataset demonstrate
that the proposed method outperforms four closely related methods.
","Yan Gao, Feng Gao, Junyu Dong",Junyu Dong,2021-04-06T06:03:44Z
"Model-Based Deep Autoencoder Networks for Nonlinear Hyperspectral
  Unmixing","  Autoencoder (AEC) networks have recently emerged as a promising approach to
perform unsupervised hyperspectral unmixing (HU) by associating the latent
representations with the abundances, the decoder with the mixing model and the
encoder with its inverse. AECs are especially appealing for nonlinear HU since
they lead to unsupervised and model-free algorithms. However, existing
approaches fail to explore the fact that the encoder should invert the mixing
process, which might reduce their robustness. In this paper, we propose a
model-based AEC for nonlinear HU by considering the mixing model a nonlinear
fluctuation over a linear mixture. Differently from previous works, we show
that this restriction naturally imposes a particular structure to both the
encoder and to the decoder networks. This introduces prior information in the
AEC without reducing the flexibility of the mixing model. Simulations with
synthetic and real data indicate that the proposed strategy improves nonlinear
HU.
","Haoqing Li, Ricardo Augusto Borsoi, Tales Imbiriba, Pau Closas, José Carlos Moreira Bermudez, Deniz Erdoğmuş",Deniz Erdoğmuş,2021-04-17T00:14:11Z
"Spatially Coherent Clustering Based on Orthogonal Nonnegative Matrix
  Factorization","  Classical approaches in cluster analysis are typically based on a feature
space analysis. However, many applications lead to datasets with additional
spatial information and a ground truth with spatially coherent classes, which
will not necessarily be reconstructed well by standard clustering methods.
Motivated by applications in hyperspectral imaging, we introduce in this work
clustering models based on orthogonal nonnegative matrix factorization, which
include an additional total variation (TV) regularization procedure on the
cluster membership matrix to enforce the needed spatial coherence in the
clusters. We propose several approaches with different optimization techniques,
where the TV regularization is either performed as a subsequent postprocessing
step or included into the clustering algorithm. Finally, we provide a numerical
evaluation of all proposed methods on a hyperspectral dataset obtained from a
matrix-assisted laser desorption/ionisation imaging measurement, which leads to
significantly better clustering results compared to classical clustering
models.
",Pascal Fernsel,Pascal Fernsel,2021-04-25T23:40:41Z
"Superpixel-guided Discriminative Low-rank Representation of
  Hyperspectral Images for Classification","  In this paper, we propose a novel classification scheme for the remotely
sensed hyperspectral image (HSI), namely SP-DLRR, by comprehensively exploring
its unique characteristics, including the local spatial information and
low-rankness. SP-DLRR is mainly composed of two modules, i.e., the
classification-guided superpixel segmentation and the discriminative low-rank
representation, which are iteratively conducted. Specifically, by utilizing the
local spatial information and incorporating the predictions from a typical
classifier, the first module segments pixels of an input HSI (or its
restoration generated by the second module) into superpixels. According to the
resulting superpixels, the pixels of the input HSI are then grouped into
clusters and fed into our novel discriminative low-rank representation model
with an effective numerical solution. Such a model is capable of increasing the
intra-class similarity by suppressing the spectral variations locally while
promoting the inter-class discriminability globally, leading to a restored HSI
with more discriminative pixels. Experimental results on three benchmark
datasets demonstrate the significant superiority of SP-DLRR over
state-of-the-art methods, especially for the case with an extremely limited
number of training pixels.
","Shujun Yang, Junhui Hou, Yuheng Jia, Shaohui Mei, Qian Du",Qian Du,2021-08-25T10:47:26Z
Image Processing via Multilayer Graph Spectra,"  Graph signal processing (GSP) has become an important tool in image
processing because of its ability to reveal underlying data structures. Many
real-life multimedia datasets, however, exhibit heterogeneous structures across
frames. Multilayer graphs (MLG), instead of traditional single-layer graphs,
provide better representation of these datasets such as videos and
hyperspectral images. To generalize GSP to multilayer graph models and develop
multilayer analysis for image processing, this work introduces a tensor-based
framework of multilayer graph signal processing (M-GSP) and present useful
M-GSP tools for image processing. We then present guidelines for applying M-GSP
in image processing and introduce several applications, including RGB image
compression, edge detection and hyperspectral image segmentation. Successful
experimental results demonstrate the efficacy and promising futures of M-GSP in
image processing.
","Songyang Zhang, Qinwen Deng, Zhi Ding",Zhi Ding,2021-08-31T06:41:56Z
"Implicit Neural Representation Learning for Hyperspectral Image
  Super-Resolution","  Hyperspectral image (HSI) super-resolution without additional auxiliary image
remains a constant challenge due to its high-dimensional spectral patterns,
where learning an effective spatial and spectral representation is a
fundamental issue. Recently, Implicit Neural Representations (INRs) are making
strides as a novel and effective representation, especially in the
reconstruction task. Therefore, in this work, we propose a novel HSI
reconstruction model based on INR which represents HSI by a continuous function
mapping a spatial coordinate to its corresponding spectral radiance values. In
particular, as a specific implementation of INR, the parameters of parametric
model are predicted by a hypernetwork that operates on feature extraction using
convolution network. It makes the continuous functions map the spatial
coordinates to pixel values in a content-aware manner. Moreover, periodic
spatial encoding are deeply integrated with the reconstruction procedure, which
makes our model capable of recovering more high frequency details. To verify
the efficacy of our model, we conduct experiments on three HSI datasets (CAVE,
NUS, and NTIRE2018). Experimental results show that the proposed model can
achieve competitive reconstruction performance in comparison with the
state-of-the-art methods. In addition, we provide an ablation study on the
effect of individual components of our model. We hope this paper could server
as a potent reference for future research.
",Kaiwei Zhang,Kaiwei Zhang,2021-12-20T14:07:54Z
"Projected Sliced Wasserstein Autoencoder-based Hyperspectral Images
  Anomaly Detection","  Anomaly detection (AD) has been an active research area in various domains.
Yet, the increasing data scale, complexity, and dimension turn the traditional
methods into challenging. Recently, the deep generative model, such as the
variational autoencoder (VAE), has sparked a renewed interest in the AD
problem. However, the probability distribution divergence used as the
regularization is too strong, which causes the model cannot capture the
manifold of the true data. In this paper, we propose the Projected Sliced
Wasserstein (PSW) autoencoder-based anomaly detection method. Rooted in the
optimal transportation, the PSW distance is a weaker distribution measure
compared with $f$-divergence. In particular, the computation-friendly
eigen-decomposition method is leveraged to find the principal component for
slicing the high-dimensional data. In this case, the Wasserstein distance can
be calculated with the closed-form, even the prior distribution is not
Gaussian. Comprehensive experiments conducted on various real-world
hyperspectral anomaly detection benchmarks demonstrate the superior performance
of the proposed method.
","Yurong Chen, Hui Zhang, Yaonan Wang, Q. M. Jonathan Wu, Yimin Yang",Yimin Yang,2021-12-20T09:21:02Z
"Hyperspectral nanoscale mapping of hybrid perovskite photophysics at the
  single grain level","  Hybrid organic-inorganic perovskites have drawn significant interest for
applications in optoelectronics over the last few years. Despite rapid progress
in understanding the photophysics of perovskite, there remains a need for
improved understanding of the effect of microstructure on perovskite
photophysical processes. Here, we combine unsupervised machine learning and
cathodoluminescence microscopy of a prototypical hybrid perovskite film to
decode photophysical processes that are otherwise lost with conventional
Gaussian image processing. Hyperspectral maps are decoded with non-negative
matrix factorization, revealing components relating to primary band-edge
emission, photon recycling, and defect emission. A blind-spectral non-negative
matrix factorization procedure provides additional understanding of changes in
an intermediate perovskite phase under electron beam exposure and illustrates
how traditional Gaussian techniques may hide relevant emission features that
are critical to the development of environmentally robust perovskite devices
","Ethan J. Taylor, Vasudevan Iyer, Bibek S. Dhami, Clay Klein, Benjamin J. Lawrie, Kannatassen Appavoo",Kannatassen Appavoo,2022-01-17T17:51:11Z
"SRL-SOA: Self-Representation Learning with Sparse 1D-Operational
  Autoencoder for Hyperspectral Image Band Selection","  The band selection in the hyperspectral image (HSI) data processing is an
important task considering its effect on the computational complexity and
accuracy. In this work, we propose a novel framework for the band selection
problem: Self-Representation Learning (SRL) with Sparse 1D-Operational
Autoencoder (SOA). The proposed SLR-SOA approach introduces a novel autoencoder
model, SOA, that is designed to learn a representation domain where the data
are sparsely represented. Moreover, the network composes of 1D-operational
layers with the non-linear neuron model. Hence, the learning capability of
neurons (filters) is greatly improved with shallow architectures. Using compact
architectures is especially crucial in autoencoders as they tend to overfit
easily because of their identity mapping objective. Overall, we show that the
proposed SRL-SOA band selection approach outperforms the competing methods over
two HSI data including Indian Pines and Salinas-A considering the achieved land
cover classification accuracies. The software implementation of the SRL-SOA
approach is shared publicly at https://github.com/meteahishali/SRL-SOA.
","Mete Ahishali, Serkan Kiranyaz, Iftikhar Ahmad, Moncef Gabbouj",Moncef Gabbouj,2022-02-20T22:17:01Z
"CEU-Net: Ensemble Semantic Segmentation of Hyperspectral Images Using
  Clustering","  Most semantic segmentation approaches of Hyperspectral images (HSIs) use and
require preprocessing steps in the form of patching to accurately classify
diversified land cover in remotely sensed images. These approaches use patching
to incorporate the rich neighborhood information in images and exploit the
simplicity and segmentability of the most common HSI datasets. In contrast,
most landmasses in the world consist of overlapping and diffused classes,
making neighborhood information weaker than what is seen in common HSI
datasets. To combat this issue and generalize the segmentation models to more
complex and diverse HSI datasets, in this work, we propose our novel flagship
model: Clustering Ensemble U-Net (CEU-Net). CEU-Net uses the ensemble method to
combine spectral information extracted from convolutional neural network (CNN)
training on a cluster of landscape pixels. Our CEU-Net model outperforms
existing state-of-the-art HSI semantic segmentation methods and gets
competitive performance with and without patching when compared to baseline
models. We highlight CEU-Net's high performance across Botswana, KSC, and
Salinas datasets compared to HybridSN and AeroRIT methods.
","Nicholas Soucy, Salimeh Yasaei Sekeh",Salimeh Yasaei Sekeh,2022-03-09T16:51:15Z
JigsawHSI: a network for Hyperspectral Image classification,"  This article describes Jigsaw, a convolutional neural network (CNN) used in
geosciences and based on Inception but tailored for geoscientific analyses.
Introduces JigsawHSI (based on Jigsaw) and uses it on the land-use land-cover
(LULC) classification problem with the Indian Pines, Pavia University and
Salinas hyperspectral image data sets. The network is compared against
HybridSN, a spectral-spatial 3D-CNN followed by 2D-CNN that achieves
state-of-the-art results on the datasets. This short article proves that
JigsawHSI is able to meet or exceed HybridSN's performance in all three cases.
Additionally, the use of jigsaw in geosciences is highlighted, while the code
and toolkit are made available.
","Jaime Moraga, H. Sebnem Duzgun",H. Sebnem Duzgun,2022-06-06T02:56:51Z
"Unsupervised multi-branch Capsule for Hyperspectral and LiDAR
  classification","  With the convenient availability of remote sensing data, how to make models
to interpret complex remote sensing data attracts wide attention. In remote
sensing data, hyperspectral images contain spectral information and LiDAR
contains elevation information. Hence, more explorations are warranted to
better fuse the features of different source data. In this paper, we introduce
semantic understanding to dynamically fuse data from two different sources,
extract features of HSI and LiDAR through different capsule network branches
and improve self-supervised loss and random rigid rotation in Canonical Capsule
to a high-dimensional situation. Canonical Capsule computes the capsule
decomposition of objects by permutation-equivariant attention and the process
is self-supervised by training pairs of randomly rotated objects. After fusing
the features of HSI and LiDAR with semantic understanding, the unsupervised
extraction of spectral-spatial-elevation fusion features is achieved. With two
real-world examples of HSI and LiDAR fused, the experimental results show that
the proposed multi-branch high-dimensional canonical capsule algorithm can be
effective for semantic understanding of HSI and LiDAR. It indicates that the
model can extract HSI and LiDAR data features effectively as opposed to
existing models for unsupervised extraction of multi-source RS data.
","Quanfeng Xu, Yi Tang, Yumei She",Yumei She,2022-06-15T07:57:58Z
"Corrosion Monitoring On Zinc Electroplated Steel Using Shortwave
  Infrared Hyperspectral Imaging","  In this study, we investigate the use of hyperspectral imaging (HSI) to
inspect the formation of corrosion products on galvanised carbon steel samples.
Ten samples were subjected to an accelerated corrosion test with different
exposure times. The analysis is performed in a two-step procedure: First, the
different corrosion minerals are identified by microscopic Fourier transform
infrared spectroscopy (FTIR) at specific locations on the samples. The
following corrosion minerals are identified: ZnO (zincite/zinc oxide)
Zn5(OH)8Cl2 H2O (simonkolleite), ZnCO3 (smithsonite), Zn5(CO3)2(OH)6
(marionite/ hydrozincite). Second, the identified corrosion minerals are
correlated with the HSI spectra for these specific locations. This correlation
provides us with the spectra in the SWIR region and allows us to construct a
classification map for the different corrosion minerals. The results show that
we are able to identify the different minerals using HSI camera. This proposed
methodology allows us to speed up the inspection process, compared to FTIR,
while still accurately distinguishing between the different corrosion minerals.
","Thomas De Kerf, Zohreh Zahiri, Paul Scheunders, Steve Vanlanduit",Steve Vanlanduit,2022-06-23T10:05:12Z
Self Supervised Learning for Few Shot Hyperspectral Image Classification,"  Deep learning has proven to be a very effective approach for Hyperspectral
Image (HSI) classification. However, deep neural networks require large
annotated datasets to generalize well. This limits the applicability of deep
learning for HSI classification, where manually labelling thousands of pixels
for every scene is impractical. In this paper, we propose to leverage Self
Supervised Learning (SSL) for HSI classification. We show that by pre-training
an encoder on unlabeled pixels using Barlow-Twins, a state-of-the-art SSL
algorithm, we can obtain accurate models with a handful of labels. Experimental
results demonstrate that this approach significantly outperforms vanilla
supervised learning.
","Nassim Ait Ali Braham, Lichao Mou, Jocelyn Chanussot, Julien Mairal, Xiao Xiang Zhu",Xiao Xiang Zhu,2022-06-24T07:21:53Z
"Automatic inspection of cultural monuments using deep and tensor-based
  learning on hyperspectral imagery","  In Cultural Heritage, hyperspectral images are commonly used since they
provide extended information regarding the optical properties of materials.
Thus, the processing of such high-dimensional data becomes challenging from the
perspective of machine learning techniques to be applied. In this paper, we
propose a Rank-$R$ tensor-based learning model to identify and classify
material defects on Cultural Heritage monuments. In contrast to conventional
deep learning approaches, the proposed high order tensor-based learning
demonstrates greater accuracy and robustness against overfitting. Experimental
results on real-world data from UNESCO protected areas indicate the superiority
of the proposed scheme compared to conventional deep learning models.
","Ioannis N. Tzortzis, Ioannis Rallis, Konstantinos Makantasis, Anastasios Doulamis, Nikolaos Doulamis, Athanasios Voulodimos",Athanasios Voulodimos,2022-07-05T16:38:27Z
"Rank-Enhanced Low-Dimensional Convolution Set for Hyperspectral Image
  Denoising","  This paper tackles the challenging problem of hyperspectral (HS) image
denoising. Unlike existing deep learning-based methods usually adopting
complicated network architectures or empirically stacking off-the-shelf modules
to pursue performance improvement, we focus on the efficient and effective
feature extraction manner for capturing the high-dimensional characteristics of
HS images. To be specific, based on the theoretical analysis that increasing
the rank of the matrix formed by the unfolded convolutional kernels can promote
feature diversity, we propose rank-enhanced low-dimensional convolution set
(Re-ConvSet), which separately performs 1-D convolution along the three
dimensions of an HS image side-by-side, and then aggregates the resulting
spatial-spectral embeddings via a learnable compression layer. Re-ConvSet not
only learns the diverse spatial-spectral features of HS images, but also
reduces the parameters and complexity of the network. We then incorporate
Re-ConvSet into the widely-used U-Net architecture to construct an HS image
denoising method. Surprisingly, we observe such a concise framework outperforms
the most recent method to a large extent in terms of quantitative metrics,
visual results, and efficiency. We believe our work may shed light on deep
learning-based HS image processing and analysis.
","Jinhui Hou, Zhiyu Zhu, Hui Liu, Junhui Hou",Junhui Hou,2022-07-09T13:35:12Z
"Multimodal Image Registration of Raman Spectral Maps in Two Dimensional
  Materials by Strain and Doping Analysis","  It is common to measure a single sample using multiple different microscopy
methods that have variable scales, rotation and translation. Registering
hyperspectral images of two dimensional materials is particularly difficult due
to the lack of keypoints on unprepared substrates. Identifying variations in
the strain of these samples can assist in the registration of these samples by
creating keypoints to correlate images. Registration of these images allow for
multimodal analysis from these various instruments by aligning multiple images
into a single coordinate space. This is done by Hough transformations and
arbitrary resolution definitions to generate a new coordinate frame where
spatial information may be preserved and correlated on a pixel by pixel basis.
Such multimodal image alignment may be used to correlate data from various
instruments. Strain information is extracted from the Raman spectra and the
resulting hyperspectral image is used to register the Raman information with
the other modes of microscopy.
","Kirby Schmidt, Anthony Trofe, Tetyana Ignatova",Tetyana Ignatova,2022-07-09T16:08:45Z
"Graph Spatio-Spectral Total Variation Model for Hyperspectral Image
  Denoising","  The spatio-spectral total variation (SSTV) model has been widely used as an
effective regularization of hyperspectral images (HSI) for various applications
such as mixed noise removal. However, since SSTV computes local spatial
differences uniformly, it is difficult to remove noise while preserving complex
spatial structures with fine edges and textures, especially in situations of
high noise intensity. To solve this problem, we propose a new TV-type
regularization called Graph-SSTV (GSSTV), which generates a graph explicitly
reflecting the spatial structure of the target HSI from noisy HSIs and
incorporates a weighted spatial difference operator designed based on this
graph. Furthermore, we formulate the mixed noise removal problem as a convex
optimization problem involving GSSTV and develop an efficient algorithm based
on the primal-dual splitting method to solve this problem. Finally, we
demonstrate the effectiveness of GSSTV compared with existing HSI
regularization models through experiments on mixed noise removal. The source
code will be available at https://www.mdi.c.titech.ac.jp/publications/gsstv.
","Shingo Takemoto, Kazuki Naganuma, Shunsuke Ono",Shunsuke Ono,2022-07-22T12:46:21Z
"Classifying Crop Types using Gaussian Bayesian Models and Neural
  Networks on GHISACONUS USGS data from NASA Hyperspectral Satellite Imagery","  Hyperspectral Imagining is a type of digital imaging in which each pixel
contains typically hundreds of wavelengths of light providing spectroscopic
information about the materials present in the pixel. In this paper we provide
classification methods for determining crop type in the USGS GHISACONUS data,
which contains around 7,000 pixel spectra from the five major U.S. agricultural
crops (winter wheat, rice, corn, soybeans, and cotton) collected by the NASA
Hyperion satellite, and includes the spectrum, geolocation, crop type, and
stage of growth for each pixel. We apply standard LDA and QDA as well as
Bayesian custom versions that compute the joint probability of crop type and
stage, and then the marginal probability for crop type, outperforming the
non-Bayesian methods. We also test a single layer neural network with dropout
on the data, which performs comparable to LDA and QDA but not as well as the
Bayesian methods.
",Bill Basener,Bill Basener,2022-07-21T14:22:05Z
"Nondestructive Quality Control in Powder Metallurgy using Hyperspectral
  Imaging","  Measuring the purity in the metal powder is critical for preserving the
quality of additive manufacturing products. Contamination is one of the most
headache problems which can be caused by multiple reasons and lead to the
as-built components cracking and malfunctions. Existing methods for
metallurgical condition assessment are mostly time-consuming and mainly focus
on the physical integrity of structure rather than material composition.
Through capturing spectral data from a wide frequency range along with the
spatial information, hyperspectral imaging (HSI) can detect minor differences
in terms of temperature, moisture and chemical composition. Therefore, HSI can
provide a unique way to tackle this challenge. In this paper, with the use of a
near-infrared HSI camera, applications of HSI for the non-destructive
inspection of metal powders are introduced. Technical assumptions and solutions
on three step-by-step case studies are presented in detail, including powder
characterization, contamination detection, and band selection analysis.
Experimental results have fully demonstrated the great potential of HSI and
related AI techniques for NDT of powder metallurgy, especially the potential to
satisfy the industrial manufacturing environment.
","Yijun Yan, Jinchang Ren, He Sun",He Sun,2022-07-26T15:20:35Z
Enhancement of CASSI by a zero-order image employing a single detector,"  Coded aperture snapshot spectral imaging (CASSI) makes it possible to recover
3D hyperspectral data from a single 2D image. However, the reconstruction
problem is severely underdetermined and efforts to improve the compression
ratio typically make the imaging system more complex and cause a significant
loss of incoming light intensity. In this paper, we propose a novel approach to
CASSI which enables capturing both spectrally sheared and integrated image of a
scene with a single camera. We performed hyperspectral imaging of three
different testing scenes in the spectral range of 500-900 nm. We demonstrate
the prominent effect of using the non-diffracted image on the reconstruction of
data from our camera. The use of the spectrally integrated image improves the
reconstruction quality and we observed an approx. fivefold reduction in
reconstruction time.
","Jiri Hlubucek, Jakub Lukes, Jan Vaclavik, Karel Zidek",Karel Zidek,2022-08-02T08:29:34Z
Differential Coded Aperture Single-Snapshot Spectral Imaging,"  We propose a novel concept of differential coded aperture snapshot spectral
imaging (D-CASSI) technique exploiting the benefits of using {-1,+1} random
mask, which is demonstrated by a broadband single-snapshot hyperspectral camera
using compressed sensing. To double the information, we encode the image by two
complementary random masks, which proved to be superior to two independent
patterns. We utilize dispersed and non-dispersed encoded images captured in
parallel onto a single detector. We explored several different approaches to
processing the measured data, which demonstrates significant improvement in
retrieving complex hyperspectral scenes. The experiments were completed by
simulations in order to quantify the reconstruction fidelity. The concept of
differential CASSI could be easily implemented also by multi-snapshot CASSI
without any need for optical system modification.
","Jiri Hlubucek, Jakub Lukes, Jan Vaclavik, Karel Zidek",Karel Zidek,2022-08-02T08:29:55Z
"Learning and predicting photonic responses of plasmonic nanoparticle
  assemblies via dual variational autoencoders","  We demonstrate the application of machine learning for rapid and accurate
extraction of plasmonic particles cluster geometries from hyperspectral image
data via a dual variational autoencoder (dual-VAE). In this approach, the
information is shared between the latent spaces of two VAEs acting on the
particle shape data and spectral data, respectively, but enforcing a common
encoding on the shape-spectra pairs. We show that this approach can establish
the relationship between the geometric characteristics of nanoparticles and
their far-field photonic responses, demonstrating that we can use hyperspectral
darkfield microscopy to accurately predict the geometry (number of particles,
arrangement) of a multiparticle assemblies below the diffraction limit in an
automated fashion with high fidelity (for monomers (0.96), dimers (0.86), and
trimers (0.58). This approach of building structure-property relationships via
shared encoding is universal and should have applications to a broader range of
materials science and physics problems in imaging of both molecular and
nanomaterial systems.
","Muammer Y. Yaman, Sergei V. Kalinin, Kathryn N. Guye, David Ginger, Maxim Ziatdinov",Maxim Ziatdinov,2022-08-08T01:40:52Z
"A Guide to Employ Hyperspectral Imaging for Assessing Wheat Quality at
  Different Stages of Supply Chain in Australia: A Review","  Wheat is one of the major staple crops across the globe. Therefore, it is
mandatory to measure, maintain and improve the wheat quality for human
consumption. Traditional wheat quality measurement methods are mostly invasive,
destructive and limited to small samples of wheat. In a typical supply chain of
wheat, there are many receival points where bulk wheat arrives, gets stored and
forwarded as per the requirements. In this receival points, the application of
traditional quality measurement methods is difficult and often very expensive.
Therefore, there is a need for non-invasive, non-destructive real-time methods
for wheat quality assessments. One such method that fulfils the above-mentioned
criteria is hyperspectral imaging (HSI) for food quality measurement and it can
also be applied to bulk samples. In this paper, we have investigated how HSI
has been used in the literature for assessing stored wheat quality. So that the
required information to implement real-time digital quality assessment methods
at the different stages of Australian supply chain can be made available in a
single and compact document.
","Priyabrata Karmakar, Shyh Wei Teng. Manzur Murshed, Paul Pang, Cuong Van Bui",Cuong Van Bui,2022-09-13T04:30:40Z
"Robust Hyperspectral Image Fusion with Simultaneous Guide Image
  Denoising via Constrained Convex Optimization","  The paper proposes a new high spatial resolution hyperspectral (HR-HS) image
estimation method based on convex optimization. The method assumes a low
spatial resolution HS (LR-HS) image and a guide image as observations, where
both observations are contaminated by noise. Our method simultaneously
estimates an HR-HS image and a noiseless guide image, so the method can utilize
spatial information in a guide image even if it is contaminated by heavy noise.
The proposed estimation problem adopts hybrid spatio-spectral total variation
as regularization and evaluates the edge similarity between HR-HS and guide
images to effectively use apriori knowledge on an HR-HS image and spatial
detail information in a guide image. To efficiently solve the problem, we apply
a primal-dual splitting method. Experiments demonstrate the performance of our
method and the advantage over several existing methods.
","Saori Takeyama, Shunsuke Ono",Shunsuke Ono,2022-09-24T10:58:27Z
Semi-Blind Source Separation with Learned Constraints,"  Blind source separation (BSS) algorithms are unsupervised methods, which are
the cornerstone of hyperspectral data analysis by allowing for physically
meaningful data decompositions. BSS problems being ill-posed, the resolution
requires efficient regularization schemes to better distinguish between the
sources and yield interpretable solutions. For that purpose, we investigate a
semi-supervised source separation approach in which we combine a projected
alternating least-square algorithm with a learning-based regularization scheme.
In this article, we focus on constraining the mixing matrix to belong to a
learned manifold by making use of generative models. Altogether, we show that
this allows for an innovative BSS algorithm, with improved accuracy, which
provides physically interpretable solutions. The proposed method, coined sGMCA,
is tested on realistic hyperspectral astrophysical data in challenging
scenarios involving strong noise, highly correlated spectra and unbalanced
sources. The results highlight the significant benefit of the learned prior to
reduce the leakages between the sources, which allows an overall better
disentanglement.
","Rémi Carloni Gertosio, Jérôme Bobin, Fabio Acero",Fabio Acero,2022-09-27T17:58:23Z
"A Dashboard to Analysis and Synthesis of Dimensionality Reduction
  Methods in Remote Sensing","  Hyperspectral images (HSI) classification is a high technical remote sensing
software. The purpose is to reproduce a thematic map . The HSI contains more
than a hundred hyperspectral measures, as bands (or simply images), of the
concerned region. They are taken at neighbors frequencies. Unfortunately, some
bands are redundant features, others are noisily measured, and the high
dimensionality of features made classification accuracy poor. The problematic
is how to find the good bands to classify the regions items. Some methods use
Mutual Information (MI) and thresholding, to select relevant images, without
processing redundancy. Others control and avoid redundancy. But they process
the dimensionality reduction, some times as selection, other times as wrapper
methods without any relationship . Here , we introduce a survey on all scheme
used, and after critics and improvement, we synthesize a dashboard, that helps
user to analyze an hypothesize features selection and extraction softwares.
","Elkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine",Driss Aboutajdine,2022-10-18T10:42:14Z
"p$^3$VAE: a physics-integrated generative model. Application to the
  pixel-wise classification of airborne hyperspectral images","  The combination of machine learning models with physical models is a recent
research path to learn robust data representations. In this paper, we introduce
p$^3$VAE, a generative model that integrates a physical model which
deterministically models some of the true underlying factors of variation in
the data. To fully leverage our hybrid design, we enhance an existing
semi-supervised optimization technique and introduce a new inference scheme
that comes along meaningful uncertainty estimates. We apply p$^3$VAE to the
pixel-wise classification of airborne hyperspectral images. Our experiments on
simulated and real data demonstrate the benefits of our hybrid model against
conventional machine learning models in terms of extrapolation capabilities and
interpretability. In particular, we show that p$^3$VAE naturally has high
disentanglement capabilities. Our code and data have been made publicly
available at https://github.com/Romain3Ch216/p3VAE.
","Romain Thoreau, Laurent Risser, Véronique Achard, Béatrice Berthelot, Xavier Briottet",Xavier Briottet,2022-10-19T09:32:15Z
"One-Class Risk Estimation for One-Class Hyperspectral Image
  Classification","  Hyperspectral imagery (HSI) one-class classification is aimed at identifying
a single target class from the HSI by using only knowing positive data, which
can significantly reduce the requirements for annotation. However, when
one-class classification meets HSI, it is difficult for classifiers to find a
balance between the overfitting and underfitting of positive data due to the
problems of distribution overlap and distribution imbalance. Although deep
learning-based methods are currently the mainstream to overcome distribution
overlap in HSI multiclassification, few studies focus on deep learning-based
HSI one-class classification. In this article, a weakly supervised deep HSI
one-class classifier, namely, HOneCls, is proposed, where a risk estimator,the
one-class risk estimator, is particularly introduced to make the fully
convolutional neural network (FCN) with the ability of one class classification
in the case of distribution imbalance. Extensive experiments (20 tasks in
total) were conducted to demonstrate the superiority of the proposed
classifier.
","Hengwei Zhao, Yanfei Zhong, Xinyu Wang, Hong Shu",Hong Shu,2022-10-27T14:15:13Z
"Hyperspectral images classification and Dimensionality Reduction using
  Homogeneity feature and mutual information","  The Hyperspectral image (HSI) contains several hundred bands of the same
region called the Ground Truth (GT). The bands are taken in juxtaposed
frequencies, but some of them are noisily measured or contain no information.
For the classification, the selection of bands, affects significantly the
results of classification, in fact, using a subset of relevant bands, these
results can be better than those obtained using all bands, from which the need
to reduce the dimensionality of the HSI. In this paper, a categorization of
dimensionality reduction methods, according to the generation process, is
presented. Furthermore, we reproduce an algorithm based on mutual information
(MI) to reduce dimensionality by features selection and we introduce an
algorithm using mutual information and homogeneity. The two schemas are a
filter strategy. Finally, to validate this, we consider the case study AVIRIS
HSI 92AV3C.
  Keywords: Hyperspectrale images; classification; features selection; mutual
information; homogeneity
","Hasna Nhaila, Maria Merzouqi, Elkebir Sarhrouni, Ahmed Hammouch",Ahmed Hammouch,2022-10-25T23:55:04Z
Improving Hyperspectral Adversarial Robustness Under Multiple Attacks,"  Semantic segmentation models classifying hyperspectral images (HSI) are
vulnerable to adversarial examples. Traditional approaches to adversarial
robustness focus on training or retraining a single network on attacked data,
however, in the presence of multiple attacks these approaches decrease in
performance compared to networks trained individually on each attack. To combat
this issue we propose an Adversarial Discriminator Ensemble Network (ADE-Net)
which focuses on attack type detection and adversarial robustness under a
unified model to preserve per data-type weight optimally while robustifiying
the overall network. In the proposed method, a discriminator network is used to
separate data by attack type into their specific attack-expert ensemble
network.
","Nicholas Soucy, Salimeh Yasaei Sekeh",Salimeh Yasaei Sekeh,2022-10-28T18:21:45Z
"A deep scalable neural architecture for soil properties estimation from
  spectral information","  In this paper we propose an adaptive deep neural architecture for the
prediction of multiple soil characteristics from the analysis of hyperspectral
signatures. The proposed method overcomes the limitations of previous methods
in the state of art: (i) it allows to predict multiple soil variables at once;
(ii) it permits to backtrace the spectral bands that most contribute to the
estimation of a given variable; (iii) it is based on a flexible neural
architecture capable of automatically adapting to the spectral library under
analysis. The proposed architecture is experimented on LUCAS, a large
laboratory dataset and on a dataset achieved by simulating PRISMA hyperspectral
sensor. 'Results, compared with other state-of-the-art methods confirm the
effectiveness of the proposed solution.
","Flavio Piccoli, Micol Rossini, Roberto Colombo, Raimondo Schettini, Paolo Napoletano",Paolo Napoletano,2022-10-26T16:50:06Z
Spatial-Spectral Transformer for Hyperspectral Image Denoising,"  Hyperspectral image (HSI) denoising is a crucial preprocessing procedure for
the subsequent HSI applications. Unfortunately, though witnessing the
development of deep learning in HSI denoising area, existing convolution-based
methods face the trade-off between computational efficiency and capability to
model non-local characteristics of HSI. In this paper, we propose a
Spatial-Spectral Transformer (SST) to alleviate this problem. To fully explore
intrinsic similarity characteristics in both spatial dimension and spectral
dimension, we conduct non-local spatial self-attention and global spectral
self-attention with Transformer architecture. The window-based spatial
self-attention focuses on the spatial similarity beyond the neighboring region.
While, spectral self-attention exploits the long-range dependencies between
highly correlative bands. Experimental results show that our proposed method
outperforms the state-of-the-art HSI denoising methods in quantitative quality
and visual results.
","Miaoyu Li, Ying Fu, Yulun Zhang",Yulun Zhang,2022-11-25T13:18:45Z
"Improved Quasi-Recurrent Neural Network for Hyperspectral Image
  Denoising","  Hyperspectral image is unique and useful for its abundant spectral bands, but
it subsequently requires extra elaborated treatments of the spatial-spectral
correlation as well as the global correlation along the spectrum for building a
robust and powerful HSI restoration algorithm. By considering such HSI
characteristics, 3D Quasi-Recurrent Neural Network (QRNN3D) is one of the HSI
denoising networks that has been shown to achieve excellent performance and
flexibility. In this paper, we show that with a few simple modifications, the
performance of QRNN3D could be substantially improved further. Our
modifications are based on the finding that through QRNN3D is powerful for
modeling spectral correlation, it neglects the proper treatment between
features from different sources and its training strategy is suboptimal. We,
therefore, introduce an adaptive fusion module to replace its vanilla additive
skip connection to better fuse the features of the encoder and decoder. We
additionally identify several important techniques to further enhance the
performance, which includes removing batch normalization, use of extra
frequency loss, and learning rate warm-up. Experimental results on various
noise settings demonstrate the effectiveness and superior performance of our
method.
","Zeqiang Lai, Ying Fu",Ying Fu,2022-11-27T12:38:03Z
"Tuning-free Plug-and-Play Hyperspectral Image Deconvolution with Deep
  Priors","  Deconvolution is a widely used strategy to mitigate the blurring and noisy
degradation of hyperspectral images~(HSI) generated by the acquisition devices.
This issue is usually addressed by solving an ill-posed inverse problem. While
investigating proper image priors can enhance the deconvolution performance, it
is not trivial to handcraft a powerful regularizer and to set the
regularization parameters. To address these issues, in this paper we introduce
a tuning-free Plug-and-Play (PnP) algorithm for HSI deconvolution.
Specifically, we use the alternating direction method of multipliers (ADMM) to
decompose the optimization problem into two iterative sub-problems. A flexible
blind 3D denoising network (B3DDN) is designed to learn deep priors and to
solve the denoising sub-problem with different noise levels. A measure of 3D
residual whiteness is then investigated to adjust the penalty parameters when
solving the quadratic sub-problems, as well as a stopping criterion.
Experimental results on both simulated and real-world data with ground-truth
demonstrate the superiority of the proposed method.
","Xiuheng Wang, Jie Chen, Cédric Richard",Cédric Richard,2022-11-28T13:41:14Z
"Detecting Methane Plumes using PRISMA: Deep Learning Model and Data
  Augmentation","  The new generation of hyperspectral imagers, such as PRISMA, has improved
significantly our detection capability of methane (CH4) plumes from space at
high spatial resolution (30m). We present here a complete framework to identify
CH4 plumes using images from the PRISMA satellite mission and a deep learning
model able to detect plumes over large areas. To compensate for the relative
scarcity of PRISMA images, we trained our model by transposing high resolution
plumes from Sentinel-2 to PRISMA. Our methodology thus avoids computationally
expensive synthetic plume generation from Large Eddy Simulations by generating
a broad and realistic training database, and paves the way for large-scale
detection of methane plumes using future hyperspectral sensors (EnMAP, EMIT,
CarbonMapper).
","Alexis Groshenry, Clement Giron, Thomas Lauvaux, Alexandre d'Aspremont, Thibaud Ehret",Thibaud Ehret,2022-11-17T17:36:05Z
"Monolayer-to-mesoscale modulation of the optical properties in 2D CrI3
  mapped by hyperspectral microscopy","  Magnetic 2D materials hold promise to change the miniaturization paradigm of
unidirectional photonic components. However, the integration of these materials
in devices hinges on the accurate determination of the optical properties down
to the monolayer limit, which is still missing. By using hyperspectral
wide-field imaging we reveal a non-monotonic thickness dependence of the
complex optical dielectric function in the archetypal magnetic 2D material CrI3
extending across different length scales: onsetting at the mesoscale, peaking
at the nanoscale and decreasing again down to the single layer. These results
portray a modification of the electronic properties of the material and align
with the layer-dependent magnetism in CrI3, shedding light into the
long-standing structural conundrum in this material. The unique modulation of
the complex dielectric function from the monolayer up to more than 100 layers
will be instrumental for understanding and manipulating the magneto-optical
effects of magnetic 2D materials.
","Marta Galbiati, Fernando Ramiro-Manzano, José Joaquín Pérez Grau, Fernando Cantos-Prieto, Jaume Meseguer-Sanchez, Ivona Košić, Filippo Mione, Ana Pallarés Vilar, Andrés Cantarero, David Soriano, Efrén Navarro-Moratalla",Efrén Navarro-Moratalla,2023-01-03T08:37:27Z
"A Simple Adaptive Unfolding Network for Hyperspectral Image
  Reconstruction","  We present a simple, efficient, and scalable unfolding network, SAUNet, to
simplify the network design with an adaptive alternate optimization framework
for hyperspectral image (HSI) reconstruction. SAUNet customizes a Residual
Adaptive ADMM Framework (R2ADMM) to connect each stage of the network via a
group of learnable parameters to promote the usage of mask prior, which greatly
stabilizes training and solves the accuracy degradation issue. Additionally, we
introduce a simple convolutional modulation block (CMB), which leads to
efficient training, easy scale-up, and less computation. Coupling these two
designs, SAUNet can be scaled to non-trivial 13 stages with continuous
improvement. Without bells and whistles, SAUNet improves both performance and
speed compared with the previous state-of-the-art counterparts, which makes it
feasible for practical high-resolution HSI reconstruction scenarios. We set new
records on CAVE and KAIST HSI reconstruction benchmarks. Code and models are
available at https://github.com/hustvl/SAUNet.
","Junyu Wang, Shijie Wang, Wenyu Liu, Zengqiang Zheng, Xinggang Wang",Xinggang Wang,2023-01-24T18:28:21Z
"A2S-NAS: Asymmetric Spectral-Spatial Neural Architecture Search For
  Hyperspectral Image Classification","  Existing deep learning-based hyperspectral image (HSI) classification works
still suffer from the limitation of the fixed-sized receptive field, leading to
difficulties in distinctive spectral-spatial features for ground objects with
various sizes and arbitrary shapes. Meanwhile, plenty of previous works ignore
asymmetric spectral-spatial dimensions in HSI. To address the above issues, we
propose a multi-stage search architecture in order to overcome asymmetric
spectral-spatial dimensions and capture significant features. First, the
asymmetric pooling on the spectral-spatial dimension maximally retains the
essential features of HSI. Then, the 3D convolution with a selectable range of
receptive fields overcomes the constraints of fixed-sized convolution kernels.
Finally, we extend these two searchable operations to different layers of each
stage to build the final architecture. Extensive experiments are conducted on
two challenging HSI benchmarks including Indian Pines and Houston University,
and results demonstrate the effectiveness of the proposed method with superior
performance compared with the related works.
","Lin Zhan, Jiayuan Fan, Peng Ye, Jianjian Cao",Jianjian Cao,2023-02-23T09:15:14Z
"3D wind field profiles from hyperspectral sounders: revisiting
  optic-flow from a meteorological perspective","  In this work, we present an efficient optic flow algorithm for the extraction
of vertically resolved 3D atmospheric motion vector (AMV) fields from
incomplete hyperspectral image data measures by infrared sounders. The model at
the heart of the energy to be minimized is consistent with atmospheric
dynamics, incorporating ingredients of thermodynamics, hydrostatic equilibrium
and statistical turbulence. Modern optimization techniques are deployed to
design a low-complexity solver for the energy minimization problem, which is
non-convex, non-differentiable, high-dimensional and subject to physical
constraints. In particular, taking advantage of the alternate direction of
multipliers methods (ADMM), we show how to split the original high-dimensional
problem into a recursion involving a set of standard and tractable optic-flow
sub-problems. By comparing with the ground truth provided by the operational
numerical simulation of the European Centre for Medium-Range Weather Forecasts
(ECMWF), we show that the performance of the proposed method is superior to
state-of-the-art optical flow algorithms in the context of real infrared
atmospheric sounding interferometer (IASI) observations.
","P. Héas, O. Hautecoeur, R. Borde",R. Borde,2023-03-09T10:14:25Z
"Spectral Enhanced Rectangle Transformer for Hyperspectral Image
  Denoising","  Denoising is a crucial step for hyperspectral image (HSI) applications.
Though witnessing the great power of deep learning, existing HSI denoising
methods suffer from limitations in capturing the non-local self-similarity.
Transformers have shown potential in capturing long-range dependencies, but few
attempts have been made with specifically designed Transformer to model the
spatial and spectral correlation in HSIs. In this paper, we address these
issues by proposing a spectral enhanced rectangle Transformer, driving it to
explore the non-local spatial similarity and global spectral low-rank property
of HSIs. For the former, we exploit the rectangle self-attention horizontally
and vertically to capture the non-local similarity in the spatial domain. For
the latter, we design a spectral enhancement module that is capable of
extracting global underlying low-rank property of spatial-spectral cubes to
suppress noise, while enabling the interactions among non-overlapping spatial
rectangles. Extensive experiments have been conducted on both synthetic noisy
HSIs and real noisy HSIs, showing the effectiveness of our proposed method in
terms of both objective metric and subjective visual quality. The code is
available at https://github.com/MyuLi/SERT.
","Miaoyu Li, Ji Liu, Ying Fu, Yulun Zhang, Dejing Dou",Dejing Dou,2023-04-03T09:42:13Z
"DCN-T: Dual Context Network with Transformer for Hyperspectral Image
  Classification","  Hyperspectral image (HSI) classification is challenging due to spatial
variability caused by complex imaging conditions. Prior methods suffer from
limited representation ability, as they train specially designed networks from
scratch on limited annotated data. We propose a tri-spectral image generation
pipeline that transforms HSI into high-quality tri-spectral images, enabling
the use of off-the-shelf ImageNet pretrained backbone networks for feature
extraction. Motivated by the observation that there are many homogeneous areas
with distinguished semantic and geometric properties in HSIs, which can be used
to extract useful contexts, we propose an end-to-end segmentation network named
DCN-T. It adopts transformers to effectively encode regional adaptation and
global aggregation spatial contexts within and between the homogeneous areas
discovered by similarity-based clustering. To fully exploit the rich spectrums
of the HSI, we adopt an ensemble approach where all segmentation results of the
tri-spectral images are integrated into the final prediction through a voting
scheme. Extensive experiments on three public benchmarks show that our proposed
method outperforms state-of-the-art methods for HSI classification.
","Di Wang, Jing Zhang, Bo Du, Liangpei Zhang, Dacheng Tao",Dacheng Tao,2023-04-19T18:32:52Z
"H2TF for Hyperspectral Image Denoising: Where Hierarchical Nonlinear
  Transform Meets Hierarchical Matrix Factorization","  Recently, tensor singular value decomposition (t-SVD) has emerged as a
promising tool for hyperspectral image (HSI) processing. In the t-SVD, there
are two key building blocks: (i) the low-rank enhanced transform and (ii) the
accompanying low-rank characterization of transformed frontal slices. Previous
t-SVD methods mainly focus on the developments of (i), while neglecting the
other important aspect, i.e., the exact characterization of transformed frontal
slices. In this letter, we exploit the potentiality in both building blocks by
leveraging the \underline{\bf H}ierarchical nonlinear transform and the
\underline{\bf H}ierarchical matrix factorization to establish a new
\underline{\bf T}ensor \underline{\bf F}actorization (termed as H2TF). Compared
to shallow counter partners, e.g., low-rank matrix factorization or its convex
surrogates, H2TF can better capture complex structures of transformed frontal
slices due to its hierarchical modeling abilities. We then suggest the
H2TF-based HSI denoising model and develop an alternating direction method of
multipliers-based algorithm to address the resultant model. Extensive
experiments validate the superiority of our method over state-of-the-art HSI
denoising methods.
","Jiayi Li, Jinyu Xie, Yisi Luo, Xile Zhao, Jianli Wang",Jianli Wang,2023-04-21T17:27:43Z
"Deep Learning Techniques for Hyperspectral Image Analysis in
  Agriculture: A Review","  In the recent years, hyperspectral imaging (HSI) has gained considerably
popularity among computer vision researchers for its potential in solving
remote sensing problems, especially in agriculture field. However, HSI
classification is a complex task due to the high redundancy of spectral bands,
limited training samples, and non-linear relationship between spatial position
and spectral bands. Fortunately, deep learning techniques have shown promising
results in HSI analysis. This literature review explores recent applications of
deep learning approaches such as Autoencoders, Convolutional Neural Networks
(1D, 2D, and 3D), Recurrent Neural Networks, Deep Belief Networks, and
Generative Adversarial Networks in agriculture. The performance of these
approaches has been evaluated and discussed on well-known land cover datasets
including Indian Pines, Salinas Valley, and Pavia University.
","Mohamed Fadhlallah Guerri, Cosimo Distante, Paolo Spagnolo, Fares Bougourzi, Abdelmalik Taleb-Ahmed",Abdelmalik Taleb-Ahmed,2023-04-26T23:58:18Z
"Sharpend Cosine Similarity based Neural Network for Hyperspectral Image
  Classification","  Hyperspectral Image Classification (HSIC) is a difficult task due to high
inter and intra-class similarity and variability, nested regions, and
overlapping. 2D Convolutional Neural Networks (CNN) emerged as a viable network
whereas, 3D CNNs are a better alternative due to accurate classification.
However, 3D CNNs are highly computationally complex due to their volume and
spectral dimensions. Moreover, down-sampling and hierarchical filtering (high
frequency) i.e., texture features need to be smoothed during the forward pass
which is crucial for accurate HSIC. Furthermore, CNN requires tons of tuning
parameters which increases the training time. Therefore, to overcome the
aforesaid issues, Sharpened Cosine Similarity (SCS) concept as an alternative
to convolutions in a Neural Network for HSIC is introduced. SCS is
exceptionally parameter efficient due to skipping the non-linear activation
layers, normalization, and dropout after the SCS layer. Use of MaxAbsPool
instead of MaxPool which selects the element with the highest magnitude of
activity, even if it's negative. Experimental results on publicly available HSI
datasets proved the performance of SCS as compared to the convolutions in
Neural Networks.
",Muhammad Ahmad,Muhammad Ahmad,2023-05-26T07:04:00Z
"Hyperspectral Target Detection Based on Low-Rank Background Subspace
  Learning and Graph Laplacian Regularization","  Hyperspectral target detection is good at finding dim and small objects based
on spectral characteristics. However, existing representation-based methods are
hindered by the problem of the unknown background dictionary and insufficient
utilization of spatial information. To address these issues, this paper
proposes an efficient optimizing approach based on low-rank representation
(LRR) and graph Laplacian regularization (GLR). Firstly, to obtain a complete
and pure background dictionary, we propose a LRR-based background subspace
learning method by jointly mining the low-dimensional structure of all pixels.
Secondly, to fully exploit local spatial relationships and capture the
underlying geometric structure, a local region-based GLR is employed to
estimate the coefficients. Finally, the desired detection map is generated by
computing the ratio of representation errors from binary hypothesis testing.
The experiments conducted on two benchmark datasets validate the effectiveness
and superiority of the approach. For reproduction, the accompanying code is
available at https://github.com/shendb2022/LRBSL-GLR.
","Dunbin Shen, Xiaorui Ma, Wenfeng Kong, Jiacheng Tian, Hongyu Wang",Hongyu Wang,2023-06-01T13:51:08Z
"An Optimization-based Deep Equilibrium Model for Hyperspectral Image
  Deconvolution with Convergence Guarantees","  In this paper, we propose a novel methodology for addressing the
hyperspectral image deconvolution problem. This problem is highly ill-posed,
and thus, requires proper priors (regularizers) to model the inherent
spectral-spatial correlations of the HSI signals. To this end, a new
optimization problem is formulated, leveraging a learnable regularizer in the
form of a neural network. To tackle this problem, an effective solver is
proposed using the half quadratic splitting methodology. The derived iterative
solver is then expressed as a fixed-point calculation problem within the Deep
Equilibrium (DEQ) framework, resulting in an interpretable architecture, with
clear explainability to its parameters and convergence properties with
practical benefits. The proposed model is a first attempt to handle the
classical HSI degradation problem with different blurring kernels and noise
levels via a single deep equilibrium model with significant computational
efficiency. Extensive numerical experiments validate the superiority of the
proposed methodology over other state-of-the-art methods. This superior
restoration performance is achieved while requiring 99.85\% less computation
time as compared to existing methods.
","Alexandros Gkillas, Dimitris Ampeliotis, Kostas Berberidis",Kostas Berberidis,2023-06-10T08:25:16Z
"Self-Supervised Hyperspectral Inpainting with the Optimisation inspired
  Deep Neural Network Prior","  Hyperspectral Image (HSI)s cover hundreds or thousands of narrow spectral
bands, conveying a wealth of spatial and spectral information. However, due to
the instrumental errors and the atmospheric changes, the HSI obtained in
practice are often contaminated by noise and dead pixels(lines), resulting in
missing information that may severely compromise the subsequent applications.
We introduce here a novel HSI missing pixel prediction algorithm, called Low
Rank and Sparsity Constraint Plug-and-Play (LRS-PnP). It is shown that LRS-PnP
is able to predict missing pixels and bands even when all spectral bands of the
image are missing. The proposed LRS-PnP algorithm is further extended to a
self-supervised model by combining the LRS-PnP with the Deep Image Prior (DIP),
called LRS-PnP-DIP. In a series of experiments with real data, It is shown that
the LRS-PnP-DIP either achieves state-of-the-art inpainting performance
compared to other learning-based methods, or outperforms them.
","Shuo Li, Mehrdad Yaghoobi",Mehrdad Yaghoobi,2023-06-12T13:48:37Z
"HSR-Diff:Hyperspectral Image Super-Resolution via Conditional Diffusion
  Models","  Despite the proven significance of hyperspectral images (HSIs) in performing
various computer vision tasks, its potential is adversely affected by the
low-resolution (LR) property in the spatial domain, resulting from multiple
physical factors. Inspired by recent advancements in deep generative models, we
propose an HSI Super-resolution (SR) approach with Conditional Diffusion Models
(HSR-Diff) that merges a high-resolution (HR) multispectral image (MSI) with
the corresponding LR-HSI. HSR-Diff generates an HR-HSI via repeated refinement,
in which the HR-HSI is initialized with pure Gaussian noise and iteratively
refined. At each iteration, the noise is removed with a Conditional Denoising
Transformer (CDF ormer) that is trained on denoising at different noise levels,
conditioned on the hierarchical feature maps of HR-MSI and LR-HSI. In addition,
a progressive learning strategy is employed to exploit the global information
of full-resolution images. Systematic experiments have been conducted on four
public datasets, demonstrating that HSR-Diff outperforms state-of-the-art
methods.
","Chanyue Wu, Dong Wang, Hanyu Mao, Ying Li",Ying Li,2023-06-21T08:04:30Z
Neural Spectro-polarimetric Fields,"  Modeling the spatial radiance distribution of light rays in a scene has been
extensively explored for applications, including view synthesis. Spectrum and
polarization, the wave properties of light, are often neglected due to their
integration into three RGB spectral bands and their non-perceptibility to human
vision. However, these properties are known to encompass substantial material
and geometric information about a scene. Here, we propose to model
spectro-polarimetric fields, the spatial Stokes-vector distribution of any
light ray at an arbitrary wavelength. We present Neural Spectro-polarimetric
Fields (NeSpoF), a neural representation that models the physically-valid
Stokes vector at given continuous variables of position, direction, and
wavelength. NeSpoF manages inherently noisy raw measurements, showcases memory
efficiency, and preserves physically vital signals - factors that are crucial
for representing the high-dimensional signal of a spectro-polarimetric field.
To validate NeSpoF, we introduce the first multi-view
hyperspectral-polarimetric image dataset, comprised of both synthetic and
real-world scenes. These were captured using our compact
hyperspectral-polarimetric imaging system, which has been calibrated for
robustness against system imperfections. We demonstrate the capabilities of
NeSpoF on diverse scenes.
","Youngchan Kim, Wonjoon Jin, Sunghyun Cho, Seung-Hwan Baek",Seung-Hwan Baek,2023-06-21T21:00:46Z
"Forward-Forward Algorithm for Hyperspectral Image Classification: A
  Preliminary Study","  The back-propagation algorithm has long been the de-facto standard in
optimizing weights and biases in neural networks, particularly in cutting-edge
deep learning models. Its widespread adoption in fields like natural language
processing, computer vision, and remote sensing has revolutionized automation
in various tasks. The popularity of back-propagation stems from its ability to
achieve outstanding performance in tasks such as classification, detection, and
segmentation. Nevertheless, back-propagation is not without its limitations,
encompassing sensitivity to initial conditions, vanishing gradients,
overfitting, and computational complexity. The recent introduction of a
forward-forward algorithm (FFA), which computes local goodness functions to
optimize network parameters, alleviates the dependence on substantial
computational resources and the constant need for architectural scaling. This
study investigates the application of FFA for hyperspectral image
classification. Experimental results and comparative analysis are provided with
the use of the traditional back-propagation algorithm. Preliminary results show
the potential behind FFA and its promises.
","Sidike Paheding, Abel A. Reyes-Angulo",Abel A. Reyes-Angulo,2023-07-01T05:39:28Z
"Space Object Identification and Classification from Hyperspectral
  Material Analysis","  This paper presents a data processing pipeline designed to extract
information from the hyperspectral signature of unknown space objects. The
methodology proposed in this paper determines the material composition of space
objects from single pixel images. Two techniques are used for material
identification and classification: one based on machine learning and the other
based on a least square match with a library of known spectra. From this
information, a supervised machine learning algorithm is used to classify the
object into one of several categories based on the detection of materials on
the object. The behaviour of the material classification methods is
investigated under non-ideal circumstances, to determine the effect of
weathered materials, and the behaviour when the training library is missing a
material that is present in the object being observed. Finally the paper will
present some preliminary results on the identification and classification of
space objects.
","Massimiliano Vasile, Lewis Walker, Andrew Campbell, Simao Marto, Paul Murray, Stephen Marshall, Vasili Savitski",Vasili Savitski,2023-08-14T22:21:24Z
"Reproducing Kernel Hilbert Space Pruning for Sparse Hyperspectral
  Abundance Prediction","  Hyperspectral measurements from long range sensors can give a detailed
picture of the items, materials, and chemicals in a scene but analysis can be
difficult, slow, and expensive due to high spatial and spectral resolutions of
state-of-the-art sensors. As such, sparsity is important to enable the future
of spectral compression and analytics. It has been observed that environmental
and atmospheric effects, including scattering, can produce nonlinear effects
posing challenges for existing source separation and compression methods. We
present a novel transformation into Hilbert spaces for pruning and constructing
sparse representations via non-negative least squares minimization. Then we
introduce max likelihood compression vectors to decrease information loss. Our
approach is benchmarked against standard pruning and least squares as well as
deep learning methods. Our methods are evaluated in terms of overall spectral
reconstruction error and compression rate using real and synthetic data. We
find that pruning least squares methods converge quickly unlike matching
pursuit methods. We find that Hilbert space pruning can reduce error by as much
as 40% of the error of standard pruning and also outperform neural network
autoencoders.
","Michael G. Rawson, Timothy Doster",Timothy Doster,2023-08-16T19:59:25Z
"Image Processing and Machine Learning for Hyperspectral Unmixing: An
  Overview and the HySUPP Python Package","  Spectral pixels are often a mixture of the pure spectra of the materials,
called endmembers, due to the low spatial resolution of hyperspectral sensors,
double scattering, and intimate mixtures of materials in the scenes. Unmixing
estimates the fractional abundances of the endmembers within the pixel.
Depending on the prior knowledge of endmembers, linear unmixing can be divided
into three main groups: supervised, semi-supervised, and unsupervised (blind)
linear unmixing. Advances in Image processing and machine learning
substantially affected unmixing. This paper provides an overview of advanced
and conventional unmixing approaches. Additionally, we draw a critical
comparison between advanced and conventional techniques from the three
categories. We compare the performance of the unmixing techniques on three
simulated and two real datasets. The experimental results reveal the advantages
of different unmixing categories for different unmixing scenarios. Moreover, we
provide an open-source Python-based package available at
https://github.com/BehnoodRasti/HySUPP to reproduce the results.
","Behnood Rasti, Alexandre Zouaoui, Julien Mairal, Jocelyn Chanussot",Jocelyn Chanussot,2023-08-18T08:10:41Z
"Class Prior-Free Positive-Unlabeled Learning with Taylor Variational
  Loss for Hyperspectral Remote Sensing Imagery","  Positive-unlabeled learning (PU learning) in hyperspectral remote sensing
imagery (HSI) is aimed at learning a binary classifier from positive and
unlabeled data, which has broad prospects in various earth vision applications.
However, when PU learning meets limited labeled HSI, the unlabeled data may
dominate the optimization process, which makes the neural networks overfit the
unlabeled data. In this paper, a Taylor variational loss is proposed for HSI PU
learning, which reduces the weight of the gradient of the unlabeled data by
Taylor series expansion to enable the network to find a balance between
overfitting and underfitting. In addition, the self-calibrated optimization
strategy is designed to stabilize the training process. Experiments on 7
benchmark datasets (21 tasks in total) validate the effectiveness of the
proposed method. Code is at: https://github.com/Hengwei-Zhao96/T-HOneCls.
","Hengwei Zhao, Xinyu Wang, Jingtao Li, Yanfei Zhong",Yanfei Zhong,2023-08-29T07:29:30Z
"Spectro-spatial hyperspectral image reconstruction from interferometric
  acquisitions","  In the last decade, novel hyperspectral cameras have been developed with
particularly desirable characteristics of compactness and short acquisition
time, retaining their potential to obtain spectral/spatial resolution
competitive with respect to traditional cameras. However, a computational
effort is required to recover an interpretable data cube. In this work we focus
our attention on imaging spectrometers based on interferometry, for which the
raw acquisition is an image whose spectral component is expressed as an
interferogram. Previous works have focused on the inversion of such acquisition
on a pixel-by-pixel basis within a Bayesian framework, leaving behind critical
information on the spatial structure of the image data cube. In this work, we
address this problem by integrating a spatial regularization for image
reconstruction, showing that the combination of spectral and spatial
regularizers leads to enhanced performances with respect to the pixelwise case.
We compare our results with Plug-and-Play techniques, as its strategy to inject
a set of denoisers from the literature can be implemented seamlessly with our
physics-based formulation of the optimization problem.
","Daniele Picone, Mohamad Jouni, Mauro Dalla-Mura",Mauro Dalla-Mura,2023-10-03T09:15:19Z
"Deep Learning for EELS hyperspectral images unmixing -- using
  autoencoders","  Spatially resolved Electron Energy-Loss Spectroscopy (EELS) conducted in a
Scanning Transmission Electron Microscope (STEM) enables the acquisition of
hyperspectral images (HSIs). Spectral unmixing (SU) is the process of
decomposing each spectrum of an HSI into a combination of representative
spectra (endmembers) corresponding to compounds present in the sample along
with their local proportions (abundances). SU is a complex task, and various
methods have been developed in different communities using HSIs. However, none
of these methods fully satisfy the STEM-EELS requirements. Recent advancements
in remote sensing, which focus on Deep Learning techniques, have the potential
to meet these requirements, particularly Autoencoders (AEs). In this study, the
performance of Deep Learning methods using AE for SU is evaluated, and their
results are compared with traditional methods. Synthetic HSIs have been created
to quantitatively assess the outcomes of the unmixing process using specific
metrics. The methods are subsequently applied to a series of experimental data.
The findings demonstrate the promising potential of AE as a tool for STEM-EELS
SU, marking a starting point for exploring more sophisticated Neural Networks.
","N. Brun, G. Lambert, L. Bocher",L. Bocher,2023-10-12T13:09:08Z
"Hyperspectral Image Fusion via Logarithmic Low-rank Tensor Ring
  Decomposition","  Integrating a low-spatial-resolution hyperspectral image (LR-HSI) with a
high-spatial-resolution multispectral image (HR-MSI) is recognized as a valid
method for acquiring HR-HSI. Among the current fusion approaches, the tensor
ring (TR) decomposition-based method has received growing attention owing to
its superior performance on preserving the spatial-spectral correlation.
Furthermore, the low-rank property in some TR factors has been exploited via
the matrix nuclear norm regularization along mode-2. On the other hand, the
tensor nuclear norm (TNN)-based approaches have recently demonstrated to be
more efficient on keeping high-dimensional low-rank structures in tensor
recovery. Here, we study the low-rankness of TR factors from the TNN
perspective and consider the mode-2 logarithmic TNN (LTNN) on each TR factor. A
novel fusion model is proposed by incorporating this LTNN regularization and
the weighted total variation which is to promote the continuity of HR-HSI in
the spatial-spectral domain. Meanwhile, we have devised a highly efficient
proximal alternating minimization algorithm to solve the proposed model. The
experimental results indicate that our method improves the visual quality and
exceeds the existing state-of-the-art fusion approaches with respect to various
quantitative metrics.
","Jun Zhang, Lipeng Zhu, Chao Wang, Shutao Li",Shutao Li,2023-10-16T04:02:34Z
A Spectral Diffusion Prior for Hyperspectral Image Super-Resolution,"  Fusion-based hyperspectral image (HSI) super-resolution aims to produce a
high-spatial-resolution HSI by fusing a low-spatial-resolution HSI and a
high-spatial-resolution multispectral image. Such a HSI super-resolution
process can be modeled as an inverse problem, where the prior knowledge is
essential for obtaining the desired solution. Motivated by the success of
diffusion models, we propose a novel spectral diffusion prior for fusion-based
HSI super-resolution. Specifically, we first investigate the spectrum
generation problem and design a spectral diffusion model to model the spectral
data distribution. Then, in the framework of maximum a posteriori, we keep the
transition information between every two neighboring states during the reverse
generative process, and thereby embed the knowledge of trained spectral
diffusion model into the fusion problem in the form of a regularization term.
At last, we treat each generation step of the final optimization problem as its
subproblem, and employ the Adam to solve these subproblems in a reverse
sequence. Experimental results conducted on both synthetic and real datasets
demonstrate the effectiveness of the proposed approach. The code of the
proposed approach will be available on https://github.com/liuofficial/SDP.
","Jianjun Liu, Zebin Wu, Liang Xiao",Liang Xiao,2023-11-15T13:40:58Z
"Physics-driven generative adversarial networks empower single-pixel
  infrared hyperspectral imaging","  A physics-driven generative adversarial network (GAN) was established here
for single-pixel hyperspectral imaging (HSI) in the infrared spectrum, to
eliminate the extensive data training work required by traditional data-driven
model. Within the GAN framework, the physical process of single-pixel imaging
(SPI) was integrated into the generator, and the actual and estimated
one-dimensional (1D) bucket signals were employed as constraints in the
objective function to update the network's parameters and optimize the
generator with the assistance of the discriminator. In comparison to
single-pixel infrared HSI methods based on compressed sensing and
physics-driven convolution neural networks, our physics-driven GAN-based
single-pixel infrared HSI can achieve higher imaging performance but with fewer
measurements. We believe that this physics-driven GAN will promote practical
applications of computational imaging, especially various SPI-based techniques.
","Dong-Yin Wang, Shu-Hang Bie, Xi-Hao Chen, Wen-Kai Yu",Wen-Kai Yu,2023-11-22T17:36:46Z
"Detection and Identification Accuracy of PCA-Accelerated Real-Time
  Processing of Hyperspectral Imagery","  Real-time or near real-time hyperspectral detection and identification are
extremely useful and needed in many fields. These data sets can be quite large,
and the algorithms can require numerous computations that slow the process
down. A common way of speeding up the process is to use principal component
analysis (PCA) for dimension reduction. In the reduced dimensional space,
provided by a subset of the principal components, fewer computations are needed
to process the data resulting in a faster run time. In this paper, we propose a
way to further decrease the time required to use PCA by investigating how many
principal components may be omitted with minimal impact on the detection rate.
Using ACE to perform the detection, and then probability, and spectral fit for
identification, we find that the number of principal components can be reduced
by a substantial amount before seeing a noticeable change in detection rates.
","Abigail Basener, Meagan Herald",Meagan Herald,2023-11-23T02:36:29Z
"Contrastive Multi-view Subspace Clustering of Hyperspectral Images based
  on Graph Convolutional Networks","  High-dimensional and complex spectral structures make the clustering of
hyperspectral images (HSI) a challenging task. Subspace clustering is an
effective approach for addressing this problem. However, current subspace
clustering algorithms are primarily designed for a single view and do not fully
exploit the spatial or textural feature information in HSI. In this study,
contrastive multi-view subspace clustering of HSI was proposed based on graph
convolutional networks. Pixel neighbor textural and spatial-spectral
information were sent to construct two graph convolutional subspaces to learn
their affinity matrices. To maximize the interaction between different views, a
contrastive learning algorithm was introduced to promote the consistency of
positive samples and assist the model in extracting robust features. An
attention-based fusion module was used to adaptively integrate these affinity
matrices, constructing a more discriminative affinity matrix. The model was
evaluated using four popular HSI datasets: Indian Pines, Pavia University,
Houston, and Xu Zhou. It achieved overall accuracies of 97.61%, 96.69%, 87.21%,
and 97.65%, respectively, and significantly outperformed state-of-the-art
clustering methods. In conclusion, the proposed model effectively improves the
clustering accuracy of HSI.
","Renxiang Guan, Zihao Li, Xianju Li, Chang Tang, Ruyi Feng",Ruyi Feng,2023-12-11T02:22:10Z
"Proximal Gradient Descent Unfolding Dense-spatial Spectral-attention
  Transformer for Compressive Spectral Imaging","  The Coded Aperture Snapshot Spectral Compressive Imaging (CASSI) system
modulates three-dimensional hyperspectral images into two-dimensional
compressed images in a single exposure. Subsequently, three-dimensional
hyperspectral images (HSI) can be reconstructed from the two-dimensional
compressed measurements using reconstruction algorithms. Among these methods,
deep unfolding techniques have demonstrated excellent performance, with
RDLUF-MixS^2 achieving the best reconstruction results. However, RDLUF-MixS^2
requires extensive training time, taking approximately 14 days to train
RDLUF-MixS^2-9stg on a single RTX 3090 GPU, making it computationally
expensive. Furthermore, RDLUF-MixS^2 performs poorly on real data, resulting in
significant artifacts in the reconstructed images. In this study, we introduce
the Dense-spatial Spectral-attention Transformer (DST) into the Proximal
Gradient Descent Unfolding Framework (PGDUF), creating a novel approach called
Proximal Gradient Descent Unfolding Dense-spatial Spectral-attention
Transformer (PGDUDST). Compared to RDLUF-MixS^2, PGDUDST not only surpasses the
network reconstruction performance limit of RDLUF-MixS^2 but also achieves
faster convergence. PGDUDST requires only 58% of the training time of
RDLUF-MixS^2-9stg to achieve comparable reconstruction results. Additionally,
PGDUDST significantly alleviates the artifact issues caused by RDLUF-MixS^2 in
real experimental data, demonstrating superior performance and producing
clearer reconstructed images.
","Ziyan Chen, Jing Cheng",Jing Cheng,2023-12-25T05:51:10Z
"Empirical Analysis of Anomaly Detection on Hyperspectral Imaging Using
  Dimension Reduction Methods","  Recent studies try to use hyperspectral imaging (HSI) to detect foreign
matters in products because it enables to visualize the invisible wavelengths
including ultraviolet and infrared. Considering the enormous image channels of
the HSI, several dimension reduction methods-e.g., PCA or UMAP-can be
considered to reduce but those cannot ease the fundamental limitations, as
follows: (1) latency of HSI capturing. (2) less explanation ability of the
important channels. In this paper, to circumvent the aforementioned methods,
one of the ways to channel reduction, on anomaly detection proposed HSI.
Different from feature extraction methods (i.e., PCA or UMAP), feature
selection can sort the feature by impact and show better explainability so we
might redesign the task-optimized and cost-effective spectroscopic camera. Via
the extensive experiment results with synthesized MVTec AD dataset, we confirm
that the feature selection method shows 6.90x faster at the inference phase
compared with feature extraction-based approaches while preserving anomaly
detection performance. Ultimately, we conclude the advantage of feature
selection which is effective yet fast.
","Dongeon Kim, YeongHyeon Park",YeongHyeon Park,2024-01-09T09:05:15Z
"Adaptive Regularized Low-Rank Tensor Decomposition for Hyperspectral
  Image Denoising and Destriping","  Hyperspectral images (HSIs) are inevitably degraded by a mixture of various
types of noise, such as Gaussian noise, impulse noise, stripe noise, and dead
pixels, which greatly limits the subsequent applications. Although various
denoising methods have already been developed, accurately recovering the
spatial-spectral structure of HSIs remains a challenging problem to be
addressed. Furthermore, serious stripe noise, which is common in real HSIs, is
still not fully separated by the previous models. In this paper, we propose an
adaptive hyperLaplacian regularized low-rank tensor decomposition (LRTDAHL)
method for HSI denoising and destriping. On the one hand, the stripe noise is
separately modeled by the tensor decomposition, which can effectively encode
the spatial-spectral correlation of the stripe noise. On the other hand,
adaptive hyper-Laplacian spatial-spectral regularization is introduced to
represent the distribution structure of different HSI gradient data by
adaptively estimating the optimal hyper-Laplacian parameter, which can reduce
the spatial information loss and over-smoothing caused by the previous total
variation regularization. The proposed model is solved using the alternating
direction method of multipliers (ADMM) algorithm. Extensive simulation and
real-data experiments all demonstrate the effectiveness and superiority of the
proposed method.
","Dongyi Li, Dong Chu, Xiaobin Guan, Wei He, Huanfeng Shen",Huanfeng Shen,2024-01-11T06:07:53Z
"Local Background Estimation for Improved Gas Plume Identification in
  Hyperspectral Images","  Deep learning identification models have shown promise for identifying gas
plumes in Longwave IR hyperspectral images of urban scenes, particularly when a
large library of gases are being considered. Because many gases have similar
spectral signatures, it is important to properly estimate the signal from a
detected plume. Typically, a scene's global mean spectrum and covariance matrix
are estimated to whiten the plume's signal, which removes the background's
signature from the gas signature. However, urban scenes can have many different
background materials that are spatially and spectrally heterogeneous. This can
lead to poor identification performance when the global background estimate is
not representative of a given local background material. We use image
segmentation, along with an iterative background estimation algorithm, to
create local estimates for the various background materials that reside
underneath a gas plume. Our method outperforms global background estimation on
a set of simulated and real gas plumes. This method shows promise in increasing
deep learning identification confidence, while being simple and easy to tune
when considering diverse plumes.
","Scout Jarman, Zigfried Hampel-Arias, Adra Carr, Kevin R. Moon",Kevin R. Moon,2024-01-23T19:48:34Z
"A Generalized Multiscale Bundle-Based Hyperspectral Sparse Unmixing
  Algorithm","  In hyperspectral sparse unmixing, a successful approach employs spectral
bundles to address the variability of the endmembers in the spatial domain.
However, the regularization penalties usually employed aggregate substantial
computational complexity, and the solutions are very noise-sensitive. We
generalize a multiscale spatial regularization approach to solve the unmixing
problem by incorporating group sparsity-inducing mixed norms. Then, we propose
a noise-robust method that can take advantage of the bundle structure to deal
with endmember variability while ensuring inter- and intra-class sparsity in
abundance estimation with reasonable computational cost. We also present a
general heuristic to select the \emph{most representative} abundance estimation
over multiple runs of the unmixing process, yielding a solution that is robust
and highly reproducible. Experiments illustrate the robustness and consistency
of the results when compared to related methods.
","Luciano Carvalho Ayres, Ricardo Augusto Borsoi, José Carlos Moreira Bermudez, Sérgio José Melo de Almeida",Sérgio José Melo de Almeida,2024-01-24T00:37:14Z
"Towards Robust Hyperspectral Anomaly Detection: Decomposing Background,
  Anomaly, and Mixed Noise via Convex Optimization","  We propose a novel hyperspectral (HS) anomaly detection method that is robust
to various types of noise. Most of existing HS anomaly detection methods are
designed for cases where a given HS image is noise-free or is contaminated only
by small Gaussian noise. However, in real-world situations, observed HS images
are often degraded by various types of noise, such as sparse noise and stripe
noise, due to sensor failure or calibration errors, significantly affecting the
detection performance. To address this problem, this article establishes a
robust HS anomaly detection method with a mechanism that can properly remove
mixed noise while separating background and anomaly parts. Specifically, we
newly formulate a constrained convex optimization problem to decompose
background and anomaly parts, and three types of noise from a given HS image.
Then, we develop an efficient algorithm based on a preconditioned variant of a
primal-dual splitting method to solve this problem. Through comparison with
existing methods, including state-of-the-art ones, we illustrate that the
proposed method achieves a detection accuracy comparable to state-of-the-art
methods in noise-free cases and is significantly more robust than these methods
in noisy cases.
","Koyo Sato, Shunsuke Ono",Shunsuke Ono,2024-01-26T12:34:29Z
"LUM-ViT: Learnable Under-sampling Mask Vision Transformer for Bandwidth
  Limited Optical Signal Acquisition","  Bandwidth constraints during signal acquisition frequently impede real-time
detection applications. Hyperspectral data is a notable example, whose vast
volume compromises real-time hyperspectral detection. To tackle this hurdle, we
introduce a novel approach leveraging pre-acquisition modulation to reduce the
acquisition volume. This modulation process is governed by a deep learning
model, utilizing prior information. Central to our approach is LUM-ViT, a
Vision Transformer variant. Uniquely, LUM-ViT incorporates a learnable
under-sampling mask tailored for pre-acquisition modulation. To further
optimize for optical calculations, we propose a kernel-level weight
binarization technique and a three-stage fine-tuning strategy. Our evaluations
reveal that, by sampling a mere 10% of the original image pixels, LUM-ViT
maintains the accuracy loss within 1.8% on the ImageNet classification task.
The method sustains near-original accuracy when implemented on real-world
optical hardware, demonstrating its practicality. Code will be available at
https://github.com/MaxLLF/LUM-ViT.
","Lingfeng Liu, Dong Ni, Hangjie Yuan",Hangjie Yuan,2024-03-03T06:49:01Z
"Hyperspectral Image Analysis in Single-Modal and Multimodal setting
  using Deep Learning Techniques","  Hyperspectral imaging provides precise classification for land use and cover
due to its exceptional spectral resolution. However, the challenges of high
dimensionality and limited spatial resolution hinder its effectiveness. This
study addresses these challenges by employing deep learning techniques to
efficiently process, extract features, and classify data in an integrated
manner. To enhance spatial resolution, we integrate information from
complementary modalities such as LiDAR and SAR data through multimodal
learning. Moreover, adversarial learning and knowledge distillation are
utilized to overcome issues stemming from domain disparities and missing
modalities. We also tailor deep learning architectures to suit the unique
characteristics of HSI data, utilizing 1D convolutional and recurrent neural
networks to handle its continuous spectral dimension. Techniques like visual
attention and feedback connections within the architecture bolster the
robustness of feature extraction. Additionally, we tackle the issue of limited
training samples through self-supervised learning methods, employing
autoencoders for dimensionality reduction and exploring semi-supervised
learning techniques that leverage unlabeled data. Our proposed approaches are
evaluated across various HSI datasets, consistently outperforming existing
state-of-the-art techniques.
",Shivam Pande,Shivam Pande,2024-03-03T15:47:43Z
"Superpixel Graph Contrastive Clustering with Semantic-Invariant
  Augmentations for Hyperspectral Images","  Hyperspectral images (HSI) clustering is an important but challenging task.
The state-of-the-art (SOTA) methods usually rely on superpixels, however, they
do not fully utilize the spatial and spectral information in HSI 3-D structure,
and their optimization targets are not clustering-oriented. In this work, we
first use 3-D and 2-D hybrid convolutional neural networks to extract the
high-order spatial and spectral features of HSI through pre-training, and then
design a superpixel graph contrastive clustering (SPGCC) model to learn
discriminative superpixel representations. Reasonable augmented views are
crucial for contrastive clustering, and conventional contrastive learning may
hurt the cluster structure since different samples are pushed away in the
embedding space even if they belong to the same class. In SPGCC, we design two
semantic-invariant data augmentations for HSI superpixels: pixel sampling
augmentation and model weight augmentation. Then sample-level alignment and
clustering-center-level contrast are performed for better intra-class
similarity and inter-class dissimilarity of superpixel embeddings. We perform
clustering and network optimization alternatively. Experimental results on
several HSI datasets verify the advantages of the proposed method, e.g., on
India Pines, our model improves the clustering accuracy from 58.79% to 67.59%
compared to the SOTA method.
","Jianhan Qi, Yuheng Jia, Hui Liu, Junhui Hou",Junhui Hou,2024-03-04T07:40:55Z
"Hyperspectral unmixing for Raman spectroscopy via physics-constrained
  autoencoders","  Raman spectroscopy is widely used across scientific domains to characterize
the chemical composition of samples in a non-destructive, label-free manner.
Many applications entail the unmixing of signals from mixtures of molecular
species to identify the individual components present and their proportions,
yet conventional methods for chemometrics often struggle with complex mixture
scenarios encountered in practice. Here, we develop hyperspectral unmixing
algorithms based on autoencoder neural networks, and we systematically validate
them using both synthetic and experimental benchmark datasets created in-house.
Our results demonstrate that unmixing autoencoders provide improved accuracy,
robustness and efficiency compared to standard unmixing methods. We also
showcase the applicability of autoencoders to complex biological settings by
showing improved biochemical characterization of volumetric Raman imaging data
from a monocytic cell.
","Dimitar Georgiev, Álvaro Fernández-Galiana, Simon Vilms Pedersen, Georgios Papadopoulos, Ruoxiao Xie, Molly M. Stevens, Mauricio Barahona",Mauricio Barahona,2024-03-07T14:27:08Z
"Deep unfolding Network for Hyperspectral Image Super-Resolution with
  Automatic Exposure Correction","  In recent years, the fusion of high spatial resolution multispectral image
(HR-MSI) and low spatial resolution hyperspectral image (LR-HSI) has been
recognized as an effective method for HSI super-resolution (HSI-SR). However,
both HSI and MSI may be acquired under extreme conditions such as night or
poorly illuminating scenarios, which may cause different exposure levels,
thereby seriously downgrading the yielded HSISR. In contrast to most existing
methods based on respective low-light enhancements (LLIE) of MSI and HSI
followed by their fusion, a deep Unfolding HSI Super-Resolution with Automatic
Exposure Correction (UHSR-AEC) is proposed, that can effectively generate a
high-quality fused HSI-SR (in texture and features) even under very imbalanced
exposures, thanks to the correlation between LLIE and HSI-SR taken into
account. Extensive experiments are provided to demonstrate the state-of-the-art
overall performance of the proposed UHSR-AEC, including comparison with some
benchmark peer methods.
","Yuan Fang, Yipeng Liu, Jie Chen, Zhen Long, Ao Li, Chong-Yung Chi, Ce Zhu",Ce Zhu,2024-03-14T04:41:30Z
Varroa destructor detection on honey bees using hyperspectral imagery,"  Hyperspectral (HS) imagery in agriculture is becoming increasingly common.
These images have the advantage of higher spectral resolution. Advanced
spectral processing techniques are required to unlock the information potential
in these HS images. The present paper introduces a method rooted in
multivariate statistics designed to detect parasitic Varroa destructor mites on
the body of western honey bee Apis mellifera, enabling easier and continuous
monitoring of the bee hives. The methodology explores unsupervised (K-means++)
and recently developed supervised (Kernel Flows - Partial Least-Squares,
KF-PLS) methods for parasitic identification. Additionally, in light of the
emergence of custom-band multispectral cameras, the present research outlines a
strategy for identifying the specific wavelengths necessary for effective
bee-mite separation, suitable for implementation in a custom-band camera.
Illustrated with a real-case dataset, our findings demonstrate that as few as
four spectral bands are sufficient for accurate parasite identification.
","Zina-Sabrina Duma, Tomas Zemcik, Simon Bilik, Tuomas Sihvonen, Peter Honec, Satu-Pia Reinikainen, Karel Horak",Karel Horak,2024-03-21T12:40:41Z
"Onboard deep lossless and near-lossless predictive coding of
  hyperspectral images with line-based attention","  Deep learning methods have traditionally been difficult to apply to
compression of hyperspectral images onboard of spacecrafts, due to the large
computational complexity needed to achieve adequate representational power, as
well as the lack of suitable datasets for training and testing. In this paper,
we depart from the traditional autoencoder approach and we design a predictive
neural network, called LineRWKV, that works recursively line-by-line to limit
memory consumption. In order to achieve that, we adopt a novel hybrid
attentive-recursive operation that combines the representational advantages of
Transformers with the linear complexity and recursive implementation of
recurrent neural networks. The compression algorithm performs prediction of
each pixel using LineRWKV, followed by entropy coding of the residual.
Experiments on the HySpecNet-11k dataset and PRISMA images show that LineRWKV
is the first deep-learning method to outperform CCSDS-123.0-B-2 at lossless and
near-lossless compression. Promising throughput results are also evaluated on a
7W embedded system.
","Diego Valsesia, Tiziano Bianchi, Enrico Magli",Enrico Magli,2024-03-26T13:05:02Z
Noise2Noise Denoising of CRISM Hyperspectral Data,"  Hyperspectral data acquired by the Compact Reconnaissance Imaging
Spectrometer for Mars (CRISM) have allowed for unparalleled mapping of the
surface mineralogy of Mars. Due to sensor degradation over time, a significant
portion of the recently acquired data is considered unusable. Here a new
data-driven model architecture, Noise2Noise4Mars (N2N4M), is introduced to
remove noise from CRISM images. Our model is self-supervised and does not
require zero-noise target data, making it well suited for use in Planetary
Science applications where high quality labelled data is scarce. We demonstrate
its strong performance on synthetic-noise data and CRISM images, and its impact
on downstream classification performance, outperforming benchmark methods on
most metrics. This allows for detailed analysis for critical sites of interest
on the Martian surface, including proposed lander sites.
","Robert Platt, Rossella Arcucci, Cédric M. John",Cédric M. John,2024-03-26T14:49:22Z
"HSIDMamba: Exploring Bidirectional State-Space Models for Hyperspectral
  Denoising","  Effectively discerning spatial-spectral dependencies in HSI denoising is
crucial, but prevailing methods using convolution or transformers still face
computational efficiency limitations. Recently, the emerging Selective State
Space Model(Mamba) has risen with its nearly linear computational complexity in
processing natural language sequences, which inspired us to explore its
potential in handling long spectral sequences. In this paper, we propose
HSIDMamba(HSDM), tailored to exploit the linear complexity for effectively
capturing spatial-spectral dependencies in HSI denoising. In particular, HSDM
comprises multiple Hyperspectral Continuous Scan Blocks, incorporating
BCSM(Bidirectional Continuous Scanning Mechanism), scale residual, and spectral
attention mechanisms to enhance the capture of long-range and local
spatial-spectral information. BCSM strengthens spatial-spectral interactions by
linking forward and backward scans and enhancing information from eight
directions through SSM, significantly enhancing the perceptual capability of
HSDM and improving denoising performance more effectively. Extensive
evaluations against HSI denoising benchmarks validate the superior performance
of HSDM, achieving state-of-the-art results in performance and surpassing the
efficiency of the latest transformer architectures by $30\%$.
","Yang Liu, Jiahua Xiao, Yu Guo, Peilin Jiang, Haiwei Yang, Fei Wang",Fei Wang,2024-04-15T11:59:19Z
Pyramid Hierarchical Transformer for Hyperspectral Image Classification,"  The traditional Transformer model encounters challenges with variable-length
input sequences, particularly in Hyperspectral Image Classification (HSIC),
leading to efficiency and scalability concerns. To overcome this, we propose a
pyramid-based hierarchical transformer (PyFormer). This innovative approach
organizes input data hierarchically into segments, each representing distinct
abstraction levels, thereby enhancing processing efficiency for lengthy
sequences. At each level, a dedicated transformer module is applied,
effectively capturing both local and global context. Spatial and spectral
information flow within the hierarchy facilitates communication and abstraction
propagation. Integration of outputs from different levels culminates in the
final input representation. Experimental results underscore the superiority of
the proposed method over traditional approaches. Additionally, the
incorporation of disjoint samples augments robustness and reliability, thereby
highlighting the potential of our approach in advancing HSIC.
  The source code is available at https://github.com/mahmad00/PyFormer.
","Muhammad Ahmad, Muhammad Hassaan Farooq Butt, Manuel Mazzara, Salvatore Distifano",Salvatore Distifano,2024-04-23T11:41:19Z
Dual-Stream Attention Network for Hyperspectral Image Unmixing,"  Hyperspectral image (HSI) contains abundant spatial and spectral information,
making it highly valuable for unmixing. In this paper, we propose a Dual-Stream
Attention Network (DSANet) for HSI unmixing. The endmembers and abundance of a
pixel in HSI have high correlations with its adjacent pixels. Therefore, we
adopt a ""many to one"" strategy to estimate the abundance of the central pixel.
In addition, we adopt multiview spectral method, dividing spectral bands into
multiple partitions with low correlations to estimate abundances. To aggregate
the estimated abundances for complementary from the two branches, we design a
cross-fusion attention network to enhance valuable information. Extensive
experiments have been conducted on two real datasets, which demonstrate the
effectiveness of our DSANet.
","Yufang Wang, Wenmin Wu, Lin Qi, Feng Gao",Feng Gao,2024-06-03T12:06:37Z
Hybrid Spatial-spectral Neural Network for Hyperspectral Image Denoising,"  Hyperspectral image (HSI) denoising is an essential procedure for HSI
applications. Unfortunately, the existing Transformer-based methods mainly
focus on non-local modeling, neglecting the importance of locality in image
denoising. Moreover, deep learning methods employ complex spectral learning
mechanisms, thus introducing large computation costs.
  To address these problems, we propose a hybrid spatial-spectral denoising
network (HSSD), in which we design a novel hybrid dual-path network inspired by
CNN and Transformer characteristics, leading to capturing both local and
non-local spatial details while suppressing noise efficiently. Furthermore, to
reduce computational complexity, we adopt a simple but effective decoupling
strategy that disentangles the learning of space and spectral channels, where
multilayer perception with few parameters is utilized to learn the global
correlations among spectra. The synthetic and real experiments demonstrate that
our proposed method outperforms state-of-the-art methods on spatial and
spectral reconstruction. The code and details are available on
https://github.com/HLImg/HSSD.
","Hao Liang,  Chengjie, Kun Li, Xin Tian",Xin Tian,2024-06-13T03:27:01Z
"Coarse-Fine Spectral-Aware Deformable Convolution For Hyperspectral
  Image Reconstruction","  We study the inverse problem of Coded Aperture Snapshot Spectral Imaging
(CASSI), which captures a spatial-spectral data cube using snapshot 2D
measurements and uses algorithms to reconstruct 3D hyperspectral images (HSI).
However, current methods based on Convolutional Neural Networks (CNNs) struggle
to capture long-range dependencies and non-local similarities. The recently
popular Transformer-based methods are poorly deployed on downstream tasks due
to the high computational cost caused by self-attention. In this paper, we
propose Coarse-Fine Spectral-Aware Deformable Convolution Network (CFSDCN),
applying deformable convolutional networks (DCN) to this task for the first
time. Considering the sparsity of HSI, we design a deformable convolution
module that exploits its deformability to capture long-range dependencies and
non-local similarities. In addition, we propose a new spectral information
interaction module that considers both coarse-grained and fine-grained spectral
similarities. Extensive experiments demonstrate that our CFSDCN significantly
outperforms previous state-of-the-art (SOTA) methods on both simulated and real
HSI datasets.
","Jincheng Yang, Lishun Wang, Miao Cao, Huan Wang, Yinping Zhao, Xin Yuan",Xin Yuan,2024-06-18T15:15:12Z
"Boosting Hyperspectral Image Classification with Gate-Shift-Fuse
  Mechanisms in a Novel CNN-Transformer Approach","  During the process of classifying Hyperspectral Image (HSI), every pixel
sample is categorized under a land-cover type. CNN-based techniques for HSI
classification have notably advanced the field by their adept feature
representation capabilities. However, acquiring deep features remains a
challenge for these CNN-based methods. In contrast, transformer models are
adept at extracting high-level semantic features, offering a complementary
strength. This paper's main contribution is the introduction of an HSI
classification model that includes two convolutional blocks, a Gate-Shift-Fuse
(GSF) block and a transformer block. This model leverages the strengths of CNNs
in local feature extraction and transformers in long-range context modelling.
The GSF block is designed to strengthen the extraction of local and global
spatial-spectral features. An effective attention mechanism module is also
proposed to enhance the extraction of information from HSI cubes. The proposed
method is evaluated on four well-known datasets (the Indian Pines, Pavia
University, WHU-WHU-Hi-LongKou and WHU-Hi-HanChuan), demonstrating that the
proposed framework achieves superior results compared to other models.
","Mohamed Fadhlallah Guerri, Cosimo Distante, Paolo Spagnolo, Fares Bougourzi, Abdelmalik Taleb-Ahmed",Abdelmalik Taleb-Ahmed,2024-06-20T09:05:50Z
"Advancements in Feature Extraction Recognition of Medical Imaging
  Systems Through Deep Learning Technique","  This study introduces a novel unsupervised medical image feature extraction
method that employs spatial stratification techniques. An objective function
based on weight is proposed to achieve the purpose of fast image recognition.
The algorithm divides the pixels of the image into multiple subdomains and uses
a quadtree to access the image. A technique for threshold optimization
utilizing a simplex algorithm is presented. Aiming at the nonlinear
characteristics of hyperspectral images, a generalized discriminant analysis
algorithm based on kernel function is proposed. In this project, a
hyperspectral remote sensing image is taken as the object, and we investigate
its mathematical modeling, solution methods, and feature extraction techniques.
It is found that different types of objects are independent of each other and
compact in image processing. Compared with the traditional linear
discrimination method, the result of image segmentation is better. This method
can not only overcome the disadvantage of the traditional method which is easy
to be affected by light, but also extract the features of the object quickly
and accurately. It has important reference significance for clinical diagnosis.
","Qishi Zhan, Dan Sun, Erdi Gao, Yuhan Ma, Yaxin Liang, Haowei Yang",Haowei Yang,2024-05-23T04:46:51Z
Spectral Graph Reasoning Network for Hyperspectral Image Classification,"  Convolutional neural networks (CNNs) have achieved remarkable performance in
hyperspectral image (HSI) classification over the last few years. Despite the
progress that has been made, rich and informative spectral information of HSI
has been largely underutilized by existing methods which employ convolutional
kernels with limited size of receptive field in the spectral domain. To address
this issue, we propose a spectral graph reasoning network (SGR) learning
framework comprising two crucial modules: 1) a spectral decoupling module which
unpacks and casts multiple spectral embeddings into a unified graph whose node
corresponds to an individual spectral feature channel in the embedding space;
the graph performs interpretable reasoning to aggregate and align spectral
information to guide learning spectral-specific graph embeddings at multiple
contextual levels 2) a spectral ensembling module explores the interactions and
interdependencies across graph embedding hierarchy via a novel recurrent graph
propagation mechanism. Experiments on two HSI datasets demonstrate that the
proposed architecture can significantly improve the classification accuracy
compared with the existing methods with a sizable margin.
",Huiling Wang,Huiling Wang,2024-07-02T20:29:23Z
"Adaptive Step-size Perception Unfolding Network with Non-local Hybrid
  Attention for Hyperspectral Image Reconstruction","  Deep unfolding methods and transformer architecture have recently shown
promising results in hyperspectral image (HSI) reconstruction. However, there
still exist two issues: (1) in the data subproblem, most methods represents the
stepsize utilizing a learnable parameter. Nevertheless, for different spectral
channel, error between features and ground truth is unequal. (2) Transformer
struggles to balance receptive field size with pixel-wise detail information.
To overcome the aforementioned drawbacks, We proposed an adaptive step-size
perception unfolding network (ASPUN), a deep unfolding network based on FISTA
algorithm, which uses an adaptive step-size perception module to estimate the
update step-size of each spectral channel. In addition, we design a Non-local
Hybrid Attention Transformer(NHAT) module for fully leveraging the receptive
field advantage of transformer. By plugging the NLHA into the Non-local
Information Aggregation (NLIA) module, the unfolding network can achieve better
reconstruction results. Experimental results show that our ASPUN is superior to
the existing SOTA algorithms and achieves the best performance.
","Yanan Yang, Like Xin",Like Xin,2024-07-04T16:09:52Z
"A Hybrid Registration and Fusion Method for Hyperspectral
  Super-resolution","  Fusing hyperspectral images (HSIs) with multispectral images (MSIs) has
become a mainstream approach to enhance the spatial resolution of HSIs. Many
HSI-MSI fusion methods have achieved impressive results. Nevertheless, certain
challenges persist, including: (a) A majority of current methods rely on
accurate registration of HSI and MSI, which can be challenging in real-world
applications.(b) The obtained HSI-MSI pairs may not be fully utilized. In this
paper, we propose a hybrid registration and fusion constrained optimization
model named RAF-NLRGS. With respect to challenge (a), the RAF model integrates
batch image alignment within the fusion process, facilitating simultaneous
execution of image registration and fusion. To address issue (b), the NLRGS
model incorporates a nonconvex low-rank and group-sparse structure, leveraging
group sparsity to effectively harness valuable information embedded in the
residual data. Moreover, the NLRGS model can further enhance fusion performance
based on the RAF model. Subsequently, the RAF-NLRGS model is solved within the
framework of Generalized Gauss-Newton (GGN) algorithm and Proximal Alternating
Optimization (PAO) algorithm. Theoretically, we establish the error bounds for
the NLRGS model and the convergence analysis of corresponding algorithms is
also presented. Finally, extensive numerical experiments on HSI datasets are
conducted to verify the effectiveness of our method.
","Kunjing Yang, Minru Bai,  TingLu", TingLu,2024-07-07T06:36:19Z
"Haar Nuclear Norms with Applications to Remote Sensing Imagery
  Restoration","  Remote sensing image restoration aims to reconstruct missing or corrupted
areas within images. To date, low-rank based models have garnered significant
interest in this field. This paper proposes a novel low-rank regularization
term, named the Haar nuclear norm (HNN), for efficient and effective remote
sensing image restoration.
  It leverages the low-rank properties of wavelet coefficients derived from the
2-D frontal slice-wise Haar discrete wavelet transform, effectively modeling
the low-rank prior for separated coarse-grained structure and fine-grained
textures in the image. Experimental evaluations conducted on hyperspectral
image inpainting, multi-temporal image cloud removal, and hyperspectral image
denoising have revealed the HNN's potential. Typically, HNN achieves a
performance improvement of 1-4 dB and a speedup of 10-28x compared to some
state-of-the-art methods (e.g., tensor correlated total variation, and
fully-connected tensor network) for inpainting tasks.
","Shuang Xu, Chang Yu, Jiangjun Peng, Xiangyong Cao",Xiangyong Cao,2024-07-11T13:46:47Z
"Mapping savannah woody vegetation at the species level with multispecral
  drone and hyperspectral EnMAP data","  Savannahs are vital ecosystems whose sustainability is endangered by the
spread of woody plants. This research targets the accurate mapping of
fractional woody cover (FWC) at the species level in a South African savannah,
using EnMAP hyperspectral data. Field annotations were combined with very
high-resolution multispectral drone data to produce land cover maps that
included three woody species. The high-resolution labelled maps were then used
to generate FWC samples for each woody species class at the 30-m spatial
resolution of EnMAP. Four machine learning regression algorithms were tested
for FWC mapping on dry season EnMAP imagery. The contribution of multitemporal
information was also assessed by incorporating as additional regression
features, spectro-temporal metrics from Sentinel-2 data of both the dry and wet
seasons. The results demonstrated the suitability of our approach for
accurately mapping FWC at the species level. The highest accuracy rates
achieved from the combined EnMAP and Sentinel-2 experiments highlighted their
synergistic potential for species-level vegetation mapping.
","Christina Karakizi, Akpona Okujeni, Eleni Sofikiti, Vasileios Tsironis, Athina Psalta, Konstantinos Karantzalos, Patrick Hostert, Elias Symeonakis",Elias Symeonakis,2024-07-16T05:44:41Z
"Hyperspectral Unmixing Under Endmember Variability: A Variational
  Inference Framework","  This work proposes a variational inference (VI) framework for hyperspectral
unmixing in the presence of endmember variability (HU-EV). An EV-accounted
noisy linear mixture model (LMM) is considered, and the presence of outliers is
also incorporated into the model. Following the marginalized maximum likelihood
(MML) principle, a VI algorithmic structure is designed for probabilistic
inference for HU-EV. Specifically, a patch-wise static endmember assumption is
employed to exploit spatial smoothness and to try to overcome the ill-posed
nature of the HU-EV problem. The design facilitates lightweight, continuous
optimization-based updates under a variety of endmember priors. Some of the
priors, such as the Beta prior, were previously used under computationally
heavy, sampling-based probabilistic HU-EV methods. The effectiveness of the
proposed framework is demonstrated through synthetic, semi-real, and real-data
experiments.
","Yuening Li, Xiao Fu, Junbin Liu, Wing-Kin Ma",Wing-Kin Ma,2024-07-20T15:16:14Z
"Content-driven Magnitude-Derivative Spectrum Complementary Learning for
  Hyperspectral Image Classification","  Extracting discriminative information from complex spectral details in
hyperspectral image (HSI) for HSI classification is pivotal. While current
prevailing methods rely on spectral magnitude features, they could cause
confusion in certain classes, resulting in misclassification and decreased
accuracy. We find that the derivative spectrum proves more adept at capturing
concealed information, thereby offering a distinct advantage in separating
these confusion classes. Leveraging the complementarity between spectral
magnitude and derivative features, we propose a Content-driven Spectrum
Complementary Network based on Magnitude-Derivative Dual Encoder, employing
these two features as combined inputs. To fully utilize their complementary
information, we raise a Content-adaptive Point-wise Fusion Module, enabling
adaptive fusion of dual-encoder features in a point-wise selective manner,
contingent upon feature representation. To preserve a rich source of
complementary information while extracting more distinguishable features, we
introduce a Hybrid Disparity-enhancing Loss that enhances the differential
expression of the features from the two branches and increases the inter-class
distance. As a result, our method achieves state-of-the-art results on the
extensive WHU-OHS dataset and eight other benchmark datasets.
","Huiyan Bai, Tingfa Xu, Huan Chen, Peifu Liu, Jianan Li",Jianan Li,2024-07-26T08:28:53Z
"WaveMamba: Spatial-Spectral Wavelet Mamba for Hyperspectral Image
  Classification","  Hyperspectral Imaging (HSI) has proven to be a powerful tool for capturing
detailed spectral and spatial information across diverse applications. Despite
the advancements in Deep Learning (DL) and Transformer architectures for HSI
Classification (HSIC), challenges such as computational efficiency and the need
for extensive labeled data persist. This paper introduces WaveMamba, a novel
approach that integrates wavelet transformation with the Spatial-Spectral Mamba
architecture to enhance HSIC. WaveMamba captures both local texture patterns
and global contextual relationships in an end-to-end trainable model. The
Wavelet-based enhanced features are then processed through the state-space
architecture to model spatial-spectral relationships and temporal dependencies.
The experimental results indicate that WaveMamba surpasses existing models,
achieving an accuracy improvement of 4.5\% on the University of Houston dataset
and a 2.0\% increase on the Pavia University dataset. These findings validate
its effectiveness in addressing the complex data interactions inherent in HSIs.
","Muhammad Ahmad, Muhammad Usama, Manual Mazzara",Manual Mazzara,2024-08-02T12:44:07Z
"Hierarchical Attention and Parallel Filter Fusion Network for
  Multi-Source Data Classification","  Hyperspectral image (HSI) and synthetic aperture radar (SAR) data joint
classification is a crucial and yet challenging task in the field of remote
sensing image interpretation. However, feature modeling in existing methods is
deficient to exploit the abundant global, spectral, and local features
simultaneously, leading to sub-optimal classification performance. To solve the
problem, we propose a hierarchical attention and parallel filter fusion network
for multi-source data classification. Concretely, we design a hierarchical
attention module for hyperspectral feature extraction. This module integrates
global, spectral, and local features simultaneously to provide more
comprehensive feature representation. In addition, we develop parallel filter
fusion module which enhances cross-modal feature interactions among different
spatial locations in the frequency domain. Extensive experiments on two
multi-source remote sensing data classification datasets verify the superiority
of our proposed method over current state-of-the-art classification approaches.
Specifically, our proposed method achieves 91.44% and 80.51% of overall
accuracy (OA) on the respective datasets, highlighting its superior
performance.
","Han Luo, Feng Gao, Junyu Dong, Lin Qi",Lin Qi,2024-08-22T23:14:22Z
Selective Transformer for Hyperspectral Image Classification,"  Transformer has achieved satisfactory results in the field of hyperspectral
image (HSI) classification. However, existing Transformer models face two key
challenges when dealing with HSI scenes characterized by diverse land cover
types and rich spectral information: (1) fixed receptive field representation
overlooks effective contextual information; (2) redundant self-attention
feature representation. To address these limitations, we propose a novel
Selective Transformer (SFormer) for HSI classification. The SFormer is designed
to dynamically select receptive fields for capturing both spatial and spectral
contextual information, while mitigating the impact of redundant data by
prioritizing the most relevant features. This enables a highly accurate
classification of the land covers of the HSI. Specifically, a Kernel Selective
Transformer Block (KSTB) is first utilized to dynamically select an appropriate
receptive field range to effectively extract spatial-spectral features.
Furthermore, to capture the most crucial tokens, a Token Selective Transformer
Block (TSTB) is introduced, which selects the most relevant tokens based on the
ranking of attention scores for each query. Extensive experiments on four
benchmark HSI datasets demonstrate that the proposed SFormer outperforms the
state-of-the-art HSI classification models. The codes will be released.
","Yichu Xu, Di Wang, Lefei Zhang, Liangpei Zhang",Liangpei Zhang,2024-10-04T06:05:26Z
"Low-cost Robust Night-time Aerial Material Segmentation through
  Hyperspectral Data and Sparse Spatio-Temporal Learning","  Material segmentation is a complex task, particularly when dealing with
aerial data in poor lighting and atmospheric conditions. To address this,
hyperspectral data from specialized cameras can be very useful in addition to
RGB images. However, due to hardware constraints, high spectral data often come
with lower spatial resolution. Additionally, incorporating such data into a
learning-based segmentation framework is challenging due to the numerous data
channels involved. To overcome these difficulties, we propose an innovative
Siamese framework that uses time series-based compression to effectively and
scalably integrate the additional spectral data into the segmentation task. We
demonstrate our model's effectiveness through competitive benchmarks on aerial
datasets in various environmental conditions.
","Chandrajit Bajaj, Minh Nguyen, Shubham Bhardwaj",Shubham Bhardwaj,2024-10-19T20:48:41Z
"Irregular Tensor Low-Rank Representation for Hyperspectral Image
  Representation","  Spectral variation is a common problem for hyperspectral image (HSI)
representation. Low-rank tensor representation is an important approach to
alleviate spectral variations. However, the spatial distribution of the HSI is
always irregular, while the previous tensor low-rank representation methods can
only be applied to the regular data cubes, which limits the performance. To
remedy this issue, in this paper we propose a novel irregular tensor low-rank
representation model. We first segment the HSI data into several irregular
homogeneous regions. Then, we propose a novel irregular tensor low-rank
representation method that can efficiently model the irregular 3D cubes. We
further use a non-convex nuclear norm to pursue the low-rankness and introduce
a negative global low-rank term that improves global consistency. This proposed
model is finally formulated as a convex-concave optimization problem and solved
by alternative augmented Lagrangian method. Through experiments on four public
datasets, the proposed method outperforms the existing low-rank based HSI
methods significantly. Code is available at:
https://github.com/hb-studying/ITLRR.
","Bo Han, Yuheng Jia, Hui Liu, Junhui Hou",Junhui Hou,2024-10-24T02:56:22Z
Fast algorithms for hyperspectral Diffuse Optical Tomography,"  The image reconstruction of chromophore concentrations using Diffuse Optical
Tomography (DOT) data can be described mathematically as an ill-posed inverse
problem. Recent work has shown that the use of hyperspectral DOT data, as
opposed to data sets comprising of a single or, at most, a dozen wavelengths,
has the potential for improving the quality of the reconstructions. The use of
hyperspectral diffuse optical data in the formulation and solution of the
inverse problem poses a significant computational burden. The forward operator
is, in actuality, nonlinear. However, under certain assumptions, a linear
approximation, called the Born approximation, provides a suitable surrogate for
the forward operator, and we assume this to be true in the present work.
Computation of the Born matrix requires the solution of thousands of large
scale discrete PDEs and the reconstruction problem, requires matrix-vector
products with the (dense) Born matrix. In this paper, we address both of these
difficulties, thus making the Born approach a computational viable approach for
hyDOT reconstruction. In this paper, we assume that the images we wish to
reconstruct are anomalies of unknown shape and constant value, described using
a parametric level set approach, (PaLS) on a constant background. Specifically,
to address the issue of the PDE solves, we develop a novel recycling-based
Krylov subspace approach that leverages certain system similarities across
wavelengths. To address expense of using the Born operator in the inversion, we
present a fast algorithm for compressing the Born operator that locally
compresses across wavelengths for a given source-detector set and then
recursively combines the low-rank factors to provide a global low-rank
approximation. This low-rank approximation can be used implicitly to speed up
the recovery of the shape parameters and the chromophore concentrations.
","Arvind K. Saibaba, Misha Kilmer, Eric Miller, Sergio Fantini",Sergio Fantini,2014-10-03T22:13:22Z
"A convex formulation for hyperspectral image superresolution via
  subspace-based regularization","  Hyperspectral remote sensing images (HSIs) usually have high spectral
resolution and low spatial resolution. Conversely, multispectral images (MSIs)
usually have low spectral and high spatial resolutions. The problem of
inferring images which combine the high spectral and high spatial resolutions
of HSIs and MSIs, respectively, is a data fusion problem that has been the
focus of recent active research due to the increasing availability of HSIs and
MSIs retrieved from the same geographical area.
  We formulate this problem as the minimization of a convex objective function
containing two quadratic data-fitting terms and an edge-preserving regularizer.
The data-fitting terms account for blur, different resolutions, and additive
noise. The regularizer, a form of vector Total Variation, promotes
piecewise-smooth solutions with discontinuities aligned across the
hyperspectral bands.
  The downsampling operator accounting for the different spatial resolutions,
the non-quadratic and non-smooth nature of the regularizer, and the very large
size of the HSI to be estimated lead to a hard optimization problem. We deal
with these difficulties by exploiting the fact that HSIs generally ""live"" in a
low-dimensional subspace and by tailoring the Split Augmented Lagrangian
Shrinkage Algorithm (SALSA), which is an instance of the Alternating Direction
Method of Multipliers (ADMM), to this optimization problem, by means of a
convenient variable splitting. The spatial blur and the spectral linear
operators linked, respectively, with the HSI and MSI acquisition processes are
also estimated, and we obtain an effective algorithm that outperforms the
state-of-the-art, as illustrated in a series of experiments with simulated and
real-life data.
","Miguel Simões, José Bioucas-Dias, Luis B. Almeida, Jocelyn Chanussot",Jocelyn Chanussot,2014-11-14T18:36:31Z
Compressive Hyperspectral Imaging via Approximate Message Passing,"  We consider a compressive hyperspectral imaging reconstruction problem, where
three-dimensional spatio-spectral information about a scene is sensed by a
coded aperture snapshot spectral imager (CASSI). The CASSI imaging process can
be modeled as suppressing three-dimensional coded and shifted voxels and
projecting these onto a two-dimensional plane, such that the number of acquired
measurements is greatly reduced. On the other hand, because the measurements
are highly compressive, the reconstruction process becomes challenging. We
previously proposed a compressive imaging reconstruction algorithm that is
applied to two-dimensional images based on the approximate message passing
(AMP) framework. AMP is an iterative algorithm that can be used in signal and
image reconstruction by performing denoising at each iteration. We employed an
adaptive Wiener filter as the image denoiser, and called our algorithm
""AMP-Wiener."" In this paper, we extend AMP-Wiener to three-dimensional
hyperspectral image reconstruction, and call it ""AMP-3D-Wiener."" Applying the
AMP framework to the CASSI system is challenging, because the matrix that
models the CASSI system is highly sparse, and such a matrix is not suitable to
AMP and makes it difficult for AMP to converge. Therefore, we modify the
adaptive Wiener filter and employ a technique called damping to solve for the
divergence issue of AMP. Our approach is applied in nature, and the numerical
experiments show that AMP-3D-Wiener outperforms existing widely-used algorithms
such as gradient projection for sparse reconstruction (GPSR) and two-step
iterative shrinkage/thresholding (TwIST) given a similar amount of runtime.
Moreover, in contrast to GPSR and TwIST, AMP-3D-Wiener need not tune any
parameters, which simplifies the reconstruction process.
","Jin Tan, Yanting Ma, Hoover Rueda, Dror Baron, Gonzalo Arce",Gonzalo Arce,2015-07-05T17:43:42Z
"Unsupervised and Unregistered Hyperspectral Image Super-Resolution with
  Mutual Dirichlet-Net","  Hyperspectral images (HSI) provide rich spectral information that contributed
to the successful performance improvement of numerous computer vision tasks.
However, it can only be achieved at the expense of images' spatial resolution.
Hyperspectral image super-resolution (HSI-SR) addresses this problem by fusing
low resolution (LR) HSI with multispectral image (MSI) carrying much higher
spatial resolution (HR). All existing HSI-SR approaches require the LR HSI and
HR MSI to be well registered and the reconstruction accuracy of the HR HSI
relies heavily on the registration accuracy of different modalities. This paper
exploits the uncharted problem domain of HSI-SR without the requirement of
multi-modality registration. Given the unregistered LR HSI and HR MSI with
overlapped regions, we design a unique unsupervised learning structure linking
the two unregistered modalities by projecting them into the same statistical
space through the same encoder. The mutual information (MI) is further adopted
to capture the non-linear statistical dependencies between the representations
from two modalities (carrying spatial information) and their raw inputs. By
maximizing the MI, spatial correlations between different modalities can be
well characterized to further reduce the spectral distortion. A collaborative
$l_{2,1}$ norm is employed as the reconstruction error instead of the more
common $l_2$ norm, so that individual pixels can be recovered as accurately as
possible. With this design, the network allows to extract correlated spectral
and spatial information from unregistered images that better preserves the
spectral information. The proposed method is referred to as unregistered and
unsupervised mutual Dirichlet Net ($u^2$-MDN). Extensive experimental results
using benchmark HSI datasets demonstrate the superior performance of $u^2$-MDN
as compared to the state-of-the-art.
","Ying Qu, Hairong Qi, Chiman Kwan, Naoto Yokoya, Jocelyn Chanussot",Jocelyn Chanussot,2019-04-27T16:38:35Z
"Unmixing methods based on nonnegativity and weakly mixed pixels for
  astronomical hyperspectral datasets","  [Abridged] An increasing number of astronomical instruments (on Earth and
space-based) provide hyperspectral images, that is three-dimensional data cubes
with two spatial dimensions and one spectral dimension. The intrinsic
limitation in spatial resolution of these instruments implies that the spectra
associated with pixels of such images are most often mixtures of the spectra of
the ""pure"" components that exist in the considered region. In order to estimate
the spectra and spatial abundances of these pure components, we here propose an
original blind signal separation (BSS), that is to say an unsupervised unmixing
method. Our approach is based on extensions and combinations of linear BSS
methods that belong to two major classes of methods, namely nonnegative matrix
factorization (NMF) and Sparse Component Analysis (SCA). The former performs
the decomposition of hyperspectral images, as a set of pure spectra and
abundance maps, by using nonnegativity constraints, but the estimated solution
is not unique: It highly depends on the initialization of the algorithm. The
considered SCA methods are based on the assumption of the existence of points
or tiny spatial zones where only one source is active (i.e., one pure component
is present). In real conditions, the assumption of perfect single-source points
or zones is not always realistic. In such conditions, SCA yields approximate
versions of the unknown sources and mixing coefficients. We propose to use part
of these preliminary estimates from the SCA to initialize several runs of the
NMF to constrain the convergence of the NMF algorithm. Detailed tests with
synthetic data show that the decomposition achieved with such hybrid methods is
nearly unique and provides good performance, illustrating the potential of
applications to real data.
","Axel Boulais, Olivier Berné, Guillaume Faury, Yannick Deville",Yannick Deville,2020-11-19T09:43:41Z
"Hyperspectral Pansharpening Based on Improved Deep Image Prior and
  Residual Reconstruction","  Hyperspectral pansharpening aims to synthesize a low-resolution hyperspectral
image (LR-HSI) with a registered panchromatic image (PAN) to generate an
enhanced HSI with high spectral and spatial resolution. Recently proposed HS
pansharpening methods have obtained remarkable results using deep convolutional
networks (ConvNets), which typically consist of three steps: (1) up-sampling
the LR-HSI, (2) predicting the residual image via a ConvNet, and (3) obtaining
the final fused HSI by adding the outputs from first and second steps. Recent
methods have leveraged Deep Image Prior (DIP) to up-sample the LR-HSI due to
its excellent ability to preserve both spatial and spectral information,
without learning from large data sets. However, we observed that the quality of
up-sampled HSIs can be further improved by introducing an additional
spatial-domain constraint to the conventional spectral-domain energy function.
We define our spatial-domain constraint as the $L_1$ distance between the
predicted PAN image and the actual PAN image. To estimate the PAN image of the
up-sampled HSI, we also propose a learnable spectral response function (SRF).
Moreover, we noticed that the residual image between the up-sampled HSI and the
reference HSI mainly consists of edge information and very fine structures. In
order to accurately estimate fine information, we propose a novel over-complete
network, called HyperKite, which focuses on learning high-level features by
constraining the receptive from increasing in the deep layers. We perform
experiments on three HSI datasets to demonstrate the superiority of our
DIP-HyperKite over the state-of-the-art pansharpening methods. The deployment
codes, pre-trained models, and final fusion outputs of our DIP-HyperKite and
the methods used for the comparisons will be publicly made available at
https://github.com/wgcban/DIP-HyperKite.git.
","Wele Gedara Chaminda Bandara, Jeya Maria Jose Valanarasu, Vishal M. Patel",Vishal M. Patel,2021-07-06T14:11:03Z
"GAUSS: Guided Encoder-Decoder Architecture for Hyperspectral Unmixing
  with Spatial Smoothness","  In recent hyperspectral unmixing (HU) literature, the application of deep
learning (DL) has become more prominent, especially with the autoencoder (AE)
architecture. We propose a split architecture and use a pseudo-ground truth for
abundances to guide the `unmixing network' (UN) optimization. Preceding the UN,
an `approximation network' (AN) is proposed, which will improve the association
between the centre pixel and its neighbourhood. Hence, it will accentuate
spatial correlation in the abundances as its output is the input to the UN and
the reference for the `mixing network' (MN). In the Guided Encoder-Decoder
Architecture for Hyperspectral Unmixing with Spatial Smoothness (GAUSS), we
proposed using one-hot encoded abundances as the pseudo-ground truth to guide
the UN; computed using the k-means algorithm to exclude the use of prior HU
methods. Furthermore, we release the single-layer constraint on MN by
introducing the UN generated abundances in contrast to the standard AE for HU.
Secondly, we experimented with two modifications on the pre-trained network
using the GAUSS method. In GAUSS$_\textit{blind}$, we have concatenated the UN
and the MN to back-propagate the reconstruction error gradients to the encoder.
Then, in the GAUSS$_\textit{prime}$, abundance results of a signal processing
(SP) method with reliable abundance results were used as the pseudo-ground
truth with the GAUSS architecture. According to quantitative and graphical
results for four experimental datasets, the three architectures either
transcended or equated the performance of existing HU algorithms from both DL
and SP domains.
","Yasiru Ranasinghe, Kavinga Weerasooriya, Roshan Godaliyadda, Vijitha Herath, Parakrama Ekanayake, Dhananjaya Jayasundara, Lakshitha Ramanayake, Neranjan Senarath, Dulantha Wickramasinghe",Dulantha Wickramasinghe,2022-04-16T04:23:47Z
"Spatio-spectral deep learning methods for in-vivo hyperspectral
  laryngeal cancer detection","  Early detection of head and neck tumors is crucial for patient survival.
Often, diagnoses are made based on endoscopic examination of the larynx
followed by biopsy and histological analysis, leading to a high inter-observer
variability due to subjective assessment. In this regard, early non-invasive
diagnostics independent of the clinician would be a valuable tool. A recent
study has shown that hyperspectral imaging (HSI) can be used for non-invasive
detection of head and neck tumors, as precancerous or cancerous lesions show
specific spectral signatures that distinguish them from healthy tissue.
However, HSI data processing is challenging due to high spectral variations,
various image interferences, and the high dimensionality of the data.
Therefore, performance of automatic HSI analysis has been limited and so far,
mostly ex-vivo studies have been presented with deep learning. In this work, we
analyze deep learning techniques for in-vivo hyperspectral laryngeal cancer
detection. For this purpose we design and evaluate convolutional neural
networks (CNNs) with 2D spatial or 3D spatio-spectral convolutions combined
with a state-of-the-art Densenet architecture. For evaluation, we use an
in-vivo data set with HSI of the oral cavity or oropharynx. Overall, we present
multiple deep learning techniques for in-vivo laryngeal cancer detection based
on HSI and we show that jointly learning from the spatial and spectral domain
improves classification accuracy notably. Our 3D spatio-spectral Densenet
achieves an average accuracy of 81%.
","Marcel Bengs, Stephan Westermann, Nils Gessert, Dennis Eggert, Andreas O. H. Gerstner, Nina A. Mueller, Christian Betz, Wiebke Laffers, Alexander Schlaefer",Alexander Schlaefer,2020-04-21T17:07:18Z
"Grafting Transformer on Automatically Designed Convolutional Neural
  Network for Hyperspectral Image Classification","  Hyperspectral image (HSI) classification has been a hot topic for decides, as
hyperspectral images have rich spatial and spectral information and provide
strong basis for distinguishing different land-cover objects. Benefiting from
the development of deep learning technologies, deep learning based HSI
classification methods have achieved promising performance. Recently, several
neural architecture search (NAS) algorithms have been proposed for HSI
classification, which further improve the accuracy of HSI classification to a
new level. In this paper, NAS and Transformer are combined for handling HSI
classification task for the first time. Compared with previous work, the
proposed method has two main differences. First, we revisit the search spaces
designed in previous HSI classification NAS methods and propose a novel hybrid
search space, consisting of the space dominated cell and the spectrum dominated
cell. Compared with search spaces proposed in previous works, the proposed
hybrid search space is more aligned with the characteristic of HSI data, that
is, HSIs have a relatively low spatial resolution and an extremely high
spectral resolution. Second, to further improve the classification accuracy, we
attempt to graft the emerging transformer module on the automatically designed
convolutional neural network (CNN) to add global information to local region
focused features learned by CNN. Experimental results on three public HSI
datasets show that the proposed method achieves much better performance than
comparison approaches, including manually designed network and NAS based HSI
classification methods. Especially on the most recently captured dataset
Houston University, overall accuracy is improved by nearly 6 percentage points.
Code is available at: https://github.com/Cecilia-xue/HyT-NAS.
","Xizhe Xue, Haokui Zhang, Bei Fang, Zongwen Bai, Ying Li",Ying Li,2021-10-21T11:51:51Z
"Hyperspectral Pixel Unmixing with Latent Dirichlet Variational
  Autoencoder","  We present a method for hyperspectral pixel {\it unmixing}. The proposed
method assumes that (1) {\it abundances} can be encoded as Dirichlet
distributions and (2) spectra of {\it endmembers} can be represented as
multivariate Normal distributions. The method solves the problem of abundance
estimation and endmember extraction within a variational autoencoder setting
where a Dirichlet bottleneck layer models the abundances, and the decoder
performs endmember extraction. The proposed method can also leverage transfer
learning paradigm, where the model is only trained on synthetic data containing
pixels that are linear combinations of one or more endmembers of interest. In
this case, we retrieve endmembers (spectra) from the United States Geological
Survey Spectral Library. The model thus trained can be subsequently used to
perform pixel unmixing on ""real data"" that contains a subset of the endmembers
used to generated the synthetic data. The model achieves state-of-the-art
results on several benchmarks: Cuprite, Urban Hydice and Samson. We also
present new synthetic dataset, OnTech-HSI-Syn-21, that can be used to study
hyperspectral pixel unmixing methods. We showcase the transfer learning
capabilities of the proposed model on Cuprite and OnTech-HSI-Syn-21 datasets.
In summary, the proposed method can be applied for pixel unmixing a variety of
domains, including agriculture, forestry, mineralogy, analysis of materials,
healthcare, etc. Additionally, the proposed method eschews the need for
labelled data for training by leveraging the transfer learning paradigm, where
the model is trained on synthetic data generated using the endmembers present
in the ""real"" data.
","Kiran Mantripragada, Faisal Z. Qureshi",Faisal Z. Qureshi,2022-03-02T17:38:44Z
"An Efficient Architecture and High-Throughput Implementation of
  CCSDS-123.0-B-2 Hybrid Entropy Coder Targeting Space-Grade SRAM FPGA
  Technology","  Nowadays, hyperspectral imaging is recognized as cornerstone remote sensing
technology. The explosive growth in image data volume and instrument data
rates, compete with limited on-board storage resources and downlink bandwidth,
making hyperspectral image data compression a mission critical on-board
processing task. The Consultative Committee for Space Data Systems (CCSDS)
extended the previous issue of the CCSDS-123.0 Recommended Standard for multi-
and hyperspectral image compression to provide with Near-Lossless compression
functionality. A key feature of the CCSDS-123.0-B-2 is the improved Hybrid
Entropy Coder, which at low bit rates, provides substantially better
compression performance than the Issue 1 entropy coders. In this paper, we
introduce a high-throughput hardware implementation of the CCSDS-123.0-B-2
Hybrid Entropy Coder. The introduced architecture exploits the systolic design
pattern to provide modularity and latency insensitivity in a deep and elastic
pipeline achieving a constant throughput of 1 sample/cycle with a small FPGA
resource footprint. This architecture is described in portable VHDL RTL and is
implemented, validated and demonstrated on a commercially available Xilinx
KCU105 development board hosting a Xilinx Kintex Ultrascale XCKU040 SRAM FPGA,
and thus, is directly transferable to Xilinx Radiation Tolerant Kintex
UltraScale XQRKU060 space-grade devices for space deployments. Moreover,
state-of-the-art SpaceFibre (ECSS-E-ST-50-11C) serial link interface and test
equipment were used in the validation platform to emulate an on-board
deployment. The introduced CCSDS-123.0-B-2 Hybrid Entropy Encoder achieves a
constant throughput performance of 305 MSamples/s. To the best of our
knowledge, this is the first published fully-compliant architecture and
high-throughput implementation of the CCSDS-123.0-B-2 Hybrid Entropy Coder,
targeting space-grade FPGA technology.
","Panagiotis Chatziantoniou, Antonis Tsigkanos, Dimitris Theodoropoulos, Nektarios Kranitis, Antonis Paschalis",Antonis Paschalis,2022-05-09T08:42:03Z
"Accurately Measuring Hyperspectral Imaging Distortion in Grating
  Spectrographs Using a Clustering Algorithm","  Grating-based spectrographs suffer from smile and keystone distortion, which
are problematic for hyperspectral data applications. Due to this, spectral
lines will appear curved and roughly parabola-shaped. Smile and keystone need
to be measured and corrected for accurate spectral and spatial calibration. In
this paper, we present a novel method to accurately identify and correct curved
spectral lines in an image of a spectrum, using a clustering algorithm we
developed specifically for grating spectrographs, inspired by K-means
clustering. Our algorithm will be used for calibrating a multi-object
spectrograph (MOS) based on a digital micromirror device (DMD). For each
spectral line in a spectrum image, our algorithm automatically finds the
equation of the parabola which models it. Firstly, the positions of spectral
peaks are identified by fitting Gaussian functions to the spectrum image. The
peaks are then grouped into a given number of parabola-shaped clusters: each
peak is iteratively assigned to the nearest parabola-shaped cluster, such that
the orthogonal distances from the parabola are minimized. Smile can then be
measured from the parabolas, and keystone as well if a marked slit is used. Our
method has been verified on real-world data from a long-slit grating
spectrograph with sub-pixel error, and on simulated data from a DMD-based MOS.
Compared to traditional approaches, our method can measure distortions
automatically and accurately while making use of more spectral lines. With a
precise model and measurement of distortion, a corrected hyperspectral data
cube can be created, which can be applied for real-time data processing.
","Matthew C. H. Leung, Shaojie Chen, Colby Jurgenson",Colby Jurgenson,2022-08-22T21:32:05Z
"Towards Robust Hyperspectral Unmixing: Mixed Noise Modeling and
  Image-Domain Regularization","  Hyperspectral (HS) unmixing is the process of decomposing an HS image into
material-specific spectra (endmembers) and their spatial distributions
(abundance maps). Existing unmixing methods have two limitations with respect
to noise robustness. First, if the input HS image is highly noisy, even if the
balance between sparse and piecewise-smooth regularizations for abundance maps
is carefully adjusted, noise may remain in the estimated abundance maps or
undesirable artifacts may appear. Second, existing methods do not explicitly
account for the effects of stripe noise, which is common in HS measurements, in
their formulations, resulting in significant degradation of unmixing
performance when such noise is present in the input HS image. To overcome these
limitations, we propose a new robust hyperspectral unmixing method based on
constrained convex optimization. Our method employs, in addition to the two
regularizations for the abundance maps, regularizations for the HS image
reconstructed by mixing the estimated abundance maps and endmembers. This
strategy makes the unmixing process much more robust in highly-noisy scenarios,
under the assumption that the abundance maps used to reconstruct the HS image
with desirable spatio-spectral structure are also expected to have desirable
properties. Furthermore, our method is designed to accommodate a wider variety
of noise including stripe noise. To solve the formulated optimization problem,
we develop an efficient algorithm based on a preconditioned primal-dual
splitting method, which can automatically determine appropriate stepsizes based
on the problem structure. Experiments on synthetic and real HS images
demonstrate the advantages of our method over existing methods.
","Kazuki Naganuma, Shunsuke Ono",Shunsuke Ono,2023-02-16T11:57:25Z
"Range Resolution Enhanced Method with Spectral Properties for
  Hyperspectral Lidar","  Waveform decomposition is needed as a first step in the extraction of various
types of geometric and spectral information from hyperspectral full-waveform
LiDAR echoes. We present a new approach to deal with the ""Pseudo-monopulse""
waveform formed by the overlapped waveforms from multi-targets when they are
very close. We use one single skew-normal distribution (SND) model to fit
waveforms of all spectral channels first and count the geometric center
position distribution of the echoes to decide whether it contains
multi-targets. The geometric center position distribution of the
""Pseudo-monopulse"" presents aggregation and asymmetry with the change of
wavelength, while such an asymmetric phenomenon cannot be found from the echoes
of the single target. Both theoretical and experimental data verify the point.
Based on such observation, we further propose a hyperspectral waveform
decomposition method utilizing the SND mixture model with: 1) initializing new
waveform component parameters and their ranges based on the distinction of the
three characteristics (geometric center position, pulse width, and
skew-coefficient) between the echo and fitted SND waveform and 2) conducting
single-channel waveform decomposition for all channels and 3) setting
thresholds to find outlier channels based on statistical parameters of all
single-channel decomposition results (the standard deviation and the means of
geometric center position) and 4) re-conducting single-channel waveform
decomposition for these outlier channels. The proposed method significantly
improves the range resolution from 60cm to 5cm at most for a 4ns width laser
pulse and represents the state-of-the-art in ""Pseudo-monopulse"" waveform
decomposition.
","Yuhao Xia, Shilong Xu, Hui Shao, Ahui Hou, Jiajie Fang, Fei Han, Youlong Chen, Jiaqi Wen, Yuwei Chen, Yihua Hu",Yihua Hu,2023-03-03T03:06:14Z
"Deep Learning-Based Correction and Unmixing of Hyperspectral Images for
  Brain Tumor Surgery","  Hyperspectral Imaging (HSI) for fluorescence-guided brain tumor resection
enables visualization of differences between tissues that are not
distinguishable to humans. This augmentation can maximize brain tumor
resection, improving patient outcomes. However, much of the processing in HSI
uses simplified linear methods that are unable to capture the non-linear,
wavelength-dependent phenomena that must be modeled for accurate recovery of
fluorophore abundances. We therefore propose two deep learning models for
correction and unmixing, which can account for the nonlinear effects and
produce more accurate estimates of abundances. Both models use an
autoencoder-like architecture to process the captured spectra. One is trained
with protoporphyrin IX (PpIX) concentration labels. The other undergoes
semi-supervised training, first learning hyperspectral unmixing self-supervised
and then learning to correct fluorescence emission spectra for heterogeneous
optical and geometric properties using a reference white-light reflectance
spectrum in a few-shot manner. The models were evaluated against phantom and
pig brain data with known PpIX concentration; the supervised model achieved
Pearson correlation coefficients (R values) between the known and computed PpIX
concentrations of 0.997 and 0.990, respectively, whereas the classical approach
achieved only 0.93 and 0.82. The semi-supervised approach's R values were 0.98
and 0.91, respectively. On human data, the semi-supervised model gives
qualitatively more realistic results than the classical method, better removing
bright spots of specular reflectance and reducing the variance in PpIX
abundance over biopsies that should be relatively homogeneous. These results
show promise for using deep learning to improve HSI in fluorescence-guided
neurosurgery.
","David Black, Jaidev Gill, Andrew Xie, Benoit Liquet, Antonio Di leva, Walter Stummer, Eric Suero Molina",Eric Suero Molina,2024-02-06T07:04:35Z
"Evaluation of Deep Learning Semantic Segmentation for Land Cover Mapping
  on Multispectral, Hyperspectral and High Spatial Aerial Imagery","  In the rise of climate change, land cover mapping has become such an urgent
need in environmental monitoring. The accuracy of land cover classification has
gotten increasingly based on the improvement of remote sensing data. Land cover
classification using satellite imageries has been explored and become more
prevalent in recent years, but the methodologies remain some drawbacks of
subjective and time-consuming. Some deep learning techniques have been utilized
to overcome these limitations. However, most studies implemented just one image
type to evaluate algorithms for land cover mapping. Therefore, our study
conducted deep learning semantic segmentation in multispectral, hyperspectral,
and high spatial aerial image datasets for landcover mapping. This research
implemented a semantic segmentation method such as Unet, Linknet, FPN, and
PSPnet for categorizing vegetation, water, and others (i.e., soil and
impervious surface). The LinkNet model obtained high accuracy in IoU
(Intersection Over Union) at 0.92 in all datasets, which is comparable with
other mentioned techniques. In evaluation with different image types, the
multispectral images showed higher performance with the IoU, and F1-score are
0.993 and 0.997, respectively. Our outcome highlighted the efficiency and broad
applicability of LinkNet and multispectral image on land cover classification.
This research contributes to establishing an approach on landcover segmentation
via open source for long-term future application.
","Ilham Adi Panuntun, Ying-Nong Chen, Ilham Jamaluddin, Thi Linh Chi Tran",Thi Linh Chi Tran,2024-06-20T11:40:12Z
"CSAKD: Knowledge Distillation with Cross Self-Attention for
  Hyperspectral and Multispectral Image Fusion","  Hyperspectral imaging, capturing detailed spectral information for each
pixel, is pivotal in diverse scientific and industrial applications. Yet, the
acquisition of high-resolution (HR) hyperspectral images (HSIs) often needs to
be addressed due to the hardware limitations of existing imaging systems. A
prevalent workaround involves capturing both a high-resolution multispectral
image (HR-MSI) and a low-resolution (LR) HSI, subsequently fusing them to yield
the desired HR-HSI. Although deep learning-based methods have shown promising
in HR-MSI/LR-HSI fusion and LR-HSI super-resolution (SR), their substantial
model complexities hinder deployment on resource-constrained imaging devices.
This paper introduces a novel knowledge distillation (KD) framework for
HR-MSI/LR-HSI fusion to achieve SR of LR-HSI. Our KD framework integrates the
proposed Cross-Layer Residual Aggregation (CLRA) block to enhance efficiency
for constructing Dual Two-Streamed (DTS) network structure, designed to extract
joint and distinct features from LR-HSI and HR-MSI simultaneously. To fully
exploit the spatial and spectral feature representations of LR-HSI and HR-MSI,
we propose a novel Cross Self-Attention (CSA) fusion module to adaptively fuse
those features to improve the spatial and spectral quality of the reconstructed
HR-HSI. Finally, the proposed KD-based joint loss function is employed to
co-train the teacher and student networks. Our experimental results demonstrate
that the student model not only achieves comparable or superior LR-HSI SR
performance but also significantly reduces the model-size and computational
requirements. This marks a substantial advancement over existing
state-of-the-art methods. The source code is available at
https://github.com/ming053l/CSAKD.
","Chih-Chung Hsu, Chih-Chien Ni, Chia-Ming Lee, Li-Wei Kang",Li-Wei Kang,2024-06-28T05:25:57Z
"Hyperspectral Image Classification Based on Faster Residual Multi-branch
  Spiking Neural Network","  Convolutional neural network (CNN) performs well in Hyperspectral Image (HSI)
classification tasks, but its high energy consumption and complex network
structure make it difficult to directly apply it to edge computing devices. At
present, spiking neural networks (SNN) have developed rapidly in HSI
classification tasks due to their low energy consumption and event driven
characteristics. However, it usually requires a longer time step to achieve
optimal accuracy. In response to the above problems, this paper builds a
spiking neural network (SNN-SWMR) based on the leaky integrate-and-fire (LIF)
neuron model for HSI classification tasks. The network uses the spiking width
mixed residual (SWMR) module as the basic unit to perform feature extraction
operations. The spiking width mixed residual module is composed of spiking
mixed convolution (SMC), which can effectively extract spatial-spectral
features. Secondly, this paper designs a simple and efficient arcsine
approximate derivative (AAD), which solves the non-differentiable problem of
spike firing by fitting the Dirac function. Through AAD, we can directly train
supervised spike neural networks. Finally, this paper conducts comparative
experiments with multiple advanced HSI classification algorithms based on
spiking neural networks on six public hyperspectral data sets. Experimental
results show that the AAD function has strong robustness and a good fitting
effect. Meanwhile, compared with other algorithms, SNN-SWMR requires a time
step reduction of about 84%, training time, and testing time reduction of about
63% and 70% at the same accuracy. This study solves the key problem of SNN
based HSI classification algorithms, which has important practical significance
for promoting the practical application of HSI classification algorithms in
edge devices such as spaceborne and airborne devices.
","Yang Liu, Yahui Li, Rui Li, Liming Zhou, Lanxue Dang, Huiyu Mu, Qiang Ge",Qiang Ge,2024-09-18T00:51:01Z
HSIGene: A Foundation Model For Hyperspectral Image Generation,"  Hyperspectral image (HSI) plays a vital role in various fields such as
agriculture and environmental monitoring. However, due to the expensive
acquisition cost, the number of hyperspectral images is limited, degenerating
the performance of downstream tasks. Although some recent studies have
attempted to employ diffusion models to synthesize HSIs, they still struggle
with the scarcity of HSIs, affecting the reliability and diversity of the
generated images. Some studies propose to incorporate multi-modal data to
enhance spatial diversity, but the spectral fidelity cannot be ensured. In
addition, existing HSI synthesis models are typically uncontrollable or only
support single-condition control, limiting their ability to generate accurate
and reliable HSIs. To alleviate these issues, we propose HSIGene, a novel HSI
generation foundation model which is based on latent diffusion and supports
multi-condition control, allowing for more precise and reliable HSI generation.
To enhance the spatial diversity of the training data while preserving spectral
fidelity, we propose a new data augmentation method based on spatial
super-resolution, in which HSIs are upscaled first, and thus abundant training
patches could be obtained by cropping the high-resolution HSIs. In addition, to
improve the perceptual quality of the augmented data, we introduce a novel
two-stage HSI super-resolution framework, which first applies RGB bands
super-resolution and then utilizes our proposed Rectangular Guided Attention
Network (RGAN) for guided HSI super-resolution. Experiments demonstrate that
the proposed model is capable of generating a vast quantity of realistic HSIs
for downstream tasks such as denoising and super-resolution. The code and
models are available at https://github.com/LiPang/HSIGene.
","Li Pang, Xiangyong Cao, Datao Tang, Shuang Xu, Xueru Bai, Feng Zhou, Deyu Meng",Deyu Meng,2024-09-19T05:17:44Z
"Photospheric hot spots at solar coronal loop footpoints revealed by
  hyperspectral imaging observations","  Poynting flux generated by random shuffling of photospheric magnetic
footpoints is transferred through the upper atmosphere of the Sun where the
plasma is heated to over 1 MK in the corona. High spatiotemporal resolution
observations of the lower atmosphere at the base of coronal magnetic loops are
crucial to better understand the nature of the footpoint dynamics and the
details of magnetic processes that eventually channel energy into the corona.
Here we report high spatial resolution ($\sim$0.1\arcsec) and cadence (1.33 s)
hyperspectral imaging of the solar H$\alpha$ line, acquired by the Microlensed
Hyperspectral Imager prototype installed at the Swedish 1-m Solar Telescope,
that reveal photospheric hot spots at the base of solar coronal loops. These
hot spots manifest themselves as H$\alpha$ wing enhancements, occurring on
small spatial scales of $\sim$0.2\arcsec, and timescales of less than 100 s. By
assuming that the H$\alpha$ wings and the continuum form under the local
thermodynamic equilibrium condition, we inverted the H$\alpha$ line profiles
and found that the hot spots are compatible with a temperature increase of
about 1000 K above the ambient quiet-Sun temperature. The H$\alpha$ wing
integrated Stokes $V/I$ maps indicate that hot spots are related to magnetic
patches with field strengths comparable to or even stronger than the
surrounding network elements. But they do not show the presence of parasitic
polarity magnetic field that would support the interpretation that these hot
spots are reconnection-driven Ellerman bombs. Therefore, we interpret these
features as proxies of locations where convection-driven magnetic field
intensification in the photosphere can lead to energy transfer into higher
layers. We suggest that such hot spots at coronal loop footpoints may be
indicative of the specific locations and onset of energy flux injection into
the upper atmosphere.
","L. P. Chitta, M. van Noort, H. N. Smitha, E. R. Priest, L. H. M. Rouppe van der Voort",L. H. M. Rouppe van der Voort,2024-10-07T12:04:02Z
"Concentration-modulation FT emission spectroscopy of TiCl_4/He plasma.
  Analysis of the C ^4Δ- X ^4 ΦΔv=0 perturbed transitions of
  TiCl","  A TiCl_4/He plasma is observed by high resolution double-modulation FTS using
concentration-modulation as a selective detection method. Analysis of the C
^4\Delta- X ^4 \Phi \Delta v=0 transitions of ^48Ti^35Cl reveals perturbations
affecting the C ^4\Delta_{1/2} sub-state.
","Hervé Herbin, Robert Farrenq, Guy Guelachvili, Nathalie Picqué",Nathalie Picqué,2007-11-24T18:01:44Z
Support Vector classifiers for Land Cover Classification,"  Support vector machines represent a promising development in machine learning
research that is not widely used within the remote sensing community. This
paper reports the results of Multispectral(Landsat-7 ETM+) and Hyperspectral
DAIS)data in which multi-class SVMs are compared with maximum likelihood and
artificial neural network methods in terms of classification accuracy. Our
results show that the SVM achieves a higher level of classification accuracy
than either the maximum likelihood or the neural classifier, and that the
support vector machine can be used with small training datasets and
high-dimensional data.
","Mahesh Pal, Paul M. Mather",Paul M. Mather,2008-02-15T04:53:33Z
"An Infrared Spatial and Frequency Selective Metamaterial Perfect
  Absorber","  We demonstrate, for the first time, a spatially dependent metamaterial
perfect absorber operating in the infrared regime. We achieve an experimental
absorption of 97% at a wavelength of 6.0 microns, and our results agree well
with numerical full-wave simulations. By using two different metamaterial
sublattices we experimentally demonstrate a spatial and frequency varying
absorption which may have many relevant applications including hyperspectral
sub-sampling imaging
","Xianliang Liu, Tatiana Starr, Anthony Starr, Willie J. Padilla",Willie J. Padilla,2010-02-10T20:28:24Z
Information and Communication Technology in Combating Counterfeit Drugs,"  Pharma frauds are on the rise, counterfeit drugs are giving sleepless nights
to patients, pharmaceutical companies and governments. The laws prohibiting the
sales of counterfeit drugs cannot succeed without technological interventions.
Several analytical techniques and tools including spectroscopy, holograms,
barcoding, differentiated packing, radio frequency identification,
fingerprints, hyperspectral imaging etc. have been employed over the years in
combating this menace; however this challenge is becoming more sophisticated
with the evolution of the World Wide Web and online pharmacies. This paper
presents a review on the contribution of Information and Communication
Technology (ICT) as a drug counterfeit countermeasure.
",Haruna Isah,Haruna Isah,2012-11-01T15:29:05Z
"Hydrothermal alteration at the Panorama Formation, North Pole Dome,
  Pilbara Craton, Western Australia","  An airborne hyperspectral remote sensing dataset was obtained of the North
Pole Dome region of the Pilbara Craton in October 2002. It has been analyzed
for indications of hydrothermal minerals. Here we report on the identification
and mapping of hydrothermal minerals in the 3.459 Ga Panorama Formation and
surrounding strata. The spatial distribution of a pattern of subvertical
pyrophyllite rich veins connected to a pyrophyllite rich palaeohorizontal layer
is interpreted to represent the base of an acid-sulfate epithermal system that
is unconformably overlain by the stromatolitic 3.42 Ga Strelley Pool Chert.
","Adrian J. Brown, Thomas J. Cudahy, Malcolm R. Walter",Malcolm R. Walter,2014-01-24T20:51:20Z
Consistency Analysis for the Doubly Stochastic Dirichlet Process,"  This technical report proves components consistency for the Doubly Stochastic
Dirichlet Process with exponential convergence of posterior probability. We
also present the fundamental properties for DSDP as well as inference
algorithms. Simulation toy experiment and real-world experiment results for
single and multi-cluster also support the consistency proof. This report is
also a support document for the paper ""Computationally Efficient Hyperspectral
Data Learning Based on the Doubly Stochastic Dirichlet Process"".
","Xing Sun, Nelson H. C. Yung, Edmund Y. Lam, Hayden K. -H. So",Hayden K. -H. So,2016-05-24T10:13:19Z
"3D zigzag for multislicing, multiband and video processing","  We present a 3D zigzag rafter (first in literature) which allows us to obtain
the exact sequence of spectral components after application of Discrete Cosine
Transform 3D (DCT-2D) over a cube. Such cube represents part of a video or
eventually a group of images such as multislicing (e.g., Magnetic Resonance or
Computed Tomography imaging) and multi or hyperspectral imagery (optical
satellites). Besides, we present a new version of the traditional 2D zigzag,
including the case of rectangular blocks. Finally, all the attached code is
done in MATLAB, and that code serves both blocks of pixels or blocks of blocks.
",Mario Mastriani,Mario Mastriani,2016-06-16T16:45:39Z
Dictionary-based Tensor Canonical Polyadic Decomposition,"  To ensure interpretability of extracted sources in tensor decomposition, we
introduce in this paper a dictionary-based tensor canonical polyadic
decomposition which enforces one factor to belong exactly to a known
dictionary. A new formulation of sparse coding is proposed which enables high
dimensional tensors dictionary-based canonical polyadic decomposition. The
benefits of using a dictionary in tensor decomposition models are explored both
in terms of parameter identifiability and estimation accuracy. Performances of
the proposed algorithms are evaluated on the decomposition of simulated data
and the unmixing of hyperspectral images.
","Jérémy E. Cohen, Nicolas Gillis",Nicolas Gillis,2017-04-03T12:03:39Z
"Pump-probe micro-spectroscopy by means of an ultra-fast acousto-optics
  delay line","  We demonstrate femtosecond pump-probe transient absorption spectroscopy using
a programmable dispersive filter as an ultra-fast delay line. Combined with
fast synchronous detection this delay line allows for recording of 6 ps decay
traces at 34 kHz. With such acquisition speed we perform single point
pump-probe spectroscopy on bulk samples in 80 $\mu$s and hyperspectral
pump-probe imaging over a field of view of 100 $\mu$m in less than a second.
The usability of the method is illustrated on a showcase experiment to image
and discriminate two pigments in a mixture.
","Xavier Audier, Naveen Balla, Herve Rigneault",Herve Rigneault,2018-05-04T12:34:30Z
A Novel Energy Resolved X-Ray Semiconductor Detector,"  The hyperspectral X-ray imaging has been long sought in various fields from
material analysis to medical diagnosis. Here we propose a new semiconductor
detector structure to realize energy-resolved imaging at potentially low cost.
The working principle is based on the strong energy-dependent absorption of
X-ray in solids. Namely, depending on the energy, X-ray photons experience
dramatically different attenuation. An array or matrix of semiconductor cells
is to map the X-ray intensity along its trajectory. The X-ray spectrum could be
extracted from a Laplace like transform or even a supervised machine learning.
We demonstrated an energy-resolved X-ray detection with a regular silicon
camera.
","Tengfei Yan, Chunlei Yang, Xiaodong Cui",Xiaodong Cui,2019-07-25T01:52:56Z
"A Comparison of Adaptive and Template Matching Techniques for
  Radio-Isotope Identification","  We compare and contrast the effectiveness of a set of adaptive and
non-adaptive algorithms for isotope identification based on gamma-ray spectra.
One dimensional energy spectra are simulated for a variety of dwell-times and
source to detector distances in order to reflect conditions typically
encountered in radiological emergency response and environmental monitoring
applications. We find that adaptive methods are more accurate and
computationally efficient than non-adaptive in cases of operational interest.
","Emma J. Hague, Mark Kamuda, William P. Ford, Eric T. Moore, Johanna Turk",Johanna Turk,2019-08-26T17:41:54Z
"Impulse Denoising From Hyper-Spectral Images: A Blind Compressed Sensing
  Approach","  In this work we propose a technique to remove sparse impulse noise from
hyperspectral images. Our algorithm accounts for the spatial redundancy and
spectral correlation of such images. The proposed method is based on the
recently introduced Blind Compressed Sensing (BCS) framework, i.e. it
empirically learns the spatial and spectral sparsifying dictionaries while
denoising the images. The BCS framework differs from existing CS techniques -
which assume the sparsifying dictionaries to be data independent, and from
prior dictionary learning studies which learn the dictionary in an offline
training phase. Our proposed formulation have shown over 5 dB improvement in
PSNR over other techniques.
","Angshul Majumdar, Naushad Ansari, Hemant Aggarwal, Pravesh Biyani",Pravesh Biyani,2019-12-11T12:43:56Z
"Label Consistent Transform Learning for Hyperspectral Image
  Classification","  This work proposes a new image analysis tool called Label Consistent
Transform Learning (LCTL). Transform learning is a recent unsupervised
representation learning approach; we add supervision by incorporating a label
consistency constraint. The proposed technique is especially suited for
hyper-spectral image classification problems owing to its ability to learn from
fewer samples. We have compared our proposed method on state-of-the-art
techniques like label consistent KSVD, Stacked Autoencoder, Deep Belief Network
and Convolutional Neural Network. Our method yields considerably better results
(more than 0.1 improvement in Kappa coefficient) than all the aforesaid
techniques.
","Jyoti Maggu, Hemant K. Aggarwal, Angshul Majumdar",Angshul Majumdar,2019-12-11T09:55:54Z
"Deep connections between learning from limited labels & physical
  parameter estimation -- inspiration for regularization","  Recently established equivalences between differential equations and the
structure of neural networks enabled some interpretation of training of a
neural network as partial-differential-equation (PDE) constrained optimization.
We add to the previously established connections, explicit regularization that
is particularly beneficial in the case of single large-scale examples with
partial annotation. We show that explicit regularization of model parameters in
PDE constrained optimization translates to regularization of the network
output. Examination of the structure of the corresponding Lagrangian and
backpropagation algorithm do not reveal additional computational challenges. A
hyperspectral imaging example shows that minimum prior information together
with cross-validation for optimal regularization parameters boosts the
segmentation accuracy.
",Bas Peters,Bas Peters,2020-03-17T19:33:50Z
"A vignetting advantage for thin-film filter arrays in hyperspectral
  cameras","  Vignetting in camera lenses is generally seen as something to avoid. For
spectral cameras with thin-film interference filters, however, we argue that
vignetting can be an advantage. When illuminated by focused light, the
bandwidth of interference filters increases with the chief-ray angle, causing
position-dependent smoothing of the spectra. We show that vignetting can be
used to reduce smoothing and preserve important spectral features. Furthermore,
we demonstrate that by adding additional vignetting to a lens, measurements can
be made more consistent across the scene. This makes vignetting a useful
parameter during spectral camera design.
","Thomas Goossens, Bert Geelen, Andy Lambrechts, Chris Van Hoof",Chris Van Hoof,2020-03-26T15:45:43Z
Hybrid Metasurfaces for Simultaneous Focusing and Filtering,"  This work presents the design and fabrication of simple, polymeric,
structure-based optical filters that simultaneously focus light. These filters
represent a novel design at the boundary between diffractive optics and
metasurfaces that may provide significant advantages for both digital and
hyperspectral imaging. The fabrication process for the proposed filters
resembles 3D printing, and is based on direct laser writing of a polymeric
material using two-photon lithography. In addition, printed structures could be
used to create molds for nanoimprint replication and mass production. Filters
for visible and near-infrared wavelengths were designed using finite difference
time domain (FDTD) simulations.
","Mansoor A. Sultan, Fatih Balli, Daniel L. Lau, J. T. Hastings",J. T. Hastings,2020-09-16T01:00:36Z
"Averaging Atmospheric Gas Concentration Data using Wasserstein
  Barycenters","  Hyperspectral satellite images report greenhouse gas concentrations worldwide
on a daily basis. While taking simple averages of these images over time
produces a rough estimate of relative emission rates, atmospheric transport
means that simple averages fail to pinpoint the source of these emissions. We
propose using Wasserstein barycenters coupled with weather data to average gas
concentration data sets and better concentrate the mass around significant
sources.
","Mathieu Barré, Clément Giron, Matthieu Mazzolini, Alexandre d'Aspremont",Alexandre d'Aspremont,2020-10-06T14:31:25Z
Single-pixel diffuser camera,"  We present a compact, diffuser-assisted, single-pixel computational camera. A
rotating ground glass diffuser is adopted, in preference to a commonly used
digital micro-mirror device (DMD), to encode a two-dimensional (2D) image into
single-pixel signals. We retrieve images with an 8.8% sampling ratio after the
calibration of the pseudo-random pattern of the diffuser under incoherent
illumination. Furthermore, we demonstrate hyperspectral imaging with line array
detection by adding a diffraction grating. The implementation results in a
cost-effective single-pixel camera for high-dimensional imaging, with potential
for imaging in non-visible wavebands.
","Baolei Liu, Fan Wang, Chaohao Chen, David McGloin",David McGloin,2021-05-06T06:37:26Z
Compressive classification and the rare eclipse problem,"  This paper addresses the fundamental question of when convex sets remain
disjoint after random projection. We provide an analysis using ideas from
high-dimensional convex geometry. For ellipsoids, we provide a bound in terms
of the distance between these ellipsoids and simple functions of their
polynomial coefficients. As an application, this theorem provides bounds for
compressive classification of convex sets. Rather than assuming that the data
to be classified is sparse, our results show that the data can be acquired via
very few measurements yet will remain linearly separable. We demonstrate the
feasibility of this approach in the context of hyperspectral imaging.
","Afonso S. Bandeira, Dustin G. Mixon, Benjamin Recht",Benjamin Recht,2014-04-11T19:49:05Z
"Fast and Lightweight Rate Control for Onboard Predictive Coding of
  Hyperspectral Images","  Predictive coding is attractive for compression of hyperspecral images
onboard of spacecrafts in light of the excellent rate-distortion performance
and low complexity of recent schemes. In this letter we propose a rate control
algorithm and integrate it in a lossy extension to the CCSDS-123 lossless
compression recommendation. The proposed rate algorithm overhauls our previous
scheme by being orders of magnitude faster and simpler to implement, while
still providing the same accuracy in terms of output rate and comparable or
better image quality.
","Diego Valsesia, Enrico Magli",Enrico Magli,2017-01-30T08:45:39Z
Introduction to Nonnegative Matrix Factorization,"  In this paper, we introduce and provide a short overview of nonnegative
matrix factorization (NMF). Several aspects of NMF are discussed, namely, the
application in hyperspectral imaging, geometry and uniqueness of NMF solutions,
complexity, algorithms, and its link with extended formulations of polyhedra.
In order to put NMF into perspective, the more general problem class of
constrained low-rank matrix approximation problems is first briefly introduced.
",Nicolas Gillis,Nicolas Gillis,2017-03-02T08:23:04Z
Orthogonal Nonnegative Tucker Decomposition,"  In this paper, we study the nonnegative tensor data and propose an orthogonal
nonnegative Tucker decomposition (ONTD). We discuss some properties of ONTD and
develop a convex relaxation algorithm of the augmented Lagrangian function to
solve the optimization problem. The convergence of the algorithm is given. We
employ ONTD on the image data sets from the real world applications including
face recognition, image representation, hyperspectral unmixing. Numerical
results are shown to illustrate the effectiveness of the proposed algorithm.
","Junjun Pan, Michael K. Ng, Ye Liu, Xiongjun Zhang, Hong Yan",Hong Yan,2019-10-21T11:18:21Z
"Characterizing Transition-Metal Dichalcogenide Thin-Films using
  Hyperspectral Imaging and Machine Learning","  Atomically thin polycrystalline transition-metal dichalcogenides (TMDs) are
relevant to both fundamental science investigation and applications. TMD
thin-films present uniquely difficult challenges to effective nanoscale
crystalline characterization. Here we present a method to quickly characterize
the nanocrystalline grain structure and texture of monolayer WS2 films using
scanning nanobeam electron diffraction coupled with multivariate statistical
analysis of the resulting data. Our analysis pipeline is highly generalizable
and is a useful alternative to the time consuming, complex, and
system-dependent methodology traditionally used to analyze spatially resolved
electron diffraction measurements.
","Brian Shevitski, Christopher T. Chen, Christoph Kastl, Tevye Kuykendall, Adam Schwartzberg, Shaul Aloni, Alex Zettl",Alex Zettl,2020-01-30T02:32:24Z
"Accelerating computed tomographic imaging spectrometer reconstruction
  using a parallel algorithm exploiting spatial shift-invariance","  Computed Tomographic Imaging Spectrometers (CTIS) capture hyperspectral
images in realtime. However, post processing the imagery can require enormous
computational resources; thus, limiting its application to non-realtime
scenarios. To overcome these challenges we developed a highly parallelizable
algorithm that exploits spatial shift-invariance. To demonstrate the
versatility of our new algorithm, we developed implementations on a desktop and
an embedded graphics processing unit (GPU). To our knowledge, our results show
the fastest image reconstruction times reported.
","Larz White, W. Bryan Bell, Ryan Haygood",Ryan Haygood,2020-06-02T12:51:54Z
"Partial least squares discriminant analysis: A dimensionality reduction
  method to classify hyperspectral data","  The recent development of more sophisticated spectroscopic methods allows
acqui- sition of high dimensional datasets from which valuable information may
be extracted using multivariate statistical analyses, such as dimensionality
reduction and automatic classification (supervised and unsupervised). In this
work, a supervised classification through a partial least squares discriminant
analysis (PLS-DA) is performed on the hy- perspectral data. The obtained
results are compared with those obtained by the most commonly used
classification approaches.
","Mario Fordellone, Andrea Bellincontro, Fabio Mencarelli",Fabio Mencarelli,2018-06-25T09:37:27Z
Efficient and Parallel Separable Dictionary Learning,"  Separable, or Kronecker product, dictionaries provide natural decompositions
for 2D signals, such as images. In this paper, we describe a highly
parallelizable algorithm that learns such dictionaries which reaches sparse
representations competitive with the previous state of the art dictionary
learning algorithms from the literature but at a lower computational cost. We
highlight the performance of the proposed method to sparsely represent image
and hyperspectral data, and for image denoising.
","Cristian Rusu, Paul Irofti",Paul Irofti,2020-07-07T21:46:32Z
"Some detection tests for low complexity data models and unknown
  background distribution","  We consider several detection situations where, under the alternative
hypothesis, the signal admits a low complexity model and, under both the null
and the alternative hypotheses, the distribution of the background noise is
{unknown}. We present several detection strategies for such cases, whose design
relies on exogenous or on endogenous data. These testing procedures have been
inspired by and are applied to two specific problems in Astrophysics, namely
the detection of exoplanets from radial velocity curves and of distant galaxies
in hyperspectral datacubes.
","D. Mary, S. Bourguignon, E. Roquain, S. Sulis, M. Perrot-Dockes",M. Perrot-Dockes,2020-12-07T08:53:12Z
"Successive Nonnegative Projection Algorithm for Linear Quadratic
  Mixtures","  In this work, we tackle the problem of hyperspectral (HS) unmixing by
departing from the usual linear model and focusing on a Linear-Quadratic (LQ)
one. The proposed algorithm, referred to as Successive Nonnegative Projection
Algorithm for Linear Quadratic mixtures (SNPALQ), extends the Successive
Nonnegative Projection Algorithm (SNPA), designed to address the unmixing
problem under a linear model. By explicitly modeling the product terms inherent
to the LQ model along the iterations of the SNPA scheme, the nonlinear
contributions in the mixing are mitigated, thus improving the separation
quality. The approach is shown to be relevant in a realistic numerical
experiment.
","Christophe Kervazo, Nicolas Gillis, Nicolas Dobigeon",Nicolas Dobigeon,2020-12-08T18:29:56Z
Exploring the high dimensional geometry of HSI features,"  We explore feature space geometries induced by the 3-D Fourier scattering
transform and deep neural network with extended attribute profiles on four
standard hyperspectral images. We examine the distances and angles of class
means, the variability of classes, and their low-dimensional structures. These
statistics are compared to that of raw features, and our results provide
insight into the vastly different properties of these two methods. We also
explore a connection with the newly observed deep learning phenomenon of neural
collapse.
","Wojciech Czaja, Ilya Kavalerov, Weilin Li",Weilin Li,2021-03-01T20:48:43Z
"A 3D 2D convolutional Neural Network Model for Hyperspectral Image
  Classification","  In the proposed SEHybridSN model, a dense block was used to reuse shallow
feature and aimed at better exploiting hierarchical spatial spectral feature.
Subsequent depth separable convolutional layers were used to discriminate the
spatial information. Further refinement of spatial spectral features was
realized by the channel attention method, which were performed behind every 3D
convolutional layer and every 2D convolutional layer. Experiment results
indicate that our proposed model learn more discriminative spatial spectral
features using very few training data. SEHybridSN using only 0.05 and 0.01
labeled data for training, a very satisfactory performance is obtained.
","Jiaxin Cao, Xiaoyan Li",Xiaoyan Li,2021-11-19T16:09:25Z
"Identifiable Solutions to Foreground Signature Extraction from
  Hyperspectral Images in an Intimate Mixing Scenario","  The problem of foreground material signature extraction in an intimate
(nonlinear) mixing setting is considered. It is possible for a foreground
material signature to appear in combination with multiple background material
signatures. We explore a framework for foreground material signature extraction
based on a patch model that accounts for such background variation. We identify
data conditions under which a foreground material signature can be extracted up
to scaling and elementwise-inverse variations. We present algorithms based on
volume minimization and endpoint member identification to recover foreground
material signatures under these conditions. Numerical experiments on real and
synthetic data illustrate the efficacy of the proposed algorithms.
","Jarrod Hollis, Raviv Raich, Jinsub Kim, Barak Fishbain, Shai Kendler",Shai Kendler,2023-03-20T22:18:49Z
Self-Supervised Learning for Covariance Estimation,"  We consider the use of deep learning for covariance estimation. We propose to
globally learn a neural network that will then be applied locally at inference
time. Leveraging recent advancements in self-supervised foundational models, we
train the network without any labeling by simply masking different samples and
learning to predict their covariance given their surrounding neighbors. The
architecture is based on the popular attention mechanism. Its main advantage
over classical methods is the automatic exploitation of global characteristics
without any distributional assumptions or regularization. It can be pre-trained
as a foundation model and then be repurposed for various downstream tasks,
e.g., adaptive target detection in radar or hyperspectral imagery.
","Tzvi Diskin, Ami Wiesel",Ami Wiesel,2024-03-13T16:16:20Z
Enhancing hyperspectral image unmixing with spatial correlations,"  This paper describes a new algorithm for hyperspectral image unmixing. Most
of the unmixing algorithms proposed in the literature do not take into account
the possible spatial correlations between the pixels. In this work, a Bayesian
model is introduced to exploit these correlations. The image to be unmixed is
assumed to be partitioned into regions (or classes) where the statistical
properties of the abundance coefficients are homogeneous. A Markov random field
is then proposed to model the spatial dependency of the pixels within any
class. Conditionally upon a given class, each pixel is modeled by using the
classical linear mixing model with additive white Gaussian noise. This strategy
is investigated the well known linear mixing model. For this model, the
posterior distributions of the unknown parameters and hyperparameters allow
ones to infer the parameters of interest. These parameters include the
abundances for each pixel, the means and variances of the abundances for each
class, as well as a classification map indicating the classes of all pixels in
the image. To overcome the complexity of the posterior distribution of
interest, we consider Markov chain Monte Carlo methods that generate samples
distributed according to the posterior of interest. The generated samples are
then used for parameter and hyperparameter estimation. The accuracy of the
proposed algorithms is illustrated on synthetic and real data.
","Olivier Eches, Nicolas Dobigeon, Jean-Yves Tourneret",Jean-Yves Tourneret,2010-02-04T19:17:04Z
Fusion between ground- and space-based mid-infrared observations,"  Mid-infrared astronomy (operating at wavelengths ranging from 2 to 25 $\mu$m)
has progressed significantly in the last decades, thanks to the improvement of
detector techniques and the growing diameter of telescopes. Space observatories
benefit from the absence of atmospheric absorption, allowing to reach the very
high sensitivities needed to perform 3D hyperspectral observations, but
telescopes are limited in diameter ($< 1$ meter) and therefore provide
observations at low angular resolution (typically a few seconds of arc). On the
other hand, ground-based facilities suffer from strong atmospheric absorption
but use large telescopes (above 8m diameter) to perform sub-arcsecond angular
resolution imaging through selected windows in the mid-infrared range. In this
Paper, we present a method based on Lee and Seung's Non-negative Matrix
Factorization (NMF) to merge data from space and ground based mid-infrared
(mid-IR) telescopes in order to combine the best sensitivity, spectral coverage
and angular resolution. We prove the efficiency of this technique when applied
to real mid-IR astronomical data. We suggest that this method can be applied to
any combination of low and high spatial resolution positive hyperspectral
datasets, as long as the spectral variety of the data allows decomposition into
components using NMF.
","O. Berne, A. G. G. M. Tielens, P. Pilleri, C. Joblin",C. Joblin,2010-03-03T13:56:32Z
"Compressive Fluorescence Microscopy for Biological and Hyperspectral
  Imaging","  The mathematical theory of compressed sensing (CS) asserts that one can
acquire signals from measurements whose rate is much lower than the total
bandwidth. Whereas the CS theory is now well developed, challenges concerning
hardware implementations of CS-based acquisition devices---especially in
optics---have only started being addressed. This paper presents an
implementation of compressive sensing in fluorescence microscopy and its
applications to biomedical imaging. Our CS microscope combines a dynamic
structured wide-field illumination and a fast and sensitive single-point
fluorescence detection to enable reconstructions of images of fluorescent
beads, cells and tissues with undersampling ratios (between the number of
pixels and number of measurements) up to 32. We further demonstrate a
hyperspectral mode and record images with 128 spectral channels and
undersampling ratios up to 64, illustrating the potential benefits of CS
acquisition for higher dimensional signals which typically exhibits extreme
redundancy. Altogether, our results emphasize the interest of CS schemes for
acquisition at a significantly reduced rate and point out to some remaining
challenges for CS fluorescence microscopy.
","Vincent Studer, Jerome Bobin, Makhlad Chahid, S. Hamed Shams Mousavi, Emmanuel Candes, Maxime Dahan",Maxime Dahan,2012-01-03T14:55:33Z
"Hyperspectral Unmixing Overview: Geometrical, Statistical, and Sparse
  Regression-Based Approaches","  Imaging spectrometers measure electromagnetic energy scattered in their
instantaneous field view in hundreds or thousands of spectral channels with
higher spectral resolution than multispectral cameras. Imaging spectrometers
are therefore often referred to as hyperspectral cameras (HSCs). Higher
spectral resolution enables material identification via spectroscopic analysis,
which facilitates countless applications that require identifying materials in
scenarios unsuitable for classical spectroscopic analysis. Due to low spatial
resolution of HSCs, microscopic material mixing, and multiple scattering,
spectra measured by HSCs are mixtures of spectra of materials in a scene. Thus,
accurate estimation requires unmixing. Pixels are assumed to be mixtures of a
few materials, called endmembers. Unmixing involves estimating all or some of:
the number of endmembers, their spectral signatures, and their abundances at
each pixel. Unmixing is a challenging, ill-posed inverse problem because of
model inaccuracies, observation noise, environmental conditions, endmember
variability, and data set size. Researchers have devised and investigated many
models searching for robust, stable, tractable, and accurate unmixing
algorithms. This paper presents an overview of unmixing methods from the time
of Keshava and Mustard's unmixing tutorial [1] to the present. Mixing models
are first discussed. Signal-subspace, geometrical, statistical, sparsity-based,
and spatial-contextual unmixing algorithms are described. Mathematical problems
and potential solutions are described. Algorithm characteristics are
illustrated experimentally.
","José M. Bioucas-Dias, Antonio Plaza, Nicolas Dobigeon, Mario Parente, Qian Du, Paul Gader, Jocelyn Chanussot",Jocelyn Chanussot,2012-02-28T17:30:39Z
Nonlinear Dynamic Field Embedding: On Hyperspectral Scene Visualization,"  Graph embedding techniques are useful to characterize spectral signature
relations for hyperspectral images. However, such images consists of disjoint
classes due to spatial details that are often ignored by existing graph
computing tools. Robust parameter estimation is a challenge for kernel
functions that compute such graphs. Finding a corresponding high quality
coordinate system to map signature relations remains an open research question.
We answer positively on these challenges by first proposing a kernel function
of spatial and spectral information in computing neighborhood graphs. Secondly,
the study exploits the force field interpretation from mechanics and devise a
unifying nonlinear graph embedding framework. The generalized framework leads
to novel unsupervised multidimensional artificial field embedding techniques
that rely on the simple additive assumption of pair-dependent attraction and
repulsion functions. The formulations capture long range and short range
distance related effects often associated with living organisms and help to
establish algorithmic properties that mimic mutual behavior for the purpose of
dimensionality reduction. The main benefits from the proposed models includes
the ability to preserve the local topology of data and produce quality
visualizations i.e. maintaining disjoint meaningful neighborhoods. As part of
evaluation, visualization, gradient field trajectories, and semisupervised
classification experiments are conducted for image scenes acquired by multiple
sensors at various spatial resolutions over different types of objects. The
results demonstrate the superiority of the proposed embedding framework over
various widely used methods.
",Dalton Lunga 'and' Okan Ersoy,Dalton Lunga 'and' Okan Ersoy,2012-11-28T17:39:16Z
Spectral Unmixing via Data-guided Sparsity,"  Hyperspectral unmixing, the process of estimating a common set of spectral
bases and their corresponding composite percentages at each pixel, is an
important task for hyperspectral analysis, visualization and understanding.
From an unsupervised learning perspective, this problem is very
challenging---both the spectral bases and their composite percentages are
unknown, making the solution space too large. To reduce the solution space,
many approaches have been proposed by exploiting various priors. In practice,
these priors would easily lead to some unsuitable solution. This is because
they are achieved by applying an identical strength of constraints to all the
factors, which does not hold in practice. To overcome this limitation, we
propose a novel sparsity based method by learning a data-guided map to describe
the individual mixed level of each pixel. Through this data-guided map, the
$\ell_{p}(0<p<1)$ constraint is applied in an adaptive manner. Such
implementation not only meets the practical situation, but also guides the
spectral bases toward the pixels under highly sparse constraint. What's more,
an elegant optimization scheme as well as its convergence proof have been
provided in this paper. Extensive experiments on several datasets also
demonstrate that the data-guided map is feasible, and high quality unmixing
results could be obtained by our method.
","Feiyun Zhu, Ying Wang, Bin Fan, Gaofeng Meng, Shiming Xiang, Chunhong Pan",Chunhong Pan,2014-03-13T03:29:22Z
"Effective Spectral Unmixing via Robust Representation and Learning-based
  Sparsity","  Hyperspectral unmixing (HU) plays a fundamental role in a wide range of
hyperspectral applications. It is still challenging due to the common presence
of outlier channels and the large solution space. To address the above two
issues, we propose a novel model by emphasizing both robust representation and
learning-based sparsity. Specifically, we apply the $\ell_{2,1}$-norm to
measure the representation error, preventing outlier channels from dominating
our objective. In this way, the side effects of outlier channels are greatly
relieved. Besides, we observe that the mixed level of each pixel varies over
image grids. Based on this observation, we exploit a learning-based sparsity
method to simultaneously learn the HU results and a sparse guidance map. Via
this guidance map, the sparsity constraint in the $\ell_{p}\!\left(\!0\!<\!
p\!\leq\!1\right)$-norm is adaptively imposed according to the learnt mixed
level of each pixel. Compared with state-of-the-art methods, our model is
better suited to the real situation, thus expected to achieve better HU
results. The resulted objective is highly non-convex and non-smooth, and so it
is hard to optimize. As a profound theoretical contribution, we propose an
efficient algorithm to solve it. Meanwhile, the convergence proof and the
computational complexity analysis are systematically provided. Extensive
evaluations verify that our method is highly promising for the HU task---it
achieves very accurate guidance maps and much better HU results compared with
state-of-the-art methods.
","Feiyun Zhu, Ying Wang, Bin Fan, Gaofeng Meng, Chunhong Pan",Chunhong Pan,2014-09-02T12:36:53Z
"Collaborative sparse regression using spatially correlated supports -
  Application to hyperspectral unmixing","  This paper presents a new Bayesian collaborative sparse regression method for
linear unmixing of hyperspectral images. Our contribution is twofold; first, we
propose a new Bayesian model for structured sparse regression in which the
supports of the sparse abundance vectors are a priori spatially correlated
across pixels (i.e., materials are spatially organised rather than randomly
distributed at a pixel level). This prior information is encoded in the model
through a truncated multivariate Ising Markov random field, which also takes
into consideration the facts that pixels cannot be empty (i.e, there is at
least one material present in each pixel), and that different materials may
exhibit different degrees of spatial regularity. Secondly, we propose an
advanced Markov chain Monte Carlo algorithm to estimate the posterior
probabilities that materials are present or absent in each pixel, and,
conditionally to the maximum marginal a posteriori configuration of the
support, compute the MMSE estimates of the abundance vectors. A remarkable
property of this algorithm is that it self-adjusts the values of the parameters
of the Markov random field, thus relieving practitioners from setting
regularisation parameters by cross-validation. The performance of the proposed
methodology is finally demonstrated through a series of experiments with
synthetic and real data and comparisons with other algorithms from the
literature.
","Yoann Altmann, Marcelo Pereyra, Jose Bioucas-Dias",Jose Bioucas-Dias,2014-09-29T14:10:16Z
Dimensionality Reduction via Regression in Hyperspectral Imagery,"  This paper introduces a new unsupervised method for dimensionality reduction
via regression (DRR). The algorithm belongs to the family of invertible
transforms that generalize Principal Component Analysis (PCA) by using
curvilinear instead of linear features. DRR identifies the nonlinear features
through multivariate regression to ensure the reduction in redundancy between
he PCA coefficients, the reduction of the variance of the scores, and the
reduction in the reconstruction error. More importantly, unlike other nonlinear
dimensionality reduction methods, the invertibility, volume-preservation, and
straightforward out-of-sample extension, makes DRR interpretable and easy to
apply. The properties of DRR enable learning a more broader class of data
manifolds than the recently proposed Non-linear Principal Components Analysis
(NLPCA) and Principal Polynomial Analysis (PPA). We illustrate the performance
of the representation in reducing the dimensionality of remote sensing data. In
particular, we tackle two common problems: processing very high dimensional
spectral information such as in hyperspectral image sounding data, and dealing
with spatial-spectral image patches of multispectral images. Both settings pose
collinearity and ill-determination problems. Evaluation of the expressive power
of the features is assessed in terms of truncation error, estimating
atmospheric variables, and surface land cover classification error. Results
show that DRR outperforms linear PCA and recently proposed invertible
extensions based on neural networks (NLPCA) and univariate regressions (PPA).
","Valero Laparra, Jesus Malo, Gustau Camps-Valls",Gustau Camps-Valls,2016-01-31T09:34:58Z
"On the Sampling Strategy for Evaluation of Spectral-spatial Methods in
  Hyperspectral Image Classification","  Spectral-spatial processing has been increasingly explored in remote sensing
hyperspectral image classification. While extensive studies have focused on
developing methods to improve the classification accuracy, experimental setting
and design for method evaluation have drawn little attention. In the scope of
supervised classification, we find that traditional experimental designs for
spectral processing are often improperly used in the spectral-spatial
processing context, leading to unfair or biased performance evaluation. This is
especially the case when training and testing samples are randomly drawn from
the same image - a practice that has been commonly adopted in the experiments.
Under such setting, the dependence caused by overlap between the training and
testing samples may be artificially enhanced by some spatial information
processing methods such as spatial filtering and morphological operation. Such
interaction between training and testing sets has violated data independence
assumption that is abided by supervised learning theory and performance
evaluation mechanism. Therefore, the widely adopted pixel-based random sampling
strategy is not always suitable to evaluate spectral-spatial classification
algorithms because it is difficult to determine whether the improvement of
classification accuracy is caused by incorporating spatial information into
classifier or by increasing the overlap between training and testing samples.
To partially solve this problem, we propose a novel controlled random sampling
strategy for spectral-spatial methods. It can greatly reduce the overlap
between training and testing samples and provides more objective and accurate
evaluation.
","Jie Liang, Jun Zhou, Yuntao Qian, Lian Wen, Xiao Bai, Yongsheng Gao",Yongsheng Gao,2016-05-19T06:59:03Z
Denoising Hyperspectral Image with Non-i.i.d. Noise Structure,"  Hyperspectral image (HSI) denoising has been attracting much research
attention in remote sensing area due to its importance in improving the HSI
qualities. The existing HSI denoising methods mainly focus on specific spectral
and spatial prior knowledge in HSIs, and share a common underlying assumption
that the embedded noise in HSI is independent and identically distributed
(i.i.d.). In real scenarios, however, the noise existed in a natural HSI is
always with much more complicated non-i.i.d. statistical structures and the
under-estimation to this noise complexity often tends to evidently degenerate
the robustness of current methods. To alleviate this issue, this paper attempts
the first effort to model the HSI noise using a non-i.i.d. mixture of Gaussians
(NMoG) noise assumption, which is finely in accordance with the noise
characteristics possessed by a natural HSI and thus is capable of adapting
various noise shapes encountered in real applications. Then we integrate such
noise modeling strategy into the low-rank matrix factorization (LRMF) model and
propose a NMoG-LRMF model in the Bayesian framework. A variational Bayes
algorithm is designed to infer the posterior of the proposed model. All
involved parameters can be recursively updated in closed-form. Compared with
the current techniques, the proposed method performs more robust beyond the
state-of-the-arts, as substantiated by our experiments implemented on synthetic
and real noisy HSIs.
","Yang Chen, Xiangyong Cao, Qian Zhao, Deyu Meng, Zongben Xu",Zongben Xu,2017-02-01T00:52:01Z
"Computational Techniques in Multispectral Image Processing: Application
  to the Syriac Galen Palimpsest","  Multispectral and hyperspectral image analysis has experienced much
development in the last decade. The application of these methods to palimpsests
has produced significant results, enabling researchers to recover texts that
would be otherwise lost under the visible overtext, by improving the contrast
between the undertext and the overtext. In this paper we explore an extended
number of multispectral and hyperspectral image analysis methods, consisting of
supervised and unsupervised dimensionality reduction techniques, on a part of
the Syriac Galen Palimpsest dataset (www.digitalgalen.net). Of this extended
set of methods, eight methods gave good results: three were supervised methods
Generalized Discriminant Analysis (GDA), Linear Discriminant Analysis (LDA),
and Neighborhood Component Analysis (NCA); and the other five methods were
unsupervised methods (but still used in a supervised way) Gaussian Process
Latent Variable Model (GPLVM), Isomap, Landmark Isomap, Principal Component
Analysis (PCA), and Probabilistic Principal Component Analysis (PPCA). The
relative success of these methods was determined visually, using color
pictures, on the basis of whether the undertext was distinguishable from the
overtext, resulting in the following ranking of the methods: LDA, NCA, GDA,
Isomap, Landmark Isomap, PPCA, PCA, and GPLVM. These results were compared with
those obtained using the Canonical Variates Analysis (CVA) method on the same
dataset, which showed remarkably accuracy (LDA is a particular case of CVA
where the objects are classified to two classes).
","Corneliu Arsene, Peter Pormann, William Sellers, Siam Bhayro",Siam Bhayro,2017-01-31T13:03:20Z
"Hyperspectral Image Unmixing with Endmember Bundles and Group Sparsity
  Inducing Mixed Norms","  Hyperspectral images provide much more information than conventional imaging
techniques, allowing a precise identification of the materials in the observed
scene, but because of the limited spatial resolution, the observations are
usually mixtures of the contributions of several materials. The spectral
unmixing problem aims at recovering the spectra of the pure materials of the
scene (endmembers), along with their proportions (abundances) in each pixel. In
order to deal with the intra-class variability of the materials and the induced
spectral variability of the endmembers, several spectra per material,
constituting endmember bundles, can be considered. However, the usual abundance
estimation techniques do not take advantage of the particular structure of
these bundles, organized into groups of spectra. In this paper, we propose to
use group sparsity by introducing mixed norms in the abundance estimation
optimization problem. In particular, we propose a new penalty which
simultaneously enforces group and within group sparsity, to the cost of being
nonconvex. All the proposed penalties are compatible with the abundance
sum-to-one constraint, which is not the case with traditional sparse
regression. We show on simulated and real datasets that well chosen penalties
can significantly improve the unmixing performance compared to the naive bundle
approach.
","Lucas Drumetz, Travis R. Meyer, Jocelyn Chanussot, Andrea L. Bertozzi, Christian Jutten",Christian Jutten,2018-05-25T16:16:09Z
"Rice Classification Using Spatio-Spectral Deep Convolutional Neural
  Network","  Rice has been one of the staple foods that contribute significantly to human
food supplies. Numerous rice varieties have been cultivated, imported, and
exported worldwide. Different rice varieties could be mixed during rice
production and trading. Rice impurities could damage the trust between rice
importers and exporters, calling for the need to develop a rice variety
inspection system. In this work, we develop a non-destructive rice variety
classification system that benefits from the synergy between hyperspectral
imaging and deep convolutional neural network (CNN). The proposed method uses a
hyperspectral imaging system to simultaneously acquire complementary spatial
and spectral information of rice seeds. The rice varieties are then determined
from the acquired spatio-spectral data using a deep CNN. As opposed to several
existing rice variety classification methods that require hand-engineered
features, the proposed method automatically extracts spatio-spectral features
from the raw sensor data. As demonstrated using two types of rice datasets, the
proposed method achieved up to 11.9% absolute improvement in the mean
classification accuracy, compared to the commonly used classification methods
based on support vector machines.
","Itthi Chatnuntawech, Kittipong Tantisantisom, Paisan Khanchaitit, Thitikorn Boonkoom, Berkin Bilgic, Ekapol Chuangsuwanich",Ekapol Chuangsuwanich,2018-05-29T14:17:12Z
"Cross-Domain Collaborative Learning via Cluster Canonical Correlation
  Analysis and Random Walker for Hyperspectral Image Classification","  This paper introduces a novel heterogenous domain adaptation (HDA) method for
hyperspectral image classification with a limited amount of labeled samples in
both domains. The method is achieved in the way of cross-domain collaborative
learning (CDCL), which is addressed via cluster canonical correlation analysis
(C-CCA) and random walker (RW) algorithms. To be specific, the proposed CDCL
method is an iterative process of three main stages, i.e. twice of RW-based
pseudolabeling and cross domain learning via C-CCA. Firstly, given the
initially labeled target samples as training set ($\mathbf{TS}$), the RW-based
pseudolabeling is employed to update $\mathbf{TS}$ and extract target clusters
($\mathbf{TCs}$) by fusing the segmentation results obtained by RW and extended
RW (ERW) classifiers. Secondly, cross domain learning via C-CCA is applied
using labeled source samples and $\mathbf{TCs}$. The unlabeled target samples
are then classified with the estimated probability maps using the model trained
in the projected correlation subspace. Thirdly, both $\mathbf{TS}$ and
estimated probability maps are used for updating $\mathbf{TS}$ again via
RW-based pseudolabeling. When the iterative process finishes, the result
obtained by the ERW classifier using the final $\mathbf{TS}$ and estimated
probability maps is regarded as the final classification map. Experimental
results on four real HSIs demonstrate that the proposed method can achieve
better performance compared with the state-of-the-art HDA and ERW methods.
","Yao Qin, Lorenzo Bruzzone, Biao Li, Yuanxin Ye",Yuanxin Ye,2018-08-29T11:37:23Z
"A Semi-supervised Spatial Spectral Regularized Manifold Local Scaling
  Cut With HGF for Dimensionality Reduction of Hyperspectral Images","  Hyperspectral images (HSI) contain a wealth of information over hundreds of
contiguous spectral bands, making it possible to classify materials through
subtle spectral discrepancies. However, the classification of this rich
spectral information is accompanied by the challenges like high dimensionality,
singularity, limited training samples, lack of labeled data samples,
heteroscedasticity and nonlinearity. To address these challenges, we propose a
semi-supervised graph based dimensionality reduction method named
`semi-supervised spatial spectral regularized manifold local scaling cut'
(S3RMLSC). The underlying idea of the proposed method is to exploit the limited
labeled information from both the spectral and spatial domains along with the
abundant unlabeled samples to facilitate the classification task by retaining
the original distribution of the data. In S3RMLSC, a hierarchical guided filter
(HGF) is initially used to smoothen the pixels of the HSI data to preserve the
spatial pixel consistency. This step is followed by the construction of linear
patches from the nonlinear manifold by using the maximal linear patch (MLP)
criterion. Then the inter-patch and intra-patch dissimilarity matrices are
constructed in both spectral and spatial domains by regularized manifold local
scaling cut (RMLSC) and neighboring pixel manifold local scaling cut (NPMLSC)
respectively. Finally, we obtain the projection matrix by optimizing the
updated semi-supervised spatial-spectral between-patch and total-patch
dissimilarity. The effectiveness of the proposed DR algorithm is illustrated
with publicly available real-world HSI datasets.
","Ramanarayan Mohanty, SL Happy, Aurobinda Routray",Aurobinda Routray,2018-11-20T12:56:39Z
"Matrix Cofactorization for Joint Representation Learning and Supervised
  Classification -- Application to Hyperspectral Image Analysis","  Supervised classification and representation learning are two widely used
classes of methods to analyze multivariate images. Although complementary,
these methods have been scarcely considered jointly in a hierarchical modeling.
In this paper, a method coupling these two approaches is designed using a
matrix cofactorization formulation. Each task is modeled as a factorization
matrix problem and a term relating both coding matrices is then introduced to
drive an appropriate coupling. The link can be interpreted as a clustering
operation over a low-dimensional representation vectors. The attribution
vectors of the clustering are then used as features vectors for the
classification task, i.e., the coding vectors of the corresponding
factorization problem. A proximal gradient descent algorithm, ensuring
convergence to a critical point of the objective function, is then derived to
solve the resulting non-convex non-smooth optimization problem. An evaluation
of the proposed method is finally conducted both on synthetic and real data in
the specific context of hyperspectral image interpretation, unifying two
standard analysis techniques, namely unmixing and classification.
","Adrien Lagrange, Mathieu Fauvel, Stéphane May, José Bioucas-Dias, Nicolas Dobigeon",Nicolas Dobigeon,2019-02-07T12:54:56Z
"A block-based inter-band predictor using multilayer propagation neural
  network for hyperspectral image compression","  In this paper, a block-based inter-band predictor (BIP) with multilayer
propagation neural network model (MLPNN) is presented by a completely new
framework. This predictor can combine with diversity entropy coding methods.
Hyperspectral (HS) images are composed by a series high similarity spectral
bands. Our assumption is to use trained MLPNN predict the succeeding bands
based on current band information. The purpose is to explore whether BIP-MLPNN
can provide better image predictive results with high efficiency. The algorithm
also changed from the traditional compression methods encoding images pixel by
pixel, the compression process only encodes the weights and the biases vectors
of BIP-MLPNN which require few bits to transfer. The decoder will reconstruct a
band by using the same structure of the network at the encoder side. The
BIP-MLPNN decoder does not need to be trained as the weights and biases have
already been transmitted. We can easily reconstruct the succeeding bands by
using the BIP-MLPNN decoder. The experimental results indicate that BIP-MLPNN
predictor outperforms the CCSDS-123 HS image coding standard. Due to a good
approximation of the target band, the proposed method outperforms the CCSDS-123
by more than 2.0dB PSNR image quality in the predicted bands. Moreover, the
proposed method provides high quality image e.g., 30 to 40dB PSNR at very low
bit rate (less than 0.1 bpppb) and outperforms the existing methods e.g., JPEG,
3DSPECK, 3DSPIHT and in terms of rate-distortion performance.
","Rui Dusselaar, Manoranjan Paul",Manoranjan Paul,2019-02-12T00:26:38Z
"Active Transfer Learning Network: A Unified Deep Joint Spectral-Spatial
  Feature Learning Model For Hyperspectral Image Classification","  Deep learning has recently attracted significant attention in the field of
hyperspectral images (HSIs) classification. However, the construction of an
efficient deep neural network (DNN) mostly relies on a large number of labeled
samples being available. To address this problem, this paper proposes a unified
deep network, combined with active transfer learning that can be well-trained
for HSIs classification using only minimally labeled training data. More
specifically, deep joint spectral-spatial feature is first extracted through
hierarchical stacked sparse autoencoder (SSAE) networks. Active transfer
learning is then exploited to transfer the pre-trained SSAE network and the
limited training samples from the source domain to the target domain, where the
SSAE network is subsequently fine-tuned using the limited labeled samples
selected from both source and target domain by corresponding active learning
strategies. The advantages of our proposed method are threefold: 1) the network
can be effectively trained using only limited labeled samples with the help of
novel active learning strategies; 2) the network is flexible and scalable
enough to function across various transfer situations, including cross-dataset
and intra-image; 3) the learned deep joint spectral-spatial feature
representation is more generic and robust than many joint spectral-spatial
feature representation. Extensive comparative evaluations demonstrate that our
proposed method significantly outperforms many state-of-the-art approaches,
including both traditional and deep network-based methods, on three popular
datasets.
","Cheng Deng, Yumeng Xue, Xianglong Liu, Chao Li, Dacheng Tao",Dacheng Tao,2019-04-04T10:18:06Z
Optimizing CNN-based Hyperspectral Image Classification on FPGAs,"  Hyperspectral image (HSI) classification has been widely adopted in
applications involving remote sensing imagery analysis which require high
classification accuracy and real-time processing speed. Methods based on
Convolutional neural networks (CNNs) have been proven to achieve
state-of-the-art accuracy in classifying HSIs. However, CNN models are often
too computationally intensive to achieve real-time response due to the high
dimensional nature of HSI, compared to traditional methods such as Support
Vector Machines (SVMs). Besides, previous CNN models used in HSI are not
specially designed for efficient implementation on embedded devices such as
FPGAs. This paper proposes a novel CNN-based algorithm for HSI classification
which takes into account hardware efficiency. A customized architecture which
enables the proposed algorithm to be mapped effectively onto FPGA resources is
then proposed to support real-time on-board classification with low power
consumption. Implementation results show that our proposed accelerator on a
Xilinx Zynq 706 FPGA board achieves more than 70x faster than an Intel 8-core
Xeon CPU and 3x faster than an NVIDIA GeForce 1080 GPU. Compared to previous
SVM-based FPGA accelerators, we achieve comparable processing speed but provide
a much higher classification accuracy.
","Shuanglong Liu, Ringo S. W. Chu, Xiwei Wang, Wayne Luk",Wayne Luk,2019-06-27T22:05:22Z
"Matrix cofactorization for joint spatial-spectral unmixing of
  hyperspectral images","  Hyperspectral unmixing aims at identifying a set of elementary spectra and
the corresponding mixture coefficients for each pixel of an image. As the
elementary spectra correspond to the reflectance spectra of real materials,
they are often very correlated yielding an ill-conditioned problem. To enrich
the model and to reduce ambiguity due to the high correlation, it is common to
introduce spatial information to complement the spectral information. The most
common way to introduce spatial information is to rely on a spatial
regularization of the abundance maps. In this paper, instead of considering a
simple but limited regularization process, spatial information is directly
incorporated through the newly proposed context of spatial unmixing. Contextual
features are extracted for each pixel and this additional set of observations
is decomposed according to a linear model. Finally the spatial and spectral
observations are unmixed jointly through a cofactorization model. In
particular, this model introduces a coupling term used to identify clusters of
shared spatial and spectral signatures. An evaluation of the proposed method is
conducted on synthetic and real data and shows that results are accurate and
also very meaningful since they describe both spatially and spectrally the
various areas of the scene.
","Adrien Lagrange, Mathieu Fauvel, Stéphane May, Nicolas Dobigeon",Nicolas Dobigeon,2019-07-19T13:43:08Z
NPSA: Nonorthogonal Principal Skewness Analysis,"  Principal skewness analysis (PSA) has been introduced for feature extraction
in hyperspectral imagery. As a third-order generalization of principal
component analysis (PCA), its solution of searching for the locally maximum
skewness direction is transformed into the problem of calculating the
eigenpairs (the eigenvalues and the corresponding eigenvectors) of a coskewness
tensor. By combining a fixed-point method with an orthogonal constraint, it can
prevent the new eigenpairs from converging to the same maxima that has been
determined before. However, the eigenvectors of the supersymmetric tensor are
not inherently orthogonal in general, which implies that the results obtained
by the search strategy used in PSA may unavoidably deviate from the actual
eigenpairs. In this paper, we propose a new nonorthogonal search strategy to
solve this problem and the new algorithm is named nonorthogonal principal
skewness analysis (NPSA). The contribution of NPSA lies in the finding that the
search space of the eigenvector to be determined can be enlarged by using the
orthogonal complement of the Kronecker product of the previous one, instead of
its orthogonal complement space. We give a detailed theoretical proof to
illustrate why the new strategy can result in the more accurate eigenpairs. In
addition, after some algebraic derivations, the complexity of the presented
algorithm is also greatly reduced. Experiments with both simulated data and
real multi/hyperspectral imagery demonstrate its validity in feature
extraction.
","Xiurui Geng, Lei Wang",Lei Wang,2019-07-23T10:48:15Z
"A Constrained Convex Optimization Approach to Hyperspectral Image
  Restoration with Hybrid Spatio-Spectral Regularization","  We propose a new constrained optimization approach to hyperspectral (HS)
image restoration. Most existing methods restore a desirable HS image by
solving some optimization problem, which consists of a regularization term(s)
and a data-fidelity term(s). The methods have to handle a regularization
term(s) and a data-fidelity term(s) simultaneously in one objective function,
and so we need to carefully control the hyperparameter(s) that balances these
terms. However, the setting of such hyperparameters is often a troublesome task
because their suitable values depend strongly on the regularization terms
adopted and the noise intensities on a given observation. Our proposed method
is formulated as a convex optimization problem, where we utilize a novel hybrid
regularization technique named Hybrid Spatio-Spectral Total Variation (HSSTV)
and incorporate data-fidelity as hard constraints. HSSTV has a strong ability
of noise and artifact removal while avoiding oversmoothing and spectral
distortion, without combining other regularizations such as low-rank
modeling-based ones. In addition, the constraint-type data-fidelity enables us
to translate the hyperparameters that balance between regularization and
data-fidelity to the upper bounds of the degree of data-fidelity that can be
set in a much easier manner. We also develop an efficient algorithm based on
the alternating direction method of multipliers (ADMM) to efficiently solve the
optimization problem. Through comprehensive experiments, we illustrate the
advantages of the proposed method over various HS image restoration methods
including state-of-the-art ones.
","Saori Takeyama, Shunsuke Ono, Itsuo Kumazawa",Itsuo Kumazawa,2019-07-31T08:04:54Z
"Spatial and spectral dynamics in STEM hyperspectral imaging using random
  scan patterns","  The evolution of the scanning modules for scanning transmission electron
microscopes (STEM) has realized the possibility to generate arbitrary scan
pathways, an approach currently explored to improve acquisition speed and to
reduce electron dose effects. In this work, we present the implementation of a
random scan operating mode in STEM achieved at the hardware level via a custom
scan control module. A pre-defined pattern with fully shuffled raster order is
used to sample the entire region of interest. Subsampled random sparse images
can then be extracted at successive time frames, to which suitable image
reconstruction techniques can be applied. With respect to the conventional
raster scan mode, this method permits to limit dose accumulation effects, but
also to decouple the spatial and temporal information in hyperspectral images.
We provide some proofs of concept of the flexibility of the random scan
operating mode, presenting examples of its applications in different
spectro-microscopy contexts: atomically-resolved elemental maps with electron
energy loss spectroscopy and nanoscale-cathodoluminescence spectrum images. By
employing adapted post-processing tools, it is demonstrated that the method
allows to precisely track and correct for sample instabilities and to follow
spectral diffusion with a high spatial localization.
","Alberto Zobelli, Steffi Y. Woo, Luiz H. G. Tizei, Nathalie Brun, Anna Tararan, Xiaoyan Li, Odile Stéphan, Mathieu Kociak, Marcel Tencé",Marcel Tencé,2019-09-17T14:29:37Z
"Hybrid Inexact BCD for Coupled Structured Matrix Factorization in
  Hyperspectral Super-Resolution","  This paper develops a first-order optimization method for coupled structured
matrix factorization (CoSMF) problems that arise in the context of
hyperspectral super-resolution (HSR) in remote sensing. To best leverage the
problem structures for computational efficiency, we introduce a hybrid inexact
block coordinate descent (HiBCD) scheme wherein one coordinate is updated via
the fast proximal gradient (FPG) method, while another via the Frank-Wolfe (FW)
method. The FPG-type methods are known to take less number of iterations to
converge, by numerical experience, while the FW-type methods can offer lower
per-iteration complexity in certain cases; and we wish to take the best of
both. We show that the limit points of this HiBCD scheme are stationary. Our
proof treats HiBCD as an optimization framework for a class of multi-block
structured optimization problems, and our stationarity claim is applicable not
only to CoSMF but also to many other problems. Previous optimization research
showed the same stationarity result for inexact block coordinate descent with
either FPG or FW updates only. Numerical results indicate that the proposed
HiBCD scheme is computationally much more efficient than the state-of-the-art
CoSMF schemes in HSR.
","Ruiyuan Wu, Hoi-To Wai, Wing-Kin Ma",Wing-Kin Ma,2019-09-19T18:34:07Z
"Hyperspectral Image Classification With Context-Aware Dynamic Graph
  Convolutional Network","  In hyperspectral image (HSI) classification, spatial context has demonstrated
its significance in achieving promising performance. However, conventional
spatial context-based methods simply assume that spatially neighboring pixels
should correspond to the same land-cover class, so they often fail to correctly
discover the contextual relations among pixels in complex situations, and thus
leading to imperfect classification results on some irregular or inhomogeneous
regions such as class boundaries. To address this deficiency, we develop a new
HSI classification method based on the recently proposed Graph Convolutional
Network (GCN), as it can flexibly encode the relations among arbitrarily
structured non-Euclidean data. Different from traditional GCN, there are two
novel strategies adopted by our method to further exploit the contextual
relations for accurate HSI classification. First, since the receptive field of
traditional GCN is often limited to fairly small neighborhood, we proposed to
capture long range contextual relations in HSI by performing successive graph
convolutions on a learned region-induced graph which is transformed from the
original 2D image grids. Second, we refine the graph edge weight and the
connective relationships among image regions by learning the improved adjacency
matrix and the 'edge filter', so that the graph can be gradually refined to
adapt to the representations generated by each graph convolutional layer. Such
updated graph will in turn result in accurate region representations, and vice
versa. The experiments carried out on three real-world benchmark datasets
demonstrate that the proposed method yields significant improvement in the
classification performance when compared with some state-of-the-art approaches.
","Sheng Wan, Chen Gong, Ping Zhong, Shirui Pan, Guangyu Li, Jian Yang",Jian Yang,2019-09-26T07:37:37Z
An Open-source Tool for Hyperspectral Image Augmentation in Tensorflow,"  Satellite imagery allows a plethora of applications ranging from weather
forecasting to land surveying. The rapid development of computer vision systems
could open new horizons to the utilization of satellite data due to the
abundance of large volumes of data. However, current state-of-the-art computer
vision systems mainly cater to applications that mainly involve natural images.
While useful, those images exhibit a different distribution from satellite
images in addition to having more spectral channels. This allows the use of
pretrained deep learning models only in a subset of spectral channels that are
equivalent to natural images thus discarding valuable information from other
spectral channels. This calls for research effort to optimize deep learning
models for satellite imagery to enable the assessment of their utility in the
domain of remote sensing. Tensorflow tool allows for rapid prototyping and
testing of deep learning models, however, its built-in image generator is
designed to handle a maximum of four spectral channels. This manuscript
introduces an open-source tool that allows the implementation of image
augmentation for hyperspectral images in Tensorflow. Given how accessible and
easy-to-use Tensorflow is, this tool would provide many researchers with the
means to implement, test, and deploy deep learning models for remote sensing
applications.
",Mohamed Abdelhack,Mohamed Abdelhack,2020-03-30T14:28:12Z
Single-shot Hyperspectral-Depth Imaging with Learned Diffractive Optics,"  Imaging depth and spectrum have been extensively studied in isolation from
each other for decades. Recently, hyperspectral-depth (HS-D) imaging emerges to
capture both information simultaneously by combining two different imaging
systems; one for depth, the other for spectrum. While being accurate, this
combinational approach induces increased form factor, cost, capture time, and
alignment/registration problems. In this work, departing from the combinational
principle, we propose a compact single-shot monocular HS-D imaging method. Our
method uses a diffractive optical element (DOE), the point spread function of
which changes with respect to both depth and spectrum. This enables us to
reconstruct spectrum and depth from a single captured image. To this end, we
develop a differentiable simulator and a neural-network-based reconstruction
that are jointly optimized via automatic differentiation. To facilitate
learning the DOE, we present a first HS-D dataset by building a benchtop HS-D
imager that acquires high-quality ground truth. We evaluate our method with
synthetic and real experiments by building an experimental prototype and
achieve state-of-the-art HS-D imaging results.
","Seung-Hwan Baek, Hayato Ikoma, Daniel S. Jeon, Yuqi Li, Wolfgang Heidrich, Gordon Wetzstein, Min H. Kim",Min H. Kim,2020-09-01T14:19:35Z
"High-throughput molecular imaging via deep learning enabled Raman
  spectroscopy","  Raman spectroscopy enables non-destructive, label-free imaging with
unprecedented molecular contrast but is limited by slow data acquisition,
largely preventing high-throughput imaging applications. Here, we present a
comprehensive framework for higher-throughput molecular imaging via deep
learning enabled Raman spectroscopy, termed DeepeR, trained on a large dataset
of hyperspectral Raman images, with over 1.5 million spectra (400 hours of
acquisition) in total. We firstly perform denoising and reconstruction of low
signal-to-noise ratio Raman molecular signatures via deep learning, with a 9x
improvement in mean squared error over state-of-the-art Raman filtering
methods. Next, we develop a neural network for robust 2-4x super-resolution of
hyperspectral Raman images that preserves molecular cellular information.
Combining these approaches, we achieve Raman imaging speed-ups of up to 160x,
enabling high resolution, high signal-to-noise ratio cellular imaging in under
one minute. Finally, transfer learning is applied to extend DeepeR from cell to
tissue-scale imaging. DeepeR provides a foundation that will enable a host of
higher-throughput Raman spectroscopy and molecular imaging applications across
biomedicine.
","Conor C. Horgan, Magnus Jensen, Anika Nagelkerke, Jean-Phillipe St-Pierre, Tom Vercauteren, Molly M. Stevens, Mads S. Bergholt",Mads S. Bergholt,2020-09-28T13:40:14Z
"SLCRF: Subspace Learning with Conditional Random Field for Hyperspectral
  Image Classification","  Subspace learning (SL) plays an important role in hyperspectral image (HSI)
classification, since it can provide an effective solution to reduce the
redundant information in the image pixels of HSIs. Previous works about SL aim
to improve the accuracy of HSI recognition. Using a large number of labeled
samples, related methods can train the parameters of the proposed solutions to
obtain better representations of HSI pixels. However, the data instances may
not be sufficient enough to learn a precise model for HSI classification in
real applications. Moreover, it is well-known that it takes much time, labor
and human expertise to label HSI images. To avoid the aforementioned problems,
a novel SL method that includes the probability assumption called subspace
learning with conditional random field (SLCRF) is developed. In SLCRF, first,
the 3D convolutional autoencoder (3DCAE) is introduced to remove the redundant
information in HSI pixels. In addition, the relationships are also constructed
using the spectral-spatial information among the adjacent pixels. Then, the
conditional random field (CRF) framework can be constructed and further
embedded into the HSI SL procedure with the semi-supervised approach. Through
the linearized alternating direction method termed LADMAP, the objective
function of SLCRF is optimized using a defined iterative algorithm. The
proposed method is comprehensively evaluated using the challenging public HSI
datasets. We can achieve stateof-the-art performance using these HSI sets.
","Yun Cao, Jie Mei, Yuebin Wang, Liqiang Zhang, Junhuan Peng, Bing Zhang, Lihua Li, Yibo Zheng",Yibo Zheng,2020-10-07T02:25:32Z
"Non-local Meets Global: An Iterative Paradigm for Hyperspectral Image
  Restoration","  Non-local low-rank tensor approximation has been developed as a
state-of-the-art method for hyperspectral image (HSI) restoration, which
includes the tasks of denoising, compressed HSI reconstruction and inpainting.
Unfortunately, while its restoration performance benefits from more spectral
bands, its runtime also substantially increases. In this paper, we claim that
the HSI lies in a global spectral low-rank subspace, and the spectral subspaces
of each full band patch group should lie in this global low-rank subspace. This
motivates us to propose a unified paradigm combining the spatial and spectral
properties for HSI restoration. The proposed paradigm enjoys performance
superiority from the non-local spatial denoising and light computation
complexity from the low-rank orthogonal basis exploration. An efficient
alternating minimization algorithm with rank adaptation is developed. It is
done by first solving a fidelity term-related problem for the update of a
latent input image, and then learning a low-dimensional orthogonal basis and
the related reduced image from the latent input image. Subsequently, non-local
low-rank denoising is developed to refine the reduced image and orthogonal
basis iteratively. Finally, the experiments on HSI denoising, compressed
reconstruction, and inpainting tasks, with both simulated and real datasets,
demonstrate its superiority with respect to state-of-the-art HSI restoration
methods.
","Wei He, Quanming Yao, Chao Li, Naoto Yokoya, Qibin Zhao, Hongyan Zhang, Liangpei Zhang",Liangpei Zhang,2020-10-24T15:53:56Z
"A Spectral-Spatial-Dependent Global Learning Framework for Insufficient
  and Imbalanced Hyperspectral Image Classification","  Deep learning techniques have been widely applied to hyperspectral image
(HSI) classification and have achieved great success. However, the deep neural
network model has a large parameter space and requires a large number of
labeled data. Deep learning methods for HSI classification usually follow a
patchwise learning framework. Recently, a fast patch-free global learning
(FPGA) architecture was proposed for HSI classification according to global
spatial context information. However, FPGA has difficulty extracting the most
discriminative features when the sample data is imbalanced. In this paper, a
spectral-spatial dependent global learning (SSDGL) framework based on global
convolutional long short-term memory (GCL) and global joint attention mechanism
(GJAM) is proposed for insufficient and imbalanced HSI classification. In
SSDGL, the hierarchically balanced (H-B) sampling strategy and the weighted
softmax loss are proposed to address the imbalanced sample problem. To
effectively distinguish similar spectral characteristics of land cover types,
the GCL module is introduced to extract the long short-term dependency of
spectral features. To learn the most discriminative feature representations,
the GJAM module is proposed to extract attention areas. The experimental
results obtained with three public HSI datasets show that the SSDGL has
powerful performance in insufficient and imbalanced sample problems and is
superior to other state-of-the-art methods. Code can be obtained at:
https://github.com/dengweihuan/SSDGL.
","Qiqi Zhu, Weihuan Deng, Zhuo Zheng, Yanfei Zhong, Qingfeng Guan, Weihua Lin, Liangpei Zhang, Deren Li",Deren Li,2021-05-29T15:39:03Z
"Multi-task fully convolutional network for tree species mapping in dense
  forests using small training hyperspectral data","  This work proposes a multi-task fully convolutional architecture for tree
species mapping in dense forests from sparse and scarce polygon-level
annotations using hyperspectral UAV-borne data. Our model implements a partial
loss function that enables dense tree semantic labeling outcomes from non-dense
training samples, and a distance regression complementary task that enforces
tree crown boundary constraints and substantially improves the model
performance. Our multi-task architecture uses a shared backbone network that
learns common representations for both tasks and two task-specific decoders,
one for the semantic segmentation output and one for the distance map
regression. We report that introducing the complementary task boosts the
semantic segmentation performance compared to the single-task counterpart in up
to 11% reaching an average user's accuracy of 88.63% and an average producer's
accuracy of 88.59%, achieving state-of-art performance for tree species
classification in tropical forests.
","Laura Elena Cué La Rosa, Camile Sothe, Raul Queiroz Feitosa, Cláudia Maria de Almeida, Marcos Benedito Schimalski, Dario Augusto Borges Oliveira",Dario Augusto Borges Oliveira,2021-06-01T21:10:10Z
"Hyperspectral imaging with Raman scattered photons: A new paradigm in
  Raman analysis","  Surface enhanced Raman spectroscopy, is a technique of fundamental importance
to analytical science and technology where the amplified Raman spectrum of
analytes is used for chemical fingerprinting. Here, we showcase an engineered
hierarchical substrate in which the plasmonically active regions are restricted
to a micron scale, 2D hexagonal pattern. The Raman signal enhancement of any
analyte uniformly coating the substrate is consequently bears a high registry
with the 2D pattern. This spatially segregated enhancement allows optical
imaging of the 2D pattern solely using the Raman scattered photons from the
analyte. While pattern brightness and contrast determine analyte identification
and detection sensitivity, the spectrally selective contrast allows for tuning
specificity. Conceptual proof of the technique is demonstrated via the
acquisition of Raman images with rhodamine and fluorescein and finally applied
to detect glucose in 40 mM concentration. The large area imaging and the
inherent requirement of spatial uniformity for positive detection implemented
using a machine learning based automated pattern recognition protocol increases
the statistical confidence of analyte detection. This simultaneously multisite
signal detection sacrifices continuous spectral information at the cost of
speed, reproducibility and human error via automation of detection of the
hyperspectral imaging technique presented here.
","K N Prajapati, Anoop A Nair, S Ravi P Silva, J Mitra",J Mitra,2021-06-05T11:51:00Z
"Multi-modal and frequency-weighted tensor nuclear norm for hyperspectral
  image denoising","  Low-rankness is important in the hyperspectral image (HSI) denoising tasks.
The tensor nuclear norm (TNN), defined based on the tensor singular value
decomposition, is a state-of-the-art method to describe the low-rankness of
HSI. However, TNN ignores some physical meanings of HSI in tackling denoising
tasks, leading to suboptimal denoising performance. In this paper, we propose
the multi-modal and frequency-weighted tensor nuclear norm (MFWTNN) and the
non-convex MFWTNN for HSI denoising tasks. Firstly, we investigate the physical
meaning of frequency slices and reconsider their weights to improve the
low-rank representation ability of TNN. Secondly, we consider the correlation
among two spatial dimensions and the spectral dimension of HSI and combine the
above improvements to TNN to propose MFWTNN. Thirdly, we use non-convex
functions to approximate the rank function of the frequency tensor and propose
the NonMFWTNN to relax the MFWTNN better. Besides, we adaptively choose bigger
weights for slices mainly containing noise information and smaller weights for
slices containing profile information. Finally, we develop the efficient
alternating direction method of multiplier (ADMM) based algorithm to solve the
proposed models, and the effectiveness of our models are substantiated in
simulated and real HSI datasets.
","Xiaozhen Xie, Sheng Liu",Sheng Liu,2021-06-23T16:01:08Z
"Atomic-scale analysis of disorder by similarity learning from tunneling
  spectroscopy","  Rapid proliferation of hyperspectral imaging in scanning probe microscopies
creates unique opportunities to systematically capture and categorize higher
dimensional datasets, toward new insights into electronic, mechanical and
chemical properties of materials with nano- and atomic-scale resolution. Here
we demonstrate similarity learning for tunneling spectroscopy acquired on
superconducting material (FeSe) with sparse density of imperfections (Fe
vacancies). Popular methods for unsupervised learning and discrete
representation of the data in terms of clusters of characteristic behaviors
were found to produce inconsistencies with respect to capturing the location
and tunneling characteristics of the vacancy sites. To this end, we applied a
more general, non-linear similarity learning. This approach was found to
outperform several widely used methods for dimensionality reduction and produce
a clear differentiation of the type of tunneling spectra. In particular,
significant spectral weight transfer likely associated with the electronic
reconstruction by the vacancy sites, is systematically captured, as is the
spatial extent of the vacancy region. Given that a great variety of electronic
materials will exhibit similarly smooth variation of the spectral responses due
to random or engineered inhomogeneities in their structure, we believe our
approach will be useful for systematic analysis of hyperspectral imaging with
minimal prior knowledge, as well as prospective comparison of experimental
measurements to theoretical calculations with explicit consideration of
disorder.
","Petro Maksymovych, Jiaqiang Yan, Brian Sales, Jun Wang",Jun Wang,2021-06-25T15:23:15Z
Image Restoration for Remote Sensing: Overview and Toolbox,"  Remote sensing provides valuable information about objects or areas from a
distance in either active (e.g., RADAR and LiDAR) or passive (e.g.,
multispectral and hyperspectral) modes. The quality of data acquired by
remotely sensed imaging sensors (both active and passive) is often degraded by
a variety of noise types and artifacts. Image restoration, which is a vibrant
field of research in the remote sensing community, is the task of recovering
the true unknown image from the degraded observed image. Each imaging sensor
induces unique noise types and artifacts into the observed image. This fact has
led to the expansion of restoration techniques in different paths according to
each sensor type. This review paper brings together the advances of image
restoration techniques with particular focuses on synthetic aperture radar and
hyperspectral images as the most active sub-fields of image restoration in the
remote sensing community. We, therefore, provide a comprehensive,
discipline-specific starting point for researchers at different levels (i.e.,
students, researchers, and senior researchers) willing to investigate the
vibrant topic of data restoration by supplying sufficient detail and
references. Additionally, this review paper accompanies a toolbox to provide a
platform to encourage interested students and researchers in the field to
further explore the restoration techniques and fast-forward the community. The
toolboxes are provided in https://github.com/ImageRestorationToolbox.
","Benhood Rasti, Yi Chang, Emanuele Dalsasso, Loïc Denis, Pedram Ghamisi",Pedram Ghamisi,2021-07-01T15:54:49Z
"SpectralFormer: Rethinking Hyperspectral Image Classification with
  Transformers","  Hyperspectral (HS) images are characterized by approximately contiguous
spectral information, enabling the fine identification of materials by
capturing subtle spectral discrepancies. Owing to their excellent locally
contextual modeling ability, convolutional neural networks (CNNs) have been
proven to be a powerful feature extractor in HS image classification. However,
CNNs fail to mine and represent the sequence attributes of spectral signatures
well due to the limitations of their inherent network backbone. To solve this
issue, we rethink HS image classification from a sequential perspective with
transformers, and propose a novel backbone network called \ul{SpectralFormer}.
Beyond band-wise representations in classic transformers, SpectralFormer is
capable of learning spectrally local sequence information from neighboring
bands of HS images, yielding group-wise spectral embeddings. More
significantly, to reduce the possibility of losing valuable information in the
layer-wise propagation process, we devise a cross-layer skip connection to
convey memory-like components from shallow to deep layers by adaptively
learning to fuse ""soft"" residuals across layers. It is worth noting that the
proposed SpectralFormer is a highly flexible backbone network, which can be
applicable to both pixel- and patch-wise inputs. We evaluate the classification
performance of the proposed SpectralFormer on three HS datasets by conducting
extensive experiments, showing the superiority over classic transformers and
achieving a significant improvement in comparison with state-of-the-art
backbone networks. The codes of this work will be available at
https://github.com/danfenghong/IEEE_TGRS_SpectralFormer for the sake of
reproducibility.
","Danfeng Hong, Zhu Han, Jing Yao, Lianru Gao, Bing Zhang, Antonio Plaza, Jocelyn Chanussot",Jocelyn Chanussot,2021-07-07T02:59:21Z
"Hyperspectral Image Restoration via Total Variation Regularized Low-rank
  Tensor Decomposition","  Hyperspectral images (HSIs) are often corrupted by a mixture of several types
of noise during the acquisition process, e.g., Gaussian noise, impulse noise,
dead lines, stripes, and many others. Such complex noise could degrade the
quality of the acquired HSIs, limiting the precision of the subsequent
processing. In this paper, we present a novel tensor-based HSI restoration
approach by fully identifying the intrinsic structures of the clean HSI part
and the mixed noise part respectively. Specifically, for the clean HSI part, we
use tensor Tucker decomposition to describe the global correlation among all
bands, and an anisotropic spatial-spectral total variation (SSTV)
regularization to characterize the piecewise smooth structure in both spatial
and spectral domains. For the mixed noise part, we adopt the $\ell_1$ norm
regularization to detect the sparse noise, including stripes, impulse noise,
and dead pixels. Despite that TV regulariztion has the ability of removing
Gaussian noise, the Frobenius norm term is further used to model heavy Gaussian
noise for some real-world scenarios. Then, we develop an efficient algorithm
for solving the resulting optimization problem by using the augmented Lagrange
multiplier (ALM) method. Finally, extensive experiments on simulated and
real-world noise HSIs are carried out to demonstrate the superiority of the
proposed method over the existing state-of-the-art ones.
","Yao Wang, Jiangjun Peng, Qian Zhao, Deyu Meng, Yee Leung, Xi-Le Zhao",Xi-Le Zhao,2017-07-08T18:41:06Z
"An Overflow Free Fixed-point Eigenvalue Decomposition Algorithm: Case
  Study of Dimensionality Reduction in Hyperspectral Images","  We consider the problem of enabling robust range estimation of eigenvalue
decomposition (EVD) algorithm for a reliable fixed-point design. The simplicity
of fixed-point circuitry has always been so tempting to implement EVD algo-
rithms in fixed-point arithmetic. Working towards an effective fixed-point
design, integer bit-width allocation is a significant step which has a crucial
impact on accuracy and hardware efficiency. This paper investigates the
shortcomings of the existing range estimation methods while deriving bounds for
the variables of the EVD algorithm. In light of the circumstances, we introduce
a range estimation approach based on vector and matrix norm properties together
with a scaling procedure that maintains all the assets of an analytical method.
The method could derive robust and tight bounds for the variables of EVD
algorithm. The bounds derived using the proposed approach remain same for any
input matrix and are also independent of the number of iterations or size of
the problem. Some benchmark hyperspectral data sets have been used to evaluate
the efficiency of the proposed technique. It was found that by the proposed
range estimation approach, all the variables generated during the computation
of Jacobi EVD is bounded within $\pm1$.
","Bibek Kabi, Anand S Sahadevan, Tapan Pradhan",Tapan Pradhan,2017-11-28T22:57:53Z
"99% beta factor and directional coupling of quantum dots to fast light
  in photonic crystal waveguides determined by hyperspectral imaging","  Spontaneous emission from excitonic transitions in InAs/GaAs quantum dots
embedded in photonic crystal waveguides at 5K into non-guided and guided modes
is determined by direct hyperspectral imaging. This enables measurement of the
absolute coupling efficiency into the guided modes, the beta-factor, directly,
without assumptions on decay rates used previously. Notably, we found
beta-factors above 90% over a wide spectral range of 40meV in the fast light
regime, reaching a maximum of (99 $\pm$ 1)%. We measure the directional
emission of the circularly polarized transitions in a magnetic field into
counter-propagating guided modes, to deduce the mode circularity at the quantum
dot sites. We find that points of high directionality, up to 97%, correlate
with a reduced beta-factor, consistent with their positions away from the mode
field antinode. By comparison with calibrated finite-difference time-domain
simulations, we use the emission energy, mode circularity and beta-factor to
estimate the quantum dot position inside the photonic crystal waveguide unit
cell.
","L. Scarpelli, B. Lang, F. Masia, D. M. Beggs, E. A. Muljarov, A. B. Young, R. Oulton, M. Kamp, S. Höfling, C. Schneider, W. Langbein",W. Langbein,2019-05-03T14:21:54Z
"Generative Adversarial Networks and Conditional Random Fields for
  Hyperspectral Image Classification","  In this paper, we address the hyperspectral image (HSI) classification task
with a generative adversarial network and conditional random field (GAN-CRF)
-based framework, which integrates a semi-supervised deep learning and a
probabilistic graphical model, and make three contributions. First, we design
four types of convolutional and transposed convolutional layers that consider
the characteristics of HSIs to help with extracting discriminative features
from limited numbers of labeled HSI samples. Second, we construct
semi-supervised GANs to alleviate the shortage of training samples by adding
labels to them and implicitly reconstructing real HSI data distribution through
adversarial training. Third, we build dense conditional random fields (CRFs) on
top of the random variables that are initialized to the softmax predictions of
the trained GANs and are conditioned on HSIs to refine classification maps.
This semi-supervised framework leverages the merits of discriminative and
generative models through a game-theoretical approach. Moreover, even though we
used very small numbers of labeled training HSI samples from the two most
challenging and extensively studied datasets, the experimental results
demonstrated that spectral-spatial GAN-CRF (SS-GAN-CRF) models achieved
top-ranking accuracy for semi-supervised HSI classification.
","Zilong Zhong, Jonathan Li, David A. Clausi, Alexander Wong",Alexander Wong,2019-05-12T01:13:35Z
"Band selection for oxygenation estimation with
  multispectral/hyperspectral imaging","  Multispectral imaging provides valuable information on tissue composition
such as hemoglobin oxygen saturation. However, the real-time application of
this technique in interventional medicine can be challenging due to the long
acquisition times needed for large amounts of hyperspectral data with hundreds
of bands. While this challenge can partially be addressed by choosing a
discriminative subset of bands, the band selection methods proposed to date are
mainly restricted by the availability of often hard to obtain reference
measurements. We address this bottleneck with a new approach to band selection
that leverages highly accurate Monte Carlo (MC) simulations. We hypothesize
that a so chosen small subset of bands can reproduce or even improve upon the
results of a quasi continuous spectral measurement. We further investigate
whether novel domain adaptation techniques can address the inevitable domain
shift stemming from the use of simulations. Initial results based on in silico
and in vivo experiments suggest that 10-20 bands are sufficient to closely
reproduce results from spectral measurements with 101 bands in the 500-700 nm
range. The investigated domain adaptation technique, which only requires
unlabeled in vivo measurements, yielded better results than the pure in silico
band selection method. Overall, our method could guide development of fast
multispectral imaging systems suited for interventional use without relying on
complex hardware setups or manually labeled data
","Leonardo A. Ayala, Fabian Isensee, Sebastian J. Wirkert, Anant S. Vemuri, Klaus H. Maier-Hein, Baowei Fei, Lena Maier-Hein",Lena Maier-Hein,2019-05-27T15:30:22Z
Peanut Maturity Classification using Hyperspectral Imagery,"  Seed maturity in peanut (Arachis hypogaea L.) determines economic return to a
producer because of its impact on seed weight (yield), and critically
influences seed vigor and other quality characteristics. During seed
development, the inner mesocarp layer of the pericarp (hull) transitions in
color from white to black as the seed matures. The maturity assessment process
involves the removal of the exocarp of the hull and visually categorizing the
mesocarp color into varying color classes from immature (white, yellow, orange)
to mature (brown, and black). This visual color classification is time
consuming because the exocarp must be manually removed. In addition, the visual
classification process involves human assessment of colors, which leads to
large variability of color classification from observer to observer. A more
objective, digital imaging approach to peanut maturity is needed, optimally
without the requirement of removal of the hull's exocarp. This study examined
the use of a hyperspectral imaging (HSI) process to determine pod maturity with
intact pericarps. The HSI method leveraged spectral differences between mature
and immature pods within a classification algorithm to identify the mature and
immature pods. The results showed a high classification accuracy with
consistency using samples from different years and cultivars. In addition, the
proposed method was capable of estimating a continuous-valued, pixel-level
maturity value for individual peanut pods, allowing for a valuable tool that
can be utilized in seed quality research. This new method solves issues of
labor intensity and subjective error that all current methods of peanut
maturity determination have.
","Sheng Zou, Yu-Chien Tseng, Alina Zare, Diane Rowland, Barry Tillman, Seung-Chul Yoon",Seung-Chul Yoon,2019-10-20T22:51:49Z
Simulated JWST datasets for multispectral and hyperspectral image fusion,"  This paper aims at providing a comprehensive framework to generate an
astrophysical scene and to simulate realistic hyperspectral and multispectral
data acquired by two JWST instruments, namely NIRCam Imager and NIRSpec IFU. We
want to show that this simulation framework can be resorted to assess the
benefits of fusing these images to recover an image of high spatial and
spectral resolutions. To do so, we create a synthetic scene associated with a
canonical infrared source, the Orion Bar. This scene combines pre-existing
modelled spectra provided by the JWST Early Release Science Program 1288 and
real high resolution spatial maps from the Hubble space and ALMA telescopes. We
develop forward models including corresponding noises for the two JWST
instruments based on their technical designs and physical features. JWST
observations are then simulated by applying the forward models to the
aforementioned synthetic scene. We test a dedicated fusion algorithm we
developed on these simulated observations. We show the fusion process
reconstructs the high spatio-spectral resolution scene with a good accuracy on
most areas, and we identify some limitations of the method to be tackled in
future works. The synthetic scene and observations presented in the paper are
made publicly available and can be used for instance to evaluate instrument
models (aboard the JWST or on the ground), pipelines, or more sophisticated
algorithms dedicated to JWST data analysis. Besides, fusion methods such as the
one presented in this paper are shown to be promising tools to fully exploit
the unprecedented capabilities of the JWST.
","Claire Guilloteau, Thomas Oberlin, Olivier Berné, Nicolas Dobigeon",Nicolas Dobigeon,2020-01-08T16:57:45Z
"Hyperspectral Image Restoration via Global Total Variation Regularized
  Local nonconvex Low-Rank matrix Approximation","  Several bandwise total variation (TV) regularized low-rank (LR)-based models
have been proposed to remove mixed noise in hyperspectral images (HSIs).
Conventionally, the rank of LR matrix is approximated using nuclear norm (NN).
The NN is defined by adding all singular values together, which is essentially
a $L_1$-norm of the singular values. It results in non-negligible approximation
errors and thus the resulting matrix estimator can be significantly biased.
Moreover, these bandwise TV-based methods exploit the spatial information in a
separate manner. To cope with these problems, we propose a spatial-spectral TV
(SSTV) regularized non-convex local LR matrix approximation (NonLLRTV) method
to remove mixed noise in HSIs. From one aspect, local LR of HSIs is formulated
using a non-convex $L_{\gamma}$-norm, which provides a closer approximation to
the matrix rank than the traditional NN. From another aspect, HSIs are assumed
to be piecewisely smooth in the global spatial domain. The TV regularization is
effective in preserving the smoothness and removing Gaussian noise. These facts
inspire the integration of the NonLLR with TV regularization. To address the
limitations of bandwise TV, we use the SSTV regularization to simultaneously
consider global spatial structure and spectral correlation of neighboring
bands. Experiment results indicate that the use of local non-convex penalty and
global SSTV can boost the preserving of spatial piecewise smoothness and
overall structural information.
","Haijin Zeng, Xiaozhen Xie, Jifeng Ning",Jifeng Ning,2020-05-08T16:42:18Z
"Real-time and high-throughput Raman signal extraction and processing in
  CARS hyperspectral imaging","  We present a new collection of processing techniques, collectively
""factorized Kramers--Kronig and error correction"" (fKK-EC), for (a) Raman
signal extraction, (b) denoising, and (c) phase- and scale-error correction in
coherent anti-Stokes Raman scattering (CARS) hyperspectral imaging and
spectroscopy. These new methods are orders-of-magnitude faster than
conventional methods and are capable of real-time performance, owing to the
unique core concept: performing all processing on a small basis vector set and
using matrix/vector multiplication afterwards for direct and fast
transformation of the entire dataset. Experimentally, we demonstrate that a
703026 spectra image of chicken cartilage can be processed in 70 s
(approximately 0.1 ms / spectrum), which is approximately 70 times faster than
with the conventional workflow (approximately 7.0 ms / spectrum). Additionally,
we discuss how this method may be used for machine learning (ML) by re-using
the transformed basis vector sets with new data. Using this ML paradigm, the
same tissue image was processed (post-training) in approximately 33 s, which is
a speed-up of approximately 150 times when compared with the conventional
workflow.
","Charles H. Camp Jr., John S. Bender, Young Jong Lee",Young Jong Lee,2020-05-12T20:26:05Z
"Gaussian process analysis of Electron Energy Loss Spectroscopy (EELS)
  data: parallel reconstruction and kernel control","  Advances in hyperspectral imaging modes including electron energy loss
spectroscopy (EELS) in scanning transmission electron microscopy (STEM) bring
forth the challenges of exploratory and subsequently physics-based analysis of
multidimensional data sets. The (by now common) multivariate unsupervised
linear unmixing methods and their nonlinear analogs generally explore
similarities in the energy dimension but ignore correlations in the spatial
domain. At the same time, Gaussian process (GP) methods that explicitly
incorporate spatial correlations in the form of kernel functions tend to be
extremely computationally intensive, while the use of inducing point-based
sparse methods often leads to reconstruction artefacts. Here, we suggest and
implement a parallel GP method operating on the full spatial domain and reduced
representations in the energy domain. In this parallel GP, the information
between the components is shared via a common spatial kernel structure while
allowing for variability in the relative noise magnitude or image morphology.
We explore the role of common spatial structures and kernel constraints on the
quality of the reconstruction and suggest an approach for estimating these
factors from the experimental data. Application of this method to an example
EELS dataset demonstrates that spatial information contained in higher-order
components can be reconstructed and spatially localized. This approach can be
further applied to other hyperspectral and multimodal imaging modes. The
notebooks developed in this manuscript are freely available as part of a GPim
package (https://github.com/ziatdinovmax/GPim).
","Sergei V. Kalinin, Andrew R. Lupini, Rama K. Vasudevan, Maxim Ziatdinov",Maxim Ziatdinov,2020-05-21T07:58:17Z
"Hyperspectral Unmixing Network Inspired by Unfolding an Optimization
  Problem","  The hyperspectral image (HSI) unmixing task is essentially an inverse
problem, which is commonly solved by optimization algorithms under a predefined
(non-)linear mixture model. Although these optimization algorithms show
impressive performance, they are very computational demanding as they often
rely on an iterative updating scheme. Recently, the rise of neural networks has
inspired lots of learning based algorithms in unmixing literature. However,
most of them lack of interpretability and require a large training dataset. One
natural question then arises: can one leverage the model based algorithm and
learning based algorithm to achieve interpretable and fast algorithm for HSI
unmixing problem? In this paper, we propose two novel network architectures,
named U-ADMM-AENet and U-ADMM-BUNet, for abundance estimation and blind
unmixing respectively, by combining the conventional optimization-model based
unmixing method and the rising learning based unmixing method. We first
consider a linear mixture model with sparsity constraint, then we unfold
Alternating Direction Method of Multipliers (ADMM) algorithm to construct the
unmixing network structures. We also show that the unfolded structures can find
corresponding interpretations in machine learning literature, which further
demonstrates the effectiveness of proposed methods. Benefit from the
interpretation, the proposed networks can be initialized by incorporating prior
information about the HSI data. Different from traditional unfolding networks,
we propose a new training strategy for proposed networks to better fit in the
HSI applications. Extensive experiments show that the proposed methods can
achieve much faster convergence and competitive performance even with very
small size of training data, when compared with state-of-art algorithms.
",Chao Zhou,Chao Zhou,2020-05-21T18:49:45Z
"Photo-degradation Protection in 2D In-Plane Heterostructures Revealed by
  Hyperspectral Nanoimaging: the Role of Nano-Interface 2D Alloys","  Single-layer heterostructures exhibit striking quasiparticle properties and
many-body interaction effects that hold promise for a range of applications.
However, their properties can be altered by intrinsic and extrinsic defects,
thus diminishing their applicability. Therefore, it is of paramount importance
to identify defects and understand 2D materials' degradation over time using
advanced multimodal imaging techniques as well as stabilize degradation via
built-in interface protection. Here we implemented a liquid-phase precursor
approach to synthesize 2D in-plane MoS2-WS2 heterostructures exhibiting
nanoscale alloyed interfaces and map exotic interface effects during
photo-degradation using a novel combination of hyperspectral tip-enhanced
photoluminescence, Raman and near-field nanoscopy. Surprisingly, 2D alloyed
regions exhibit remarkable thermal and photo-degradation stability providing
protection against oxidation. Coupled with surface and interface strain, 2D
alloy regions create localized potential wells that concentrate excitonic
species via a charge carrier funneling effect. These results provide a clear
understanding of the importance of 2D alloys as systems able to withstand
degradation effects over time, and could be now used to stabilize
optoelectronic devices based on 2D materials.
","Alireza Fali, Tianyi Zhang, Jason Patrick Terry, Ethan Kahn, Kazunori Fujisawa, Sandhaya Koirala, Yassamin Ghafouri, Wenshen Song, Li Yang, Mauricio Terrones, Yohannes Abate",Yohannes Abate,2020-05-22T19:31:02Z
"Hyperspectral Image Super-resolution via Deep Progressive Zero-centric
  Residual Learning","  This paper explores the problem of hyperspectral image (HSI) super-resolution
that merges a low resolution HSI (LR-HSI) and a high resolution multispectral
image (HR-MSI). The cross-modality distribution of the spatial and spectral
information makes the problem challenging. Inspired by the classic wavelet
decomposition-based image fusion, we propose a novel \textit{lightweight} deep
neural network-based framework, namely progressive zero-centric residual
network (PZRes-Net), to address this problem efficiently and effectively.
Specifically, PZRes-Net learns a high resolution and \textit{zero-centric}
residual image, which contains high-frequency spatial details of the scene
across all spectral bands, from both inputs in a progressive fashion along the
spectral dimension. And the resulting residual image is then superimposed onto
the up-sampled LR-HSI in a \textit{mean-value invariant} manner, leading to a
coarse HR-HSI, which is further refined by exploring the coherence across all
spectral bands simultaneously. To learn the residual image efficiently and
effectively, we employ spectral-spatial separable convolution with dense
connections. In addition, we propose zero-mean normalization implemented on the
feature maps of each layer to realize the zero-mean characteristic of the
residual image. Extensive experiments over both real and synthetic benchmark
datasets demonstrate that our PZRes-Net outperforms state-of-the-art methods to
a \textit{significant} extent in terms of both 4 quantitative metrics and
visual quality, e.g., our PZRes-Net improves the PSNR more than 3dB, while
saving 2.3$\times$ parameters and consuming 15$\times$ less FLOPs. The code is
publicly available at https://github.com/zbzhzhy/PZRes-Net .
","Zhiyu Zhu, Junhui Hou, Jie Chen, Huanqiang Zeng, Jiantao Zhou",Jiantao Zhou,2020-06-18T06:32:11Z
"Coupled Tensor Decomposition for Hyperspectral and Multispectral Image
  Fusion with Inter-Image Variability","  Coupled tensor approximation has recently emerged as a promising approach for
the fusion of hyperspectral and multispectral images, reconciling state of the
art performance with strong theoretical guarantees. However, tensor-based
approaches previously proposed assume that the different observed images are
acquired under exactly the same conditions. A recent work proposed to
accommodate inter-image spectral variability in the image fusion problem using
a matrix factorization-based formulation, but did not account for
spatially-localized variations. Moreover, it lacks theoretical guarantees and
has a high associated computational complexity. In this paper, we consider the
image fusion problem while accounting for both spatially and spectrally
localized changes in an additive model. We first study how the general
identifiability of the model is impacted by the presence of such changes. Then,
assuming that the high-resolution image and the variation factors admit a
Tucker decomposition, two new algorithms are proposed -- one purely algebraic,
and another based on an optimization procedure. Theoretical guarantees for the
exact recovery of the high-resolution image are provided for both algorithms.
Experimental results show that the proposed method outperforms state-of-the-art
methods in the presence of spectral and spatial variations between the images,
at a smaller computational cost.
","Ricardo Augusto Borsoi, Clémence Prévost, Konstantin Usevich, David Brie, José Carlos Moreira Bermudez, Cédric Richard",Cédric Richard,2020-06-30T17:00:20Z
"Efficient Deep Learning of Non-local Features for Hyperspectral Image
  Classification","  Deep learning based methods, such as Convolution Neural Network (CNN), have
demonstrated their efficiency in hyperspectral image (HSI) classification.
These methods can automatically learn spectral-spatial discriminative features
within local patches. However, for each pixel in an HSI, it is not only related
to its nearby pixels but also has connections to pixels far away from itself.
Therefore, to incorporate the long-range contextual information, a deep fully
convolutional network (FCN) with an efficient non-local module, named ENL-FCN,
is proposed for HSI classification. In the proposed framework, a deep FCN
considers an entire HSI as input and extracts spectral-spatial information in a
local receptive field. The efficient non-local module is embedded in the
network as a learning unit to capture the long-range contextual information.
Different from the traditional non-local neural networks, the long-range
contextual information is extracted in a specially designed criss-cross path
for computation efficiency. Furthermore, by using a recurrent operation, each
pixel's response is aggregated from all pixels of HSI. The benefits of our
proposed ENL-FCN are threefold: 1) the long-range contextual information is
incorporated effectively, 2) the efficient module can be freely embedded in a
deep neural network in a plug-and-play fashion, and 3) it has much fewer
learning parameters and requires less computational resources. The experiments
conducted on three popular HSI datasets demonstrate that the proposed method
achieves state-of-the-art classification performance with lower computational
cost in comparison with several leading deep neural networks for HSI.
","Yu Shen, Sijie Zhu, Chen Chen, Qian Du, Liang Xiao, Jianyu Chen, Delu Pan",Delu Pan,2020-08-02T19:13:22Z
"Hyperspectral Image Classification with Spatial Consistence Using Fully
  Convolutional Spatial Propagation Network","  In recent years, deep convolutional neural networks (CNNs) have shown
impressive ability to represent hyperspectral images (HSIs) and achieved
encouraging results in HSI classification. However, the existing CNN-based
models operate at the patch-level, in which pixel is separately classified into
classes using a patch of images around it. This patch-level classification will
lead to a large number of repeated calculations, and it is difficult to
determine the appropriate patch size that is beneficial to classification
accuracy. In addition, the conventional CNN models operate convolutions with
local receptive fields, which cause failures in modeling contextual spatial
information. To overcome the aforementioned limitations, we propose a novel
end-to-end, pixels-to-pixels fully convolutional spatial propagation network
(FCSPN) for HSI classification. Our FCSPN consists of a 3D fully convolution
network (3D-FCN) and a convolutional spatial propagation network (CSPN).
Specifically, the 3D-FCN is firstly introduced for reliable preliminary
classification, in which a novel dual separable residual (DSR) unit is proposed
to effectively capture spectral and spatial information simultaneously with
fewer parameters. Moreover, the channel-wise attention mechanism is adapted in
the 3D-FCN to grasp the most informative channels from redundant channel
information. Finally, the CSPN is introduced to capture the spatial
correlations of HSI via learning a local linear spatial propagation, which
allows maintaining the HSI spatial consistency and further refining the
classification results. Experimental results on three HSI benchmark datasets
demonstrate that the proposed FCSPN achieves state-of-the-art performance on
HSI classification.
","Yenan Jiang, Ying Li, Shanrong Zou, Haokui Zhang, Yunpeng Bai",Yunpeng Bai,2020-08-04T09:05:52Z
"Physically-Constrained Transfer Learning through Shared Abundance Space
  for Hyperspectral Image Classification","  Hyperspectral image (HSI) classification is one of the most active research
topics and has achieved promising results boosted by the recent development of
deep learning. However, most state-of-the-art approaches tend to perform poorly
when the training and testing images are on different domains, e.g., source
domain and target domain, respectively, due to the spectral variability caused
by different acquisition conditions. Transfer learning-based methods address
this problem by pre-training in the source domain and fine-tuning on the target
domain. Nonetheless, a considerable amount of data on the target domain has to
be labeled and non-negligible computational resources are required to retrain
the whole network. In this paper, we propose a new transfer learning scheme to
bridge the gap between the source and target domains by projecting the HSI data
from the source and target domains into a shared abundance space based on their
own physical characteristics. In this way, the domain discrepancy would be
largely reduced such that the model trained on the source domain could be
applied on the target domain without extra efforts for data labeling or network
retraining. The proposed method is referred to as physically-constrained
transfer learning through shared abundance space (PCTL-SAS). Extensive
experimental results demonstrate the superiority of the proposed method as
compared to the state-of-the-art. The success of this endeavor would largely
facilitate the deployment of HSI classification for real-world sensing
scenarios.
","Ying Qu, Razieh Kaviani Baghbaderani, Wei Li, Lianru Gao, Hairong Qi",Hairong Qi,2020-08-19T17:41:37Z
"Unsupervised Hyperspectral Mixed Noise Removal Via Spatial-Spectral
  Constrained Deep Image Prior","  Recently, convolutional neural network (CNN)-based methods are proposed for
hyperspectral images (HSIs) denoising. Among them, unsupervised methods such as
the deep image prior (DIP) have received much attention because these methods
do not require any training data. However, DIP suffers from the
semi-convergence behavior, i.e., the iteration of DIP needs to terminate by
referring to the ground-truth image at the optimal iteration point. In this
paper, we propose the spatial-spectral constrained deep image prior (S2DIP) for
HSI mixed noise removal. Specifically, we incorporate DIP with a
spatial-spectral total variation (SSTV) term to fully preserve the
spatial-spectral local smoothness of the HSI and an $\ell_1$-norm term to
capture the complex sparse noise. The proposed S2DIP jointly leverages the
expressive power brought from the deep CNN without any training data and
exploits the HSI and noise structures via hand-crafted priors. Thus, our method
avoids the semi-convergence behavior, showing higher stabilities than DIP.
Meanwhile, our method largely enhances the HSI denoising ability of DIP. To
tackle the proposed denoising model, we develop an alternating direction
multiplier method algorithm. Extensive experiments demonstrate that the
proposed S2DIP outperforms optimization-based and supervised CNN-based
state-of-the-art HSI denoising methods.
","Yi-Si Luo, Xi-Le Zhao, Tai-Xiang Jiang, Yu-Bang Zheng, Yi Chang",Yi Chang,2020-08-22T04:25:08Z
Coreset of Hyperspectral Images on Small Quantum Computer,"  Machine Learning (ML) techniques are employed to analyze and process big
Remote Sensing (RS) data, and one well-known ML technique is a Support Vector
Machine (SVM). An SVM is a quadratic programming (QP) problem, and a D-Wave
quantum annealer (D-Wave QA) promises to solve this QP problem more efficiently
than a conventional computer. However, the D-Wave QA cannot solve directly the
SVM due to its very few input qubits. Hence, we use a coreset (""core of a
dataset"") of given EO data for training an SVM on this small D-Wave QA. The
coreset is a small, representative weighted subset of an original dataset, and
any training models generate competitive classes by using the coreset in
contrast to by using its original dataset. We measured the closeness between an
original dataset and its coreset by employing a Kullback-Leibler (KL)
divergence measure. Moreover, we trained the SVM on the coreset data by using
both a D-Wave QA and a conventional method. We conclude that the coreset
characterizes the original dataset with very small KL divergence measure. In
addition, we present our KL divergence results for demonstrating the closeness
between our original data and its coreset. As practical RS data, we use
Hyperspectral Image (HSI) of Indian Pine, USA.
","Soronzonbold Otgonbaatar, Mihai Datcu, Begüm Demir",Begüm Demir,2022-04-10T14:14:20Z
"Adaptive Cross-Attention-Driven Spatial-Spectral Graph Convolutional
  Network for Hyperspectral Image Classification","  Recently, graph convolutional networks (GCNs) have been developed to explore
spatial relationship between pixels, achieving better classification
performance of hyperspectral images (HSIs). However, these methods fail to
sufficiently leverage the relationship between spectral bands in HSI data. As
such, we propose an adaptive cross-attention-driven spatial-spectral graph
convolutional network (ACSS-GCN), which is composed of a spatial GCN (Sa-GCN)
subnetwork, a spectral GCN (Se-GCN) subnetwork, and a graph cross-attention
fusion module (GCAFM). Specifically, Sa-GCN and Se-GCN are proposed to extract
the spatial and spectral features by modeling correlations between spatial
pixels and between spectral bands, respectively. Then, by integrating attention
mechanism into information aggregation of graph, the GCAFM, including three
parts, i.e., spatial graph attention block, spectral graph attention block, and
fusion block, is designed to fuse the spatial and spectral features and
suppress noise interference in Sa-GCN and Se-GCN. Moreover, the idea of the
adaptive graph is introduced to explore an optimal graph through back
propagation during the training process. Experiments on two HSI data sets show
that the proposed method achieves better performance than other classification
methods.
","Jin-Yu Yang, Heng-Chao Li, Wen-Shuai Hu, Lei Pan, Qian Du",Qian Du,2022-04-12T14:06:11Z
"Adaptive hyperspectral imaging using structured illumination in a
  spatial light modulator-based interferometer","  We develop a novel hyperspectral imaging system using structured illumination
in an SLM-based Michelson interferometer. In our design, we use a reflective
SLM as a mirror in one of the arms of a Michelson interferometer, and scan the
interferometer by varying the phase across the SLM display. For achieving the
latter, we apply a checkerboard phase mask on the SLM display where the gray
value varies between 0-255, thereby imparting a dynamic phase of up to
262{\deg} to the incident light beam. We couple a supercontinuum source into
the interferometer in order to mimic an astronomical object such as the Sun,
and choose a central wavelength of 637.4 nm akin to the strong emission line of
Fe X present in the solar spectrum. We use a bandwidth of 30 nm, and extract
fringes corresponding to a spectral resolution of 3.8 nm which is limited by
the reflectivity of the SLM. We also demonstrate a maximum wavelength
tunability of ~8 nm by varying the phase over the phase mask with a spectral
sampling of around 0.03 nm between intermediate fringes. The checkerboard phase
mask can be adapted close to real time on time-scales of a few tens of
milliseconds to obtain spectral information for other near-contiguous
wavelengths. The compactness, potential low cost, low power requirements,
real-time tunability and lack of moving mechanical parts in the setup implies
that it can have very useful applications in settings which require near
real-time, multi-wavelength spectroscopic applications, and is especially
relevant in space astronomy.
","Amar Deo Chandra, Mintu Karmakar, Dibyendu Nandy, Ayan Banerjee",Ayan Banerjee,2022-04-22T09:17:15Z
"Linear vs Nonlinear Extreme Learning Machine for Spectral-Spatial
  Classification of Hyperspectral Image","  As a new machine learning approach, extreme learning machine (ELM) has
received wide attentions due to its good performances. However, when directly
applied to the hyperspectral image (HSI) classification, the recognition rate
is too low. This is because ELM does not use the spatial information which is
very important for HSI classification. In view of this, this paper proposes a
new framework for spectral-spatial classification of HSI by combining ELM with
loopy belief propagation (LBP). The original ELM is linear, and the nonlinear
ELMs (or Kernel ELMs) are the improvement of linear ELM (LELM). However, based
on lots of experiments and analysis, we found out that the LELM is a better
choice than nonlinear ELM for spectral-spatial classification of HSI.
Furthermore, we exploit the marginal probability distribution that uses the
whole information in the HSI and learn such distribution using the LBP. The
proposed method not only maintain the fast speed of ELM, but also greatly
improves the accuracy of classification. The experimental results in the
well-known HSI data sets, Indian Pines and Pavia University, demonstrate the
good performances of the proposed method.
","Faxian Cao, Zhijing Yang, Jinchang Ren, Mengying Jiang, Wing-Kuen Ling",Wing-Kuen Ling,2017-09-05T06:53:02Z
"Extreme Sparse Multinomial Logistic Regression: A Fast and Robust
  Framework for Hyperspectral Image Classification","  Although the sparse multinomial logistic regression (SMLR) has provided a
useful tool for sparse classification, it suffers from inefficacy in dealing
with high dimensional features and manually set initial regressor values. This
has significantly constrained its applications for hyperspectral image (HSI)
classification. In order to tackle these two drawbacks, an extreme sparse
multinomial logistic regression (ESMLR) is proposed for effective
classification of HSI. First, the HSI dataset is projected to a new feature
space with randomly generated weight and bias. Second, an optimization model is
established by the Lagrange multiplier method and the dual principle to
automatically determine a good initial regressor for SMLR via minimizing the
training error and the regressor value. Furthermore, the extended
multi-attribute profiles (EMAPs) are utilized for extracting both the spectral
and spatial features. A combinational linear multiple features learning (MFL)
method is proposed to further enhance the features extracted by ESMLR and
EMAPs. Finally, the logistic regression via the variable splitting and the
augmented Lagrangian (LORSAL) is adopted in the proposed framework for reducing
the computational time. Experiments are conducted on two well-known HSI
datasets, namely the Indian Pines dataset and the Pavia University dataset,
which have shown the fast and robust performance of the proposed ESMLR
framework.
","Faxian Cao, Zhijing Yang, Jinchang Ren, Wing-Kuen Ling",Wing-Kuen Ling,2017-09-08T03:16:52Z
"Sparse Representation Based Augmented Multinomial Logistic Extreme
  Learning Machine with Weighted Composite Features for Spectral Spatial
  Hyperspectral Image Classification","  Although extreme learning machine (ELM) has been successfully applied to a
number of pattern recognition problems, it fails to pro-vide sufficient good
results in hyperspectral image (HSI) classification due to two main drawbacks.
The first is due to the random weights and bias of ELM, which may lead to
ill-posed problems. The second is the lack of spatial information for
classification. To tackle these two problems, in this paper, we propose a new
framework for ELM based spectral-spatial classification of HSI, where
probabilistic modelling with sparse representation and weighted composite
features (WCF) are employed respectively to derive the op-timized output
weights and extract spatial features. First, the ELM is represented as a
concave logarithmic likelihood function under statistical modelling using the
maximum a posteriori (MAP). Second, the sparse representation is applied to the
Laplacian prior to effi-ciently determine a logarithmic posterior with a unique
maximum in order to solve the ill-posed problem of ELM. The variable splitting
and the augmented Lagrangian are subsequently used to further reduce the
computation complexity of the proposed algorithm and it has been proven a more
efficient method for speed improvement. Third, the spatial information is
extracted using the weighted compo-site features (WCFs) to construct the
spectral-spatial classification framework. In addition, the lower bound of the
proposed method is derived by a rigorous mathematical proof. Experimental
results on two publicly available HSI data sets demonstrate that the proposed
methodology outperforms ELM and a number of state-of-the-art approaches.
","Faxian Cao, Zhijing Yang, Jinchang Ren, Wing-Kuen Ling",Wing-Kuen Ling,2017-09-12T11:39:51Z
Tensor-Based Classifiers for Hyperspectral Data Analysis,"  In this work, we present tensor-based linear and nonlinear models for
hyperspectral data classification and analysis. By exploiting principles of
tensor algebra, we introduce new classification architectures, the weight
parameters of which satisfies the {\it rank}-1 canonical decomposition
property. Then, we introduce learning algorithms to train both the linear and
the non-linear classifier in a way to i) to minimize the error over the
training samples and ii) the weight coefficients satisfies the {\it rank}-1
canonical decomposition property. The advantages of the proposed classification
model is that i) it reduces the number of parameters required and thus reduces
the respective number of training samples required to properly train the model,
ii) it provides a physical interpretation regarding the model coefficients on
the classification output and iii) it retains the spatial and spectral
coherency of the input samples. To address issues related with linear
classification, characterizing by low capacity, since it can produce rules that
are linear in the input space, we introduce non-linear classification models
based on a modification of a feedforward neural network. We call the proposed
architecture {\it rank}-1 Feedfoward Neural Network (FNN), since their weights
satisfy the {\it rank}-1 caconical decomposition property. Appropriate learning
algorithms are also proposed to train the network. Experimental results and
comparisons with state of the art classification methods, either linear (e.g.,
SVM) and non-linear (e.g., deep learning) indicates the outperformance of the
proposed scheme, especially in cases where a small number of training samples
are available. Furthermore, the proposed tensor-based classfiers are evaluated
against their capabilities in dimensionality reduction.
","Konstantinos Makantasis, Anastasios Doulamis, Nikolaos Doulamis, Antonis Nikitakis",Antonis Nikitakis,2017-09-24T09:05:36Z
"A Gaussian mixture model representation of endmember variability in
  hyperspectral unmixing","  Hyperspectral unmixing while considering endmember variability is usually
performed by the normal compositional model (NCM), where the endmembers for
each pixel are assumed to be sampled from unimodal Gaussian distributions.
However, in real applications, the distribution of a material is often not
Gaussian. In this paper, we use Gaussian mixture models (GMM) to represent the
endmember variability. We show, given the GMM starting premise, that the
distribution of the mixed pixel (under the linear mixing model) is also a GMM
(and this is shown from two perspectives). The first perspective originates
from the random variable transformation and gives a conditional density
function of the pixels given the abundances and GMM parameters. With proper
smoothness and sparsity prior constraints on the abundances, the conditional
density function leads to a standard maximum a posteriori (MAP) problem which
can be solved using generalized expectation maximization. The second
perspective originates from marginalizing over the endmembers in the GMM, which
provides us with a foundation to solve for the endmembers at each pixel. Hence,
our model can not only estimate the abundances and distribution parameters, but
also the distinct endmember set for each pixel. We tested the proposed GMM on
several synthetic and real datasets, and showed its potential by comparing it
to current popular methods.
","Yuan Zhou, Anand Rangarajan, Paul D. Gader",Paul D. Gader,2017-09-29T20:10:00Z
"SuperPCA: A Superpixelwise PCA Approach for Unsupervised Feature
  Extraction of Hyperspectral Imagery","  As an unsupervised dimensionality reduction method, principal component
analysis (PCA) has been widely considered as an efficient and effective
preprocessing step for hyperspectral image (HSI) processing and analysis tasks.
It takes each band as a whole and globally extracts the most representative
bands. However, different homogeneous regions correspond to different objects,
whose spectral features are diverse. It is obviously inappropriate to carry out
dimensionality reduction through a unified projection for an entire HSI. In
this paper, a simple but very effective superpixelwise PCA approach, called
SuperPCA, is proposed to learn the intrinsic low-dimensional features of HSIs.
In contrast to classical PCA models, SuperPCA has four main properties. (1)
Unlike the traditional PCA method based on a whole image, SuperPCA takes into
account the diversity in different homogeneous regions, that is, different
regions should have different projections. (2) Most of the conventional feature
extraction models cannot directly use the spatial information of HSIs, while
SuperPCA is able to incorporate the spatial context information into the
unsupervised dimensionality reduction by superpixel segmentation. (3) Since the
regions obtained by superpixel segmentation have homogeneity, SuperPCA can
extract potential low-dimensional features even under noise. (4) Although
SuperPCA is an unsupervised method, it can achieve competitive performance when
compared with supervised approaches. The resulting features are discriminative,
compact, and noise resistant, leading to improved HSI classification
performance. Experiments on three public datasets demonstrate that the SuperPCA
model significantly outperforms the conventional PCA based dimensionality
reduction baselines for HSI classification. The Matlab source code is available
at https://github.com/junjun-jiang/SuperPCA
","Junjun Jiang, Jiayi Ma, Chen Chen, Zhongyuan Wang, Zhihua Cai, Lizhe Wang",Lizhe Wang,2018-06-26T06:38:07Z
"Spatial Feature Extraction in Airborne Hyperspectral Images Using Local
  Spectral Similarity","  Local spectral similarity (LSS) algorithm has been developed for detecting
homogeneous areas and edges in hyperspectral images (HSIs). The proposed
algorithm transforms the 3-D data cube (within a spatial window) into a
spectral similarity matrix by calculating the vector-similarity between the
center pixel-spectrum and the neighborhood spectra. The final edge intensity is
derived upon order statistics of the similarity matrix or spatial convolution
of the similarity matrix with the spatial kernels. The LSS algorithm
facilitates simultaneous use of spectral-spatial information for the edge
detection by considering the spatial pattern of similar spectra within a
spatial window. The proposed edge-detection method is tested on benchmark HSIs
as well as the image obtained from
Airborne-Visible-and-Infra-RedImaging-Spectrometer-Next-Generation (AVIRIS-NG).
Robustness of the LSS method against multivariate Gaussian noise and low
spatial resolution scenarios were also verified with the benchmark HSIs.
Figure-of-merit, false-alarm-count and miss-count were applied to evaluate the
performance of edge detection methods. Results showed that Fractional distance
measure and Euclidean distance measure were able to detect the edges in HSIs
more precisely as compared to other spectral similarity measures. The proposed
method can be applied to radiance and reflectance data (whole spectrum) and it
has shown good performance on principal component images as well. In addition,
the proposed algorithm outperforms the traditional multichannel edge detectors
in terms of both fastness, accuracy and the robustness. The experimental
results also confirm that LSS can be applied as a pre-processing approach to
reduce the errors in clustering as well as classification outputs.
","Anand S Sahadevan, Arundhati Misra, Praveen Gupta",Praveen Gupta,2019-11-06T10:11:41Z
"Unsupervised adulterated red-chili pepper content transformation for
  hyperspectral classification","  Preserving red-chili quality is of utmost importance in which the authorities
demand the quality techniques to detect, classify and prevent it from the
impurities. For example, salt, wheat flour, wheat bran, and rice bran
contamination in grounded red chili, which typically a food, are a serious
threat to people who are allergic to such items. This work presents the
feasibility of utilizing visible and near-infrared (VNIR) hyperspectral imaging
(HSI) to detect and classify the aforementioned adulterants in red chili.
However, adulterated red chili data annotation is a big challenge for
classification because the acquisition of labeled data for real-time supervised
learning is expensive in terms of cost and time. Therefore, this study, for the
very first time proposes a novel approach to annotate the red chili samples
using a clustering mechanism at 500~nm wavelength spectral response due to its
dark appearance at a specified wavelength. Later the spectral samples are
classified into pure or adulterated using one-class SVM. The classification
performance achieves 99% in case of pure adulterants or red chili whereas 85%
for adulterated samples. We further investigate that the single classification
model is enough to detect any foreign substance in red chili pepper rather than
cascading multiple PLS regression models.
","Muhammad Hussain Khan, Zainab Saleem, Muhammad Ahmad, Ahmed Sohaib, Hamail Ayaz",Hamail Ayaz,2019-11-09T15:12:27Z
"Improving Deep Hyperspectral Image Classification Performance with
  Spectral Unmixing","  Recent advances in neural networks have made great progress in the
hyperspectral image (HSI) classification. However, the overfitting effect,
which is mainly caused by complicated model structure and small training set,
remains a major concern. Reducing the complexity of the neural networks could
prevent overfitting to some extent, but also declines the networks' ability to
express more abstract features. Enlarging the training set is also difficult,
for the high expense of acquisition and manual labeling. In this paper, we
propose an abundance-based multi-HSI classification method. Firstly, we convert
every HSI from the spectral domain to the abundance domain by a
dataset-specific autoencoder. Secondly, the abundance representations from
multiple HSIs are collected to form an enlarged dataset. Lastly, we train an
abundance-based classifier and employ the classifier to predict over all the
involved HSI datasets. Different from the spectra that are usually highly
mixed, the abundance features are more representative in reduced dimension with
less noise. This benefits the proposed method to employ simple classifiers and
enlarged training data, and to expect less overfitting issues. The
effectiveness of the proposed method is verified by the ablation study and the
comparative experiments.
","Alan J. X. Guo, Fei Zhu",Fei Zhu,2020-04-01T17:14:05Z
Robust Image Reconstruction with Misaligned Structural Information,"  Multi-modality (or multi-channel) imaging is becoming increasingly important
and more widely available, e.g. hyperspectral imaging in remote sensing,
spectral CT in material sciences as well as multi-contrast MRI and PET-MR in
medicine. Research in the last decades resulted in a plethora of mathematical
methods to combine data from several modalities. State-of-the-art methods,
often formulated as variational regularization, have shown to significantly
improve image reconstruction both quantitatively and qualitatively. Almost all
of these models rely on the assumption that the modalities are perfectly
registered, which is not the case in most real world applications. We propose a
variational framework which jointly performs reconstruction and registration,
thereby overcoming this hurdle. Our approach is the first to achieve this for
different modalities and outranks established approaches in terms of accuracy
of both reconstruction and registration. Numerical results on simulated and
real data show the potential of the proposed strategy for various applications
in multi-contrast MRI, PET-MR, and hyperspectral imaging: typical misalignments
between modalities such as rotations, translations, zooms can be effectively
corrected during the reconstruction process. Therefore the proposed framework
allows the robust exploitation of shared information across multiple modalities
under real conditions.
","Leon Bungert, Matthias J. Ehrhardt",Matthias J. Ehrhardt,2020-04-01T17:21:25Z
"Graph Convolutional Subspace Clustering: A Robust Subspace Clustering
  Framework for Hyperspectral Image","  Hyperspectral image (HSI) clustering is a challenging task due to the high
complexity of HSI data. Subspace clustering has been proven to be powerful for
exploiting the intrinsic relationship between data points. Despite the
impressive performance in the HSI clustering, traditional subspace clustering
methods often ignore the inherent structural information among data. In this
paper, we revisit the subspace clustering with graph convolution and present a
novel subspace clustering framework called Graph Convolutional Subspace
Clustering (GCSC) for robust HSI clustering. Specifically, the framework
recasts the self-expressiveness property of the data into the non-Euclidean
domain, which results in a more robust graph embedding dictionary. We show that
traditional subspace clustering models are the special forms of our framework
with the Euclidean data. Basing on the framework, we further propose two novel
subspace clustering models by using the Frobenius norm, namely Efficient GCSC
(EGCSC) and Efficient Kernel GCSC (EKGCSC). Both models have a globally optimal
closed-form solution, which makes them easier to implement, train, and apply in
practice. Extensive experiments on three popular HSI datasets demonstrate that
EGCSC and EKGCSC can achieve state-of-the-art clustering performance and
dramatically outperforms many existing methods with significant margins.
","Yaoming Cai, Zijia Zhang, Zhihua Cai, Xiaobo Liu, Xinwei Jiang, Qin Yan",Qin Yan,2020-04-22T10:09:19Z
"Hyperspectral Image Denoising with Partially Orthogonal Matrix Vector
  Tensor Factorization","  Hyperspectral image (HSI) has some advantages over natural image for various
applications due to the extra spectral information. During the acquisition, it
is often contaminated by severe noises including Gaussian noise, impulse noise,
deadlines, and stripes. The image quality degeneration would badly effect some
applications. In this paper, we present a HSI restoration method named smooth
and robust low rank tensor recovery. Specifically, we propose a structural
tensor decomposition in accordance with the linear spectral mixture model of
HSI. It decomposes a tensor into sums of outer matrix vector products, where
the vectors are orthogonal due to the independence of endmember spectrums.
Based on it, the global low rank tensor structure can be well exposited for HSI
denoising. In addition, the 3D anisotropic total variation is used for spatial
spectral piecewise smoothness of HSI. Meanwhile, the sparse noise including
impulse noise, deadlines and stripes, is detected by the l1 norm
regularization. The Frobenius norm is used for the heavy Gaussian noise in some
real world scenarios. The alternating direction method of multipliers is
adopted to solve the proposed optimization model, which simultaneously exploits
the global low rank property and the spatial spectral smoothness of the HSI.
Numerical experiments on both simulated and real data illustrate the
superiority of the proposed method in comparison with the existing ones.
","Zhen Long, Yipeng Liu, Sixing Zeng, Jiani Liu, Fei Wen, Ce Zhu",Ce Zhu,2020-06-29T02:10:07Z
"Hyperspectral Imaging to detect Age, Defects and Individual Nutrient
  Deficiency in Grapevine Leaves","  Hyperspectral (HS) imaging was successfully employed in the 380 nm to 1000 nm
wavelength range to investigate the efficacy of detecting age, healthiness and
individual nutrient deficiency of grapevine leaves collected from vineyards
located in central west NSW, Australia. For age detection, the appearance of
many healthy grapevine leaves has been examined. Then visually defective leaves
were compared with healthy leaves. Control leaves and individual
nutrient-deficient leaves (e.g. N, K and Mg) were also analysed. Several
features were employed at various stages in the Ultraviolet (UV), Visible (VIS)
and Near Infrared (NIR) regions to evaluate the experimental data: mean
brightness, mean 1st derivative brightness, variation index, mean spectral
ratio, normalised difference vegetation index (NDVI) and standard deviation
(SD). Experiment results demonstrate that these features could be utilised with
a high degree of effectiveness to compare age, identify unhealthy samples and
not only to distinguish from control and nutrient deficiency but also to
identify individual nutrient defects. Therefore, our work corroborated that HS
imaging has excellent potential as a non-destructive as well as a non-contact
method to detect age, healthiness and individual nutrient deficiencies of
grapevine leaves
","Manoranjan Paul, Sourabhi Debnath, Tanmoy Debnath, Suzy Rogiers, Tintu Baby, DM Motiur Rahaman, Lihong Zheng, Leigh Schmidtke",Leigh Schmidtke,2020-07-10T06:42:24Z
"Cross-Attention in Coupled Unmixing Nets for Unsupervised Hyperspectral
  Super-Resolution","  The recent advancement of deep learning techniques has made great progress on
hyperspectral image super-resolution (HSI-SR). Yet the development of
unsupervised deep networks remains challenging for this task. To this end, we
propose a novel coupled unmixing network with a cross-attention mechanism,
CUCaNet for short, to enhance the spatial resolution of HSI by means of
higher-spatial-resolution multispectral image (MSI). Inspired by coupled
spectral unmixing, a two-stream convolutional autoencoder framework is taken as
backbone to jointly decompose MS and HS data into a spectrally meaningful basis
and corresponding coefficients. CUCaNet is capable of adaptively learning
spectral and spatial response functions from HS-MS correspondences by enforcing
reasonable consistency assumptions on the networks. Moreover, a cross-attention
module is devised to yield more effective spatial-spectral information transfer
in networks. Extensive experiments are conducted on three widely-used HS-MS
datasets in comparison with state-of-the-art HSI-SR models, demonstrating the
superiority of the CUCaNet in the HSI-SR application. Furthermore, the codes
and datasets will be available at:
https://github.com/danfenghong/ECCV2020_CUCaNet.
","Jing Yao, Danfeng Hong, Jocelyn Chanussot, Deyu Meng, Xiaoxiang Zhu, Zongben Xu",Zongben Xu,2020-07-10T08:08:20Z
"Spectral Superresolution of Multispectral Imagery with Joint Sparse and
  Low-Rank Learning","  Extensive attention has been widely paid to enhance the spatial resolution of
hyperspectral (HS) images with the aid of multispectral (MS) images in remote
sensing. However, the ability in the fusion of HS and MS images remains to be
improved, particularly in large-scale scenes, due to the limited acquisition of
HS images. Alternatively, we super-resolve MS images in the spectral domain by
the means of partially overlapped HS images, yielding a novel and promising
topic: spectral superresolution (SSR) of MS imagery. This is challenging and
less investigated task due to its high ill-posedness in inverse imaging. To
this end, we develop a simple but effective method, called joint sparse and
low-rank learning (J-SLoL), to spectrally enhance MS images by jointly learning
low-rank HS-MS dictionary pairs from overlapped regions. J-SLoL infers and
recovers the unknown hyperspectral signals over a larger coverage by sparse
coding on the learned dictionary pair. Furthermore, we validate the SSR
performance on three HS-MS datasets (two for classification and one for
unmixing) in terms of reconstruction, classification, and unmixing by comparing
with several existing state-of-the-art baselines, showing the effectiveness and
superiority of the proposed J-SLoL algorithm. Furthermore, the codes and
datasets will be available at:
https://github.com/danfenghong/IEEE\_TGRS\_J-SLoL, contributing to the RS
community.
","Lianru Gao, Danfeng Hong, Jing Yao, Bing Zhang, Paolo Gamba, Jocelyn Chanussot",Jocelyn Chanussot,2020-07-28T06:08:44Z
"Unsupervised Alternating Optimization for Blind Hyperspectral Imagery
  Super-resolution","  Despite the great success of deep model on Hyperspectral imagery (HSI)
super-resolution(SR) for simulated data, most of them function unsatisfactory
when applied to the real data, especially for unsupervised HSI SR methods. One
of the main reason comes from the fact that the predefined degeneration models
(e.g. blur in spatial domain) utilized by most HSI SR methods often exist great
discrepancy with the real one, which results in these deep models overfit and
ultimately degrade their performance on real data. To well mitigate such a
problem, we explore the unsupervised blind HSI SR method. Specifically, we
investigate how to effectively obtain the degeneration models in spatial and
spectral domain, respectively, and makes them can well compatible with the
fusion based SR reconstruction model. To this end, we first propose an
alternating optimization based deep framework to estimate the degeneration
models and reconstruct the latent image, with which the degeneration models
estimation and HSI reconstruction can mutually promotes each other. Then, a
meta-learning based mechanism is further proposed to pre-train the network,
which can effectively improve the speed and generalization ability adapting to
different complex degeneration. Experiments on three benchmark HSI SR datasets
report an excellent superiority of the proposed method on handling blind HSI
fusion problem over other competing methods.
","Jiangtao Nie, Lei Zhang, Wei Wei, Zhiqiang Lang, Yanning Zhang",Yanning Zhang,2020-12-03T07:52:32Z
"SMDS-Net: Model Guided Spectral-Spatial Network for Hyperspectral Image
  Denoising","  Deep learning (DL) based hyperspectral images (HSIs) denoising approaches
directly learn the nonlinear mapping between observed noisy images and
underlying clean images. They normally do not consider the physical
characteristics of HSIs, therefore making them lack of interpretability that is
key to understand their denoising mechanism.. In order to tackle this problem,
we introduce a novel model guided interpretable network for HSI denoising.
Specifically, fully considering the spatial redundancy, spectral low-rankness
and spectral-spatial properties of HSIs, we first establish a subspace based
multi-dimensional sparse model. This model first projects the observed HSIs
into a low-dimensional orthogonal subspace, and then represents the projected
image with a multidimensional dictionary. After that, the model is unfolded
into an end-to-end network named SMDS-Net whose fundamental modules are
seamlessly connected with the denoising procedure and optimization of the
model. This makes SMDS-Net convey clear physical meanings, i.e., learning the
low-rankness and sparsity of HSIs. Finally, all key variables including
dictionaries and thresholding parameters are obtained by the end-to-end
training. Extensive experiments and comprehensive analysis confirm the
denoising ability and interpretability of our method against the
state-of-the-art HSI denoising methods.
","Fengchao Xiong, Shuyin Tao, Jun Zhou, Jianfeng Lu, Jiantao Zhou, Yuntao Qian",Yuntao Qian,2020-12-03T11:05:01Z
"Hyperspectral Classification Based on Lightweight 3-D-CNN With Transfer
  Learning","  Recently, hyperspectral image (HSI) classification approaches based on deep
learning (DL) models have been proposed and shown promising performance.
However, because of very limited available training samples and massive model
parameters, DL methods may suffer from overfitting. In this paper, we propose
an end-to-end 3-D lightweight convolutional neural network (CNN) (abbreviated
as 3-D-LWNet) for limited samples-based HSI classification. Compared with
conventional 3-D-CNN models, the proposed 3-D-LWNet has a deeper network
structure, less parameters, and lower computation cost, resulting in better
classification performance. To further alleviate the small sample problem, we
also propose two transfer learning strategies: 1) cross-sensor strategy, in
which we pretrain a 3-D model in the source HSI data sets containing a greater
number of labeled samples and then transfer it to the target HSI data sets and
2) cross-modal strategy, in which we pretrain a 3-D model in the 2-D RGB image
data sets containing a large number of samples and then transfer it to the
target HSI data sets. In contrast to previous approaches, we do not impose
restrictions over the source data sets, in which they do not have to be
collected by the same sensors as the target data sets. Experiments on three
public HSI data sets captured by different sensors demonstrate that our model
achieves competitive performance for HSI classification compared to several
state-of-the-art methods
","Haokui Zhang, Ying Li, Yenan Jiang, Peng Wang, Qiang Shen, Chunhua Shen",Chunhua Shen,2020-12-07T03:44:35Z
"Tip-induced nano-engineering of strain, bandgap, and exciton dynamics in
  2D semiconductors","  The tunability of the bandgap, absorption and emission energies,
photoluminescence (PL) quantum yield, exciton transport, and energy transfer in
transition metal dichalcogenide (TMD) monolayers provides a new class of
functions for a wide range of ultrathin photonic devices. Recent
strain-engineering approaches have enabled us to tune some of these properties,
yet dynamic control at the nanoscale with real-time and -space
characterizations remains a challenge. Here, we demonstrate a dynamic
nano-mechanical strain-engineering of naturally-formed wrinkles in a WSe2
monolayer, with real-time investigation of nano-spectroscopic properties using
hyperspectral adaptive tip-enhanced PL (a-TEPL) spectroscopy. First, we
characterize nanoscale wrinkles through hyperspectral a-TEPL nano-imaging with
<15 nm spatial resolution which reveals the modified nano-excitonic properties
by the induced tensile strain at the wrinkle apex, e.g., an increase in the
quantum yield due to the exciton funneling, decrease in PL energy up to ~10
meV, and a symmetry change in the TEPL spectra caused by the reconfigured
electronic bandstructure. We then dynamically engineer the local strain by
pressing and releasing the wrinkle apex through an atomic force tip control.
This nano-mechanical strain-engineering allows us to tune the exciton dynamics
and emission properties at the nanoscale in a reversible fashion. In addition,
we demonstrate a systematic switching and modulation platform of the wrinkle
emission, which provides a new strategy for robust, tunable, and ultracompact
nano-optical sources in atomically thin semiconductors.
","Yeonjeong Koo, Yongchul Kim, Soo Ho Choi, Hyeongwoo Lee, Jinseong Choi, Dong Yun Lee, Mingu Kang, Hyun Seok Lee, Ki Kang Kim, Geunsik Lee, Kyoung-Duck Park",Kyoung-Duck Park,2020-12-07T07:38:44Z
"Covariance Estimation from Compressive Data Partitions using a Projected
  Gradient-based Algorithm","  Compressive covariance estimation has arisen as a class of techniques whose
aim is to obtain second-order statistics of stochastic processes from
compressive measurements. Recently, these methods have been used in various
image processing and communications applications, including denoising, spectrum
sensing, and compression. Notice that estimating the covariance matrix from
compressive samples leads to ill-posed minimizations with severe performance
loss at high compression rates. In this regard, a regularization term is
typically aggregated to the cost function to consider prior information about a
particular property of the covariance matrix. Hence, this paper proposes an
algorithm based on the projected gradient method to recover low-rank or
Toeplitz approximations of the covariance matrix from compressive measurements.
The algorithm divides the compressive measurements into data subsets projected
onto different subspaces and accurately estimates the covariance matrix by
solving a single optimization problem assuming that each data subset contains
an approximation of the signal statistics. Furthermore, gradient filtering is
included at every iteration of the proposed algorithm to minimize the
estimation error. The error induced by the proposed splitting approach is
analytically derived along with the convergence guarantees of the proposed
method. The algorithm estimates the covariance matrix of hyperspectral images
from synthetic and real compressive samples. Extensive simulations show that
the proposed algorithm can effectively recover the covariance matrix of
hyperspectral images from compressive measurements (8-15% approx). Moreover,
simulations and theoretical results show that the filtering step reduces the
recovery error up to twice the number of eigenvectors. Finally, an optical
implementation is proposed, and real measurements are used to validate the
theoretical findings.
","Jonathan Monsalve, Juan Ramirez, Iñaki Esnaola, Henry Arguello",Henry Arguello,2021-01-11T16:59:29Z
"3D-ANAS: 3D Asymmetric Neural Architecture Search for Fast Hyperspectral
  Image Classification","  Hyperspectral images involve abundant spectral and spatial information,
playing an irreplaceable role in land-cover classification. Recently, based on
deep learning technologies, an increasing number of HSI classification
approaches have been proposed, which demonstrate promising performance.
However, previous studies suffer from two major drawbacks: 1) the architecture
of most deep learning models is manually designed, relies on specialized
knowledge, and is relatively tedious. Moreover, in HSI classifications,
datasets captured by different sensors have different physical properties.
Correspondingly, different models need to be designed for different datasets,
which further increases the workload of designing architectures; 2) the
mainstream framework is a patch-to-pixel framework. The overlap regions of
patches of adjacent pixels are calculated repeatedly, which increases
computational cost and time cost. Besides, the classification accuracy is
sensitive to the patch size, which is artificially set based on extensive
investigation experiments. To overcome the issues mentioned above, we firstly
propose a 3D asymmetric neural network search algorithm and leverage it to
automatically search for efficient architectures for HSI classifications. By
analysing the characteristics of HSIs, we specifically build a 3D asymmetric
decomposition search space, where spectral and spatial information are
processed with different decomposition convolutions. Furthermore, we propose a
new fast classification framework, i,e., pixel-to-pixel classification
framework, which has no repetitive operations and reduces the overall cost.
Experiments on three public HSI datasets captured by different sensors
demonstrate the networks designed by our 3D-ANAS achieve competitive
performance compared to several state-of-the-art methods, while having a much
faster inference speed.
","Haokui Zhang, Chengrong Gong, Yunpeng Bai, Zongwen Bai, Ying Li",Ying Li,2021-01-12T04:15:40Z
"Hyperspectral Image Super-Resolution with Spectral Mixup and
  Heterogeneous Datasets","  This work studies Hyperspectral image (HSI) super-resolution (SR). HSI SR is
characterized by high-dimensional data and a limited amount of training
examples. This exacerbates the undesirable behaviors of neural networks such as
memorization and sensitivity to out-of-distribution samples. This work
addresses these issues with three contributions. First, we observe that HSI SR
and RGB image SR are correlated and develop a novel multi-tasking network to
train them jointly so that the auxiliary task RGB image SR can provide
additional supervision. Second, we propose a simple, yet effective data
augmentation routine, termed Spectral Mixup, to construct effective virtual
training samples to enlarge the training set. Finally, we extend the network to
a semi-supervised setting so that it can learn from datasets containing only
low-resolution HSIs. With these contributions, our method is able to learn from
heterogeneous datasets and lift the requirement for having a large amount of HD
HSI training samples. Extensive experiments on four standard datasets show that
our method outperforms existing methods significantly and underpin the
relevance of our contributions. Code has been made available at
https://github.com/kli8996/HSISR.
","Ke Li, Dengxin Dai, Ender Konukoglu, Luc Van Gool",Luc Van Gool,2021-01-19T12:19:53Z
"Enhanced hyperspectral tomography for bioimaging by spatiospectral
  reconstruction","  Here we apply hyperspectral bright field imaging to collect computed
tomographic images with excellent energy resolution (800 eV), applying it for
the first time to map the distribution of stain in a fixed biological sample
through its characteristic K-edge. Conventionally, because the photons detected
at each pixel are distributed across as many as 200 energy channels,
energy-selective images are characterised by low count-rates and poor
signal-to-noise ratio. This means high X-ray exposures, long scan times and
high doses are required to image unique spectral markers. Here, we achieve high
quality energy-dispersive tomograms from low dose, noisy datasets using a
dedicated iterative reconstruction algorithm. This exploits the spatial
smoothness and inter-channel structural correlation in the spectral domain
using two carefully chosen regularisation terms. For a multi-phase phantom, a
reduction in scan time of 36 times is demonstrated. Spectral analysis methods
including K-edge subtraction and absorption step-size fitting are evaluated for
an ex vivo, single (iodine)-stained biological sample, where low chemical
concentration and inhomogeneous distribution can affect soft tissue
segmentation and visualisation. The reconstruction algorithms are available
through the open-source Core Imaging Library. Taken together, these tools offer
new capabilities for visualisation and elemental mapping, with promising
applications for multiply-stained biological specimens.
","Ryan Warr, Evelina Ametova, Robert J. Cernik, Gemma Fardell, Stephan Handschuh, Jakob S. Jørgensen, Evangelos Papoutsellis, Edoardo Pasca, Philip J. Withers",Philip J. Withers,2021-03-08T14:46:41Z
Untrained networks for compressive lensless photography,"  Compressive lensless imagers enable novel applications in an extremely
compact device, requiring only a phase or amplitude mask placed close to the
sensor. They have been demonstrated for 2D and 3D microscopy, single-shot
video, and single-shot hyperspectral imaging; in each of these cases, a
compressive-sensing-based inverse problem is solved in order to recover a 3D
data-cube from a 2D measurement. Typically, this is accomplished using convex
optimization and hand-picked priors. Alternatively, deep learning-based
reconstruction methods offer the promise of better priors, but require many
thousands of ground truth training pairs, which can be difficult or impossible
to acquire. In this work, we propose the use of untrained networks for
compressive image recovery. Our approach does not require any labeled training
data, but instead uses the measurement itself to update the network weights. We
demonstrate our untrained approach on lensless compressive 2D imaging as well
as single-shot high-speed video recovery using the camera's rolling shutter,
and single-shot hyperspectral imaging. We provide simulation and experimental
verification, showing that our method results in improved image quality over
existing methods.
","Kristina Monakhova, Vi Tran, Grace Kuo, Laura Waller",Laura Waller,2021-03-13T03:47:06Z
Triplet-Watershed for Hyperspectral Image Classification,"  Hyperspectral images (HSI) consist of rich spatial and spectral information,
which can potentially be used for several applications. However, noise, band
correlations and high dimensionality restrict the applicability of such data.
This is recently addressed using creative deep learning network architectures
such as ResNet, SSRN, and A2S2K. However, the last layer, i.e the
classification layer, remains unchanged and is taken to be the softmax
classifier. In this article, we propose to use a watershed classifier.
Watershed classifier extends the watershed operator from Mathematical
Morphology for classification. In its vanilla form, the watershed classifier
does not have any trainable parameters. In this article, we propose a novel
approach to train deep learning networks to obtain representations suitable for
the watershed classifier. The watershed classifier exploits the connectivity
patterns, a characteristic of HSI datasets, for better inference. We show that
exploiting such characteristics allows the Triplet-Watershed to achieve
state-of-art results in supervised and semi-supervised contexts. These results
are validated on Indianpines (IP), University of Pavia (UP), Kennedy Space
Center (KSC) and University of Houston (UH) datasets, relying on simple convnet
architecture using a quarter of parameters compared to previous
state-of-the-art networks. The source code for reproducing the experiments and
supplementary material (high resolution images) is available at
https://github.com/ac20/TripletWatershed Code.
","Aditya Challa, Sravan Danda, B. S. Daya Sagar, Laurent Najman",Laurent Najman,2021-03-17T01:06:49Z
"Hyperspectral Image Super-Resolution in Arbitrary Input-Output Band
  Settings","  Hyperspectral image (HSI) with narrow spectral bands can capture rich
spectral information, but it sacrifices its spatial resolution in the process.
Many machine-learning-based HSI super-resolution (SR) algorithms have been
proposed recently. However, one of the fundamental limitations of these
approaches is that they are highly dependent on image and camera settings and
can only learn to map an input HSI with one specific setting to an output HSI
with another. However, different cameras capture images with different spectral
response functions and bands numbers due to the diversity of HSI cameras.
Consequently, the existing machine-learning-based approaches fail to learn to
super-resolve HSIs for a wide variety of input-output band settings. We propose
a single Meta-Learning-Based Super-Resolution (MLSR) model, which can take in
HSI images at an arbitrary number of input bands' peak wavelengths and generate
SR HSIs with an arbitrary number of output bands' peak wavelengths. We leverage
NTIRE2020 and ICVL datasets to train and validate the performance of the MLSR
model. The results show that the single proposed model can successfully
generate super-resolved HSI bands at arbitrary input-output band settings. The
results are better or at least comparable to baselines that are separately
trained on a specific input-output band setting.
","Zhongyang Zhang, Zhiyang Xu, Zia Ahmed, Asif Salekin, Tauhidur Rahman",Tauhidur Rahman,2021-03-19T03:32:28Z
"SpectralNET: Exploring Spatial-Spectral WaveletCNN for Hyperspectral
  Image Classification","  Hyperspectral Image (HSI) classification using Convolutional Neural Networks
(CNN) is widely found in the current literature. Approaches vary from using
SVMs to 2D CNNs, 3D CNNs, 3D-2D CNNs. Besides 3D-2D CNNs and FuSENet, the other
approaches do not consider both the spectral and spatial features together for
HSI classification task, thereby resulting in poor performances. 3D CNNs are
computationally heavy and are not widely used, while 2D CNNs do not consider
multi-resolution processing of images, and only limits itself to the spatial
features. Even though 3D-2D CNNs try to model the spectral and spatial features
their performance seems limited when applied over multiple dataset. In this
article, we propose SpectralNET, a wavelet CNN, which is a variation of 2D CNN
for multi-resolution HSI classification. A wavelet CNN uses layers of wavelet
transform to bring out spectral features. Computing a wavelet transform is
lighter than computing 3D CNN. The spectral features extracted are then
connected to the 2D CNN which bring out the spatial features, thereby creating
a spatial-spectral feature vector for classification. Overall a better model is
achieved that can classify multi-resolution HSI data with high accuracy.
Experiments performed with SpectralNET on benchmark dataset, i.e. Indian Pines,
University of Pavia, and Salinas Scenes confirm the superiority of proposed
SpectralNET with respect to the state-of-the-art methods. The code is publicly
available in https://github.com/tanmay-ty/SpectralNET.
","Tanmay Chakraborty, Utkarsh Trehan",Utkarsh Trehan,2021-04-01T08:45:15Z
"Time-Multiplexed Coded Aperture Imaging: Learned Coded Aperture and
  Pixel Exposures for Compressive Imaging Systems","  Compressive imaging using coded apertures (CA) is a powerful technique that
can be used to recover depth, light fields, hyperspectral images and other
quantities from a single snapshot. The performance of compressive imaging
systems based on CAs mostly depends on two factors: the properties of the
mask's attenuation pattern, that we refer to as ""codification"" and the
computational techniques used to recover the quantity of interest from the
coded snapshot. In this work, we introduce the idea of using time-varying CAs
synchronized with spatially varying pixel shutters. We divide the exposure of a
sensor into sub-exposures at the beginning of which the CA mask changes and at
which the sensor's pixels are simultaneously and individually switched ""on"" or
""off"". This is a practically appealing codification as it does not introduce
additional optical components other than the already present CA but uses a
change in the pixel shutter that can be easily realized electronically. We show
that our proposed time multiplexed coded aperture (TMCA) can be optimized
end-to-end and induces better coded snapshots enabling superior reconstructions
in two different applications: compressive light field imaging and
hyperspectral imaging. We demonstrate both in simulation and on real captures
(taken with prototypes we built) that this codification outperforms the
state-of-the-art compressive imaging systems by more than 4dB in those
applications.
","Edwin Vargas, Julien N. P. Martel, Gordon Wetzstein, Henry Arguello",Henry Arguello,2021-04-06T22:42:34Z
Fast Unmixing and Change Detection in Multitemporal Hyperspectral Data,"  Multitemporal spectral unmixing (SU) is a powerful tool to process
hyperspectral image (HI) sequences due to its ability to reveal the evolution
of materials over time and space in a scene. However, significant spectral
variability is often observed between collection of images due to variations in
acquisition or seasonal conditions. This characteristic has to be considered in
the design of SU algorithms. Because of its good performance, the multiple
endmember spectral mixture analysis algorithm (MESMA) has been recently used to
perform SU in multitemporal scenarios arising in several practical
applications. However, MESMA does not consider the relationship between the
different HIs, and its computational complexity is extremely high for large
spectral libraries. In this work, we propose an efficient multitemporal SU
method that exploits the high temporal correlation between the abundances to
provide more accurate results at a lower computational complexity. We propose
to solve the complex general multitemporal SU problem by separately addressing
the endmember selection and the abundance estimation problems. This leads to a
simpler solution without sacrificing the accuracy of the results. We also
propose a strategy to detect and address abrupt abundance variations in time.
Theoretical results demonstrate how the proposed method compares to MESMA in
terms of quality, and how effective it is in detecting abundance changes. This
analysis provides valuable insight into the conditions under which the
algorithm succeeds. Simulation results show that the proposed method achieves
state-of-the-art performance at a smaller computational cost.
","Ricardo Augusto Borsoi, Tales Imbiriba, José Carlos Moreira Bermudez, Cédric Richard",Cédric Richard,2021-04-07T00:34:42Z
Robust Self-Ensembling Network for Hyperspectral Image Classification,"  Recent research has shown the great potential of deep learning algorithms in
the hyperspectral image (HSI) classification task. Nevertheless, training these
models usually requires a large amount of labeled data. Since the collection of
pixel-level annotations for HSI is laborious and time-consuming, developing
algorithms that can yield good performance in the small sample size situation
is of great significance. In this study, we propose a robust self-ensembling
network (RSEN) to address this problem. The proposed RSEN consists of two
subnetworks including a base network and an ensemble network. With the
constraint of both the supervised loss from the labeled data and the
unsupervised loss from the unlabeled data, the base network and the ensemble
network can learn from each other, achieving the self-ensembling mechanism. To
the best of our knowledge, the proposed method is the first attempt to
introduce the self-ensembling technique into the HSI classification task, which
provides a different view on how to utilize the unlabeled data in HSI to assist
the network training. We further propose a novel consistency filter to increase
the robustness of self-ensembling learning. Extensive experiments on three
benchmark HSI datasets demonstrate that the proposed algorithm can yield
competitive performance compared with the state-of-the-art methods. Code is
available online (\url{https://github.com/YonghaoXu/RSEN}).
","Yonghao Xu, Bo Du, Liangpei Zhang",Liangpei Zhang,2021-04-08T13:33:14Z
Estimating Leaf Water Content using Remotely Sensed Hyperspectral Data,"  Plant water stress may occur due to the limited availability of water to the
roots/soil or due to increased transpiration. These factors adversely affect
plant physiology and photosynthetic ability to the extent that it has been
shown to have inhibitory effects in both growth and yield [18]. Early
identification of plant water stress status enables suitable corrective
measures to be applied to obtain the expected crop yield. Further, improving
crop yield through precision agriculture methods is a key component of climate
policy and the UN sustainable development goals [1]. Leaf water content (LWC)
is a measure that can be used to estimate water content and identify stressed
plants. LWC during the early crop growth stages is an important indicator of
plant productivity and yield. The effect of water stress can be instantaneous
[15], affecting gaseous exchange or long-term, significantly reducing [9, 18,
22]. It is thus necessary to identify potential plant water stress during the
early stages of growth [15] to introduce corrective irrigation and alleviate
stress. LWC is also useful for identifying plant genotypes that are tolerant to
water stress and salinity by measuring the stability of LWC even under
artificially induced water stress [18, 25]. Such experiments generally employ
destructive procedures to obtain the LWC, which is time-consuming and labor
intensive. Accordingly, this research has developed a non-destructive method to
estimate LWC from UAV-based hyperspectral data.
","Vishal Vinod, Rahul Raj, Rohit Pingale, Adinarayana Jagarlapudi",Adinarayana Jagarlapudi,2021-09-06T05:52:17Z
Smoothed Separable Nonnegative Matrix Factorization,"  Given a set of data points belonging to the convex hull of a set of vertices,
a key problem in linear algebra, signal processing, data analysis and machine
learning is to estimate these vertices in the presence of noise. Many
algorithms have been developed under the assumption that there is at least one
nearby data point to each vertex; two of the most widely used ones are vertex
component analysis (VCA) and the successive projection algorithm (SPA). This
assumption is known as the pure-pixel assumption in blind hyperspectral
unmixing, and as the separability assumption in nonnegative matrix
factorization. More recently, Bhattacharyya and Kannan (ACM-SIAM Symposium on
Discrete Algorithms, 2020) proposed an algorithm for learning a latent simplex
(ALLS) that relies on the assumption that there is more than one nearby data
point to each vertex. In that scenario, ALLS is probalistically more robust to
noise than algorithms based on the separability assumption. In this paper,
inspired by ALLS, we propose smoothed VCA (SVCA) and smoothed SPA (SSPA) that
generalize VCA and SPA by assuming the presence of several nearby data points
to each vertex. We illustrate the effectiveness of SVCA and SSPA over VCA, SPA
and ALLS on synthetic data sets, on the unmixing of hyperspectral images, and
on feature extraction on facial images data sets. In addition, our study
highlights new theoretical results for VCA.
","Nicolas Nadisic, Nicolas Gillis, Christophe Kervazo",Christophe Kervazo,2021-10-11T18:10:30Z
"Model Inspired Autoencoder for Unsupervised Hyperspectral Image
  Super-Resolution","  This paper focuses on hyperspectral image (HSI) super-resolution that aims to
fuse a low-spatial-resolution HSI and a high-spatial-resolution multispectral
image to form a high-spatial-resolution HSI (HR-HSI). Existing deep
learning-based approaches are mostly supervised that rely on a large number of
labeled training samples, which is unrealistic. The commonly used model-based
approaches are unsupervised and flexible but rely on hand-craft priors.
Inspired by the specific properties of model, we make the first attempt to
design a model inspired deep network for HSI super-resolution in an
unsupervised manner. This approach consists of an implicit autoencoder network
built on the target HR-HSI that treats each pixel as an individual sample. The
nonnegative matrix factorization (NMF) of the target HR-HSI is integrated into
the autoencoder network, where the two NMF parts, spectral and spatial
matrices, are treated as decoder parameters and hidden outputs respectively. In
the encoding stage, we present a pixel-wise fusion model to estimate hidden
outputs directly, and then reformulate and unfold the model's algorithm to form
the encoder network. With the specific architecture, the proposed network is
similar to a manifold prior-based model, and can be trained patch by patch
rather than the entire image. Moreover, we propose an additional unsupervised
network to estimate the point spread function and spectral response function.
Experimental results conducted on both synthetic and real datasets demonstrate
the effectiveness of the proposed approach.
","Jianjun Liu, Zebin Wu, Liang Xiao, Xiao-Jun Wu",Xiao-Jun Wu,2021-10-22T05:15:16Z
"Nondestructive Testing of Composite Fibre Materials with Hyperspectral
  Imaging : Evaluative Studies in the EU H2020 FibreEUse Project","  Through capturing spectral data from a wide frequency range along with the
spatial information, hyperspectral imaging (HSI) can detect minor differences
in terms of temperature, moisture and chemical composition. Therefore, HSI has
been successfully applied in various applications, including remote sensing for
security and defense, precision agriculture for vegetation and crop monitoring,
food/drink, and pharmaceuticals quality control. However, for condition
monitoring and damage detection in carbon fibre reinforced polymer (CFRP), the
use of HSI is a relatively untouched area, as existing non-destructive testing
(NDT) techniques focus mainly on delivering information about physical
integrity of structures but not on material composition. To this end, HSI can
provide a unique way to tackle this challenge. In this paper, with the use of a
near-infrared HSI camera, applications of HSI for the non-destructive
inspection of CFRP products are introduced, taking the EU H2020 FibreEUse
project as the background. Technical challenges and solutions on three case
studies are presented in detail, including adhesive residues detection, surface
damage detection and Cobot based automated inspection. Experimental results
have fully demonstrated the great potential of HSI and related vision
techniques for NDT of CFRP, especially the potential to satisfy the industrial
manufacturing environment.
","Yijun Yan, Jinchang Ren, Huan Zhao, James F. C. Windmill, Winifred Ijomah, Jesper de Wit, Justus von Freeden",Justus von Freeden,2021-11-04T17:01:38Z
"Mask-guided Spectral-wise Transformer for Efficient Hyperspectral Image
  Reconstruction","  Hyperspectral image (HSI) reconstruction aims to recover the 3D
spatial-spectral signal from a 2D measurement in the coded aperture snapshot
spectral imaging (CASSI) system. The HSI representations are highly similar and
correlated across the spectral dimension. Modeling the inter-spectra
interactions is beneficial for HSI reconstruction. However, existing CNN-based
methods show limitations in capturing spectral-wise similarity and long-range
dependencies. Besides, the HSI information is modulated by a coded aperture
(physical mask) in CASSI. Nonetheless, current algorithms have not fully
explored the guidance effect of the mask for HSI restoration. In this paper, we
propose a novel framework, Mask-guided Spectral-wise Transformer (MST), for HSI
reconstruction. Specifically, we present a Spectral-wise Multi-head
Self-Attention (S-MSA) that treats each spectral feature as a token and
calculates self-attention along the spectral dimension. In addition, we
customize a Mask-guided Mechanism (MM) that directs S-MSA to pay attention to
spatial regions with high-fidelity spectral representations. Extensive
experiments show that our MST significantly outperforms state-of-the-art (SOTA)
methods on simulation and real HSI datasets while requiring dramatically
cheaper computational and memory costs. Code and pre-trained models are
available at https://github.com/caiyuanhao1998/MST/
","Yuanhao Cai, Jing Lin, Xiaowan Hu, Haoqian Wang, Xin Yuan, Yulun Zhang, Radu Timofte, Luc Van Gool",Luc Van Gool,2021-11-15T16:59:48Z
"A Latent Encoder Coupled Generative Adversarial Network (LE-GAN) for
  Efficient Hyperspectral Image Super-resolution","  Realistic hyperspectral image (HSI) super-resolution (SR) techniques aim to
generate a high-resolution (HR) HSI with higher spectral and spatial fidelity
from its low-resolution (LR) counterpart. The generative adversarial network
(GAN) has proven to be an effective deep learning framework for image
super-resolution. However, the optimisation process of existing GAN-based
models frequently suffers from the problem of mode collapse, leading to the
limited capacity of spectral-spatial invariant reconstruction. This may cause
the spectral-spatial distortion on the generated HSI, especially with a large
upscaling factor. To alleviate the problem of mode collapse, this work has
proposed a novel GAN model coupled with a latent encoder (LE-GAN), which can
map the generated spectral-spatial features from the image space to the latent
space and produce a coupling component to regularise the generated samples.
Essentially, we treat an HSI as a high-dimensional manifold embedded in a
latent space. Thus, the optimisation of GAN models is converted to the problem
of learning the distributions of high-resolution HSI samples in the latent
space, making the distributions of the generated super-resolution HSIs closer
to those of their original high-resolution counterparts. We have conducted
experimental evaluations on the model performance of super-resolution and its
capability in alleviating mode collapse. The proposed approach has been tested
and validated based on two real HSI datasets with different sensors (i.e.
AVIRIS and UHD-185) for various upscaling factors and added noise levels, and
compared with the state-of-the-art super-resolution models (i.e. HyCoNet, LTTR,
BAGAN, SR- GAN, WGAN).
","Yue Shi, Liangxiu Han, Lianghao Han, Sheng Chang, Tongle Hu, Darren Dancey",Darren Dancey,2021-11-16T18:40:19Z
"Shallow Network Based on Depthwise Over-Parameterized Convolution for
  Hyperspectral Image Classification","  Recently, convolutional neural network (CNN) techniques have gained
popularity as a tool for hyperspectral image classification (HSIC). To improve
the feature extraction efficiency of HSIC under the condition of limited
samples, the current methods generally use deep models with plenty of layers.
However, deep network models are prone to overfitting and gradient vanishing
problems when samples are limited. In addition, the spatial resolution
decreases severely with deeper depth, which is very detrimental to spatial edge
feature extraction. Therefore, this letter proposes a shallow model for HSIC,
which is called depthwise over-parameterized convolutional neural network
(DOCNN). To ensure the effective extraction of the shallow model, the depthwise
over-parameterized convolution (DO-Conv) kernel is introduced to extract the
discriminative features. The depthwise over-parameterized Convolution kernel is
composed of a standard convolution kernel and a depthwise convolution kernel,
which can extract the spatial feature of the different channels individually
and fuse the spatial features of the whole channels simultaneously. Moreover,
to further reduce the loss of spatial edge features due to the convolution
operation, a dense residual connection (DRC) structure is proposed to apply to
the feature extraction part of the whole network. Experimental results obtained
from three benchmark data sets show that the proposed method outperforms other
state-of-the-art methods in terms of classification accuracy and computational
efficiency.
","Hongmin Gao, Zhonghao Chen, Chenming Li",Chenming Li,2021-12-01T03:10:02Z
Joint Characterization of the Cryospheric Spectral Feature Space,"  Hyperspectral feature spaces are useful for many remote sensing applications
ranging from spectral mixture modeling to discrete thematic classification. In
such cases, characterization of the feature space dimensionality, geometry and
topology can provide guidance for effective model design. The objective of this
study is to compare and contrast two approaches for identifying feature space
basis vectors via dimensionality reduction. These approaches can be combined to
render a joint characterization that reveals spectral properties not apparent
using either approach alone. We use a diverse collection of AVIRIS-NG
reflectance spectra of the snow-firn-ice continuum to illustrate the utility of
joint characterization and identify physical properties inferred from the
spectra. Spectral feature spaces combining principal components (PCs) and
t-distributed Stochastic Neighbor Embeddings (t-SNEs) provide physically
interpretable dimensions representing the global (PC) structure of cryospheric
reflectance properties and local (t-SNE) manifold structures revealing
clustering not resolved in the global continuum. Joint characterization reveals
distinct continua for snow-firn gradients on different parts of the Greenland
Ice Sheet and multiple clusters of ice reflectance properties common to both
glacier and sea ice in different locations. Clustering revealed in t-SNE
feature spaces, and extended to the joint characterization, distinguishes
differences in spectral curvature specific to location within the snow
accumulation zone, and BRDF effects related to view geometry. The ability of
PC+t-SNE joint characterization to produce a physically interpretable spectral
feature spaces revealing global topology while preserving local manifold
structures suggests that this characterization might be extended to the much
higher dimensional hyperspectral feature space of all terrestrial land cover.
","Christopher Small, Daniel Sousa",Daniel Sousa,2021-12-02T17:04:50Z
"A Survey: Deep Learning for Hyperspectral Image Classification with Few
  Labeled Samples","  With the rapid development of deep learning technology and improvement in
computing capability, deep learning has been widely used in the field of
hyperspectral image (HSI) classification. In general, deep learning models
often contain many trainable parameters and require a massive number of labeled
samples to achieve optimal performance. However, in regard to HSI
classification, a large number of labeled samples is generally difficult to
acquire due to the difficulty and time-consuming nature of manual labeling.
Therefore, many research works focus on building a deep learning model for HSI
classification with few labeled samples. In this article, we concentrate on
this topic and provide a systematic review of the relevant literature.
Specifically, the contributions of this paper are twofold. First, the research
progress of related methods is categorized according to the learning paradigm,
including transfer learning, active learning and few-shot learning. Second, a
number of experiments with various state-of-the-art approaches has been carried
out, and the results are summarized to reveal the potential research
directions. More importantly, it is notable that although there is a vast gap
between deep learning models (that usually need sufficient labeled samples) and
the HSI scenario with few labeled samples, the issues of small-sample sets can
be well characterized by fusion of deep learning methods and related
techniques, such as transfer learning and a lightweight model. For
reproducibility, the source codes of the methods assessed in the paper can be
found at https://github.com/ShuGuoJ/HSI-Classification.git.
","Sen Jia, Shuguo Jiang, Zhijie Lin, Nanying Li, Meng Xu, Shiqi Yu",Shiqi Yu,2021-12-03T09:16:05Z
Modeling Mask Uncertainty in Hyperspectral Image Reconstruction,"  Recently, hyperspectral imaging (HSI) has attracted increasing research
attention, especially for the ones based on a coded aperture snapshot spectral
imaging (CASSI) system. Existing deep HSI reconstruction models are generally
trained on paired data to retrieve original signals upon 2D compressed
measurements given by a particular optical hardware mask in CASSI, during which
the mask largely impacts the reconstruction performance and could work as a
""model hyperparameter"" governing on data augmentations. This mask-specific
training style will lead to a hardware miscalibration issue, which sets up
barriers to deploying deep HSI models among different hardware and noisy
environments. To address this challenge, we introduce mask uncertainty for HSI
with a complete variational Bayesian learning treatment and explicitly model it
through a mask decomposition inspired by real hardware. Specifically, we
propose a novel Graph-based Self-Tuning (GST) network to reason uncertainties
adapting to varying spatial structures of masks among different hardware.
Moreover, we develop a bilevel optimization framework to balance HSI
reconstruction and uncertainty estimation, accounting for the hyperparameter
property of masks. Extensive experimental results and model discussions
validate the effectiveness (over 33/30 dB) of the proposed GST method under two
miscalibration scenarios and demonstrate a highly competitive performance
compared with the state-of-the-art well-calibrated methods. Our code and
pre-trained model are available at
https://github.com/Jiamian-Wang/mask_uncertainty_spectral_SCI
","Jiamian Wang, Yulun Zhang, Xin Yuan, Ziyi Meng, Zhiqiang Tao",Zhiqiang Tao,2021-12-31T09:39:13Z
Adaptive Transfer Learning for Plant Phenotyping,"  Plant phenotyping (Guo et al. 2021; Pieruschka et al. 2019) focuses on
studying the diverse traits of plants related to the plants' growth. To be more
specific, by accurately measuring the plant's anatomical, ontogenetical,
physiological and biochemical properties, it allows identifying the crucial
factors of plants' growth in different environments. One commonly used approach
is to predict the plant's traits using hyperspectral reflectance (Yendrek et
al. 2017; Wang et al. 2021). However, the data distributions of the
hyperspectral reflectance data in plant phenotyping might vary in different
environments for different plants. That is, it would be computationally
expansive to learn the machine learning models separately for one plant in
different environments. To solve this problem, we focus on studying the
knowledge transferability of modern machine learning models in plant
phenotyping. More specifically, this work aims to answer the following
questions. (1) How is the performance of conventional machine learning models,
e.g., partial least squares regression (PLSR), Gaussian process regression
(GPR) and multi-layer perceptron (MLP), affected by the number of annotated
samples for plant phenotyping? (2) Whether could the neural network based
transfer learning models improve the performance of plant phenotyping? (3)
Could the neural network based transfer learning be improved by using
infinite-width hidden layers for plant phenotyping?
","Jun Wu, Elizabeth A. Ainsworth, Sheng Wang, Kaiyu Guan, Jingrui He",Jingrui He,2022-01-14T00:40:40Z
"Reconstruction-based spectroscopy using CMOS image sensors with random
  photon-trapping nanostructure per sensor","  Optical spectrometers are widely used scientific equipment with many
applications involving material characterization, chemical analysis, disease
diagnostics, surveillance, etc. Emerging applications in biomedical and
communication fields have boosted the research in the miniaturization of
spectrometers. Recently, reconstruction-based spectrometers have gained
popularity for their compact size, easy maneuverability, and versatile
utilities. These devices exploit the superior computational capabilities of
recent computers to reconstruct hyperspectral images using detectors with
distinct responsivity to different wavelengths. In this paper, we propose a
CMOS compatible reconstruction-based on-chip spectrometer pixels capable of
spectrally resolving the visible spectrum with 1 nm spectral resolution
maintaining high accuracy (>95 %) and low footprint (8 um x 8 um), all without
the use of any additional filters. A single spectrometer pixel is formed by an
array of silicon photodiodes, each having a distinct absorption spectrum due to
their integrated nanostructures, this allows us to computationally reconstruct
the hyperspectral image. To achieve distinct responsivity, we utilize random
photon-trapping nanostructures per photodiode with different dimensions and
shapes that modify the coupling of light at different wavelengths. This also
reduces the spectrometer pixel footprint (comparable to conventional camera
pixels), thus improving spatial resolution. Moreover, deep trench isolation
(DTI) reduces the crosstalk between adjacent photodiodes. This miniaturized
spectrometer can be utilized for real-time in-situ biomedical applications such
as Fluorescence Lifetime Imaging Microscopy (FLIM), pulse oximetry, disease
diagnostics, and surgical guidance.
","Ahasan Ahamed, Cesar Bartolo-Perez, Ahmed Sulaiman Mayet, Soroush Ghandiparsi, Lisa McPhillips, Shih-Yuan Wang, M. Saif Islam",M. Saif Islam,2022-01-16T23:03:59Z
"Adaptive DropBlock Enhanced Generative Adversarial Networks for
  Hyperspectral Image Classification","  In recent years, hyperspectral image (HSI) classification based on generative
adversarial networks (GAN) has achieved great progress. GAN-based
classification methods can mitigate the limited training sample dilemma to some
extent. However, several studies have pointed out that existing GAN-based HSI
classification methods are heavily affected by the imbalanced training data
problem. The discriminator in GAN always contradicts itself and tries to
associate fake labels to the minority-class samples, and thus impair the
classification performance. Another critical issue is the mode collapse in
GAN-based methods. The generator is only capable of producing samples within a
narrow scope of the data space, which severely hinders the advancement of
GAN-based HSI classification methods. In this paper, we proposed an Adaptive
DropBlock-enhanced Generative Adversarial Networks (ADGAN) for HSI
classification. First, to solve the imbalanced training data problem, we adjust
the discriminator to be a single classifier, and it will not contradict itself.
Second, an adaptive DropBlock (AdapDrop) is proposed as a regularization method
employed in the generator and discriminator to alleviate the mode collapse
issue. The AdapDrop generated drop masks with adaptive shapes instead of a
fixed size region, and it alleviates the limitations of DropBlock in dealing
with ground objects with various shapes. Experimental results on three HSI
datasets demonstrated that the proposed ADGAN achieved superior performance
over state-of-the-art GAN-based methods. Our codes are available at
https://github.com/summitgao/HC_ADGAN
","Junjie Wang, Feng Gao, Junyu Dong, Qian Du",Qian Du,2022-01-22T01:43:59Z
Coarse-to-Fine Sparse Transformer for Hyperspectral Image Reconstruction,"  Many algorithms have been developed to solve the inverse problem of coded
aperture snapshot spectral imaging (CASSI), i.e., recovering the 3D
hyperspectral images (HSIs) from a 2D compressive measurement. In recent years,
learning-based methods have demonstrated promising performance and dominated
the mainstream research direction. However, existing CNN-based methods show
limitations in capturing long-range dependencies and non-local self-similarity.
Previous Transformer-based methods densely sample tokens, some of which are
uninformative, and calculate the multi-head self-attention (MSA) between some
tokens that are unrelated in content. This does not fit the spatially sparse
nature of HSI signals and limits the model scalability. In this paper, we
propose a novel Transformer-based method, coarse-to-fine sparse Transformer
(CST), firstly embedding HSI sparsity into deep learning for HSI
reconstruction. In particular, CST uses our proposed spectra-aware screening
mechanism (SASM) for coarse patch selecting. Then the selected patches are fed
into our customized spectra-aggregation hashing multi-head self-attention
(SAH-MSA) for fine pixel clustering and self-similarity capturing.
Comprehensive experiments show that our CST significantly outperforms
state-of-the-art methods while requiring cheaper computational costs. The code
and models will be released at https://github.com/caiyuanhao1998/MST
","Yuanhao Cai, Jing Lin, Xiaowan Hu, Haoqian Wang, Xin Yuan, Yulun Zhang, Radu Timofte, Luc Van Gool",Luc Van Gool,2022-03-09T16:17:47Z
"Lymphocyte Classification in Hyperspectral Images of Ovarian Cancer
  Tissue Biopsy Samples","  Current methods for diagnosing the progression of multiple types of cancer
within patients rely on interpreting stained needle biopsies. This process is
time-consuming and susceptible to error throughout the paraffinization,
Hematoxylin and Eosin (H&E) staining, deparaffinization, and annotation stages.
Fourier Transform Infrared (FTIR) imaging has been shown to be a promising
alternative to staining for appropriately annotating biopsy cores without the
need for deparaffinization or H&E staining with the use of Fourier Transform
Infrared (FTIR) images when combined with machine learning to interpret the
dense spectral information. We present a machine learning pipeline to segment
white blood cell (lymphocyte) pixels in hyperspectral images of biopsy cores.
These cells are clinically important for diagnosis, but some prior work has
struggled to incorporate them due to difficulty obtaining precise pixel labels.
Evaluated methods include Support Vector Machine (SVM), Gaussian Naive Bayes,
and Multilayer Perceptron (MLP), as well as analyzing the comparatively modern
convolutional neural network (CNN).
","Benjamin Paulson, Theodore Colwell, Natalia Bukowski, Joseph Weller, Andrew Crisler, John Cisler, Alexander Drobek, Alexander Neuwirth",Alexander Neuwirth,2022-03-23T00:58:27Z
"Decoupled-and-Coupled Networks: Self-Supervised Hyperspectral Image
  Super-Resolution with Subpixel Fusion","  Enormous efforts have been recently made to super-resolve hyperspectral (HS)
images with the aid of high spatial resolution multispectral (MS) images. Most
prior works usually perform the fusion task by means of multifarious
pixel-level priors. Yet the intrinsic effects of a large distribution gap
between HS-MS data due to differences in the spatial and spectral resolution
are less investigated. The gap might be caused by unknown sensor-specific
properties or highly-mixed spectral information within one pixel (due to low
spatial resolution). To this end, we propose a subpixel-level HS
super-resolution framework by devising a novel decoupled-and-coupled network,
called DC-Net, to progressively fuse HS-MS information from the pixel- to
subpixel-level, from the image- to feature-level. As the name suggests, DC-Net
first decouples the input into common (or cross-sensor) and sensor-specific
components to eliminate the gap between HS-MS images before further fusion, and
then fully blends them by a model-guided coupled spectral unmixing (CSU) net.
More significantly, we append a self-supervised learning module behind the CSU
net by guaranteeing the material consistency to enhance the detailed
appearances of the restored HS product. Extensive experimental results show the
superiority of our method both visually and quantitatively and achieve a
significant improvement in comparison with the state-of-the-arts. Furthermore,
the codes and datasets will be available at
https://sites.google.com/view/danfeng-hong for the sake of reproducibility.
","Danfeng Hong, Jing Yao, Deyu Meng, Naoto Yokoya, Jocelyn Chanussot",Jocelyn Chanussot,2022-05-07T23:40:36Z
"A Survey on Hyperspectral Image Restoration: From the View of Low-Rank
  Tensor Approximation","  The ability of capturing fine spectral discriminative information enables
hyperspectral images (HSIs) to observe, detect and identify objects with subtle
spectral discrepancy. However, the captured HSIs may not represent true
distribution of ground objects and the received reflectance at imaging
instruments may be degraded, owing to environmental disturbances, atmospheric
effects and sensors' hardware limitations. These degradations include but are
not limited to: complex noise (i.e., Gaussian noise, impulse noise, sparse
stripes, and their mixtures), heavy stripes, deadlines, cloud and shadow
occlusion, blurring and spatial-resolution degradation and spectral absorption,
etc. These degradations dramatically reduce the quality and usefulness of HSIs.
Low-rank tensor approximation (LRTA) is such an emerging technique, having
gained much attention in HSI restoration community, with ever-growing
theoretical foundation and pivotal technological innovation. Compared to
low-rank matrix approximation (LRMA), LRTA is capable of characterizing more
complex intrinsic structure of high-order data and owns more efficient learning
abilities, being established to address convex and non-convex inverse
optimization problems induced by HSI restoration. This survey mainly attempts
to present a sophisticated, cutting-edge, and comprehensive technical survey of
LRTA toward HSI restoration, specifically focusing on the following six topics:
Denoising, Destriping, Inpainting, Deblurring, Super--resolution and Fusion.
The theoretical development and variants of LRTA techniques are also
elaborated. For each topic, the state-of-the-art restoration methods are
compared by assessing their performance both quantitatively and visually. Open
issues and challenges are also presented, including model formulation,
algorithm design, prior exploration and application concerning the
interpretation requirements.
","Na Liu, Wei Li, Yinjian Wang, Rao Tao, Qian Du, Jocelyn Chanussot",Jocelyn Chanussot,2022-05-18T10:11:09Z
"Bayesian Convolutional Neural Networks for Limited Data Hyperspectral
  Remote Sensing Image Classification","  Employing deep neural networks for Hyperspectral remote sensing (HSRS) image
classification is a challenging task. HSRS images have high dimensionality and
a large number of channels with substantial redundancy between channels. In
addition, the training data for classifying HSRS images is limited and the
amount of available training data is much smaller compared to other
classification tasks. These factors complicate the training process of deep
neural networks with many parameters and cause them to not perform well even
compared to conventional models. Moreover, convolutional neural networks
produce over-confident predictions, which is highly undesirable considering the
aforementioned problem.
  In this work, we use for HSRS image classification a special class of deep
neural networks, namely a Bayesian neural network (BNN). To the extent of our
knowledge, this is the first time that BNNs are used in HSRS image
classification. BNNs inherently provide a measure for uncertainty. We perform
extensive experiments on the Pavia Centre, Salinas, and Botswana datasets. We
show that a BNN outperforms a standard convolutional neural network (CNN) and
an off-the-shelf Random Forest (RF). Further experiments underline that the BNN
is more stable and robust to model pruning, and that the uncertainty is higher
for samples with higher expected prediction error.
","Mohammad Joshaghani, Amirabbas Davari, Faezeh Nejati Hatamian, Andreas Maier, Christian Riess",Christian Riess,2022-05-19T00:02:16Z
"Hyperspectral Image Classification With Contrastive Graph Convolutional
  Network","  Recently, Graph Convolutional Network (GCN) has been widely used in
Hyperspectral Image (HSI) classification due to its satisfactory performance.
However, the number of labeled pixels is very limited in HSI, and thus the
available supervision information is usually insufficient, which will
inevitably degrade the representation ability of most existing GCN-based
methods. To enhance the feature representation ability, in this paper, a GCN
model with contrastive learning is proposed to explore the supervision signals
contained in both spectral information and spatial relations, which is termed
Contrastive Graph Convolutional Network (ConGCN), for HSI classification.
First, in order to mine sufficient supervision signals from spectral
information, a semi-supervised contrastive loss function is utilized to
maximize the agreement between different views of the same node or the nodes
from the same land cover category. Second, to extract the precious yet implicit
spatial relations in HSI, a graph generative loss function is leveraged to
explore supplementary supervision signals contained in the graph topology. In
addition, an adaptive graph augmentation technique is designed to flexibly
incorporate the spectral-spatial priors of HSI, which helps facilitate the
subsequent contrastive representation learning. The extensive experimental
results on four typical benchmark datasets firmly demonstrate the effectiveness
of the proposed ConGCN in both qualitative and quantitative aspects.
","Wentao Yu, Sheng Wan, Guangyu Li, Jian Yang, Chen Gong",Chen Gong,2022-05-11T12:06:37Z
"Deep Posterior Distribution-based Embedding for Hyperspectral Image
  Super-resolution","  In this paper, we investigate the problem of hyperspectral (HS) image spatial
super-resolution via deep learning. Particularly, we focus on how to embed the
high-dimensional spatial-spectral information of HS images efficiently and
effectively. Specifically, in contrast to existing methods adopting
empirically-designed network modules, we formulate HS embedding as an
approximation of the posterior distribution of a set of carefully-defined HS
embedding events, including layer-wise spatial-spectral feature extraction and
network-level feature aggregation. Then, we incorporate the proposed feature
embedding scheme into a source-consistent super-resolution framework that is
physically-interpretable, producing lightweight PDE-Net, in which
high-resolution (HR) HS images are iteratively refined from the residuals
between input low-resolution (LR) HS images and pseudo-LR-HS images degenerated
from reconstructed HR-HS images via probability-inspired HS embedding.
Extensive experiments over three common benchmark datasets demonstrate that
PDE-Net achieves superior performance over state-of-the-art methods. Besides,
the probabilistic characteristic of this kind of networks can provide the
epistemic uncertainty of the network outputs, which may bring additional
benefits when used for other HS image-based applications. The code will be
publicly available at https://github.com/jinnh/PDE-Net.
","Jinhui Hou, Zhiyu Zhu, Junhui Hou, Huanqiang Zeng, Jinjian Wu, Jiantao Zhou",Jiantao Zhou,2022-05-30T06:59:01Z
"The hybrid approach -- Convolutional Neural Networks and Expectation
  Maximization Algorithm -- for Tomographic Reconstruction of Hyperspectral
  Images","  We present a simple but novel hybrid approach to hyperspectral data cube
reconstruction from computed tomography imaging spectrometry (CTIS) images that
sequentially combines neural networks and the iterative Expectation
Maximization (EM) algorithm. We train and test the ability of the method to
reconstruct data cubes of $100\times100\times25$ and $100\times100\times100$
voxels, corresponding to 25 and 100 spectral channels, from simulated CTIS
images generated by our CTIS simulator. The hybrid approach utilizes the
inherent strength of the Convolutional Neural Network (CNN) with regard to
noise and its ability to yield consistent reconstructions and make use of the
EM algorithm's ability to generalize to spectral images of any object without
training. The hybrid approach achieves better performance than both the CNNs
and EM alone for seen (included in CNN training) and unseen (excluded from CNN
training) cubes for both the 25- and 100-channel cases. For the 25 spectral
channels, the improvements from CNN to the hybrid model (CNN + EM) in terms of
the mean-squared errors are between 14-26%. For 100 spectral channels, the
improvements between 19-40% are attained with the largest improvement of 40%
for the unseen data, to which the CNNs are not exposed during the training.
","Mads J. Ahlebæk, Mads S. Peters, Wei-Chih Huang, Mads T. Frandsen, René L. Eriksen, Bjarke Jørgensen",Bjarke Jørgensen,2022-05-31T13:22:02Z
"Single-source Domain Expansion Network for Cross-Scene Hyperspectral
  Image Classification","  Currently, cross-scene hyperspectral image (HSI) classification has drawn
increasing attention. It is necessary to train a model only on source domain
(SD) and directly transferring the model to target domain (TD), when TD needs
to be processed in real time and cannot be reused for training. Based on the
idea of domain generalization, a Single-source Domain Expansion Network
(SDEnet) is developed to ensure the reliability and effectiveness of domain
extension. The method uses generative adversarial learning to train in SD and
test in TD. A generator including semantic encoder and morph encoder is
designed to generate the extended domain (ED) based on
encoder-randomization-decoder architecture, where spatial and spectral
randomization are specifically used to generate variable spatial and spectral
information, and the morphological knowledge is implicitly applied as domain
invariant information during domain expansion. Furthermore, the supervised
contrastive learning is employed in the discriminator to learn class-wise
domain invariant representation, which drives intra-class samples of SD and ED.
Meanwhile, adversarial training is designed to optimize the generator to drive
intra-class samples of SD and ED to be separated. Extensive experiments on two
public HSI datasets and one additional multispectral image (MSI) dataset
demonstrate the superiority of the proposed method when compared with
state-of-the-art techniques.
","Yuxiang Zhang, Wei Li, Weidong Sun, Ran Tao, Qian Du",Qian Du,2022-09-04T14:54:34Z
"Language-aware Domain Generalization Network for Cross-Scene
  Hyperspectral Image Classification","  Text information including extensive prior knowledge about land cover classes
has been ignored in hyperspectral image classification (HSI) tasks. It is
necessary to explore the effectiveness of linguistic mode in assisting HSI
classification. In addition, the large-scale pre-training image-text foundation
models have demonstrated great performance in a variety of downstream
applications, including zero-shot transfer. However, most domain generalization
methods have never addressed mining linguistic modal knowledge to improve the
generalization performance of model. To compensate for the inadequacies listed
above, a Language-aware Domain Generalization Network (LDGnet) is proposed to
learn cross-domain invariant representation from cross-domain shared prior
knowledge. The proposed method only trains on the source domain (SD) and then
transfers the model to the target domain (TD). The dual-stream architecture
including image encoder and text encoder is used to extract visual and
linguistic features, in which coarse-grained and fine-grained text
representations are designed to extract two levels of linguistic features.
Furthermore, linguistic features are used as cross-domain shared semantic
space, and visual-linguistic alignment is completed by supervised contrastive
learning in semantic space. Extensive experiments on three datasets demonstrate
the superiority of the proposed method when compared with state-of-the-art
techniques.
","Yuxiang Zhang, Mengmeng Zhang, Wei Li, Shuai Wang, Ran Tao",Ran Tao,2022-09-06T10:06:10Z
Deep Plug-and-Play Prior for Hyperspectral Image Restoration,"  Deep-learning-based hyperspectral image (HSI) restoration methods have gained
great popularity for their remarkable performance but often demand expensive
network retraining whenever the specifics of task changes. In this paper, we
propose to restore HSIs in a unified approach with an effective plug-and-play
method, which can jointly retain the flexibility of optimization-based methods
and utilize the powerful representation capability of deep neural networks.
Specifically, we first develop a new deep HSI denoiser leveraging gated
recurrent convolution units, short- and long-term skip connections, and an
augmented noise level map to better exploit the abundant spatio-spectral
information within HSIs. It, therefore, leads to the state-of-the-art
performance on HSI denoising under both Gaussian and complex noise settings.
Then, the proposed denoiser is inserted into the plug-and-play framework as a
powerful implicit HSI prior to tackle various HSI restoration tasks. Through
extensive experiments on HSI super-resolution, compressed sensing, and
inpainting, we demonstrate that our approach often achieves superior
performance, which is competitive with or even better than the state-of-the-art
on each task, via a single model without any task-specific training.
","Zeqiang Lai, Kaixuan Wei, Ying Fu",Ying Fu,2022-09-17T04:41:43Z
"S$^3$R: Self-supervised Spectral Regression for Hyperspectral
  Histopathology Image Classification","  Benefited from the rich and detailed spectral information in hyperspectral
images (HSI), HSI offers great potential for a wide variety of medical
applications such as computational pathology. But, the lack of adequate
annotated data and the high spatiospectral dimensions of HSIs usually make
classification networks prone to overfit. Thus, learning a general
representation which can be transferred to the downstream tasks is imperative.
To our knowledge, no appropriate self-supervised pre-training method has been
designed for histopathology HSIs. In this paper, we introduce an efficient and
effective Self-supervised Spectral Regression (S$^3$R) method, which exploits
the low rank characteristic in the spectral domain of HSI. More concretely, we
propose to learn a set of linear coefficients that can be used to represent one
band by the remaining bands via masking out these bands. Then, the band is
restored by using the learned coefficients to reweight the remaining bands. Two
pre-text tasks are designed: (1)S$^3$R-CR, which regresses the linear
coefficients, so that the pre-trained model understands the inherent structures
of HSIs and the pathological characteristics of different morphologies;
(2)S$^3$R-BR, which regresses the missing band, making the model to learn the
holistic semantics of HSIs. Compared to prior arts i.e., contrastive learning
methods, which focuses on natural images, S$^3$R converges at least 3 times
faster, and achieves significant improvements up to 14% in accuracy when
transferring to HSI classification tasks.
","Xingran Xie, Yan Wang, Qingli Li",Qingli Li,2022-09-19T05:47:11Z
"Optical Design and Wavelength Calibration of a DMD-based Multi-Object
  Spectrograph","  The multi-object spectrograph (MOS) has been the benchmark for the current
generation of astronomical spectrographs, valued for its ability to acquire the
spectra of hundreds of objects simultaneously. In the last two decades, the
digital micromirror device (DMD) has shown potential in becoming the central
component of the MOS, being used as a programmable slit array. We have designed
a seeing-limited DMD-based MOS covering a spectral range of 0.4 to 0.7 $\mu$m,
with a field of view (FOV) of $10.5^\prime \times 13.98^\prime$ and a spectral
resolution of $R\sim1000$. This DMD-MOS employs all-spherical refractive
optics, and a volume phase holographic (VPH) grism as the dispersive element
for high throughput. In this paper, we present the optical design and
optimization process of this DMD-MOS, as well as a preliminary wavelength
calibration procedure for hyperspectral data reduction. Using simulated data of
the DMD-MOS, a procedure was developed to measure hyperspectral imaging
distortion and to construct pixel-to-wavelength mappings on the detector. An
investigation into the relationships between DMD micromirrors and detector
pixels was conducted. This DMD-MOS will be placed on a 0.5 m diameter telescope
as an exploratory study for future DMD-based MOS systems.
","Shaojie Chen, Matthew C. H. Leung, Xuefeng Yao, Suresh Sivanandam, Isabelle Sanders, Rosalind Liang",Rosalind Liang,2022-09-29T19:55:42Z
"Hyperspectral and LiDAR data for the prediction via machine learning of
  tree species, volume and biomass: a possible contribution for updating forest
  management plans","  This work intends to lay the foundations for identifying the prevailing
forest types and the delineation of forest units within private forest
inventories in the Autonomous Province of Trento (PAT), using currently
available remote sensing solutions. In particular, data from LiDAR and
hyperspectral surveys of 2014 made available by PAT were acquired and
processed. Such studies are very important in the context of forest management
scenarios. The method includes defining tree species ground-truth by outlining
single tree crowns with polygons and labeling them. Successively two supervised
machine learning classifiers, K-Nearest Neighborhood and Support Vector Machine
(SVM) were used. The results show that, by setting specific hyperparameters,
the SVM methodology gave the best results in classification of tree species.
Biomass was estimated using canopy parameters and the Jucker equation for the
above ground biomass (AGB) and that of Scrinzi for the tariff volume. Predicted
values were compared with 11 field plots of fixed radius where volume and
biomass were field-estimated in 2017. Results show significant coefficients of
correlation: 0.94 for stem volume and 0.90 for total aboveground tree biomass.
","Daniele Michelini, Michele Dalponte, Angelo Carriero, Erico Kutchart, Salvatore Eugenio Pappalardo, Massimo De Marchi, Francesco Pirotti",Francesco Pirotti,2022-09-30T06:06:25Z
"Feature selection intelligent algorithm with mutual information and
  steepest ascent strategy","  Remote sensing is a higher technology to produce knowledge for data mining
applications. In principle hyperspectral images (HSIs) is a remote sensing tool
that provides precise classification of regions. The HSI contains more than a
hundred of images of the ground truth (GT) map. Some images are carrying
relevant information, but others describe redundant information, or they are
affected by atmospheric noise. The aim is to reduce dimensionality of HSI. Many
studies use mutual information (MI) or normalised forms of MI to select
appropriate bands. In this paper we design an algorithm based also on MI, and
we combine MI with steepest ascent algorithm, to improve a symmetric
uncertainty coefficient-based strategy to select relevant bands for
classification of HSI. This algorithm is a feature selection tool and a wrapper
strategy. We perform our study on HSI AVIRIS 92AV3C. This is an artificial
intelligent system to control redundancy; we had to clear the difference of the
result's algorithm and the human decision, and this can be viewed as case study
which human decision is perhaps different to an intelligent algorithm. Index
Terms - Hyperspectral images, Classification, Fea-ture selection, Mutual
Information, Redundancy, Steepest Ascent. Artificial Intelligence
","Elkebir Sarhrouni, Ahmed Hammouch, Driss Aboutajdine",Driss Aboutajdine,2022-10-21T23:15:42Z
"Fast Noise Removal in Hyperspectral Images via Representative
  Coefficient Total Variation","  Mining structural priors in data is a widely recognized technique for
hyperspectral image (HSI) denoising tasks, whose typical ways include
model-based methods and data-based methods. The model-based methods have good
generalization ability, while the runtime cannot meet the fast processing
requirements of the practical situations due to the large size of an HSI data $
\mathbf{X} \in \mathbb{R}^{MN\times B}$. For the data-based methods, they
perform very fast on new test data once they have been trained. However, their
generalization ability is always insufficient. In this paper, we propose a fast
model-based HSI denoising approach. Specifically, we propose a novel
regularizer named Representative Coefficient Total Variation (RCTV) to
simultaneously characterize the low rank and local smooth properties. The RCTV
regularizer is proposed based on the observation that the representative
coefficient matrix $\mathbf{U}\in\mathbb{R}^{MN\times R} (R\ll B)$ obtained by
orthogonally transforming the original HSI $\mathbf{X}$ can inherit the strong
local-smooth prior of $\mathbf{X}$. Since $R/B$ is very small, the HSI
denoising model based on the RCTV regularizer has lower time complexity.
Additionally, we find that the representative coefficient matrix $\mathbf{U}$
is robust to noise, and thus the RCTV regularizer can somewhat promote the
robustness of the HSI denoising model. Extensive experiments on mixed noise
removal demonstrate the superiority of the proposed method both in denoising
performance and denoising speed compared with other state-of-the-art methods.
Remarkably, the denoising speed of our proposed method outperforms all the
model-based techniques and is comparable with the deep learning-based
approaches.
","Jiangjun Peng, Hailin Wang, Xiangyong Cao, Xinlin Liu, Xiangyu Rui, Deyu Meng",Deyu Meng,2022-11-03T14:06:37Z
"Nearest Neighbor-Based Contrastive Learning for Hyperspectral and LiDAR
  Data Classification","  The joint hyperspectral image (HSI) and LiDAR data classification aims to
interpret ground objects at more detailed and precise level. Although deep
learning methods have shown remarkable success in the multisource data
classification task, self-supervised learning has rarely been explored. It is
commonly nontrivial to build a robust self-supervised learning model for
multisource data classification, due to the fact that the semantic similarities
of neighborhood regions are not exploited in existing contrastive learning
framework. Furthermore, the heterogeneous gap induced by the inconsistent
distribution of multisource data impedes the classification performance. To
overcome these disadvantages, we propose a Nearest Neighbor-based Contrastive
Learning Network (NNCNet), which takes full advantage of large amounts of
unlabeled data to learn discriminative feature representations. Specifically,
we propose a nearest neighbor-based data augmentation scheme to use enhanced
semantic relationships among nearby regions. The intermodal semantic alignments
can be captured more accurately. In addition, we design a bilinear attention
module to exploit the second-order and even high-order feature interactions
between the HSI and LiDAR data. Extensive experiments on four public datasets
demonstrate the superiority of our NNCNet over state-of-the-art methods. The
source codes are available at \url{https://github.com/summitgao/NNCNet}.
","Meng Wang, Feng Gao, Junyu Dong, Heng-Chao Li, Qian Du",Qian Du,2023-01-09T13:43:54Z
"Identifying chromophore fingerprints of brain tumor tissue on
  hyperspectral imaging using principal component analysis","  Hyperspectral imaging (HSI) is an optical technique that processes the
electromagnetic spectrum at a multitude of monochromatic, adjacent frequency
bands. The wide-bandwidth spectral signature of a target object's reflectance
allows fingerprinting its physical, biochemical, and physiological properties.
HSI has been applied for various applications, such as remote sensing and
biological tissue analysis. Recently, HSI was also used to differentiate
between healthy and pathological tissue under operative conditions in a surgery
room on patients diagnosed with brain tumors. In this article, we perform a
statistical analysis of the brain tumor patients' HSI scans from the HELICoiD
dataset with the aim of identifying the correlation between reflectance spectra
and absorption spectra of tissue chromophores. By using the principal component
analysis (PCA), we determine the most relevant spectral features for intra- and
inter-tissue class differentiation. Furthermore, we demonstrate that such
spectral features are correlated with the spectra of cytochrome, i.e., the
chromophore highly involved in (hyper) metabolic processes. Identifying such
fingerprints of chromophores in reflectance spectra is a key step for automated
molecular profiling and, eventually, expert-free biomarker discovery.
","Ivan Ezhov, Luca Giannoni, Suprosanna Shit, Frederic Lange, Florian Kofler, Bjoern Menze, Ilias Tachtsidis, Daniel Rueckert",Daniel Rueckert,2023-01-12T14:16:25Z
Learning to adapt unknown noise for hyperspectral image denoising,"  For hyperspectral image (HSI) denoising task, the causes of noise embeded in
an HSI are typically complex and uncontrollable. Thus, it remains a challenge
for model-based HSI denoising methods to handle complex noise. To enhance the
noise-handling capabilities of existing model-based methods, we resort to
design a general weighted data fidelity term. The weight in this term is used
to assess the noise intensity and thus elementwisely adjust the contribution of
the observed noisy HSI in a denoising model. The similar concept of ""weighting""
has been hinted in several methods. Due to the unknown nature of the noise
distribution, the implementation of ""weighting"" in these works are usually
achieved via empirical formula for specific denoising method. In this work, we
propose to predict the weight by a hyper-weight network (i.e., HWnet). The
HWnet is learned exactly from several model-based HSI denoising methods in a
bi-level optimization framework based on the data-driven methodology. For a
noisy HSI, the learned HWnet outputs its corresponding weight. Then the
weighted data fidelity term implemented with the predicted weight can be
explicitly combined with a target model-based HSI denoising method. In this
way, our HWnet achieves the goal of enhancing the noise adaptation ability of
model-based HSI denoising methods for different noisy HSIs. Extensive
experiments verify that the proposed HWnet can effecitvely help to improve the
ability of an HSI denoising model to handle different complex noises. This
further implies that our HWnet could transfer the noise knowledge at the model
level and we also study the corresponding generalization theory for simple
illustration.
","Xiangyu Rui, Xiangyong Cao, Jun Shu, Qian Zhao, Deyu Meng",Deyu Meng,2022-12-09T03:28:07Z
Deep Diversity-Enhanced Feature Representation of Hyperspectral Images,"  In this paper, we study the problem of efficiently and effectively embedding
the high-dimensional spatio-spectral information of hyperspectral (HS) images,
guided by feature diversity. Specifically, based on the theoretical formulation
that feature diversity is correlated with the rank of the unfolded kernel
matrix, we rectify 3D convolution by modifying its topology to enhance the rank
upper-bound. This modification yields a rank-enhanced spatial-spectral
symmetrical convolution set (ReS$^3$-ConvSet), which not only learns diverse
and powerful feature representations but also saves network parameters.
Additionally, we also propose a novel diversity-aware regularization (DA-Reg)
term that directly acts on the feature maps to maximize independence among
elements. To demonstrate the superiority of the proposed ReS$^3$-ConvSet and
DA-Reg, we apply them to various HS image processing and analysis tasks,
including denoising, spatial super-resolution, and classification. Extensive
experiments show that the proposed approaches outperform state-of-the-art
methods both quantitatively and qualitatively to a significant extent. The code
is publicly available at https://github.com/jinnh/ReSSS-ConvSet.
","Jinhui Hou, Zhiyu Zhu, Junhui Hou, Hui Liu, Huanqiang Zeng, Deyu Meng",Deyu Meng,2023-01-15T16:19:18Z
"Variable-Wise Diagonal Preconditioning for Primal-Dual Splitting: Design
  and Applications","  This paper proposes a method for designing diagonal preconditioners for a
preconditioned primal-dual splitting method (P-PDS), an efficient algorithm
that solves nonsmooth convex optimization problems. To speed up the convergence
of P-PDS, a design method has been proposed to automatically determine
appropriate preconditioners from the problem structure. However, the existing
method has two limitations. One is that it directly accesses all elements of
matrices representing linear operators involved in a given problem, which is
inconvenient for handling linear operators implemented as procedures rather
than matrices. The other is that it takes an element-wise preconditioning
approach, which turns certain types of proximity operators into analytically
intractable forms. To overcome these limitations, we establish an Operator
norm-based design method of Variable-wise Diagonal Preconditioning (OVDP).
First, OVDP constructs diagonal preconditioners using only (upper bounds) of
the operator norms of linear operators, thus eliminating the need for their
explicit matrix representations. Furthermore, since OVDP takes a variable-wise
preconditioning approach, it keeps any proximity operator analytically
computable. We also prove that our preconditioners satisfy the convergence
condition of P-PDS. Finally, we demonstrate the effectiveness and usefulness of
OVDP through applications to mixed noise removal of hyperspectral images,
hyperspectral unmixing, and graph signal recovery.
","Kazuki Naganuma, Shunsuke Ono",Shunsuke Ono,2023-01-20T08:34:32Z
Mixed Attention Network for Hyperspectral Image Denoising,"  Hyperspectral image denoising is unique for the highly similar and correlated
spectral information that should be properly considered. However, existing
methods show limitations in exploring the spectral correlations across
different bands and feature interactions within each band. Besides, the low-
and high-level features usually exhibit different importance for different
spatial-spectral regions, which is not fully explored for current algorithms as
well. In this paper, we present a Mixed Attention Network (MAN) that
simultaneously considers the inter- and intra-spectral correlations as well as
the interactions between low- and high-level spatial-spectral meaningful
features. Specifically, we introduce a multi-head recurrent spectral attention
that efficiently integrates the inter-spectral features across all the spectral
bands. These features are further enhanced with a progressive spectral channel
attention by exploring the intra-spectral relationships. Moreover, we propose
an attentive skip-connection that adaptively controls the proportion of the
low- and high-level spatial-spectral features from the encoder and decoder to
better enhance the aggregated features. Extensive experiments show that our MAN
outperforms existing state-of-the-art methods on simulated and real noise
settings while maintaining a low cost of parameters and running time.
","Zeqiang Lai, Ying Fu",Ying Fu,2023-01-27T04:02:35Z
"Objective Evaluation-based High-efficiency Learning Framework for
  Hyperspectral Image Classification","  Deep learning methods have been successfully applied to hyperspectral image
(HSI) classification with remarkable performance. Because of limited labelled
HSI data, earlier studies primarily adopted a patch-based classification
framework, which divides images into overlapping patches for training and
testing. However, this approach results in redundant computations and possible
information leakage. In this study, we propose an objective evaluation-based
high-efficiency learning framework for tiny HSI classification. This framework
comprises two main parts: (i) a leakage-free balanced sampling strategy, and
(ii) a modified end-to-end fully convolutional network (FCN) architecture that
optimizes the trade-off between accuracy and efficiency. The leakage-free
balanced sampling strategy generates balanced and non-overlapping training and
testing data by partitioning an HSI and the ground truth image into small
windows, each of which corresponds to one training or testing sample. The
proposed high-efficiency FCN exhibits a pixel-to-pixel architecture with
modifications aimed at faster inference speed and improved parameter
efficiency. Experiments conducted on four representative datasets demonstrated
that the proposed sampling strategy can provide objective performance
evaluation and that the proposed network outperformed many state-of-the-art
approaches with respect to the speed/accuracy tradeoff. Our source code is
available at https://github.com/xmzhang2018.
","Xuming Zhang, Jian Yan, Jia Tian, Wei Li, Xingfa Gu, Qingjiu Tian",Qingjiu Tian,2023-01-10T15:15:55Z
"Topological Generality and Spectral Dimensionality in the Earth Mineral
  Dust Source Investigation (EMIT) using Joint Characterization and the
  Spectral Mixture Residual","  NASA's Earth Surface Mineral Dust Source Investigation (EMIT) mission seeks
to use spaceborne imaging spectroscopy (hyperspectral imaging) to map the
mineralogy of arid dust source regions. Here we apply recent developments in
Joint Characterization (JC) and the spectral Mixture Residual (MR) to explore
the information content of data from this novel mission. Specifically, for a
mosaic of 20 spectrally diverse scenes we find: 1) a generalized
three-endmember (Substrate, Vegetation, Dark; SVD) spectral mixture model is
capable of capturing the preponderance (99% in 3 dimensions) of spectral
variance with low misfit (99% of pixels with RMSE < 3.7%); 2) manifold learning
(UMAP) is capable of identifying spatially coherent, physically interpretable
clustering relationships in the spectral feature space; 3) UMAP yields results
that are at least as informative when applied to the MR as when applied to raw
reflectance; 4) SVD fraction information usefully contextualizes UMAP
clustering relationships, and vice-versa (JC); and 5) when EMIT data are
convolved to spectral response functions of multispectral instruments
(Sentinel-2, Landsat 8/9, Planet SuperDove), SVD fractions correlate strongly
across sensors but UMAP clustering relationships for the EMIT hyperspectral
feature space are far more informative than for simulated multispectral
sensors. Implications are discussed for both the utility of EMIT data in the
near-term, and for the potential of high SNR spaceborne imaging spectroscopy
more generally, to transform the future of optical remote sensing in the years
and decades to come.
","Daniel Sousa, Christopher Small",Christopher Small,2023-03-08T20:31:06Z
Blind deblurring of hyperspectral document images,"  Most computer vision and machine learning-based approaches for historical
document analysis are tailored to grayscale or RGB images and thus, mostly
exploit their spatial information. Multispectral (MS) and hyperspectral (HS)
images contain, next to the spatial information, much richer spectral
information than RGB images (usually spreading beyond the visible spectral
range) that can facilitate more effective feature extraction, more accurate
classification and recognition, and thus, improved analysis. Although
utilization of rich spectral information can improve historical document
analysis tremendously, there are still some potential limitations of HS imagery
such as camera-induced noise and blur that require a carefully designed
preprocessing step. Here, we propose novel blind HS image deblurring methods
tailored to document images. We exploit a low-rank property of HS images (i.e.,
by projecting an HS image to a lower dimensional subspace) and utilize a text
tailor image prior to performing a PSF estimation and deblurring of subspace
components. The preliminary results show that the proposed approach gives good
results over all spectral bands, removing successfully image artefacts
introduced by blur and noise and significantly increasing the number of bands
that can be used in further analysis.
","M. Ljubenovic, P. Guzzonato, G. Franceschin, A. Traviglia",A. Traviglia,2023-03-09T09:31:13Z
"DDS2M: Self-Supervised Denoising Diffusion Spatio-Spectral Model for
  Hyperspectral Image Restoration","  Diffusion models have recently received a surge of interest due to their
impressive performance for image restoration, especially in terms of noise
robustness. However, existing diffusion-based methods are trained on a large
amount of training data and perform very well in-distribution, but can be quite
susceptible to distribution shift. This is especially inappropriate for
data-starved hyperspectral image (HSI) restoration. To tackle this problem,
this work puts forth a self-supervised diffusion model for HSI restoration,
namely Denoising Diffusion Spatio-Spectral Model (\texttt{DDS2M}), which works
by inferring the parameters of the proposed Variational Spatio-Spectral Module
(VS2M) during the reverse diffusion process, solely using the degraded HSI
without any extra training data. In VS2M, a variational inference-based loss
function is customized to enable the untrained spatial and spectral networks to
learn the posterior distribution, which serves as the transitions of the
sampling chain to help reverse the diffusion process. Benefiting from its
self-supervised nature and the diffusion process, \texttt{DDS2M} enjoys
stronger generalization ability to various HSIs compared to existing
diffusion-based methods and superior robustness to noise compared to existing
HSI restoration methods. Extensive experiments on HSI denoising, noisy HSI
completion and super-resolution on a variety of HSIs demonstrate
\texttt{DDS2M}'s superiority over the existing task-specific state-of-the-arts.
","Yuchun Miao, Lefei Zhang, Liangpei Zhang, Dacheng Tao",Dacheng Tao,2023-03-12T14:57:04Z
"One-Step Detection Paradigm for Hyperspectral Anomaly Detection via
  Spectral Deviation Relationship Learning","  Hyperspectral anomaly detection (HAD) involves identifying the targets that
deviate spectrally from their surroundings, without prior knowledge. Recently,
deep learning based methods have become the mainstream HAD methods, due to
their powerful spatial-spectral feature extraction ability. However, the
current deep detection models are optimized to complete a proxy task (two-step
paradigm), such as background reconstruction or generation, rather than
achieving anomaly detection directly. This leads to suboptimal results and poor
transferability, which means that the deep model is trained and tested on the
same image. In this paper, an unsupervised transferred direct detection (TDD)
model is proposed, which is optimized directly for the anomaly detection task
(one-step paradigm) and has transferability. Specially, the TDD model is
optimized to identify the spectral deviation relationship according to the
anomaly definition. Compared to learning the specific background distribution
as most models do, the spectral deviation relationship is universal for
different images and guarantees the model transferability. To train the TDD
model in an unsupervised manner, an anomaly sample simulation strategy is
proposed to generate numerous pairs of anomaly samples. Furthermore, a global
self-attention module and a local self-attention module are designed to help
the model focus on the ""spectrally deviating"" relationship. The TDD model was
validated on four public HAD datasets. The results show that the proposed TDD
model can successfully overcome the limitation of traditional model training
and testing on a single image, and the model has a powerful detection ability
and excellent transferability.
","Jingtao Li, Xinyu Wang, Shaoyu Wang, Hengwei Zhao, Liangpei Zhang, Yanfei Zhong",Yanfei Zhong,2023-03-22T06:41:09Z
"Interferometer response characterization algorithm for multi-aperture
  Fabry-Perot imaging spectrometers","  In recent years, the demand for hyperspectral imaging devices has grown
significantly, driven by their ability of capturing high-resolution spectral
information. Among the several possible optical designs for acquiring
hyperspectral images, there is a growing interest in interferometric spectral
imaging systems based on division of aperture. These systems have the advantage
of capturing snapshot acquisitions while maintaining a compact design. However,
they require a careful calibration to operate properly. In this work, we
present the interferometer response characterization algorithm (IRCA), a robust
three-step procedure designed to characterize the transmittance response of
multi-aperture imaging spectrometers based on the interferometry of
Fabry-Perot. Additionally, we propose a formulation of the image formation
model for such devices suitable to estimate the parameters of interest by
considering the model under various regimes of finesse. The proposed algorithm
processes the image output obtained from a set of monochromatic light sources
and refines the results using nonlinear regression after an ad-hoc
initialization. Through experimental analysis conducted on four different
prototypes from the Image SPectrometer On Chip (ImSPOC) family, we validate the
performance of our approach for characterization. The associated source code
for this paper is available at https://github.com/danaroth83/irca.
","Daniele Picone, Silvére Gousset, Mauro Dalla-Mura, Yann Ferrec, Etienne le-Coarer",Etienne le-Coarer,2023-03-24T15:41:39Z
Multimodal Hyperspectral Image Classification via Interconnected Fusion,"  Existing multiple modality fusion methods, such as concatenation, summation,
and encoder-decoder-based fusion, have recently been employed to combine
modality characteristics of Hyperspectral Image (HSI) and Light Detection And
Ranging (LiDAR). However, these methods consider the relationship of HSI-LiDAR
signals from limited perspectives. More specifically, they overlook the
contextual information across modalities of HSI and LiDAR and the
intra-modality characteristics of LiDAR. In this paper, we provide a new
insight into feature fusion to explore the relationships across HSI and LiDAR
modalities comprehensively. An Interconnected Fusion (IF) framework is
proposed. Firstly, the center patch of the HSI input is extracted and
replicated to the size of the HSI input. Then, nine different perspectives in
the fusion matrix are generated by calculating self-attention and
cross-attention among the replicated center patch, HSI input, and corresponding
LiDAR input. In this way, the intra- and inter-modality characteristics can be
fully exploited, and contextual information is considered in both
intra-modality and inter-modality manner. These nine interrelated elements in
the fusion matrix can complement each other and eliminate biases, which can
generate a multi-modality representation for classification accurately.
Extensive experiments have been conducted on three widely used datasets:
Trento, MUUFL, and Houston. The IF framework achieves state-of-the-art results
on these datasets compared to existing approaches.
","Lu Huo, Jiahao Xia, Leijie Zhang, Haimin Zhang, Min Xu",Min Xu,2023-04-02T09:46:13Z
"SpectralDiff: A Generative Framework for Hyperspectral Image
  Classification with Diffusion Models","  Hyperspectral Image (HSI) classification is an important issue in remote
sensing field with extensive applications in earth science. In recent years, a
large number of deep learning-based HSI classification methods have been
proposed. However, existing methods have limited ability to handle
high-dimensional, highly redundant, and complex data, making it challenging to
capture the spectral-spatial distributions of data and relationships between
samples. To address this issue, we propose a generative framework for HSI
classification with diffusion models (SpectralDiff) that effectively mines the
distribution information of high-dimensional and highly redundant data by
iteratively denoising and explicitly constructing the data generation process,
thus better reflecting the relationships between samples. The framework
consists of a spectral-spatial diffusion module, and an attention-based
classification module. The spectral-spatial diffusion module adopts forward and
reverse spectral-spatial diffusion processes to achieve adaptive construction
of sample relationships without requiring prior knowledge of graphical
structure or neighborhood information. It captures spectral-spatial
distribution and contextual information of objects in HSI and mines
unsupervised spectral-spatial diffusion features within the reverse diffusion
process. Finally, these features are fed into the attention-based
classification module for per-pixel classification. The diffusion features can
facilitate cross-sample perception via reconstruction distribution, leading to
improved classification performance. Experiments on three public HSI datasets
demonstrate that the proposed method can achieve better performance than
state-of-the-art methods. For the sake of reproducibility, the source code of
SpectralDiff will be publicly available at
https://github.com/chenning0115/SpectralDiff.
","Ning Chen, Jun Yue, Leyuan Fang, Shaobo Xia",Shaobo Xia,2023-04-12T16:32:34Z
"Hyperspectral Image Analysis with Subspace Learning-based One-Class
  Classification","  Hyperspectral image (HSI) classification is an important task in many
applications, such as environmental monitoring, medical imaging, and land
use/land cover (LULC) classification. Due to the significant amount of spectral
information from recent HSI sensors, analyzing the acquired images is
challenging using traditional Machine Learning (ML) methods. As the number of
frequency bands increases, the required number of training samples increases
exponentially to achieve a reasonable classification accuracy, also known as
the curse of dimensionality. Therefore, separate band selection or
dimensionality reduction techniques are often applied before performing any
classification task over HSI data. In this study, we investigate recently
proposed subspace learning methods for one-class classification (OCC). These
methods map high-dimensional data to a lower-dimensional feature space that is
optimized for one-class classification. In this way, there is no separate
dimensionality reduction or feature selection procedure needed in the proposed
classification framework. Moreover, one-class classifiers have the ability to
learn a data description from the category of a single class only. Considering
the imbalanced labels of the LULC classification problem and rich spectral
information (high number of dimensions), the proposed classification approach
is well-suited for HSI data. Overall, this is a pioneer study focusing on
subspace learning-based one-class classification for HSI data. We analyze the
performance of the proposed subspace learning one-class classifiers in the
proposed pipeline. Our experiments validate that the proposed approach helps
tackle the curse of dimensionality along with the imbalanced nature of HSI
data.
","Sertac Kilickaya, Mete Ahishali, Fahad Sohrab, Turker Ince, Moncef Gabbouj",Moncef Gabbouj,2023-04-19T15:17:05Z
"HKNAS: Classification of Hyperspectral Imagery Based on Hyper Kernel
  Neural Architecture Search","  Recent neural architecture search (NAS) based approaches have made great
progress in hyperspectral image (HSI) classification tasks. However, the
architectures are usually optimized independently of the network weights,
increasing searching time and restricting model performances. To tackle these
issues, in this paper, different from previous methods that extra define
structural parameters, we propose to directly generate structural parameters by
utilizing the specifically designed hyper kernels, ingeniously converting the
original complex dual optimization problem into easily implemented one-tier
optimizations, and greatly shrinking searching costs. Then, we develop a
hierarchical multi-module search space whose candidate operations only contain
convolutions, and these operations can be integrated into unified kernels.
Using the above searching strategy and searching space, we obtain three kinds
of networks to separately conduct pixel-level or image-level classifications
with 1-D or 3-D convolutions. In addition, by combining the proposed hyper
kernel searching scheme with the 3-D convolution decomposition mechanism, we
obtain diverse architectures to simulate 3-D convolutions, greatly improving
network flexibilities. A series of quantitative and qualitative experiments on
six public datasets demonstrate that the proposed methods achieve
state-of-the-art results compared with other advanced NAS-based HSI
classification approaches.
","Di Wang, Bo Du, Liangpei Zhang, Dacheng Tao",Dacheng Tao,2023-04-23T17:27:40Z
"DiffUCD:Unsupervised Hyperspectral Image Change Detection with Semantic
  Correlation Diffusion Model","  Hyperspectral image change detection (HSI-CD) has emerged as a crucial
research area in remote sensing due to its ability to detect subtle changes on
the earth's surface. Recently, diffusional denoising probabilistic models
(DDPM) have demonstrated remarkable performance in the generative domain. Apart
from their image generation capability, the denoising process in diffusion
models can comprehensively account for the semantic correlation of
spectral-spatial features in HSI, resulting in the retrieval of semantically
relevant features in the original image. In this work, we extend the diffusion
model's application to the HSI-CD field and propose a novel unsupervised HSI-CD
with semantic correlation diffusion model (DiffUCD). Specifically, the semantic
correlation diffusion model (SCDM) leverages abundant unlabeled samples and
fully accounts for the semantic correlation of spectral-spatial features, which
mitigates pseudo change between multi-temporal images arising from inconsistent
imaging conditions. Besides, objects with the same semantic concept at the same
spatial location may exhibit inconsistent spectral signatures at different
times, resulting in pseudo change. To address this problem, we propose a
cross-temporal contrastive learning (CTCL) mechanism that aligns the spectral
feature representations of unchanged samples. By doing so, the spectral
difference invariant features caused by environmental changes can be obtained.
Experiments conducted on three publicly available datasets demonstrate that the
proposed method outperforms the other state-of-the-art unsupervised methods in
terms of Overall Accuracy (OA), Kappa Coefficient (KC), and F1 scores,
achieving improvements of approximately 3.95%, 8.13%, and 4.45%, respectively.
Notably, our method can achieve comparable results to those fully supervised
methods requiring numerous annotated samples.
","Xiangrong Zhang, Shunli Tian, Guanchun Wang, Huiyu Zhou, Licheng Jiao",Licheng Jiao,2023-05-21T09:21:41Z
Cooperative Hardware-Prompt Learning for Snapshot Compressive Imaging,"  Snapshot compressive imaging emerges as a promising technology for acquiring
real-world hyperspectral signals. It uses an optical encoder and compressively
produces the 2D measurement, followed by which the 3D hyperspectral data can be
retrieved via training a deep reconstruction network. Existing reconstruction
models are trained with a single hardware instance, whose performance is
vulnerable to hardware perturbation or replacement, demonstrating an
overfitting issue to the physical configuration. This defect limits the
deployment of pre-trained models since they would suffer from large performance
degradation when are assembled to unseen hardware. To better facilitate the
reconstruction model with new hardware, previous efforts resort to centralized
training by collecting multi-hardware and data, which is impractical when
dealing with proprietary assets among institutions. In light of this, federated
learning (FL) has become a feasible solution to enable cross-hardware
cooperation without breaking privacy. However, the naive FedAvg is subject to
client drift upon data heterogeneity owning to the hardware inconsistency. In
this work, we tackle this challenge by marrying prompt tuning with FL to
snapshot compressive imaging for the first time and propose an federated
hardware-prompt learning (FedHP) method. Rather than mitigating the client
drift by rectifying the gradients, which only takes effect on the learning
manifold but fails to touch the heterogeneity rooted in the input data space,
the proposed FedHP globally learns a hardware-conditioned prompter to align the
data distribution, which serves as an indicator of the data inconsistency
stemming from different pre-defined coded apertures. Extensive experiments
demonstrate that the proposed method well coordinates the pre-trained model to
indeterminate hardware configurations.
","Jiamian Wang, Zongliang Wu, Yulun Zhang, Xin Yuan, Tao Lin, Zhiqiang Tao",Zhiqiang Tao,2023-06-01T22:21:28Z
"Semi-Supervised Learning for hyperspectral images by non parametrically
  predicting view assignment","  Hyperspectral image (HSI) classification is gaining a lot of momentum in
present time because of high inherent spectral information within the images.
However, these images suffer from the problem of curse of dimensionality and
usually require a large number samples for tasks such as classification,
especially in supervised setting. Recently, to effectively train the deep
learning models with minimal labelled samples, the unlabeled samples are also
being leveraged in self-supervised and semi-supervised setting. In this work,
we leverage the idea of semi-supervised learning to assist the discriminative
self-supervised pretraining of the models. The proposed method takes different
augmented views of the unlabeled samples as input and assigns them the same
pseudo-label corresponding to the labelled sample from the downstream task. We
train our model on two HSI datasets, namely Houston dataset (from data fusion
contest, 2013) and Pavia university dataset, and show that the proposed
approach performs better than self-supervised approach and supervised training.
","Shivam Pande, Nassim Ait Ali Braham, Yi Wang, Conrad M Albrecht, Biplab Banerjee, Xiao Xiang Zhu",Xiao Xiang Zhu,2023-06-19T14:13:56Z
"A generic self-supervised learning (SSL) framework for representation
  learning from spectra-spatial feature of unlabeled remote sensing imagery","  Remote sensing data has been widely used for various Earth Observation (EO)
missions such as land use and cover classification, weather forecasting,
agricultural management, and environmental monitoring. Most existing remote
sensing data-based models are based on supervised learning that requires large
and representative human-labelled data for model training, which is costly and
time-consuming. Recently, self-supervised learning (SSL) enables the models to
learn a representation from orders of magnitude more unlabelled data. This
representation has been proven to boost the performance of downstream tasks and
has potential for remote sensing applications. The success of SSL is heavily
dependent on a pre-designed pretext task, which introduces an inductive bias
into the model from a large amount of unlabelled data. Since remote sensing
imagery has rich spectral information beyond the standard RGB colour space, the
pretext tasks established in computer vision based on RGB images may not be
straightforward to be extended to the multi/hyperspectral domain. To address
this challenge, this work has designed a novel SSL framework that is capable of
learning representation from both spectra-spatial information of unlabelled
data. The framework contains two novel pretext tasks for object-based and
pixel-based remote sensing data analysis methods, respectively. Through two
typical downstream tasks evaluation (a multi-label land cover classification
task on Sentienl-2 multispectral datasets and a ground soil parameter retrieval
task on hyperspectral datasets), the results demonstrate that the
representation obtained through the proposed SSL achieved a significant
improvement in model performance.
","Xin Zhang, Liangxiu Han",Liangxiu Han,2023-06-27T23:50:43Z
"Boosting the Generalization Ability for Hyperspectral Image
  Classification using Spectral-spatial Axial Aggregation Transformer","  In the hyperspectral image classification (HSIC) task, the most commonly used
model validation paradigm is partitioning the training-test dataset through
pixel-wise random sampling. By training on a small amount of data, the deep
learning model can achieve almost perfect accuracy. However, in our
experiments, we found that the high accuracy was reached because the training
and test datasets share a lot of information. On non-overlapping dataset
partitions, well-performing models suffer significant performance degradation.
To this end, we propose a spectral-spatial axial aggregation transformer model,
namely SaaFormer, that preserves generalization across dataset partitions.
SaaFormer applies a multi-level spectral extraction structure to segment the
spectrum into multiple spectrum clips, such that the wavelength continuity of
the spectrum across the channel are preserved. For each spectrum clip, the
axial aggregation attention mechanism, which integrates spatial features along
multiple spectral axes is applied to mine the spectral characteristic. The
multi-level spectral extraction and the axial aggregation attention emphasize
spectral characteristic to improve the model generalization. The experimental
results on five publicly available datasets demonstrate that our model exhibits
comparable performance on the random partition, while significantly
outperforming other methods on non-overlapping partitions. Moreover, SaaFormer
shows excellent performance on background classification.
","Enzhe Zhao, Zhichang Guo, Shengzhu Shi, Yao Li, Jia Li, Dazhi Zhang",Dazhi Zhang,2023-06-29T07:55:43Z
HIDFlowNet: A Flow-Based Deep Network for Hyperspectral Image Denoising,"  Hyperspectral image (HSI) denoising is essentially ill-posed since a noisy
HSI can be degraded from multiple clean HSIs. However, current deep
learning-based approaches ignore this fact and restore the clean image with
deterministic mapping (i.e., the network receives a noisy HSI and outputs a
clean HSI). To alleviate this issue, this paper proposes a flow-based HSI
denoising network (HIDFlowNet) to directly learn the conditional distribution
of the clean HSI given the noisy HSI and thus diverse clean HSIs can be sampled
from the conditional distribution. Overall, our HIDFlowNet is induced from the
flow methodology and contains an invertible decoder and a conditional encoder,
which can fully decouple the learning of low-frequency and high-frequency
information of HSI. Specifically, the invertible decoder is built by staking a
succession of invertible conditional blocks (ICBs) to capture the local
high-frequency details since the invertible network is information-lossless.
The conditional encoder utilizes down-sampling operations to obtain
low-resolution images and uses transformers to capture correlations over a long
distance so that global low-frequency information can be effectively extracted.
Extensive experimental results on simulated and real HSI datasets verify the
superiority of our proposed HIDFlowNet compared with other state-of-the-art
methods both quantitatively and visually.
","Li Pang, Weizhen Gu, Xiangyong Cao, Xiangyu Rui, Jiangjun Peng, Shuang Xu, Gang Yang, Deyu Meng",Deyu Meng,2023-06-20T08:20:28Z
"Multi-source imagery fusion using deep learning in a cloud computing
  platform","  Given the high availability of data collected by different remote sensing
instruments, the data fusion of multi-spectral and hyperspectral images (HSI)
is an important topic in remote sensing. In particular, super-resolution as a
data fusion application using spatial and spectral domains is highly
investigated because its fused images is used to improve the classification and
tracking objects accuracy. On the other hand, the huge amount of data obtained
by remote sensing instruments represent a key concern in terms of data storage,
management and pre-processing. This paper proposes a Big Data Cloud platform
using Hadoop and Spark to store, manages, and process remote sensing data.
Also, a study over the parameter \textit{chunk size} is presented to suggest
the appropriate value for this parameter to download imagery data from Hadoop
into a Spark application, based on the format of our data. We also developed an
alternative approach based on Long Short Term Memory trained with different
patch sizes for super-resolution image. This approach fuse hyperspectral and
multispectral images. As a result, we obtain images with high-spatial and
high-spectral resolution. The experimental results show that for a chunk size
of 64k, an average of 3.5s was required to download data from Hadoop into a
Spark application. The proposed model for super-resolution provides a
structural similarity index of 0.98 and 0.907 for the used dataset.
","Carlos Theran, Michael Alvarez, Emmanuel Arzuaga, Heidy Sierra",Heidy Sierra,2023-07-06T15:18:11Z
"BiGSeT: Binary Mask-Guided Separation Training for DNN-based
  Hyperspectral Anomaly Detection","  Hyperspectral anomaly detection (HAD) aims to recognize a minority of
anomalies that are spectrally different from their surrounding background
without prior knowledge. Deep neural networks (DNNs), including autoencoders
(AEs), convolutional neural networks (CNNs) and vision transformers (ViTs),
have shown remarkable performance in this field due to their powerful ability
to model the complicated background. However, for reconstruction tasks, DNNs
tend to incorporate both background and anomalies into the estimated
background, which is referred to as the identical mapping problem (IMP) and
leads to significantly decreased performance. To address this limitation, we
propose a model-independent binary mask-guided separation training strategy for
DNNs, named BiGSeT. Our method introduces a separation training loss based on a
latent binary mask to separately constrain the background and anomalies in the
estimated image. The background is preserved, while the potential anomalies are
suppressed by using an efficient second-order Laplacian of Gaussian (LoG)
operator, generating a pure background estimate. In order to maintain
separability during training, we periodically update the mask using a robust
proportion threshold estimated before the training. In our experiments, We
adopt a vanilla AE as the network to validate our training strategy on several
real-world datasets. Our results show superior performance compared to some
state-of-the-art methods. Specifically, we achieved a 90.67% AUC score on the
HyMap Cooke City dataset. Additionally, we applied our training strategy to
other deep network structures, achieving improved detection performance
compared to their original versions, demonstrating its effective
transferability. The code of our method will be available at
https://github.com/enter-i-username/BiGSeT.
","Haijun Liu, Xi Su, Xiangfei Shen, Lihui Chen, Xichuan Zhou",Xichuan Zhou,2023-07-14T15:48:20Z
"Deep Reinforcement Learning Based System for Intraoperative
  Hyperspectral Video Autofocusing","  Hyperspectral imaging (HSI) captures a greater level of spectral detail than
traditional optical imaging, making it a potentially valuable intraoperative
tool when precise tissue differentiation is essential. Hardware limitations of
current optical systems used for handheld real-time video HSI result in a
limited focal depth, thereby posing usability issues for integration of the
technology into the operating room. This work integrates a focus-tunable liquid
lens into a video HSI exoscope, and proposes novel video autofocusing methods
based on deep reinforcement learning. A first-of-its-kind robotic focal-time
scan was performed to create a realistic and reproducible testing dataset. We
benchmarked our proposed autofocus algorithm against traditional policies, and
found our novel approach to perform significantly ($p<0.05$) better than
traditional techniques ($0.070\pm.098$ mean absolute focal error compared to
$0.146\pm.148$). In addition, we performed a blinded usability trial by having
two neurosurgeons compare the system with different autofocus policies, and
found our novel approach to be the most favourable, making our system a
desirable addition for intraoperative HSI.
","Charlie Budd, Jianrong Qiu, Oscar MacCormac, Martin Huber, Christopher Mower, Mirek Janatka, Théo Trotouin, Jonathan Shapey, Mads S. Bergholt, Tom Vercauteren",Tom Vercauteren,2023-07-21T15:04:21Z
Synthetic white balancing for intra-operative hyperspectral imaging,"  Hyperspectral imaging shows promise for surgical applications to
non-invasively provide spatially-resolved, spectral information. For
calibration purposes, a white reference image of a highly-reflective Lambertian
surface should be obtained under the same imaging conditions. Standard white
references are not sterilizable, and so are unsuitable for surgical
environments. We demonstrate the necessity for in situ white references and
address this by proposing a novel, sterile, synthetic reference construction
algorithm. The use of references obtained at different distances and lighting
conditions to the subject were examined. Spectral and color reconstructions
were compared with standard measurements qualitatively and quantitatively,
using $\Delta E$ and normalised RMSE respectively. The algorithm forms a
composite image from a video of a standard sterile ruler, whose imperfect
reflectivity is compensated for. The reference is modelled as the product of
independent spatial and spectral components, and a scalar factor accounting for
gain, exposure, and light intensity. Evaluation of synthetic references against
ideal but non-sterile references is performed using the same metrics alongside
pixel-by-pixel errors. Finally, intraoperative integration is assessed though
cadaveric experiments. Improper white balancing leads to increases in all
quantitative and qualitative errors. Synthetic references achieve median
pixel-by-pixel errors lower than 6.5% and produce similar reconstructions and
errors to an ideal reference. The algorithm integrated well into surgical
workflow, achieving median pixel-by-pixel errors of 4.77%, while maintaining
good spectral and color reconstruction.
","Anisha Bahl, Conor C. Horgan, Mirek Janatka, Oscar J. MacCormac, Philip Noonan, Yijing Xie, Jianrong Qiu, Nicola Cavalcanti, Philipp Fürnstahl, Michael Ebner, Mads S. Bergholt, Jonathan Shapey, Tom Vercauteren",Tom Vercauteren,2023-07-24T13:42:10Z
"Target Detection on Hyperspectral Images Using MCMC and VI Trained
  Bayesian Neural Networks","  Neural networks (NN) have become almost ubiquitous with image classification,
but in their standard form produce point estimates, with no measure of
confidence. Bayesian neural networks (BNN) provide uncertainty quantification
(UQ) for NN predictions and estimates through the posterior distribution. As NN
are applied in more high-consequence applications, UQ is becoming a
requirement. BNN provide a solution to this problem by not only giving accurate
predictions and estimates, but also an interval that includes reasonable values
within a desired probability. Despite their positive attributes, BNN are
notoriously difficult and time consuming to train. Traditional Bayesian methods
use Markov Chain Monte Carlo (MCMC), but this is often brushed aside as being
too slow. The most common method is variational inference (VI) due to its fast
computation, but there are multiple concerns with its efficacy. We apply and
compare MCMC- and VI-trained BNN in the context of target detection in
hyperspectral imagery (HSI), where materials of interest can be identified by
their unique spectral signature. This is a challenging field, due to the
numerous permuting effects practical collection of HSI has on measured spectra.
Both models are trained using out-of-the-box tools on a high fidelity HSI
target detection scene. Both MCMC- and VI-trained BNN perform well overall at
target detection on a simulated HSI scene. This paper provides an example of
how to utilize the benefits of UQ, but also to increase awareness that
different training methods can give different results for the same model. If
sufficient computational resources are available, the best approach rather than
the fastest or most efficient should be used, especially for high consequence
problems.
","Daniel Ries, Jason Adams, Joshua Zollweg",Joshua Zollweg,2023-08-11T01:35:54Z
"Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image
  Reconstruction","  Hyperspectral Image (HSI) reconstruction has made gratifying progress with
the deep unfolding framework by formulating the problem into a data module and
a prior module. Nevertheless, existing methods still face the problem of
insufficient matching with HSI data. The issues lie in three aspects: 1) fixed
gradient descent step in the data module while the degradation of HSI is
agnostic in the pixel-level. 2) inadequate prior module for 3D HSI cube. 3)
stage interaction ignoring the differences in features at different stages. To
address these issues, in this work, we propose a Pixel Adaptive Deep Unfolding
Transformer (PADUT) for HSI reconstruction. In the data module, a pixel
adaptive descent step is employed to focus on pixel-level agnostic degradation.
In the prior module, we introduce the Non-local Spectral Transformer (NST) to
emphasize the 3D characteristics of HSI for recovering. Moreover, inspired by
the diverse expression of features in different stages and depths, the stage
interaction is improved by the Fast Fourier Transform (FFT). Experimental
results on both simulated and real scenes exhibit the superior performance of
our method compared to state-of-the-art HSI reconstruction methods. The code is
released at: https://github.com/MyuLi/PADUT.
","Miaoyu Li, Ying Fu, Ji Liu, Yulun Zhang",Yulun Zhang,2023-08-21T16:12:31Z
Coherent Spectral Feature Extraction Using Symmetric Autoencoders,"  Hyperspectral data acquired through remote sensing are invaluable for
environmental and resource studies. While rich in spectral information, various
complexities such as environmental conditions, material properties, and sensor
characteristics can cause significant variability even among pixels belonging
to the same material class. This variability poses nuisance for accurate
land-cover classification and analysis. Focusing on the spectral domain, we
propose an autoencoder architecture called the symmetric autoencoder (SymAE),
which leverages permutation invariant representation and stochastic
regularization in tandem to disentangle class-invariant `coherent' features
from variability-causing 'nuisance' features on a pixel-by-pixel basis. This
disentanglement is achieved through a purely data-driven process, without the
need for hand-crafted modeling, noise distribution priors, or reference 'clean
signals'. Additionally, SymAE can generate virtual spectra through
manipulations in latent space. Using AVIRIS instrument data, we demonstrate
these virtual spectra, offering insights on the disentanglement. Extensive
experiments across five benchmark hyperspectral datasets show that coherent
features extracted by SymAE can be used to achieve state-of-the-art pixel-based
classification. Furthermore, we leverage these coherent features to enhance the
performance of some leading spectral-spatial HSI classification methods. Our
approach especially shows improvement in scenarios where training and test sets
are disjoint, a common challenge in real-world applications where existing
methods often struggle to maintain relatively high performance.
","Archisman Bhattacharjee, Pawan Bharadwaj",Pawan Bharadwaj,2023-09-25T16:51:26Z
"Multiview Transformer: Rethinking Spatial Information in Hyperspectral
  Image Classification","  Identifying the land cover category for each pixel in a hyperspectral image
(HSI) relies on spectral and spatial information. An HSI cuboid with a specific
patch size is utilized to extract spatial-spectral feature representation for
the central pixel. In this article, we investigate that scene-specific but not
essential correlations may be recorded in an HSI cuboid. This additional
information improves the model performance on existing HSI datasets and makes
it hard to properly evaluate the ability of a model. We refer to this problem
as the spatial overfitting issue and utilize strict experimental settings to
avoid it. We further propose a multiview transformer for HSI classification,
which consists of multiview principal component analysis (MPCA), spectral
encoder-decoder (SED), and spatial-pooling tokenization transformer (SPTT).
MPCA performs dimension reduction on an HSI via constructing spectral multiview
observations and applying PCA on each view data to extract low-dimensional view
representation. The combination of view representations, named multiview
representation, is the dimension reduction output of the MPCA. To aggregate the
multiview information, a fully-convolutional SED with a U-shape in spectral
dimension is introduced to extract a multiview feature map. SPTT transforms the
multiview features into tokens using the spatial-pooling tokenization strategy
and learns robust and discriminative spatial-spectral features for land cover
identification. Classification is conducted with a linear classifier.
Experiments on three HSI datasets with rigid settings demonstrate the
superiority of the proposed multiview transformer over the state-of-the-art
methods.
","Jie Zhang, Yongshan Zhang, Yicong Zhou",Yicong Zhou,2023-10-11T04:25:24Z
"Hyperspectral In-Memory Computing with Optical Frequency Combs and
  Programmable Optical Memories","  The rapid advancements in machine learning across numerous industries have
amplified the demand for extensive matrix-vector multiplication operations,
thereby challenging the capacities of traditional von Neumann computing
architectures. To address this, researchers are currently exploring
alternatives such as in-memory computing systems to develop faster and more
energy-efficient hardware. In particular, there is renewed interest in
computing systems based on optics, which could potentially handle matrix-vector
multiplication in a more energy-efficient way. Despite promising initial
results, developing a highly parallel, programmable, and scalable optical
computing system capable of rivaling electronic computing hardware still
remains elusive. In this context, we propose a hyperspectral in-memory
computing architecture that integrates space multiplexing with frequency
multiplexing of optical frequency combs and uses spatial light modulators as a
programmable optical memory, thereby boosting the computational throughput and
the energy efficiency. We have experimentally demonstrated multiply-accumulate
operations with higher than 4-bit precision in both matrix-vector and
matrix-matrix multiplications, which suggests the system's potential for a wide
variety of deep learning and optimization tasks. This system exhibits
extraordinary modularity, scalability, and programmability, effectively
transcending the traditional limitations of optics-based computing
architectures. Our approach demonstrates the potential to scale beyond peta
operations per second, marking a significant step towards achieving
high-throughput energy-efficient optical computing.
","Mostafa Honari Latifpour, Byoung Jun Park, Yoshihisa Yamamoto, Myoung-Gyun Suh",Myoung-Gyun Suh,2023-10-17T06:03:45Z
"A Fast and Scalable Computational Topology Framework for the Euler
  Characteristic","  The Euler characteristic (EC) is a powerful topological descriptor that can
be used to quantify the shape of data objects that are represented as
fields/manifolds. Fast methods for computing the EC are required to enable
processing of high-throughput data and real-time implementations. This
represents a challenge when processing high-resolution 2D field data (e.g.,
images) and 3D field data (e.g., video, hyperspectral images, and space-time
data obtained from fluid dynamics and molecular simulations). In this work, we
present parallel algorithms (and software implementations) to enable fast
computations of the EC for 2D and 3D fields using vertex contributions. We test
the proposed algorithms using synthetic data objects and data objects arising
in real applications such as microscopy, 3D molecular dynamics simulations, and
hyperspectral images. Results show that the proposed implementation can compute
the EC a couple of orders of magnitude faster than ${\tt GUDHI}$ (an
off-the-shelf and state-of-the art tool) and at speeds comparable to ${\tt
CHUNKYEuler}$ (a tool tailored to scalable computation of the EC). The vertex
contributions approach is flexible in that it compute the EC as well as other
topological descriptors such as perimeter, area, and volume (${\tt
CHUNKYEuler}$ can only compute the EC). Scalability with respect to memory use
is also addressed by providing low-memory versions of the algorithms; this
enables processing of data objects beyond the size of dynamic memory. All data
and software needed for reproducing the results are shared as open-source code.
","Daniel J. Laky, Victor M. Zavala",Victor M. Zavala,2023-11-20T13:01:57Z
"Spectral-wise Implicit Neural Representation for Hyperspectral Image
  Reconstruction","  Coded Aperture Snapshot Spectral Imaging (CASSI) reconstruction aims to
recover the 3D spatial-spectral signal from 2D measurement. Existing methods
for reconstructing Hyperspectral Image (HSI) typically involve learning
mappings from a 2D compressed image to a predetermined set of discrete spectral
bands. However, this approach overlooks the inherent continuity of the spectral
information. In this study, we propose an innovative method called
Spectral-wise Implicit Neural Representation (SINR) as a pioneering step toward
addressing this limitation. SINR introduces a continuous spectral amplification
process for HSI reconstruction, enabling spectral super-resolution with
customizable magnification factors. To achieve this, we leverage the concept of
implicit neural representation. Specifically, our approach introduces a
spectral-wise attention mechanism that treats individual channels as distinct
tokens, thereby capturing global spectral dependencies. Additionally, our
approach incorporates two components, namely a Fourier coordinate encoder and a
spectral scale factor module. The Fourier coordinate encoder enhances the
SINR's ability to emphasize high-frequency components, while the spectral scale
factor module guides the SINR to adapt to the variable number of spectral
channels. Notably, the SINR framework enhances the flexibility of CASSI
reconstruction by accommodating an unlimited number of spectral bands in the
desired output. Extensive experiments demonstrate that our SINR outperforms
baseline methods. By enabling continuous reconstruction within the CASSI
framework, we take the initial stride toward integrating implicit neural
representation into the field.
","Huan Chen, Wangcai Zhao, Tingfa Xu, Shiyun Zhou, Peifu Liu, Jianan Li",Jianan Li,2023-12-02T08:06:07Z
"Hyper-Restormer: A General Hyperspectral Image Restoration Transformer
  for Remote Sensing Imaging","  The deep learning model Transformer has achieved remarkable success in the
hyperspectral image (HSI) restoration tasks by leveraging Spectral and Spatial
Self-Attention (SA) mechanisms. However, applying these designs to remote
sensing (RS) HSI restoration tasks, which involve far more spectrums than
typical HSI (e.g., ICVL dataset with 31 bands), presents challenges due to the
enormous computational complexity of using Spectral and Spatial SA mechanisms.
To address this problem, we proposed Hyper-Restormer, a lightweight and
effective Transformer-based architecture for RS HSI restoration. First, we
introduce a novel Lightweight Spectral-Spatial (LSS) Transformer Block that
utilizes both Spectral and Spatial SA to capture long-range dependencies of
input features map. Additionally, we employ a novel Lightweight
Locally-enhanced Feed-Forward Network (LLFF) to further enhance local context
information. Then, LSS Transformer Blocks construct a Single-stage Lightweight
Spectral-Spatial Transformer (SLSST) that cleverly utilizes the low-rank
property of RS HSI to decompose the feature maps into basis and abundance
components, enabling Spectral and Spatial SA with low computational cost.
Finally, the proposed Hyper-Restormer cascades several SLSSTs in a stepwise
manner to progressively enhance the quality of RS HSI restoration from coarse
to fine. Extensive experiments were conducted on various RS HSI restoration
tasks, including denoising, inpainting, and super-resolution, demonstrating
that the proposed Hyper-Restormer outperforms other state-of-the-art methods.
","Yo-Yu Lai, Chia-Hsiang Lin, Zi-Chao Leng",Zi-Chao Leng,2023-12-12T07:05:59Z
"Pixel-Superpixel Contrastive Learning and Pseudo-Label Correction for
  Hyperspectral Image Clustering","  Hyperspectral image (HSI) clustering is gaining considerable attention owing
to recent methods that overcome the inefficiency and misleading results from
the absence of supervised information. Contrastive learning methods excel at
existing pixel level and super pixel level HSI clustering tasks. The
pixel-level contrastive learning method can effectively improve the ability of
the model to capture fine features of HSI but requires a large time overhead.
The super pixel-level contrastive learning method utilizes the homogeneity of
HSI and reduces computing resources; however, it yields rough classification
results. To exploit the strengths of both methods, we present a pixel super
pixel contrastive learning and pseudo-label correction (PSCPC) method for the
HSI clustering. PSCPC can reasonably capture domain-specific and fine-grained
features through super pixels and the comparative learning of a small number of
pixels within the super pixels. To improve the clustering performance of super
pixels, this paper proposes a pseudo-label correction module that aligns the
clustering pseudo-labels of pixels and super-pixels. In addition, pixel-level
clustering results are used to supervise super pixel-level clustering,
improving the generalization ability of the model. Extensive experiments
demonstrate the effectiveness and efficiency of PSCPC.
","Renxiang Guan, Zihao Li, Xianju Li, Chang Tang",Chang Tang,2023-12-15T09:19:00Z
BSS-Bench: Towards Reproducible and Effective Band Selection Search,"  The key technology to overcome the drawbacks of hyperspectral imaging
(expensive, high capture delay, and low spatial resolution) and make it widely
applicable is to select only a few representative bands from hundreds of bands.
However, current band selection (BS) methods face challenges in fair
comparisons due to inconsistent train/validation settings, including the number
of bands, dataset splits, and retraining settings. To make BS methods easy and
reproducible, this paper presents the first band selection search benchmark
(BSS-Bench) containing 52k training and evaluation records of numerous band
combinations (BC) with different backbones for various hyperspectral analysis
tasks. The creation of BSS-Bench required a significant computational effort of
1.26k GPU days. By querying BSS-Bench, BS experiments can be performed easily
and reproducibly, and the gap between the searched result and the best
achievable performance can be measured. Based on BSS-Bench, we further discuss
the impact of various factors on BS, such as the number of bands, unsupervised
statistics, and different backbones. In addition to BSS-Bench, we present an
effective one-shot BS method called Single Combination One Shot (SCOS), which
learns the priority of any BCs through one-time training, eliminating the need
for repetitive retraining on different BCs. Furthermore, the search process of
SCOS is flexible and does not require training, making it efficient and
effective. Our extensive evaluations demonstrate that SCOS outperforms current
BS methods on multiple tasks, even with much fewer bands. Our BSS-Bench and
codes are available in the supplementary material and will be publicly
available.
","Wenshuai Xu, Zhenbo Xu",Zhenbo Xu,2023-12-22T10:00:32Z
Hyperspectral Image Denoising via Spatial-Spectral Recurrent Transformer,"  Hyperspectral images (HSIs) often suffer from noise arising from both
intra-imaging mechanisms and environmental factors. Leveraging domain knowledge
specific to HSIs, such as global spectral correlation (GSC) and non-local
spatial self-similarity (NSS), is crucial for effective denoising. Existing
methods tend to independently utilize each of these knowledge components with
multiple blocks, overlooking the inherent 3D nature of HSIs where domain
knowledge is strongly interlinked, resulting in suboptimal performance. To
address this challenge, this paper introduces a spatial-spectral recurrent
transformer U-Net (SSRT-UNet) for HSI denoising. The proposed SSRT-UNet
integrates NSS and GSC properties within a single SSRT block. This block
consists of a spatial branch and a spectral branch. The spectral branch employs
a combination of transformer and recurrent neural network to perform recurrent
computations across bands, allowing for GSC exploitation beyond a fixed number
of bands. Concurrently, the spatial branch encodes NSS for each band by sharing
keys and values with the spectral branch under the guidance of GSC. This
interaction between the two branches enables the joint utilization of NSS and
GSC, avoiding their independent treatment. Experimental results demonstrate
that our method outperforms several alternative approaches. The source code
will be available at https://github.com/lronkitty/SSRT.
","Guanyiman Fu, Fengchao Xiong, Jianfeng Lu, Jun Zhou, Jiantao Zhou, Yuntao Qian",Yuntao Qian,2023-12-31T04:24:56Z
"Multispectral Stereo-Image Fusion for 3D Hyperspectral Scene
  Reconstruction","  Spectral imaging enables the analysis of optical material properties that are
invisible to the human eye. Different spectral capturing setups, e.g., based on
filter-wheel, push-broom, line-scanning, or mosaic cameras, have been
introduced in the last years to support a wide range of applications in
agriculture, medicine, and industrial surveillance. However, these systems
often suffer from different disadvantages, such as lack of real-time
capability, limited spectral coverage or low spatial resolution. To address
these drawbacks, we present a novel approach combining two calibrated
multispectral real-time capable snapshot cameras, covering different spectral
ranges, into a stereo-system. Therefore, a hyperspectral data-cube can be
continuously captured. The combined use of different multispectral snapshot
cameras enables both 3D reconstruction and spectral analysis. Both captured
images are demosaicked avoiding spatial resolution loss. We fuse the spectral
data from one camera into the other to receive a spatially and spectrally high
resolution video stream. Experiments demonstrate the feasibility of this
approach and the system is investigated with regard to its applicability for
surgical assistance monitoring.
","Eric L. Wisotzky, Jost Triller, Anna Hilsmann, Peter Eisert",Peter Eisert,2023-12-15T13:20:35Z
Physics-Inspired Degradation Models for Hyperspectral Image Fusion,"  The fusion of a low-spatial-resolution hyperspectral image (LR-HSI) with a
high-spatial-resolution multispectral image (HR-MSI) has garnered increasing
research interest. However, most fusion methods solely focus on the fusion
algorithm itself and overlook the degradation models, which results in
unsatisfactory performance in practical scenarios. To fill this gap, we propose
physics-inspired degradation models (PIDM) to model the degradation of LR-HSI
and HR-MSI, which comprises a spatial degradation network (SpaDN) and a
spectral degradation network (SpeDN). SpaDN and SpeDN are designed based on two
insights. First, we employ spatial warping and spectral modulation operations
to simulate lens aberrations, thereby introducing non-uniformity into the
spatial and spectral degradation processes. Second, we utilize asymmetric
downsampling and parallel downsampling operations to separately reduce the
spatial and spectral resolutions of the images, thus ensuring the matching of
spatial and spectral degradation processes with specific physical
characteristics. Once SpaDN and SpeDN are established, we adopt a
self-supervised training strategy to optimize the network parameters and
provide a plug-and-play solution for fusion methods. Comprehensive experiments
demonstrate that our proposed PIDM can boost the fusion performance of existing
fusion methods in practical scenarios.
","Jie Lian, Lizhi Wang, Lin Zhu, Renwei Dian, Zhiwei Xiong, Hua Huang",Hua Huang,2024-02-04T09:07:28Z
"A Multispectral Automated Transfer Technique (MATT) for machine-driven
  image labeling utilizing the Segment Anything Model (SAM)","  Segment Anything Model (SAM) is drastically accelerating the speed and
accuracy of automatically segmenting and labeling large Red-Green-Blue (RGB)
imagery datasets. However, SAM is unable to segment and label images outside of
the visible light spectrum, for example, for multispectral or hyperspectral
imagery. Therefore, this paper outlines a method we call the Multispectral
Automated Transfer Technique (MATT). By transposing SAM segmentation masks from
RGB images we can automatically segment and label multispectral imagery with
high precision and efficiency. For example, the results demonstrate that
segmenting and labeling a 2,400-image dataset utilizing MATT achieves a time
reduction of 87.8% in developing a trained model, reducing roughly 20 hours of
manual labeling, to only 2.4 hours. This efficiency gain is associated with
only a 6.7% decrease in overall mean average precision (mAP) when training
multispectral models via MATT, compared to a manually labeled dataset. We
consider this an acceptable level of precision loss when considering the time
saved during training, especially for rapidly prototyping experimental modeling
methods. This research greatly contributes to the study of multispectral object
detection by providing a novel and open-source method to rapidly segment,
label, and train multispectral object detection models with minimal human
interaction. Future research needs to focus on applying these methods to (i)
space-based multispectral, and (ii) drone-based hyperspectral imagery.
","James E. Gallagher, Aryav Gogia, Edward J. Oughton",Edward J. Oughton,2024-02-18T01:01:13Z
"Low-Rank Representations Meets Deep Unfolding: A Generalized and
  Interpretable Network for Hyperspectral Anomaly Detection","  Current hyperspectral anomaly detection (HAD) benchmark datasets suffer from
low resolution, simple background, and small size of the detection data. These
factors also limit the performance of the well-known low-rank representation
(LRR) models in terms of robustness on the separation of background and target
features and the reliance on manual parameter selection. To this end, we build
a new set of HAD benchmark datasets for improving the robustness of the HAD
algorithm in complex scenarios, AIR-HAD for short. Accordingly, we propose a
generalized and interpretable HAD network by deeply unfolding a
dictionary-learnable LLR model, named LRR-Net$^+$, which is capable of
spectrally decoupling the background structure and object properties in a more
generalized fashion and eliminating the bias introduced by vital interference
targets concurrently. In addition, LRR-Net$^+$ integrates the solution process
of the Alternating Direction Method of Multipliers (ADMM) optimizer with the
deep network, guiding its search process and imparting a level of
interpretability to parameter optimization. Additionally, the integration of
physical models with DL techniques eliminates the need for manual parameter
tuning. The manually tuned parameters are seamlessly transformed into trainable
parameters for deep neural networks, facilitating a more efficient and
automated optimization process. Extensive experiments conducted on the AIR-HAD
dataset show the superiority of our LRR-Net$^+$ in terms of detection
performance and generalization ability, compared to top-performing rivals.
Furthermore, the compilable codes and our AIR-HAD benchmark datasets in this
paper will be made available freely and openly at
\url{https://sites.google.com/view/danfeng-hong}.
","Chenyu Li, Bing Zhang, Danfeng Hong, Jing Yao, Jocelyn Chanussot",Jocelyn Chanussot,2024-02-23T14:15:58Z
"HIR-Diff: Unsupervised Hyperspectral Image Restoration Via Improved
  Diffusion Models","  Hyperspectral image (HSI) restoration aims at recovering clean images from
degraded observations and plays a vital role in downstream tasks. Existing
model-based methods have limitations in accurately modeling the complex image
characteristics with handcraft priors, and deep learning-based methods suffer
from poor generalization ability. To alleviate these issues, this paper
proposes an unsupervised HSI restoration framework with pre-trained diffusion
model (HIR-Diff), which restores the clean HSIs from the product of two
low-rank components, i.e., the reduced image and the coefficient matrix.
Specifically, the reduced image, which has a low spectral dimension, lies in
the image field and can be inferred from our improved diffusion model where a
new guidance function with total variation (TV) prior is designed to ensure
that the reduced image can be well sampled. The coefficient matrix can be
effectively pre-estimated based on singular value decomposition (SVD) and
rank-revealing QR (RRQR) factorization. Furthermore, a novel exponential noise
schedule is proposed to accelerate the restoration process (about 5$\times$
acceleration for denoising) with little performance decrease. Extensive
experimental results validate the superiority of our method in both performance
and speed on a variety of HSI restoration tasks, including HSI denoising, noisy
HSI super-resolution, and noisy HSI inpainting. The code is available at
https://github.com/LiPang/HIRDiff.
","Li Pang, Xiangyu Rui, Long Cui, Hongzhong Wang, Deyu Meng, Xiangyong Cao",Xiangyong Cao,2024-02-24T17:15:05Z
"SLIMBRAIN: Augmented Reality Real-Time Acquisition and Processing System
  For Hyperspectral Classification Mapping with Depth Information for In-Vivo
  Surgical Procedures","  Over the last two decades, augmented reality (AR) has led to the rapid
development of new interfaces in various fields of social and technological
application domains. One such domain is medicine, and to a higher extent
surgery, where these visualization techniques help to improve the effectiveness
of preoperative and intraoperative procedures. Following this trend, this paper
presents SLIMBRAIN, a real-time acquisition and processing AR system suitable
to classify and display brain tumor tissue from hyperspectral (HS) information.
This system captures and processes HS images at 14 frames per second (FPS)
during the course of a tumor resection operation to detect and delimit cancer
tissue at the same time the neurosurgeon operates. The result is represented in
an AR visualization where the classification results are overlapped with the
RGB point cloud captured by a LiDAR camera. This representation allows natural
navigation of the scene at the same time it is captured and processed,
improving the visualization and hence effectiveness of the HS technology to
delimit tumors. The whole system has been verified in real brain tumor
resection operations.
","Jaime Sancho, Manuel Villa, Miguel Chavarrías, Eduardo Juarez, Alfonso Lagares, César Sanz",César Sanz,2024-03-25T11:10:49Z
"HSIMamba: Hyperpsectral Imaging Efficient Feature Learning with
  Bidirectional State Space for Classification","  Classifying hyperspectral images is a difficult task in remote sensing, due
to their complex high-dimensional data. To address this challenge, we propose
HSIMamba, a novel framework that uses bidirectional reversed convolutional
neural network pathways to extract spectral features more efficiently.
Additionally, it incorporates a specialized block for spatial analysis. Our
approach combines the operational efficiency of CNNs with the dynamic feature
extraction capability of attention mechanisms found in Transformers. However,
it avoids the associated high computational demands. HSIMamba is designed to
process data bidirectionally, significantly enhancing the extraction of
spectral features and integrating them with spatial information for
comprehensive analysis. This approach improves classification accuracy beyond
current benchmarks and addresses computational inefficiencies encountered with
advanced models like Transformers. HSIMamba were tested against three widely
recognized datasets Houston 2013, Indian Pines, and Pavia University and
demonstrated exceptional performance, surpassing existing state-of-the-art
models in HSI classification. This method highlights the methodological
innovation of HSIMamba and its practical implications, which are particularly
valuable in contexts where computational resources are limited. HSIMamba
redefines the standards of efficiency and accuracy in HSI classification,
thereby enhancing the capabilities of remote sensing applications.
Hyperspectral imaging has become a crucial tool for environmental surveillance,
agriculture, and other critical areas that require detailed analysis of the
Earth surface. Please see our code in HSIMamba for more details.
","Judy X Yang, Jun Zhou, Jing Wang, Hui Tian, Alan Wee Chung Liew",Alan Wee Chung Liew,2024-03-30T07:27:36Z
"S2RC-GCN: A Spatial-Spectral Reliable Contrastive Graph Convolutional
  Network for Complex Land Cover Classification Using Hyperspectral Images","  Spatial correlations between different ground objects are an important
feature of mining land cover research. Graph Convolutional Networks (GCNs) can
effectively capture such spatial feature representations and have demonstrated
promising results in performing hyperspectral imagery (HSI) classification
tasks of complex land. However, the existing GCN-based HSI classification
methods are prone to interference from redundant information when extracting
complex features. To classify complex scenes more effectively, this study
proposes a novel spatial-spectral reliable contrastive graph convolutional
classification framework named S2RC-GCN. Specifically, we fused the spectral
and spatial features extracted by the 1D- and 2D-encoder, and the 2D-encoder
includes an attention model to automatically extract important information. We
then leveraged the fused high-level features to construct graphs and fed the
resulting graphs into the GCNs to determine more effective graph
representations. Furthermore, a novel reliable contrastive graph convolution
was proposed for reliable contrastive learning to learn and fuse robust
features. Finally, to test the performance of the model on complex object
classification, we used imagery taken by Gaofen-5 in the Jiang Xia area to
construct complex land cover datasets. The test results show that compared with
other models, our model achieved the best results and effectively improved the
classification performance of complex remote sensing imagery.
","Renxiang Guan, Zihao Li, Chujia Song, Guo Yu, Xianju Li, Ruyi Feng",Ruyi Feng,2024-04-01T07:17:02Z
"A Universal Knowledge Embedded Contrastive Learning Framework for
  Hyperspectral Image Classification","  Hyperspectral image (HSI) classification techniques have been intensively
studied and a variety of models have been developed. However, these HSI
classification models are confined to pocket models and unrealistic ways of
dataset partitioning. The former limits the generalization performance of the
model and the latter is partitioned leading to inflated model evaluation
metrics, which results in plummeting model performance in the real world.
Therefore, we propose a universal knowledge embedded contrastive learning
framework (KnowCL) for supervised, unsupervised, and semisupervised HSI
classification, which largely closes the gap between HSI classification models
between pocket models and standard vision backbones. We present a new HSI
processing pipeline in conjunction with a range of data transformation and
augmentation techniques that provide diverse data representations and realistic
data partitioning. The proposed framework based on this pipeline is compatible
with all kinds of backbones and can fully exploit labeled and unlabeled samples
with the expected training time. Furthermore, we design a new loss function,
which can adaptively fuse the supervised loss and unsupervised loss, enhancing
the learning performance. This proposed new classification paradigm shows great
potential in exploring for HSI classification technology. The code can be
accessed at \url{https://github.com/quanweiliu/KnowCL}.
","Quanwei Liu, Yanni Dong, Tao Huang, Lefei Zhang, Bo Du",Bo Du,2024-04-02T06:24:21Z
"Multi-level Graph Subspace Contrastive Learning for Hyperspectral Image
  Clustering","  Hyperspectral image (HSI) clustering is a challenging task due to its high
complexity. Despite subspace clustering shows impressive performance for HSI,
traditional methods tend to ignore the global-local interaction in HSI data. In
this study, we proposed a multi-level graph subspace contrastive learning
(MLGSC) for HSI clustering. The model is divided into the following main parts.
Graph convolution subspace construction: utilizing spectral and texture
feautures to construct two graph convolution views. Local-global graph
representation: local graph representations were obtained by step-by-step
convolutions and a more representative global graph representation was obtained
using an attention-based pooling strategy. Multi-level graph subspace
contrastive learning: multi-level contrastive learning was conducted to obtain
local-global joint graph representations, to improve the consistency of the
positive samples between views, and to obtain more robust graph embeddings.
Specifically, graph-level contrastive learning is used to better learn global
representations of HSI data. Node-level intra-view and inter-view contrastive
learning is designed to learn joint representations of local regions of HSI.
The proposed model is evaluated on four popular HSI datasets: Indian Pines,
Pavia University, Houston, and Xu Zhou. The overall accuracies are 97.75%,
99.96%, 92.28%, and 95.73%, which significantly outperforms the current
state-of-the-art clustering methods.
","Jingxin Wang, Renxiang Guan, Kainan Gao, Zihao Li, Hao Li, Xianju Li, Chang Tang",Chang Tang,2024-04-08T05:50:46Z
"Unsupervised Band Selection Using Fused HSI and LiDAR Attention
  Integrating With Autoencoder","  Band selection in hyperspectral imaging (HSI) is critical for optimising data
processing and enhancing analytical accuracy. Traditional approaches have
predominantly concentrated on analysing spectral and pixel characteristics
within individual bands independently. These approaches overlook the potential
benefits of integrating multiple data sources, such as Light Detection and
Ranging (LiDAR), and is further challenged by the limited availability of
labeled data in HSI processing, which represents a significant obstacle. To
address these challenges, this paper introduces a novel unsupervised band
selection framework that incorporates attention mechanisms and an Autoencoder
for reconstruction-based band selection. Our methodology distinctively
integrates HSI with LiDAR data through an attention score, using a
convolutional Autoencoder to process the combined feature mask. This fusion
effectively captures essential spatial and spectral features and reduces
redundancy in hyperspectral datasets. A comprehensive comparative analysis of
our innovative fused band selection approach is performed against existing
unsupervised band selection and fusion models. We used data sets such as
Houston 2013, Trento, and MUUFLE for our experiments. The results demonstrate
that our method achieves superior classification accuracy and significantly
outperforms existing models. This enhancement in HSI band selection,
facilitated by the incorporation of LiDAR features, underscores the
considerable advantages of integrating features from different sources.
","Judy X Yang, Jun Zhou, Jing Wang, Hui Tian, Alan Wee Chung Liew",Alan Wee Chung Liew,2024-04-08T07:47:28Z
Unfolding ADMM for Enhanced Subspace Clustering of Hyperspectral Images,"  Deep subspace clustering methods are now prominent in clustering, typically
using fully connected networks and a self-representation loss function.
However, these methods often struggle with overfitting and lack
interpretability. In this paper, we explore an alternative clustering approach
based on deep unfolding. By unfolding iterative optimization methods into
neural networks, this approach offers enhanced interpretability and reliability
compared to data-driven deep learning methods, and greater adaptability and
generalization than model-based approaches. Hence, unfolding has become widely
used in inverse imaging problems, such as image restoration, reconstruction,
and super-resolution, but has not been sufficiently explored yet in the context
of clustering. In this work, we introduce an innovative clustering architecture
for hyperspectral images (HSI) by unfolding an iterative solver based on the
Alternating Direction Method of Multipliers (ADMM) for sparse subspace
clustering. To our knowledge, this is the first attempt to apply unfolding ADMM
for computing the self-representation matrix in subspace clustering. Moreover,
our approach captures well the structural characteristics of HSI data by
employing the K nearest neighbors algorithm as part of a structure preservation
module. Experimental evaluation of three established HSI datasets shows clearly
the potential of the unfolding approach in HSI clustering and even demonstrates
superior performance compared to state-of-the-art techniques.
","Xianlu Li, Nicolas Nadisic, Shaoguang Huang, Aleksandra Pižurica",Aleksandra Pižurica,2024-04-10T15:51:46Z
SpectralMamba: Efficient Mamba for Hyperspectral Image Classification,"  Recurrent neural networks and Transformers have recently dominated most
applications in hyperspectral (HS) imaging, owing to their capability to
capture long-range dependencies from spectrum sequences. However, despite the
success of these sequential architectures, the non-ignorable inefficiency
caused by either difficulty in parallelization or computationally prohibitive
attention still hinders their practicality, especially for large-scale
observation in remote sensing scenarios. To address this issue, we herein
propose SpectralMamba -- a novel state space model incorporated efficient deep
learning framework for HS image classification. SpectralMamba features the
simplified but adequate modeling of HS data dynamics at two levels. First, in
spatial-spectral space, a dynamical mask is learned by efficient convolutions
to simultaneously encode spatial regularity and spectral peculiarity, thus
attenuating the spectral variability and confusion in discriminative
representation learning. Second, the merged spectrum can then be efficiently
operated in the hidden state space with all parameters learned input-dependent,
yielding selectively focused responses without reliance on redundant attention
or imparallelizable recurrence. To explore the room for further computational
downsizing, a piece-wise scanning mechanism is employed in-between,
transferring approximately continuous spectrum into sequences with squeezed
length while maintaining short- and long-term contextual profiles among
hundreds of bands. Through extensive experiments on four benchmark HS datasets
acquired by satellite-, aircraft-, and UAV-borne imagers, SpectralMamba
surprisingly creates promising win-wins from both performance and efficiency
perspectives.
","Jing Yao, Danfeng Hong, Chenyu Li, Jocelyn Chanussot",Jocelyn Chanussot,2024-04-12T14:12:03Z
"Parallel Implementations Assessment of a Spatial-Spectral Classifier for
  Hyperspectral Clinical Applications","  Hyperspectral (HS) imaging presents itself as a non-contact, non-ionizing and
non-invasive technique, proven to be suitable for medical diagnosis. However,
the volume of information contained in these images makes difficult providing
the surgeon with information about the boundaries in real-time. To that end,
High-Performance-Computing (HPC) platforms become necessary. This paper
presents a comparison between the performances provided by five different HPC
platforms while processing a spatial-spectral approach to classify HS images,
assessing their main benefits and drawbacks. To provide a complete study, two
different medical applications, with two different requirements, have been
analyzed. The first application consists of HS images taken from neurosurgical
operations; the second one presents HS images taken from dermatological
interventions. While the main constraint for neurosurgical applications is the
processing time, in other environments, as the dermatological one, other
requirements can be considered. In that sense, energy efficiency is becoming a
major challenge, since this kind of applications are usually developed as
hand-held devices, thus depending on the battery capacity. These requirements
have been considered to choose the target platforms: on the one hand, three of
the most powerful Graphic Processing Units (GPUs) available in the market; and,
on the other hand, a low-power GPU and a manycore architecture, both
specifically thought for being used in battery-dependent environments.
","Raquel Lazcano, Daniel Madroñal, Giordana Florimbi, Jaime Sancho, Sergio Sanchez, Raquel Leon, Himar Fabelo, Samuel Ortega, Emanuele Torti, Ruben Salvador, Margarita Marrero-Martin, Francesco Leporati, Eduardo Juarez, Gustavo M Callico, Cesar Sanz",Cesar Sanz,2024-03-28T16:33:16Z
"3D-Convolution Guided Spectral-Spatial Transformer for Hyperspectral
  Image Classification","  In recent years, Vision Transformers (ViTs) have shown promising
classification performance over Convolutional Neural Networks (CNNs) due to
their self-attention mechanism. Many researchers have incorporated ViTs for
Hyperspectral Image (HSI) classification. HSIs are characterised by narrow
contiguous spectral bands, providing rich spectral data. Although ViTs excel
with sequential data, they cannot extract spectral-spatial information like
CNNs. Furthermore, to have high classification performance, there should be a
strong interaction between the HSI token and the class (CLS) token. To solve
these issues, we propose a 3D-Convolution guided Spectral-Spatial Transformer
(3D-ConvSST) for HSI classification that utilizes a 3D-Convolution Guided
Residual Module (CGRM) in-between encoders to ""fuse"" the local spatial and
spectral information and to enhance the feature propagation. Furthermore, we
forego the class token and instead apply Global Average Pooling, which
effectively encodes more discriminative and pertinent high-level features for
classification. Extensive experiments have been conducted on three public HSI
datasets to show the superiority of the proposed model over state-of-the-art
traditional, convolutional, and Transformer models. The code is available at
https://github.com/ShyamVarahagiri/3D-ConvSST.
","Shyam Varahagiri, Aryaman Sinha, Shiv Ram Dubey, Satish Kumar Singh",Satish Kumar Singh,2024-04-20T03:39:54Z
"Fourier-enhanced Implicit Neural Fusion Network for Multispectral and
  Hyperspectral Image Fusion","  Recently, implicit neural representations (INR) have made significant strides
in various vision-related domains, providing a novel solution for Multispectral
and Hyperspectral Image Fusion (MHIF) tasks. However, INR is prone to losing
high-frequency information and is confined to the lack of global perceptual
capabilities. To address these issues, this paper introduces a Fourier-enhanced
Implicit Neural Fusion Network (FeINFN) specifically designed for MHIF task,
targeting the following phenomena: The Fourier amplitudes of the HR-HSI latent
code and LR-HSI are remarkably similar; however, their phases exhibit different
patterns. In FeINFN, we innovatively propose a spatial and frequency implicit
fusion function (Spa-Fre IFF), helping INR capture high-frequency information
and expanding the receptive field. Besides, a new decoder employing a complex
Gabor wavelet activation function, called Spatial-Frequency Interactive Decoder
(SFID), is invented to enhance the interaction of INR features. Especially, we
further theoretically prove that the Gabor wavelet activation possesses a
time-frequency tightness property that favors learning the optimal bandwidths
in the decoder. Experiments on two benchmark MHIF datasets verify the
state-of-the-art (SOTA) performance of the proposed method, both visually and
quantitatively. Also, ablation studies demonstrate the mentioned contributions.
The code will be available on Anonymous GitHub
(https://anonymous.4open.science/r/FeINFN-15C9/) after possible acceptance.
","Yu-Jie Liang, Zihan Cao, Liang-Jian Deng, Xiao Wu",Xiao Wu,2024-04-23T16:14:20Z
"Real-Time Compressed Sensing for Joint Hyperspectral Image Transmission
  and Restoration for CubeSat","  This paper addresses the challenges associated with hyperspectral image (HSI)
reconstruction from miniaturized satellites, which often suffer from stripe
effects and are computationally resource-limited. We propose a Real-Time
Compressed Sensing (RTCS) network designed to be lightweight and require only
relatively few training samples for efficient and robust HSI reconstruction in
the presence of the stripe effect and under noisy transmission conditions. The
RTCS network features a simplified architecture that reduces the required
training samples and allows for easy implementation on integer-8-based
encoders, facilitating rapid compressed sensing for stripe-like HSI, which
exactly matches the moderate design of miniaturized satellites on push broom
scanning mechanism. This contrasts optimization-based models that demand
high-precision floating-point operations, making them difficult to deploy on
edge devices. Our encoder employs an integer-8-compatible linear projection for
stripe-like HSI data transmission, ensuring real-time compressed sensing.
Furthermore, based on the novel two-streamed architecture, an efficient HSI
restoration decoder is proposed for the receiver side, allowing for edge-device
reconstruction without needing a sophisticated central server. This is
particularly crucial as an increasing number of miniaturized satellites
necessitates significant computing resources on the ground station. Extensive
experiments validate the superior performance of our approach, offering new and
vital capabilities for existing miniaturized satellite systems.
","Chih-Chung Hsu, Chih-Yu Jian, Eng-Shen Tu, Chia-Ming Lee, Guan-Lin Chen",Guan-Lin Chen,2024-04-24T10:03:37Z
Spectral-Spatial Mamba for Hyperspectral Image Classification,"  Recently, deep learning models have achieved excellent performance in
hyperspectral image (HSI) classification. Among the many deep models,
Transformer has gradually attracted interest for its excellence in modeling the
long-range dependencies of spatial-spectral features in HSI. However,
Transformer has the problem of quadratic computational complexity due to the
self-attention mechanism, which is heavier than other models and thus has
limited adoption in HSI processing. Fortunately, the recently emerging state
space model-based Mamba shows great computational efficiency while achieving
the modeling power of Transformers. Therefore, in this paper, we make a
preliminary attempt to apply the Mamba to HSI classification, leading to the
proposed spectral-spatial Mamba (SS-Mamba). Specifically, the proposed SS-Mamba
mainly consists of spectral-spatial token generation module and several stacked
spectral-spatial Mamba blocks. Firstly, the token generation module converts
any given HSI cube to spatial and spectral tokens as sequences. And then these
tokens are sent to stacked spectral-spatial mamba blocks (SS-MB). Each SS-MB
block consists of two basic mamba blocks and a spectral-spatial feature
enhancement module. The spatial and spectral tokens are processed separately by
the two basic mamba blocks, respectively. Besides, the feature enhancement
module modulates spatial and spectral tokens using HSI sample's center region
information. In this way, the spectral and spatial tokens cooperate with each
other and achieve information fusion within each block. The experimental
results conducted on widely used HSI datasets reveal that the proposed model
achieves competitive results compared with the state-of-the-art methods. The
Mamba-based method opens a new window for HSI classification.
","Lingbo Huang, Yushi Chen, Xin He",Xin He,2024-04-29T03:36:05Z
"SSUMamba: Spatial-Spectral Selective State Space Model for Hyperspectral
  Image Denoising","  Denoising is a crucial preprocessing step for hyperspectral images (HSIs) due
to noise arising from intra-imaging mechanisms and environmental factors.
Long-range spatial-spectral correlation modeling is beneficial for HSI
denoising but often comes with high computational complexity. Based on the
state space model (SSM), Mamba is known for its remarkable long-range
dependency modeling capabilities and computational efficiency. Building on
this, we introduce a memory-efficient spatial-spectral UMamba (SSUMamba) for
HSI denoising, with the spatial-spectral continuous scan (SSCS) Mamba being the
core component. SSCS Mamba alternates the row, column, and band in six
different orders to generate the sequence and uses the bidirectional SSM to
exploit long-range spatial-spectral dependencies. In each order, the images are
rearranged between adjacent scans to ensure spatial-spectral continuity.
Additionally, 3D convolutions are embedded into the SSCS Mamba to enhance local
spatial-spectral modeling. Experiments demonstrate that SSUMamba achieves
superior denoising results with lower memory consumption per batch compared to
transformer-based methods. The source code is available at
https://github.com/lronkitty/SSUMamba.
","Guanyiman Fu, Fengchao Xiong, Jianfeng Lu, Jun Zhou",Jun Zhou,2024-05-02T20:44:26Z
"Mamba-in-Mamba: Centralized Mamba-Cross-Scan in Tokenized Mamba Model
  for Hyperspectral Image Classification","  Hyperspectral image (HSI) classification is pivotal in the remote sensing
(RS) field, particularly with the advancement of deep learning techniques.
Sequential models, adapted from the natural language processing (NLP) field
such as Recurrent Neural Networks (RNNs) and Transformers, have been tailored
to this task, offering a unique viewpoint. However, several challenges persist
1) RNNs struggle with centric feature aggregation and are sensitive to
interfering pixels, 2) Transformers require significant computational resources
and often underperform with limited HSI training samples, and 3) Current
scanning methods for converting images into sequence-data are simplistic and
inefficient. In response, this study introduces the innovative Mamba-in-Mamba
(MiM) architecture for HSI classification, the first attempt of deploying State
Space Model (SSM) in this task. The MiM model includes 1) A novel centralized
Mamba-Cross-Scan (MCS) mechanism for transforming images into sequence-data, 2)
A Tokenized Mamba (T-Mamba) encoder that incorporates a Gaussian Decay Mask
(GDM), a Semantic Token Learner (STL), and a Semantic Token Fuser (STF) for
enhanced feature generation and concentration, and 3) A Weighted MCS Fusion
(WMF) module coupled with a Multi-Scale Loss Design to improve decoding
efficiency. Experimental results from three public HSI datasets with fixed and
disjoint training-testing samples demonstrate that our method outperforms
existing baselines and state-of-the-art approaches, highlighting its efficacy
and potential in HSI applications.
","Weilian Zhou, Sei-Ichiro Kamata, Haipeng Wang, Man-Sing Wong,  Huiying,  Hou", Hou,2024-05-20T13:19:02Z
"Superpixelwise Low-rank Approximation based Partial Label Learning for
  Hyperspectral Image Classification","  Insufficient prior knowledge of a captured hyperspectral image (HSI) scene
may lead the experts or the automatic labeling systems to offer incorrect
labels or ambiguous labels (i.e., assigning each training sample to a group of
candidate labels, among which only one of them is valid; this is also known as
partial label learning) during the labeling process. Accordingly, how to learn
from such data with ambiguous labels is a problem of great practical
importance. In this paper, we propose a novel superpixelwise low-rank
approximation (LRA)-based partial label learning method, namely SLAP, which is
the first to take into account partial label learning in HSI classification.
SLAP is mainly composed of two phases: disambiguating the training labels and
acquiring the predictive model. Specifically, in the first phase, we propose a
superpixelwise LRA-based model, preparing the affinity graph for the subsequent
label propagation process while extracting the discriminative representation to
enhance the following classification task of the second phase. Then to
disambiguate the training labels, label propagation propagates the labeling
information via the affinity graph of training pixels. In the second phase, we
take advantage of the resulting disambiguated training labels and the
discriminative representations to enhance the classification performance. The
extensive experiments validate the advantage of the proposed SLAP method over
state-of-the-art methods.
","Shujun Yang, Yu Zhang, Yao Ding, Danfeng Hong",Danfeng Hong,2024-05-27T12:26:49Z
"Elucidating nanostructural organisation and photonic properties of
  butterfly wing scales using hyperspectral microscopy","  Biophotonic nanostructures in butterfly wing scales remain fascinating
examples of biological functional materials, with intriguing open questions in
regards to formation and evolutionary function. One particularly interesting
butterfly species, Erora opisena (Lycaenidae: Theclinae), develops wing scales
that contain three-dimensional photonic crystals that closely resemble a single
gyroid geometry. Unlike most other gyroid forming butterflies, E. opisena
develops discrete gyroid crystallites with a pronounced size gradient hinting
at a developmental sequence frozen in time. Here, we use a hyperspectral
(wavelength-resolved) microscopy technique to investigate the ultrastructural
organisation of these gyroid crystallites in dry, adult wing scales. We show
that reflectance corresponds to crystallite size, where larger crystallites
reflect green wavelengths more intensely; this relationship could be used to
infer size from the optical signal. We further successfully resolve the
red-shifted reflectance signal from wing scales immersed in refractive index
oils with varying refractive index, including values similar to water or
cytosol. Such photonic crystals with lower refractive index contrast may be
similar to the hypothesized nanostructural forms in the developing butterfly
scales. The ability to resolve these fainter signals hints at the potential of
this facile light microscopy method for in vivo analysis of nanostructure
formation in developing butterflies.
","Anna-Lee Jessop, Primoz Pirih, Limin Wang, Nipam Patel, Peta Clode, Gerd Schroeder-Turk, Bodo Wilts",Bodo Wilts,2024-05-28T08:57:35Z
"HDMba: Hyperspectral Remote Sensing Imagery Dehazing with State Space
  Model","  Haze contamination in hyperspectral remote sensing images (HSI) can lead to
spatial visibility degradation and spectral distortion. Haze in HSI exhibits
spatial irregularity and inhomogeneous spectral distribution, with few dehazing
networks available. Current CNN and Transformer-based dehazing methods fail to
balance global scene recovery, local detail retention, and computational
efficiency. Inspired by the ability of Mamba to model long-range dependencies
with linear complexity, we explore its potential for HSI dehazing and propose
the first HSI Dehazing Mamba (HDMba) network. Specifically, we design a novel
window selective scan module (WSSM) that captures local dependencies within
windows and global correlations between windows by partitioning them. This
approach improves the ability of conventional Mamba in local feature
extraction. By modeling the local and global spectral-spatial information flow,
we achieve a comprehensive analysis of hazy regions. The DehazeMamba layer
(DML), constructed by WSSM, and residual DehazeMamba (RDM) blocks, composed of
DMLs, are the core components of the HDMba framework. These components
effectively characterize the complex distribution of haze in HSIs, aiding in
scene reconstruction and dehazing. Experimental results on the Gaofen-5 HSI
dataset demonstrate that HDMba outperforms other state-of-the-art methods in
dehazing performance. The code will be available at
https://github.com/RsAI-lab/HDMba.
","Hang Fu, Genyun Sun, Yinhe Li, Jinchang Ren, Aizhu Zhang, Cheng Jing, Pedram Ghamisi",Pedram Ghamisi,2024-06-09T08:53:02Z
"An Elliptic Kernel Unsupervised Autoencoder-Graph Convolutional Network
  Ensemble Model for Hyperspectral Unmixing","  Spectral Unmixing is an important technique in remote sensing used to analyze
hyperspectral images to identify endmembers and estimate abundance maps. Over
the past few decades, performance of techniques for endmember extraction and
fractional abundance map estimation have significantly improved. This article
presents an ensemble model workflow called Autoencoder Graph Ensemble Model
(AEGEM) designed to extract endmembers and fractional abundance maps. An
elliptical kernel is applied to measure spectral distances, generating the
adjacency matrix within the elliptical neighborhood. This information is used
to construct an elliptical graph, with centroids as senders and remaining
pixels within the geometry as receivers. The next step involves stacking
abundance maps, senders, and receivers as inputs to a Graph Convolutional
Network, which processes this input to refine abundance maps. Finally, an
ensemble decision-making process determines the best abundance maps based on
root mean square error metric. The proposed AEGEM is assessed with benchmark
datasets such as Samson, Jasper, and Urban, outperforming results obtained by
baseline algorithms. For the Samson dataset, AEGEM excels in three abundance
maps: water, tree and soil yielding values of 0.081, 0.158, and 0.182,
respectively. For the Jasper dataset, results are improved for the tree and
water endmembers with values of 0.035 and 0.060 in that order, as well as for
the mean average of the spectral angle distance metric 0.109. For the Urban
dataset, AEGEM outperforms previous results for the abundance maps of roof and
asphalt, achieving values of 0.135 and 0.240, respectively. Additionally, for
the endmembers of grass and roof, AEGEM achieves values of 0.063 and 0.094.
","Estefania Alfaro-Mejia, Carlos J Delgado, Vidya Manian",Vidya Manian,2024-06-10T19:04:39Z
"DualMamba: A Lightweight Spectral-Spatial Mamba-Convolution Network for
  Hyperspectral Image Classification","  The effectiveness and efficiency of modeling complex spectral-spatial
relations are both crucial for Hyperspectral image (HSI) classification. Most
existing methods based on CNNs and transformers still suffer from heavy
computational burdens and have room for improvement in capturing the
global-local spectral-spatial feature representation. To this end, we propose a
novel lightweight parallel design called lightweight dual-stream
Mamba-convolution network (DualMamba) for HSI classification. Specifically, a
parallel lightweight Mamba and CNN block are first developed to extract global
and local spectral-spatial features. First, the cross-attention
spectral-spatial Mamba module is proposed to leverage the global modeling of
Mamba at linear complexity. Within this module, dynamic positional embedding is
designed to enhance the spatial location information of visual sequences. The
lightweight spectral/spatial Mamba blocks comprise an efficient scanning
strategy and a lightweight Mamba design to efficiently extract global
spectral-spatial features. And the cross-attention spectral-spatial fusion is
designed to learn cross-correlation and fuse spectral-spatial features. Second,
the lightweight spectral-spatial residual convolution module is proposed with
lightweight spectral and spatial branches to extract local spectral-spatial
features through residual learning. Finally, the adaptive global-local fusion
is proposed to dynamically combine global Mamba features and local convolution
features for a global-local spectral-spatial representation. Compared with
state-of-the-art HSI classification methods, experimental results demonstrate
that DualMamba achieves significant classification accuracy on three public HSI
datasets and a superior reduction in model parameters and floating point
operations (FLOPs).
","Jiamu Sheng, Jingyi Zhou, Jiong Wang, Peng Ye, Jiayuan Fan",Jiayuan Fan,2024-06-11T08:26:42Z
"How to Learn More? Exploring Kolmogorov-Arnold Networks for
  Hyperspectral Image Classification","  Convolutional Neural Networks (CNNs) and vision transformers (ViTs) have
shown excellent capability in complex hyperspectral image (HSI) classification.
However, these models require a significant number of training data and are
computational resources. On the other hand, modern Multi-Layer Perceptrons
(MLPs) have demonstrated great classification capability. These modern
MLP-based models require significantly less training data compared to CNNs and
ViTs, achieving the state-of-the-art classification accuracy. Recently,
Kolmogorov-Arnold Networks (KANs) were proposed as viable alternatives for
MLPs. Because of their internal similarity to splines and their external
similarity to MLPs, KANs are able to optimize learned features with remarkable
accuracy in addition to being able to learn new features. Thus, in this study,
we assess the effectiveness of KANs for complex HSI data classification.
Moreover, to enhance the HSI classification accuracy obtained by the KANs, we
develop and propose a Hybrid architecture utilizing 1D, 2D, and 3D KANs. To
demonstrate the effectiveness of the proposed KAN architecture, we conducted
extensive experiments on three newly created HSI benchmark datasets:
QUH-Pingan, QUH-Tangdaowan, and QUH-Qingyun. The results underscored the
competitive or better capability of the developed hybrid KAN-based model across
these benchmark datasets over several other CNN- and ViT-based algorithms,
including 1D-CNN, 2DCNN, 3D CNN, VGG-16, ResNet-50, EfficientNet, RNN, and ViT.
The code are publicly available at (https://github.com/aj1365/HSIConvKAN)
","Ali Jamali, Swalpa Kumar Roy, Danfeng Hong, Bing Lu, Pedram Ghamisi",Pedram Ghamisi,2024-06-22T03:31:02Z
"SpectralKAN: Kolmogorov-Arnold Network for Hyperspectral Images Change
  Detection","  It has been verified that deep learning methods, including convolutional
neural networks (CNNs), graph neural networks (GNNs), and transformers, can
accurately extract features from hyperspectral images (HSIs). These algorithms
perform exceptionally well on HSIs change detection (HSIs-CD). However, the
downside of these impressive results is the enormous number of parameters,
FLOPs, GPU memory, training and test times required. In this paper, we propose
an spectral Kolmogorov-Arnold Network for HSIs-CD (SpectralKAN). SpectralKAN
represent a multivariate continuous function with a composition of activation
functions to extract HSIs feature and classification. These activation
functions are b-spline functions with different parameters that can simulate
various functions. In SpectralKAN, a KAN encoder is proposed to enhance
computational efficiency for HSIs. And a spatial-spectral KAN encoder is
introduced, where the spatial KAN encoder extracts spatial features and
compresses the spatial dimensions from patch size to one. The spectral KAN
encoder then extracts spectral features and classifies them into changed and
unchanged categories. We use five HSIs-CD datasets to verify the effectiveness
of SpectralKAN. Experimental verification has shown that SpectralKAN maintains
high HSIs-CD accuracy while requiring fewer parameters, FLOPs, GPU memory,
training and testing times, thereby increasing the efficiency of HSIs-CD. The
code will be available at https://github.com/yanhengwang-heu/SpectralKAN.
","Yanheng Wang, Xiaohan Yu, Yongsheng Gao, Jianjun Sha, Jian Wang, Lianru Gao, Yonggang Zhang, Xianhui Rong",Xianhui Rong,2024-07-01T04:09:24Z
"Pan-denoising: Guided Hyperspectral Image Denoising via Weighted
  Represent Coefficient Total Variation","  This paper introduces a novel paradigm for hyperspectral image (HSI)
denoising, which is termed \textit{pan-denoising}. In a given scene,
panchromatic (PAN) images capture similar structures and textures to HSIs but
with less noise. This enables the utilization of PAN images to guide the HSI
denoising process. Consequently, pan-denoising, which incorporates an
additional prior, has the potential to uncover underlying structures and
details beyond the internal information modeling of traditional HSI denoising
methods. However, the proper modeling of this additional prior poses a
significant challenge. To alleviate this issue, the paper proposes a novel
regularization term, Panchromatic Weighted Representation Coefficient Total
Variation (PWRCTV). It employs the gradient maps of PAN images to automatically
assign different weights of TV regularization for each pixel, resulting in
larger weights for smooth areas and smaller weights for edges. This
regularization forms the basis of a pan-denoising model, which is solved using
the Alternating Direction Method of Multipliers. Extensive experiments on
synthetic and real-world datasets demonstrate that PWRCTV outperforms several
state-of-the-art methods in terms of metrics and visual quality. Furthermore,
an HSI classification experiment confirms that PWRCTV, as a preprocessing
method, can enhance the performance of downstream classification tasks. The
code and data are available at https://github.com/shuangxu96/PWRCTV.
","Shuang Xu, Qiao Ke, Jiangjun Peng, Xiangyong Cao, Zixiang Zhao",Zixiang Zhao,2024-07-08T16:05:56Z
"HTD-Mamba: Efficient Hyperspectral Target Detection with Pyramid State
  Space Model","  Hyperspectral target detection (HTD) identifies objects of interest from
complex backgrounds at the pixel level, playing a vital role in Earth
observation. However, HTD faces challenges due to limited prior knowledge and
spectral variation, leading to underfitting models and unreliable performance.
To address these challenges, this paper proposes an efficient self-supervised
HTD method with a pyramid state space model (SSM), named HTD-Mamba, which
employs spectrally contrastive learning to distinguish between target and
background based on the similarity measurement of intrinsic features.
Specifically, to obtain sufficient training samples and leverage spatial
contextual information, we propose a spatial-encoded spectral augmentation
technique that encodes all surrounding pixels within a patch into a transformed
view of the center pixel. Additionally, to explore global band correlations, we
divide pixels into continuous group-wise spectral embeddings and introduce
Mamba to HTD for the first time to model long-range dependencies of the
spectral sequence with linear complexity. Furthermore, to alleviate spectral
variation and enhance robust representation, we propose a pyramid SSM as a
backbone to capture and fuse multiresolution spectral-wise intrinsic features.
Extensive experiments conducted on four public datasets demonstrate that the
proposed method outperforms state-of-the-art methods in both quantitative and
qualitative evaluations. Code is available at
\url{https://github.com/shendb2022/HTD-Mamba}.
","Dunbin Shen, Xuanbing Zhu, Jiacheng Tian, Jianjun Liu, Zhenrong Du, Hongyu Wang, Xiaorui Ma",Xiaorui Ma,2024-07-09T13:21:26Z
"PRIME: Blind Multispectral Unmixing Using Virtual Quantum Prism and
  Convex Geometry","  Multispectral unmixing (MU) is critical due to the inevitable mixed pixel
phenomenon caused by the limited spatial resolution of typical multispectral
images in remote sensing. However, MU mathematically corresponds to the
underdetermined blind source separation problem, thus highly challenging,
preventing researchers from tackling it. Previous MU works all ignore the
underdetermined issue, and merely consider scenarios with more bands than
sources. This work attempts to resolve the underdetermined issue by further
conducting the light-splitting task using a network-inspired virtual prism, and
as this task is challenging, we achieve so by incorporating the very advanced
quantum feature extraction techniques. We emphasize that the prism is virtual
(allowing us to fix the spectral response as a simple deterministic matrix), so
the virtual hyperspectral image (HSI) it generates has no need to correspond to
some real hyperspectral sensor; in other words, it is good enough as long as
the virtual HSI satisfies some fundamental properties of light splitting (e.g.,
non-negativity and continuity). With the above virtual quantum prism, we know
that the virtual HSI is expected to possess some desired simplex structure.
This allows us to adopt the convex geometry to unmix the spectra, followed by
downsampling the pure spectra back to the multispectral domain, thereby
achieving MU. Experimental evidence shows great potential of our MU algorithm,
termed as prism-inspired multispectral endmember extraction (PRIME).
","Chia-Hsiang Lin, Jhao-Ting Lin",Jhao-Ting Lin,2024-07-22T03:58:24Z
"Spatial-Spectral Morphological Mamba for Hyperspectral Image
  Classification","  In recent years, the emergence of Transformers with self-attention mechanism
has revolutionized the hyperspectral image (HSI) classification. However, these
models face major challenges in computational efficiency, as their complexity
increases quadratically with the sequence length. The Mamba architecture,
leveraging a state space model (SSM), offers a more efficient alternative to
Transformers. This paper introduces the Spatial-Spectral Morphological Mamba
(MorpMamba) model in which, a token generation module first converts the HSI
patch into spatial-spectral tokens. These tokens are then processed by
morphological operations, which compute structural and shape information using
depthwise separable convolutional operations. The extracted information is
enhanced in a feature enhancement module that adjusts the spatial and spectral
tokens based on the center region of the HSI sample, allowing for effective
information fusion within each block. Subsequently, the tokens are refined
through a multi-head self-attention which further improves the feature space.
Finally, the combined information is fed into the state space block for
classification and the creation of the ground truth map. Experiments on widely
used HSI datasets demonstrate that the MorpMamba model outperforms (parametric
efficiency) both CNN and Transformer models. The source code will be made
publicly available at \url{https://github.com/MHassaanButt/MorpMamba}.
","Muhammad Ahmad, Muhammad Hassaan Farooq Butt, Muhammad Usama, Adil Mehmood Khan, Manuel Mazzara, Salvatore Distefano, Hamad Ahmed Altuwaijri, Swalpa Kumar Roy, Jocelyn Chanussot, Danfeng Hong",Danfeng Hong,2024-08-02T16:28:51Z
"3D-RCNet: Learning from Transformer to Build a 3D Relational ConvNet for
  Hyperspectral Image Classification","  Recently, the Vision Transformer (ViT) model has replaced the classical
Convolutional Neural Network (ConvNet) in various computer vision tasks due to
its superior performance. Even in hyperspectral image (HSI) classification
field, ViT-based methods also show promising potential. Nevertheless, ViT
encounters notable difficulties in processing HSI data. Its self-attention
mechanism, which exhibits quadratic complexity, escalates computational costs.
Additionally, ViT's substantial demand for training samples does not align with
the practical constraints posed by the expensive labeling of HSI data. To
overcome these challenges, we propose a 3D relational ConvNet named 3D-RCNet,
which inherits both strengths of ConvNet and ViT, resulting in high performance
in HSI classification. We embed the self-attention mechanism of Transformer
into the convolutional operation of ConvNet to design 3D relational
convolutional operation and use it to build the final 3D-RCNet. The proposed
3D-RCNet maintains the high computational efficiency of ConvNet while enjoying
the flexibility of ViT. Additionally, the proposed 3D relational convolutional
operation is a plug-and-play operation, which can be inserted into previous
ConvNet-based HSI classification methods seamlessly. Empirical evaluations on
three representative benchmark HSI datasets show that the proposed model
outperforms previous ConvNet-based and ViT-based HSI approaches.
","Haizhao Jing, Liuwei Wan, Xizhe Xue, Haokui Zhang, Ying Li",Ying Li,2024-08-25T05:41:47Z
"S4DL: Shift-sensitive Spatial-Spectral Disentangling Learning for
  Hyperspectral Image Unsupervised Domain Adaptation","  Unsupervised domain adaptation techniques, extensively studied in
hyperspectral image (HSI) classification, aim to use labeled source domain data
and unlabeled target domain data to learn domain invariant features for
cross-scene classification. Compared to natural images, numerous spectral bands
of HSIs provide abundant semantic information, but they also increase the
domain shift significantly. In most existing methods, both explicit alignment
and implicit alignment simply align feature distribution, ignoring domain
information in the spectrum. We noted that when the spectral channel between
source and target domains is distinguished obviously, the transfer performance
of these methods tends to deteriorate. Additionally, their performance
fluctuates greatly owing to the varying domain shifts across various datasets.
To address these problems, a novel shift-sensitive spatial-spectral
disentangling learning (S4DL) approach is proposed. In S4DL, gradient-guided
spatial-spectral decomposition is designed to separate domain-specific and
domain-invariant representations by generating tailored masks under the
guidance of the gradient from domain classification. A shift-sensitive adaptive
monitor is defined to adjust the intensity of disentangling according to the
magnitude of domain shift. Furthermore, a reversible neural network is
constructed to retain domain information that lies in not only in semantic but
also the shallow-level detailed information. Extensive experimental results on
several cross-scene HSI datasets consistently verified that S4DL is better than
the state-of-the-art UDA methods. Our source code will be available at
https://github.com/xdu-jjgs/S4DL.
","Jie Feng, Tianshu Zhang, Junpeng Zhang, Ronghua Shang, Weisheng Dong, Guangming Shi, Licheng Jiao",Licheng Jiao,2024-08-11T15:58:24Z
"Handling Geometric Domain Shifts in Semantic Segmentation of Surgical
  RGB and Hyperspectral Images","  Robust semantic segmentation of intraoperative image data holds promise for
enabling automatic surgical scene understanding and autonomous robotic surgery.
While model development and validation are primarily conducted on idealistic
scenes, geometric domain shifts, such as occlusions of the situs, are common in
real-world open surgeries. To close this gap, we (1) present the first analysis
of state-of-the-art (SOA) semantic segmentation models when faced with
geometric out-of-distribution (OOD) data, and (2) propose an augmentation
technique called ""Organ Transplantation"", to enhance generalizability. Our
comprehensive validation on six different OOD datasets, comprising 600 RGB and
hyperspectral imaging (HSI) cubes from 33 pigs, each annotated with 19 classes,
reveals a large performance drop in SOA organ segmentation models on geometric
OOD data. This performance decline is observed not only in conventional RGB
data (with a dice similarity coefficient (DSC) drop of 46 %) but also in HSI
data (with a DSC drop of 45 %), despite the richer spectral information
content. The performance decline increases with the spatial granularity of the
input data. Our augmentation technique improves SOA model performance by up to
67 % for RGB data and 90 % for HSI data, achieving performance at the level of
in-distribution performance on real OOD test data. Given the simplicity and
effectiveness of our augmentation method, it is a valuable tool for addressing
geometric domain shifts in surgical scene segmentation, regardless of the
underlying model. Our code and pre-trained models are publicly available at
https://github.com/IMSY-DKFZ/htc.
","Silvia Seidlitz, Jan Sellner, Alexander Studier-Fischer, Alessandro Motta, Berkin Özdemir, Beat P. Müller-Stich, Felix Nickel, Lena Maier-Hein",Lena Maier-Hein,2024-08-27T19:13:15Z
"Spatial-Aware Conformal Prediction for Trustworthy Hyperspectral Image
  Classification","  Hyperspectral image (HSI) classification involves assigning unique labels to
each pixel to identify various land cover categories. While deep classifiers
have achieved high predictive accuracy in this field, they lack the ability to
rigorously quantify confidence in their predictions. Quantifying the certainty
of model predictions is crucial for the safe usage of predictive models, and
this limitation restricts their application in critical contexts where the cost
of prediction errors is significant. To support the safe deployment of HSI
classifiers, we first provide a theoretical proof establishing the validity of
the emerging uncertainty quantification technique, conformal prediction, in the
context of HSI classification. We then propose a conformal procedure that
equips any trained HSI classifier with trustworthy prediction sets, ensuring
that these sets include the true labels with a user-specified probability
(e.g., 95\%). Building on this foundation, we introduce Spatial-Aware Conformal
Prediction (\texttt{SACP}), a conformal prediction framework specifically
designed for HSI data. This method integrates essential spatial information
inherent in HSIs by aggregating the non-conformity scores of pixels with high
spatial correlation, which effectively enhances the efficiency of prediction
sets. Both theoretical and empirical results validate the effectiveness of our
proposed approach. The source code is available at
\url{https://github.com/J4ckLiu/SACP}.
","Kangdao Liu, Tianhao Sun, Hao Zeng, Yongshan Zhang, Chi-Man Pun, Chi-Man Vong",Chi-Man Vong,2024-09-02T13:11:38Z
Test-time Training for Hyperspectral Image Super-resolution,"  The progress on Hyperspectral image (HSI) super-resolution (SR) is still
lagging behind the research of RGB image SR. HSIs usually have a high number of
spectral bands, so accurately modeling spectral band interaction for HSI SR is
hard. Also, training data for HSI SR is hard to obtain so the dataset is
usually rather small. In this work, we propose a new test-time training method
to tackle this problem. Specifically, a novel self-training framework is
developed, where more accurate pseudo-labels and more accurate LR-HR
relationships are generated so that the model can be further trained with them
to improve performance. In order to better support our test-time training
method, we also propose a new network architecture to learn HSI SR without
modeling spectral band interaction and propose a new data augmentation method
Spectral Mixup to increase the diversity of the training data at test time. We
also collect a new HSI dataset with a diverse set of images of interesting
objects ranging from food to vegetation, to materials, and to general scenes.
Extensive experiments on multiple datasets show that our method can improve the
performance of pre-trained models significantly after test-time training and
outperform competing methods significantly for HSI SR.
","Ke Li, Luc Van Gool, Dengxin Dai",Dengxin Dai,2024-09-13T09:30:19Z
"A Deep Learning Approach for Pixel-level Material Classification via
  Hyperspectral Imaging","  Recent advancements in computer vision, particularly in detection,
segmentation, and classification, have significantly impacted various domains.
However, these advancements are tied to RGB-based systems, which are
insufficient for applications in industries like waste sorting,
pharmaceuticals, and defense, where advanced object characterization beyond
shape or color is necessary. Hyperspectral (HS) imaging, capturing both
spectral and spatial information, addresses these limitations and offers
advantages over conventional technologies such as X-ray fluorescence and Raman
spectroscopy, particularly in terms of speed, cost, and safety.
  This study evaluates the potential of combining HS imaging with deep learning
for material characterization. The research involves: i) designing an
experimental setup with HS camera, conveyor, and controlled lighting; ii)
generating a multi-object dataset of various plastics (HDPE, PET, PP, PS) with
semi-automated mask generation and Raman spectroscopy-based labeling; and iii)
developing a deep learning model trained on HS images for pixel-level material
classification. The model achieved 99.94\% classification accuracy,
demonstrating robustness in color, size, and shape invariance, and effectively
handling material overlap. Limitations, such as challenges with black objects,
are also discussed. Extending computer vision beyond RGB to HS imaging proves
feasible, overcoming major limitations of traditional methods and showing
strong potential for future applications.
","Savvas Sifnaios, George Arvanitakis, Fotios K. Konstantinidis, Georgios Tsimiklis, Angelos Amditis, Panayiotis Frangos",Panayiotis Frangos,2024-09-20T13:38:48Z
"Enhancing Hyperspectral Image Prediction with Contrastive Learning in
  Low-Label Regime","  Self-supervised contrastive learning is an effective approach for addressing
the challenge of limited labelled data. This study builds upon the previously
established two-stage patch-level, multi-label classification method for
hyperspectral remote sensing imagery. We evaluate the method's performance for
both the single-label and multi-label classification tasks, particularly under
scenarios of limited training data. The methodology unfolds in two stages.
Initially, we focus on training an encoder and a projection network using a
contrastive learning approach. This step is crucial for enhancing the ability
of the encoder to discern patterns within the unlabelled data. Next, we employ
the pre-trained encoder to guide the training of two distinct predictors: one
for multi-label and another for single-label classification. Empirical results
on four public datasets show that the predictors trained with our method
perform better than those trained under fully supervised techniques. Notably,
the performance is maintained even when the amount of training data is reduced
by $50\%$. This advantage is consistent across both tasks. The method's
effectiveness comes from its streamlined architecture. This design allows for
retraining the encoder along with the predictor. As a result, the encoder
becomes more adaptable to the features identified by the classifier, improving
the overall classification performance. Qualitative analysis reveals the
contrastive-learning-based encoder's capability to provide representations that
allow separation among classes and identify location-based features despite not
being explicitly trained for that. This observation indicates the method's
potential in uncovering implicit spatial information within the data.
","Salma Haidar, José Oramas",José Oramas,2024-10-10T10:20:16Z
"Cassini/VIMS hyperspectral observations of the HUYGENS landing site on
  Titan","  Titan is one of the primary scientific objectives of the NASA ESA ASI Cassini
Huygens mission. Scattering by haze particles in Titan's atmosphere and
numerous methane absorptions dramatically veil Titan's surface in the visible
range, though it can be studied more easily in some narrow infrared windows.
The Visual and Infrared Mapping Spectrometer (VIMS) instrument onboard the
Cassini spacecraft successfully imaged its surface in the atmospheric windows,
taking hyperspectral images in the range 0.4 5.2 ?m. On 26 October (TA flyby)
and 13 December 2004 (TB flyby), the Cassini Huygens mission flew over Titan at
an altitude lower than 1200 km at closest approach. We report here on the
analysis of VIMS images of the Huygens landing site acquired at TA and TB, with
a spatial resolution ranging from 16 to14.4 km/pixel. The pure atmospheric
backscattering component is corrected by using both an empirical method and a
first-order theoretical model. Both approaches provide consistent results.
After the removal of scattering, ratio images reveal subtle surface
heterogeneities. A particularly contrasted structure appears in ratio images
involving the 1.59 and 2.03 ?m images north of the Huygens landing site.
Although pure water ice cannot be the only component exposed at Titan's
surface, this area is consistent with a local enrichment in exposed water ice
and seems to be consistent with DISR/Huygens images and spectra
interpretations. The images show also a morphological structure that can be
interpreted as a 150 km diameter impact crater with a central peak.
","S. Rodriguez, S. Le Mouélic, C. Sotin, H. Clénet, R. N. Clark, B. Buratti, R. H. Brown, T. B. Mccord, P. D. Nicholson, K. H. Baines",K. H. Baines,2009-06-30T11:10:35Z
"Aerial hyperspectral imagery and deep neural networks for
  high-throughput yield phenotyping in wheat","  Crop production needs to increase in a sustainable manner to meet the growing
global demand for food. To identify crop varieties with high yield potential,
plant scientists and breeders evaluate the performance of hundreds of lines in
multiple locations over several years. To facilitate the process of selecting
advanced varieties, an automated framework was developed in this study. A
hyperspectral camera was mounted on an unmanned aerial vehicle to collect
aerial imagery with high spatial and spectral resolution. Aerial images were
captured in two consecutive growing seasons from three experimental yield
fields composed of hundreds experimental plots (1x2.4 meter), each contained a
single wheat line. The grain of more than thousand wheat plots was harvested by
a combine, weighed, and recorded as the ground truth data. To leverage the high
spatial resolution and investigate the yield variation within the plots, images
of plots were divided into sub-plots by integrating image processing techniques
and spectral mixture analysis with the expert domain knowledge. Afterwards, the
sub-plot dataset was divided into train, validation, and test sets using
stratified sampling. Subsequent to extracting features from each sub-plot, deep
neural networks were trained for yield estimation. The coefficient of
determination for predicting the yield of the test dataset at sub-plot scale
was 0.79 with root mean square error of 5.90 grams. In addition to providing
insights into yield variation at sub-plot scale, the proposed framework can
facilitate the process of high-throughput yield phenotyping as a valuable
decision support tool. It offers the possibility of (i) remote visual
inspection of the plots, (ii) studying the effect of crop density on yield, and
(iii) optimizing plot size to investigate more lines in a dedicated field each
year.
","Ali Moghimi, Ce Yang, James A. Anderson",James A. Anderson,2019-06-23T22:48:08Z
Naive Gabor Networks for Hyperspectral Image Classification,"  Recently, many convolutional neural network (CNN) methods have been designed
for hyperspectral image (HSI) classification since CNNs are able to produce
good representations of data, which greatly benefits from a huge number of
parameters. However, solving such a high-dimensional optimization problem often
requires a large amount of training samples in order to avoid overfitting.
Additionally, it is a typical non-convex problem affected by many local minima
and flat regions. To address these problems, in this paper, we introduce naive
Gabor Networks or Gabor-Nets which, for the first time in the literature,
design and learn CNN kernels strictly in the form of Gabor filters, aiming to
reduce the number of involved parameters and constrain the solution space, and
hence improve the performances of CNNs. Specifically, we develop an innovative
phase-induced Gabor kernel, which is trickily designed to perform the Gabor
feature learning via a linear combination of local low-frequency and
high-frequency components of data controlled by the kernel phase. With the
phase-induced Gabor kernel, the proposed Gabor-Nets gains the ability to
automatically adapt to the local harmonic characteristics of the HSI data and
thus yields more representative harmonic features. Also, this kernel can
fulfill the traditional complex-valued Gabor filtering in a real-valued manner,
hence making Gabor-Nets easily perform in a usual CNN thread. We evaluated our
newly developed Gabor-Nets on three well-known HSIs, suggesting that our
proposed Gabor-Nets can significantly improve the performance of CNNs,
particularly with a small training set.
","Chenying Liu, Jun Li, Lin He, Antonio J. Plaza, Shutao Li, Bo Li",Bo Li,2019-12-09T12:16:48Z
"FPGA: Fast Patch-Free Global Learning Framework for Fully End-to-End
  Hyperspectral Image Classification","  Deep learning techniques have provided significant improvements in
hyperspectral image (HSI) classification. The current deep learning based HSI
classifiers follow a patch-based learning framework by dividing the image into
overlapping patches. As such, these methods are local learning methods, which
have a high computational cost. In this paper, a fast patch-free global
learning (FPGA) framework is proposed for HSI classification. In FPGA, an
encoder-decoder based FCN is utilized to consider the global spatial
information by processing the whole image, which results in fast inference.
However, it is difficult to directly utilize the encoder-decoder based FCN for
HSI classification as it always fails to converge due to the insufficiently
diverse gradients caused by the limited training samples. To solve the
divergence problem and maintain the abilities of FCN of fast inference and
global spatial information mining, a global stochastic stratified sampling
strategy is first proposed by transforming all the training samples into a
stochastic sequence of stratified samples. This strategy can obtain diverse
gradients to guarantee the convergence of the FCN in the FPGA framework. For a
better design of FCN architecture, FreeNet, which is a fully end-to-end network
for HSI classification, is proposed to maximize the exploitation of the global
spatial information and boost the performance via a spectral attention based
encoder and a lightweight decoder. A lateral connection module is also designed
to connect the encoder and decoder, fusing the spatial details in the encoder
and the semantic features in the decoder. The experimental results obtained
using three public benchmark datasets suggest that the FPGA framework is
superior to the patch-based framework in both speed and accuracy for HSI
classification. Code has been made available at:
https://github.com/Z-Zheng/FreeNet.
","Zhuo Zheng, Yanfei Zhong, Ailong Ma, Liangpei Zhang",Liangpei Zhang,2020-11-11T09:59:48Z
"Hyperspectral Denoising Using Unsupervised Disentangled Spatio-Spectral
  Deep Priors","  Image denoising is often empowered by accurate prior information. In recent
years, data-driven neural network priors have shown promising performance for
RGB natural image denoising. Compared to classic handcrafted priors (e.g.,
sparsity and total variation), the ""deep priors"" are learned using a large
number of training samples -- which can accurately model the complex image
generating process. However, data-driven priors are hard to acquire for
hyperspectral images (HSIs) due to the lack of training data. A remedy is to
use the so-called unsupervised deep image prior (DIP). Under the unsupervised
DIP framework, it is hypothesized and empirically demonstrated that proper
neural network structures are reasonable priors of certain types of images, and
the network weights can be learned without training data. Nonetheless, the most
effective unsupervised DIP structures were proposed for natural images instead
of HSIs. The performance of unsupervised DIP-based HSI denoising is limited by
a couple of serious challenges, namely, network structure design and network
complexity. This work puts forth an unsupervised DIP framework that is based on
the classic spatio-spectral decomposition of HSIs. Utilizing the so-called
linear mixture model of HSIs, two types of unsupervised DIPs, i.e., U-Net-like
network and fully-connected networks, are employed to model the abundance maps
and endmembers contained in the HSIs, respectively. This way, empirically
validated unsupervised DIP structures for natural images can be easily
incorporated for HSI denoising. Besides, the decomposition also substantially
reduces network complexity. An efficient alternating optimization algorithm is
proposed to handle the formulated denoising problem. Semi-real and real data
experiments are employed to showcase the effectiveness of the proposed
approach.
","Yu-Chun Miao, Xi-Le Zhao, Xiao Fu, Jian-Li Wang, Yu-Bang Zheng",Yu-Bang Zheng,2021-02-24T14:38:51Z
"Machine learning-based analysis of hyperspectral images for automated
  sepsis diagnosis","  Sepsis is a leading cause of mortality and critical illness worldwide. While
robust biomarkers for early diagnosis are still missing, recent work indicates
that hyperspectral imaging (HSI) has the potential to overcome this bottleneck
by monitoring microcirculatory alterations. Automated machine learning-based
diagnosis of sepsis based on HSI data, however, has not been explored to date.
Given this gap in the literature, we leveraged an existing data set to (1)
investigate whether HSI-based automated diagnosis of sepsis is possible and (2)
put forth a list of possible confounders relevant for HSI-based tissue
classification. While we were able to classify sepsis with an accuracy of over
$98\,\%$ using the existing data, our research also revealed several subject-,
therapy- and imaging-related confounders that may lead to an overestimation of
algorithm performance when not balanced across the patient groups. We conclude
that further prospective studies, carefully designed with respect to these
confounders, are necessary to confirm the preliminary results obtained in this
study.
","Maximilian Dietrich, Silvia Seidlitz, Nicholas Schreck, Manuel Wiesenfarth, Patrick Godau, Minu Tizabi, Jan Sellner, Sebastian Marx, Samuel Knödler, Michael M. Allers, Leonardo Ayala, Karsten Schmidt, Thorsten Brenner, Alexander Studier-Fischer, Felix Nickel, Beat P. Müller-Stich, Annette Kopp-Schneider, Markus A. Weigand, Lena Maier-Hein",Lena Maier-Hein,2021-06-15T21:33:59Z
"Estimation of Tissue Oxygen Saturation from RGB images and Sparse
  Hyperspectral Signals based on Conditional Generative Adversarial Network","  Purpose: Intra-operative measurement of tissue oxygen saturation (StO2) is
important in the detection of ischemia, monitoring perfusion and identifying
disease. Hyperspectral imaging (HSI) measures the optical reflectance spectrum
of the tissue and uses this information to quantify its composition, including
StO2. However, real-time monitoring is difficult due to the capture rate and
data processing time. Methods: An endoscopic system based on a multi-fiber
probe was previously developed to sparsely capture HSI data (sHSI). These were
combined with RGB images, via a deep neural network, to generate
high-resolution hypercubes and calculate StO2. To improve accuracy and
processing speed, we propose a dual-input conditional generative adversarial
network (cGAN), Dual2StO2, to directly estimate StO2 by fusing features from
both RGB and sHSI. Results: Validation experiments were carried out on in vivo
porcine bowel data, where the ground truth StO2 was generated from the HSI
camera. The performance was also compared to our previous
super-spectral-resolution network, SSRNet in terms of mean StO2 prediction
accuracy and structural similarity metrics. Dual2StO2 was also tested using
simulated probe data with varying fiber number. Conclusions: StO2 estimation by
Dual2StO2 is visually closer to ground truth in general structure, achieves
higher prediction accuracy and faster processing speed than SSRNet. Simulations
showed that results improved when a greater number of fibers are used in the
probe. Future work will include refinement of the network architecture,
hardware optimization based on simulation results, and evaluation of the
technique in clinical applications beyond StO2 estimation.
","Qingbiao Li, Jianyu Lin, Neil T. Clancy, Daniel S. Elson",Daniel S. Elson,2019-05-01T17:25:01Z
Graph Convolutional Networks for Hyperspectral Image Classification,"  To read the final version please go to IEEE TGRS on IEEE Xplore.
Convolutional neural networks (CNNs) have been attracting increasing attention
in hyperspectral (HS) image classification, owing to their ability to capture
spatial-spectral feature representations. Nevertheless, their ability in
modeling relations between samples remains limited. Beyond the limitations of
grid sampling, graph convolutional networks (GCNs) have been recently proposed
and successfully applied in irregular (or non-grid) data representation and
analysis. In this paper, we thoroughly investigate CNNs and GCNs (qualitatively
and quantitatively) in terms of HS image classification. Due to the
construction of the adjacency matrix on all the data, traditional GCNs usually
suffer from a huge computational cost, particularly in large-scale remote
sensing (RS) problems. To this end, we develop a new mini-batch GCN (called
miniGCN hereinafter) which allows to train large-scale GCNs in a mini-batch
fashion. More significantly, our miniGCN is capable of inferring out-of-sample
data without re-training networks and improving classification performance.
Furthermore, as CNNs and GCNs can extract different types of HS features, an
intuitive solution to break the performance bottleneck of a single model is to
fuse them. Since miniGCNs can perform batch-wise network training (enabling the
combination of CNNs and GCNs) we explore three fusion strategies: additive
fusion, element-wise multiplicative fusion, and concatenation fusion to measure
the obtained performance gain. Extensive experiments, conducted on three HS
datasets, demonstrate the advantages of miniGCNs over GCNs and the superiority
of the tested fusion strategies with regards to the single CNN or GCN models.
The codes of this work will be available at
https://github.com/danfenghong/IEEE_TGRS_GCN for the sake of reproducibility.
","Danfeng Hong, Lianru Gao, Jing Yao, Bing Zhang, Antonio Plaza, Jocelyn Chanussot",Jocelyn Chanussot,2020-08-06T05:01:25Z
"A Biologically Interpretable Two-stage Deep Neural Network (BIT-DNN) For
  Vegetation Recognition From Hyperspectral Imagery","  Spectral-spatial based deep learning models have recently proven to be
effective in hyperspectral image (HSI) classification for various earth
monitoring applications such as land cover classification and agricultural
monitoring. However, due to the nature of ""black-box"" model representation, how
to explain and interpret the learning process and the model decision,
especially for vegetation classification, remains an open challenge. This study
proposes a novel interpretable deep learning model -- a biologically
interpretable two-stage deep neural network (BIT-DNN), by incorporating the
prior-knowledge (i.e. biophysical and biochemical attributes and their
hierarchical structures of target entities) based spectral-spatial feature
transformation into the proposed framework, capable of achieving both high
accuracy and interpretability on HSI based classification tasks. The proposed
model introduces a two-stage feature learning process: in the first stage, an
enhanced interpretable feature block extracts the low-level spectral features
associated with the biophysical and biochemical attributes of target entities;
and in the second stage, an interpretable capsule block extracts and
encapsulates the high-level joint spectral-spatial features representing the
hierarchical structure of biophysical and biochemical attributes of these
target entities, which provides the model an improved performance on
classification and intrinsic interpretability with reduced computational
complexity. We have tested and evaluated the model using four real HSI datasets
for four separate tasks (i.e. plant species classification, land cover
classification, urban scene recognition, and crop disease recognition tasks).
The proposed model has been compared with five state-of-the-art deep learning
models.
","Yue Shi, Liangxiu Han, Wenjiang Huang, Sheng Chang, Yingying Dong, Darren Dancey, Lianghao Han",Lianghao Han,2020-04-19T15:58:19Z
"Uncertainty Quantification for Hyperspectral Image Denoising Frameworks
  based on Low-rank Matrix Approximation","  Sliding-window based low-rank matrix approximation (LRMA) is a technique
widely used in hyperspectral images (HSIs) denoising or completion. However,
the uncertainty quantification of the restored HSI has not been addressed to
date. Accurate uncertainty quantification of the denoised HSI facilitates to
applications such as multi-source or multi-scale data fusion, data
assimilation, and product uncertainty quantification, since these applications
require an accurate approach to describe the statistical distributions of the
input data. Therefore, we propose a prior-free closed-form element-wise
uncertainty quantification method for LRMA-based HSI restoration. Our
closed-form algorithm overcomes the difficulty of the HSI patch mixing problem
caused by the sliding-window strategy used in the conventional LRMA process.
The proposed approach only requires the uncertainty of the observed HSI and
provides the uncertainty result relatively rapidly and with similar
computational complexity as the LRMA technique. We conduct extensive
experiments to validate the estimation accuracy of the proposed closed-form
uncertainty approach. The method is robust to at least 10% random impulse noise
at the cost of 10-20% of additional processing time compared to the LRMA. The
experiments indicate that the proposed closed-form uncertainty quantification
method is more applicable to real-world applications than the baseline Monte
Carlo test, which is computationally expensive. The code is available in the
attachment and will be released after the acceptance of this paper.
","Jingwei Song, Shaobo Xia, Jun Wang, Mitesh Patel, Dong Chen",Dong Chen,2020-04-23T03:56:30Z
"Retrieval of aboveground crop nitrogen content with a hybrid machine
  learning method","  Hyperspectral acquisitions have proven to be the most informative Earth
observation data source for the estimation of nitrogen (N) content, which is
the main limiting nutrient for plant growth and thus agricultural production.
In the past, empirical algorithms have been widely employed to retrieve
information on this biochemical plant component from canopy reflectance.
However, these approaches do not seek for a cause-effect relationship based on
physical laws. Moreover, most studies solely relied on the correlation of
chlorophyll content with nitrogen, and thus neglected the fact that most N is
bound in proteins. Our study presents a hybrid retrieval method using a
physically-based approach combined with machine learning regression to estimate
crop N content. Within the workflow, the leaf optical properties model
PROSPECT-PRO including the newly calibrated specific absorption coefficients
(SAC) of proteins, was coupled with the canopy reflectance model 4SAIL to
PROSAIL-PRO. The latter was then employed to generate a training database to be
used for advanced probabilistic machine learning methods: a standard
homoscedastic Gaussian process (GP) and a heteroscedastic GP regression that
accounts for signal-to-noise relations. Both GP models have the property of
providing confidence intervals for the estimates, which sets them apart from
other machine learners. GP-based band analysis identified optimal spectral
settings with ten bands mainly situated in the shortwave infrared (SWIR)
spectral region. Use of well-known protein absorption bands from the literature
showed comparative results. Finally, the heteroscedastic GP model was
successfully applied on airborne hyperspectral data for N mapping. We conclude
that GP algorithms, and in particular the heteroscedastic GP, should be
implemented for global agricultural monitoring of aboveground N from future
imaging spectroscopy data.
","Katja Berger, Jochem Verrelst, Jean-Baptiste Féret, Tobias Hank, Matthias Wocher, Wolfram Mauser, Gustau Camps-Valls",Gustau Camps-Valls,2020-12-07T13:06:59Z
"Hyperspectral Image Classification-Traditional to Deep Models: A Survey
  for Future Prospects","  Hyperspectral Imaging (HSI) has been extensively utilized in many real-life
applications because it benefits from the detailed spectral information
contained in each pixel. Notably, the complex characteristics i.e., the
nonlinear relation among the captured spectral information and the
corresponding object of HSI data make accurate classification challenging for
traditional methods. In the last few years, Deep Learning (DL) has been
substantiated as a powerful feature extractor that effectively addresses the
nonlinear problems that appeared in a number of computer vision tasks. This
prompts the deployment of DL for HSI classification (HSIC) which revealed good
performance. This survey enlists a systematic overview of DL for HSIC and
compared state-of-the-art strategies on the said topic. Primarily, we will
encapsulate the main challenges of traditional machine learning for HSIC and
then we will acquaint the superiority of DL to address these problems. This
survey breakdown the state-of-the-art DL frameworks into spectral features,
spatial features, and together spatial-spectral features to systematically
analyze the achievements (future research directions as well) of these
frameworks for HSIC. Moreover, we will consider the fact that DL requires a
large number of labeled training examples whereas acquiring such a number for
HSIC is challenging in terms of time and cost. Therefore, this survey discusses
some strategies to improve the generalization performance of DL strategies
which can provide some future guidelines.
","Muhammad Ahmad, Sidrah Shabbir, Swalpa Kumar Roy, Danfeng Hong, Xin Wu, Jing Yao, Adil Mehmood Khan, Manuel Mazzara, Salvatore Distefano, Jocelyn Chanussot",Jocelyn Chanussot,2021-01-15T13:59:22Z
"A Simple and Efficient Reconstruction Backbone for Snapshot Compressive
  Imaging","  The emerging technology of snapshot compressive imaging (SCI) enables
capturing high dimensional (HD) data in an efficient way. It is generally
implemented by two components: an optical encoder that compresses HD signals
into a 2D measurement and an algorithm decoder that retrieves the HD data upon
the hardware-encoded measurement. Over a broad range of SCI applications,
hyperspectral imaging (HSI) and video compressive sensing have received
significant research attention in recent years. Among existing SCI
reconstruction algorithms, deep learning-based methods stand out as their
promising performance and efficient inference. However, the deep reconstruction
network may suffer from overlarge model size and highly-specialized network
design, which inevitably lead to costly training time, high memory usage, and
limited flexibility, thus discouraging the deployments of SCI systems in
practical scenarios. In this paper, we tackle the above challenges by proposing
a simple yet highly efficient reconstruction method, namely stacked residual
network (SRN), by revisiting the residual learning strategy with nested
structures and spatial-invariant property. The proposed SRN empowers
high-fidelity data retrieval with fewer computation operations and negligible
model size compared with existing networks, and also serves as a versatile
backbone applicable for both hyperspectral and video data. Based on the
proposed backbone, we first develop the channel attention enhanced SRN
(CAE-SRN) to explore the spectral inter-dependencies for fine-grained spatial
estimation in HSI. We then employ SRN as a deep denoiser and incorporate it
into a generalized alternating projection (GAP) framework -- resulting in
GAP-SRN -- to handle the video compressive sensing task. Experimental results
demonstrate the state-of-the-art performance, high computational efficiency of
the proposed SRN on two SCI applications.
","Jiamian Wang, Yulun Zhang, Xin Yuan, Yun Fu, Zhiqiang Tao",Zhiqiang Tao,2021-08-17T16:20:51Z
"In Situ Photothermal Response of Single Gold Nanoparticles Through
  Hyperspectral Imaging AntiStokes Thermometry","  Several fields of applications require a reliable characterization of the
photothermal response and heat dissipation of nanoscopic systems, which remains
a challenging task both for modeling and experimental measurements. Here, we
present a new implementation of anti-Stokes thermometry that enables the in
situ photothermal characterization of individual nanoparticles (NPs) from a
single hyperspectral photoluminescence confocal image. The method is
label-free, applicable to any NP with detectable anti-Stokes emission, and does
not require any prior information about the NP itself or the surrounding media.
With it, we first studied the photothermal response of spherical gold NPs of
different sizes on glass substrates, immersed in water, and found that heat
dissipation is mainly dominated by the water for NPs larger than 50 nm. Then,
the role of the substrate was studied by comparing the photothermal response of
80 nm gold NPs on glass with sapphire and graphene, two materials with high
thermal conductivity. For a given irradiance level, the NPs reach temperatures
18% lower on sapphire and 24% higher on graphene than on bare glass. The fact
that the presence of a highly conductive material such as graphene leads to a
poorer thermal dissipation demonstrates that interfacial thermal resistances
play a very significant role in nanoscopic systems, and emphasize the need for
in situ experimental thermometry techniques. The developed method will allow
addressing several open questions about the role of temperature in
plasmon-assisted applications, especially ones where NPs of arbitrary shapes
are present in complex matrixes and environments.
","Mariano Barella, Ianina L. Violi, Julian Gargiulo, Luciana P. Martinez, Florian Goschin, Victoria Guglielmotti, Diego Pallarola, Sebastian Schlücker, Mauricio Pilo-Pais, Guillermo P. Acuna, Stefan A. Maier, Emiliano Cortes, Fernando D. Stefani",Fernando D. Stefani,2021-08-24T21:01:28Z
"HPRN: Holistic Prior-embedded Relation Network for Spectral
  Super-Resolution","  Spectral super-resolution (SSR) refers to the hyperspectral image (HSI)
recovery from an RGB counterpart. Due to the one-to-many nature of the SSR
problem, a single RGB image can be reprojected to many HSIs. The key to tackle
this ill-posed problem is to plug into multi-source prior information such as
the natural spatial context-prior of RGB images, deep feature-prior or inherent
statistical-prior of HSIs, etc., so as to effectively alleviate the degree of
ill-posedness. However, most current approaches only consider the general and
limited priors in their customized convolutional neural networks (CNNs), which
leads to the inability to guarantee the confidence and fidelity of
reconstructed spectra. In this paper, we propose a novel holistic
prior-embedded relation network (HPRN) to integrate comprehensive priors to
regularize and optimize the solution space of SSR. Basically, the core
framework is delicately assembled by several multi-residual relation blocks
(MRBs) that fully facilitate the transmission and utilization of the
low-frequency content prior of RGBs. Innovatively, the semantic prior of RGB
inputs is introduced to mark category attributes, and a semantic-driven spatial
relation module (SSRM) is invented to perform the feature aggregation of
clustered similar range for refining recovered characteristics. Additionally,
we develop a transformer-based channel relation module (TCRM), which breaks the
habit of employing scalars as the descriptors of channel-wise relations in the
previous deep feature-prior, and replaces them with certain vectors to make the
mapping function more robust and smoother. In order to maintain the
mathematical correlation and spectral consistency between hyperspectral bands,
the second-order prior constraints (SOPC) are incorporated into the loss
function to guide the HSI reconstruction.
","Chaoxiong Wu, Jiaojiao Li, Rui Song, Yunsong Li, Qian Du",Qian Du,2021-12-29T15:43:20Z
"ESW Edge-Weights : Ensemble Stochastic Watershed Edge-Weights for
  Hyperspectral Image Classification","  Hyperspectral image (HSI) classification is a topic of active research. One
of the main challenges of HSI classification is the lack of reliable labelled
samples. Various semi-supervised and unsupervised classification methods are
proposed to handle the low number of labelled samples. Chief among them are
graph convolution networks (GCN) and their variants. These approaches exploit
the graph structure for semi-supervised and unsupervised classification. While
several of these methods implicitly construct edge-weights, to our knowledge,
not much work has been done to estimate the edge-weights explicitly. In this
article, we estimate the edge-weights explicitly and use them for the
downstream classification tasks - both semi-supervised and unsupervised. The
proposed edge-weights are based on two key insights - (a) Ensembles reduce the
variance and (b) Classes in HSI datasets and feature similarity have only
one-sided implications. That is, while same classes would have similar
features, similar features do not necessarily imply the same classes.
Exploiting these, we estimate the edge-weights using an aggregate of ensembles
of watersheds over subsamples of features. These edge weights are evaluated for
both semi-supervised and unsupervised classification tasks. The evaluation for
semi-supervised tasks uses Random-Walk based approach. For the unsupervised
case, we use a simple filter using a graph convolution network (GCN). In both
these cases, the proposed edge weights outperform the traditional approaches to
compute edge-weights - Euclidean distances and cosine similarities.
Fascinatingly, with the proposed edge-weights, the simplest GCN obtained
results comparable to the recent state-of-the-art.
","Rohan Agarwal, Aman Aziz, Aditya Suraj Krishnan, Aditya Challa, Sravan Danda",Sravan Danda,2022-02-28T01:53:22Z
"Efficient and Accurate Hyperspectral Pansharpening Using 3D VolumeNet
  and 2.5D Texture Transfer","  Recently, convolutional neural networks (CNN) have obtained promising results
in single-image SR for hyperspectral pansharpening. However, enhancing CNNs'
representation ability with fewer parameters and a shorter prediction time is a
challenging and critical task. In this paper, we propose a novel multi-spectral
image fusion method using a combination of the previously proposed 3D CNN model
VolumeNet and 2.5D texture transfer method using other modality high resolution
(HR) images. Since a multi-spectral (MS) image consists of several bands and
each band is a 2D image slice, MS images can be seen as 3D data. Thus, we use
the previously proposed VolumeNet to fuse HR panchromatic (PAN) images and
bicubic interpolated MS images. Because the proposed 3D VolumeNet can
effectively improve the accuracy by expanding the receptive field of the model,
and due to its lightweight structure, we can achieve better performance against
the existing method without purchasing a large number of remote sensing images
for training. In addition, VolumeNet can restore the high-frequency information
lost in the HR MR image as much as possible, reducing the difficulty of feature
extraction in the following step: 2.5D texture transfer. As one of the latest
technologies, deep learning-based texture transfer has been demonstrated to
effectively and efficiently improve the visual performance and quality
evaluation indicators of image reconstruction. Different from the texture
transfer processing of RGB image, we use HR PAN images as the reference images
and perform texture transfer for each frequency band of MS images, which is
named 2.5D texture transfer. The experimental results show that the proposed
method outperforms the existing methods in terms of objective accuracy
assessment, method efficiency, and visual subjective evaluation.
","Yinao Li, Yutaro Iwamoto, Ryousuke Nakamura, Lanfen Lin, Ruofeng Tong, Yen-Wei Chen",Yen-Wei Chen,2022-03-08T09:24:12Z
"Tensor Decompositions for Hyperspectral Data Processing in Remote
  Sensing: A Comprehensive Review","  Owing to the rapid development of sensor technology, hyperspectral (HS)
remote sensing (RS) imaging has provided a significant amount of spatial and
spectral information for the observation and analysis of the Earth's surface at
a distance of data acquisition devices, such as aircraft, spacecraft, and
satellite. The recent advancement and even revolution of the HS RS technique
offer opportunities to realize the full potential of various applications,
while confronting new challenges for efficiently processing and analyzing the
enormous HS acquisition data. Due to the maintenance of the 3-D HS inherent
structure, tensor decomposition has aroused widespread concern and research in
HS data processing tasks over the past decades. In this article, we aim at
presenting a comprehensive overview of tensor decomposition, specifically
contextualizing the five broad topics in HS data processing, and they are HS
restoration, compressed sensing, anomaly detection, super-resolution, and
spectral unmixing. For each topic, we elaborate on the remarkable achievements
of tensor decomposition models for HS RS with a pivotal description of the
existing methodologies and a representative exhibition on the experimental
results. As a result, the remaining challenges of the follow-up research
directions are outlined and discussed from the perspective of the real HS RS
practices and tensor decomposition merged with advanced priors and even with
deep neural networks. This article summarizes different tensor
decomposition-based HS data processing methods and categorizes them into
different classes from simple adoptions to complex combinations with other
priors for the algorithm beginners. We also expect this survey can provide new
investigations and development trends for the experienced researchers who
understand tensor decomposition and HS RS to some extent.
","Minghua Wang, Danfeng Hong, Zhu Han, Jiaxin Li, Jing Yao, Lianru Gao, Bing Zhang, Jocelyn Chanussot",Jocelyn Chanussot,2022-05-13T00:39:23Z
"Unsupervised segmentation of biomedical hyperspectral image data:
  tackling high dimensionality with convolutional autoencoders","  Information about the structure and composition of biopsy specimens can
assist in disease monitoring and diagnosis. In principle, this can be acquired
from Raman and infrared (IR) hyperspectral images (HSIs) that encode
information about how a sample's constituent molecules are arranged in space.
Each tissue section/component is defined by a unique combination of spatial and
spectral features, but given the high dimensionality of HSI datasets,
extracting and utilising them to segment images is non-trivial. Here, we show
how networks based on deep convolutional autoencoders (CAEs) can perform this
task in an end-to-end fashion by first detecting and compressing relevant
features from patches of the HSI into low-dimensional latent vectors, and then
performing a clustering step that groups patches containing similar
spatio-spectral features together. We showcase the advantages of using this
end-to-end spatio-spectral segmentation approach compared to i) the same
spatio-spectral technique not trained in an end-to-end manner, and ii) a method
that only utilises spectral features (spectral k-means) using simulated HSIs of
porcine tissue as test examples. Secondly, we describe the potential
advantages/limitations of using three different CAE architectures: a generic 2D
CAE, a generic 3D CAE, and a 2D CNN architecture inspired by the recently
proposed UwU-net that is specialised for extracting features from HSI data. We
assess their performance on IR HSIs of real colon samples. We find that all
architectures are capable of producing segmentations that show good
correspondence with HE stained adjacent tissue slices used as approximate
ground truths, indicating the robustness of the CAE-driven approach for
segmenting biomedical HSI data. Additionally, we stress the need for more
accurate ground truth information to rigorously compare the advantages offered
by each architecture.
","Ciaran Bench, Jayakrupakar Nallala, Chun-Chin Wang, Hannah Sheridan, Nicholas Stone",Nicholas Stone,2022-09-09T16:16:51Z
"HyperGal: hyperspectral scene modeling for supernova typing with the
  Integral Field Spectrograph SEDmachine","  Recent developments in time domain astronomy, like the Zwicky Transient
Facility, have made possible a daily scan of the entire visible sky, leading to
the discovery of hundreds of new transients every night. Among them, 10 to 15
are supernovae (SNe), which have to be classified prior to cosmological use.
The Spectral Energy Distribution machine (SEDm), a low resolution Integral
Field Spectrograph, has been designed, built, and operated to spectroscopically
classify targets detected by the ZTF main camera. The current Pysedm pipeline
is limited by contamination when the transient is too close to its host galaxy
core; this can lead to an incorrect typing and ultimately bias the cosmological
analyses, and affect the SN sample homogeneity in terms of local environment
properties. We present a new scene modeler to extract the transient spectrum
from its structured background, aiming at improving the typing efficiency of
the SEDm. HyperGal is a fully chromatic scene modeler, which uses pre-transient
photometric images to generate a hyperspectral model of the host galaxy; it is
based on the CIGALE SED fitter used as a physically-motivated spectral
interpolator. The galaxy model, complemented by a point source and a diffuse
background component, is projected onto the SEDm spectro-spatial observation
space and adjusted to observations. The full procedure is validated on 5000
simulated cubes. We introduce the contrast as the transient-to-total flux ratio
at SN location. From estimated contrast distribution of real SEDm observations,
we show that HyperGal correctly classifies ~95% of SNe Ia. Compared to the
standard extraction method, HyperGal correctly classifies 10% more SNe Ia. The
false positive rate is less than 2%, half as much as the standard extraction
method. Assuming a similar contrast distribution for core-collapse SNe,
HyperGal classifies 14% (11%) additional SNe II (Ibc).
","J. Lezmy, Y. Copin, M. Rigault, M. Smith, J. D. Neill",J. D. Neill,2022-09-22T09:32:34Z
AEROS: Oceanographic Hyperspectral Imaging and Argos-Tracking CubeSat,"  AEROS is a 3U CubeSat pathfinder toward a future ocean-observing
constellation, targeting the Portuguese Atlantic region. AEROS features a
miniaturized, high-resolution Hyperspectral Imager (HSI), a 5MP RGB camera, and
a Software Defined Radio (SDR). The sensor generated data will be processed and
aggregated for end-users in a new web-based Data Analysis Center (DAC). The HSI
has 150 spectrally contiguous bands covering visible to near-infrared with 10
nm bandwidth. The HSI collects ocean color data to support studies of
oceanographic characteristics known to influence the spatio-temporal
distribution and movement behavior of marine organisms. Usage of an SDR expands
AEROS's operational and communication range and allows for remote
reconfiguration. The SDR receives, demodulates, and retransmits short duration
messages, from sources including tagged marine organisms, autonomous vehicles,
subsurface floats, and buoys. The future DAC will collect, store, process, and
analyze acquired data, taking advantage of its ability to disseminate data
across the stakeholders and the scientific network. Correlation of animal-borne
Argos platform locations and oceanographic data will advance fisheries
management, ecosystem-based management, monitoring of marine protected areas,
and bio-oceanographic research in the face of a rapidly changing environment.
For example, correlation of oceanographic data collected by the HSI, geolocated
with supplementary images from the RGB camera and fish locations, will provide
researchers with near real-time estimates of essential oceanographic variables
within areas selected by species of interest.
","Sophie Prendergast, Cadence Payne, Miles Lifson, Christian Haughwout, Marcos Tieppo, Paulo Figueiredo, André Guerra, Alexander Costa, Helder Magalhães, Tiago Hormigo, Francisco Câmara, Carlos Mano, Pedro Pinheiro, Alvin D. Harvey, Bruno Macena, Luis F. Azevedo, Miguel Martin, Tiago Miranda, Eduardo Pereira, João Faria, Inês Castelão, Catarina Cecilio, Emanuel Castanho, Kerri Cahoy, Manuel Coutinho, Helder Silva, Jorge Fontes",Jorge Fontes,2022-11-09T09:49:43Z
"Intra-operative Brain Tumor Detection with Deep Learning-Optimized
  Hyperspectral Imaging","  Surgery for gliomas (intrinsic brain tumors), especially when low-grade, is
challenging due to the infiltrative nature of the lesion. Currently, no
real-time, intra-operative, label-free and wide-field tool is available to
assist and guide the surgeon to find the relevant demarcations for these
tumors. While marker-based methods exist for the high-grade glioma case, there
is no convenient solution available for the low-grade case; thus, marker-free
optical techniques represent an attractive option. Although RGB imaging is a
standard tool in surgical microscopes, it does not contain sufficient
information for tissue differentiation. We leverage the richer information from
hyperspectral imaging (HSI), acquired with a snapscan camera in the 468-787 nm
range, coupled to a surgical microscope, to build a deep-learning-based
diagnostic tool for cancer resection with potential for intra-operative
guidance. However, the main limitation of the HSI snapscan camera is the image
acquisition time, limiting its widespread deployment in the operation theater.
Here, we investigate the effect of HSI channel reduction and pre-selection to
scope the design space for the development of cheaper and faster sensors.
Neural networks are used to identify the most important spectral channels for
tumor tissue differentiation, optimizing the trade-off between the number of
channels and precision to enable real-time intra-surgical application. We
evaluate the performance of our method on a clinical dataset that was acquired
during surgery on five patients. By demonstrating the possibility to
efficiently detect low-grade glioma, these results can lead to better cancer
resection demarcations, potentially improving treatment effectiveness and
patient outcome.
","Tommaso Giannantonio, Anna Alperovich, Piercosimo Semeraro, Manfredo Atzori, Xiaohan Zhang, Christoph Hauger, Alexander Freytag, Siri Luthman, Roeland Vandebriel, Murali Jayapala, Lien Solie, Steven de Vleeschouwer",Steven de Vleeschouwer,2023-02-06T15:52:03Z
Hyperspectral Image Super Resolution with Real Unaligned RGB Guidance,"  Fusion-based hyperspectral image (HSI) super-resolution has become
increasingly prevalent for its capability to integrate high-frequency spatial
information from the paired high-resolution (HR) RGB reference image. However,
most of the existing methods either heavily rely on the accurate alignment
between low-resolution (LR) HSIs and RGB images, or can only deal with
simulated unaligned RGB images generated by rigid geometric transformations,
which weakens their effectiveness for real scenes. In this paper, we explore
the fusion-based HSI super-resolution with real RGB reference images that have
both rigid and non-rigid misalignments. To properly address the limitations of
existing methods for unaligned reference images, we propose an HSI fusion
network with heterogenous feature extractions, multi-stage feature alignments,
and attentive feature fusion. Specifically, our network first transforms the
input HSI and RGB images into two sets of multi-scale features with an HSI
encoder and an RGB encoder, respectively. The features of RGB reference images
are then processed by a multi-stage alignment module to explicitly align the
features of RGB reference with the LR HSI. Finally, the aligned features of RGB
reference are further adjusted by an adaptive attention module to focus more on
discriminative regions before sending them to the fusion decoder to generate
the reconstructed HR HSI. Additionally, we collect a real-world HSI fusion
dataset, consisting of paired HSI and unaligned RGB reference, to support the
evaluation of the proposed model for real scenes. Extensive experiments are
conducted on both simulated and our real-world datasets, and it shows that our
method obtains a clear improvement over existing single-image and fusion-based
super-resolution methods on quantitative assessment as well as visual
comparison.
","Zeqiang Lai, Ying Fu, Jun Zhang",Jun Zhang,2023-02-13T11:56:45Z
"Ultra-high resolution observations of plasmoid-mediated magnetic
  reconnection in the deep solar atmosphere","  Magnetic reconnection in the deep solar atmosphere can give rise to enhanced
emission in the Balmer hydrogen lines, a phenomenon referred to as Ellerman
bombs. To effectively trace magnetic reconnection below the canopy of
chromospheric fibrils, we analyzed unique spectroscopic observations of
Ellerman bombs in the H-alpha line. We analyzed a 10 min dataset of a young
emerging active region observed with the prototype of the Microlensed
Hyperspectral Imager (MiHI) at the Swedish 1-m Solar Telescope (SST). The MiHI
instrument is an integral field spectrograph that is capable of achieving
simultaneous ultra-high resolution in the spatial, temporal and spectral
domains. With the combination of the SST adaptive optics system and image
restoration techniques, MiHI can deliver diffraction limited observations if
the atmospheric seeing conditions allow. The dataset samples the H-alpha line
over 4.5 A with 10 mA/pix, with 0.065""/pix over a field of view of 8.6"" x 7.7"",
and at a temporal cadence of 1.33s. This constitutes a hyperspectral data cube
that measures 132 x 118 spatial pixels, 456 spectral pixels, and 455 time
steps. There were multiple sites with Ellerman bomb activity associated with
strong magnetic flux emergence. The Ellerman bomb activity is very dynamic,
showing rapid variability and small-scale substructure. We found a number of
plasmoid-like blobs with full-width-half-maximum sizes between 0.1"" - 0.4"" and
moving with apparent velocities between 14 and 77 km/s. Some of these blobs
have Ellerman bomb spectral profiles with a single peak at a Doppler offset
between 47 and 57 km/s. Our observations support the idea that fast magnetic
reconnection in Ellerman bombs is mediated by the formation of plasmoids. These
MiHI observations demonstrate that a micro-lens based integral field
spectrograph is capable of probing fundamental physical processes in the solar
atmosphere.
","L. Rouppe van der Voort, M. van Noort, J. de la Cruz Rodriguez",J. de la Cruz Rodriguez,2023-02-22T17:08:59Z
"Semantic segmentation of surgical hyperspectral images under geometric
  domain shifts","  Robust semantic segmentation of intraoperative image data could pave the way
for automatic surgical scene understanding and autonomous robotic surgery.
Geometric domain shifts, however, although common in real-world open surgeries
due to variations in surgical procedures or situs occlusions, remain a topic
largely unaddressed in the field. To address this gap in the literature, we (1)
present the first analysis of state-of-the-art (SOA) semantic segmentation
networks in the presence of geometric out-of-distribution (OOD) data, and (2)
address generalizability with a dedicated augmentation technique termed ""Organ
Transplantation"" that we adapted from the general computer vision community.
According to a comprehensive validation on six different OOD data sets
comprising 600 RGB and hyperspectral imaging (HSI) cubes from 33 pigs
semantically annotated with 19 classes, we demonstrate a large performance drop
of SOA organ segmentation networks applied to geometric OOD data. Surprisingly,
this holds true not only for conventional RGB data (drop of Dice similarity
coefficient (DSC) by 46 %) but also for HSI data (drop by 45 %), despite the
latter's rich information content per pixel. Using our augmentation scheme
improves on the SOA DSC by up to 67 % (RGB) and 90 % (HSI) and renders
performance on par with in-distribution performance on real OOD test data. The
simplicity and effectiveness of our augmentation scheme makes it a valuable
network-independent tool for addressing geometric domain shifts in semantic
scene segmentation of intraoperative data. Our code and pre-trained models are
available at https://github.com/IMSY-DKFZ/htc.
","Jan Sellner, Silvia Seidlitz, Alexander Studier-Fischer, Alessandro Motta, Berkin Özdemir, Beat Peter Müller-Stich, Felix Nickel, Lena Maier-Hein",Lena Maier-Hein,2023-03-20T09:50:07Z
"Hyperspectral Image Super-Resolution via Dual-domain Network Based on
  Hybrid Convolution","  Since the number of incident energies is limited, it is difficult to directly
acquire hyperspectral images (HSI) with high spatial resolution. Considering
the high dimensionality and correlation of HSI, super-resolution (SR) of HSI
remains a challenge in the absence of auxiliary high-resolution images.
Furthermore, it is very important to extract the spatial features effectively
and make full use of the spectral information. This paper proposes a novel HSI
super-resolution algorithm, termed dual-domain network based on hybrid
convolution (SRDNet). Specifically, a dual-domain network is designed to fully
exploit the spatial-spectral and frequency information among the hyper-spectral
data. To capture inter-spectral self-similarity, a self-attention learning
mechanism (HSL) is devised in the spatial domain. Meanwhile the pyramid
structure is applied to increase the acceptance field of attention, which
further reinforces the feature representation ability of the network. Moreover,
to further improve the perceptual quality of HSI, a frequency loss(HFL) is
introduced to optimize the model in the frequency domain. The dynamic weighting
mechanism drives the network to gradually refine the generated frequency and
excessive smoothing caused by spatial loss. Finally, In order to better fully
obtain the mapping relationship between high-resolution space and
low-resolution space, a hybrid module of 2D and 3D units with progressive
upsampling strategy is utilized in our method. Experiments on a widely used
benchmark dataset illustrate that the proposed SRDNet method enhances the
texture information of HSI and is superior to state-of-the-art methods.
","Tingting Liu, Yuan Liu, Chuncheng Zhang, Yuan Liyin, Xiubao Sui, Qian Chen",Qian Chen,2023-04-10T13:51:28Z
"Exploring Multi-Timestep Multi-Stage Diffusion Features for
  Hyperspectral Image Classification","  The effectiveness of spectral-spatial feature learning is crucial for the
hyperspectral image (HSI) classification task. Diffusion models, as a new class
of groundbreaking generative models, have the ability to learn both contextual
semantics and textual details from the distinct timestep dimension, enabling
the modeling of complex spectral-spatial relations in HSIs. However, existing
diffusion-based HSI classification methods only utilize manually selected
single-timestep single-stage features, limiting the full exploration and
exploitation of rich contextual semantics and textual information hidden in the
diffusion model. To address this issue, we propose a novel diffusion-based
feature learning framework that explores Multi-Timestep Multi-Stage Diffusion
features for HSI classification for the first time, called MTMSD. Specifically,
the diffusion model is first pretrained with unlabeled HSI patches to mine the
connotation of unlabeled data, and then is used to extract the multi-timestep
multi-stage diffusion features. To effectively and efficiently leverage
multi-timestep multi-stage features,two strategies are further developed. One
strategy is class & timestep-oriented multi-stage feature purification module
with the inter-class and inter-timestep prior for reducing the redundancy of
multi-stage features and alleviating memory constraints. The other one is
selective timestep feature fusion module with the guidance of global features
to adaptively select different timestep features for integrating texture and
semantics. Both strategies facilitate the generality and adaptability of the
MTMSD framework for diverse patterns of different HSI data. Extensive
experiments are conducted on four public HSI datasets, and the results
demonstrate that our method outperforms state-of-the-art methods for HSI
classification, especially on the challenging Houston 2018 dataset.
","Jingyi Zhou, Jiamu Sheng, Jiayuan Fan, Peng Ye, Tong He, Bin Wang, Tao Chen",Tao Chen,2023-06-15T08:56:58Z
"A flexible and accurate total variation and cascaded denoisers-based
  image reconstruction algorithm for hyperspectrally compressed ultrafast
  photography","  Hyperspectrally compressed ultrafast photography (HCUP) based on compressed
sensing and the time- and spectrum-to-space mappings can simultaneously realize
the temporal and spectral imaging of non-repeatable or difficult-to-repeat
transient events passively in a single exposure. It possesses an incredibly
high frame rate of tens of trillions of frames per second and a sequence depth
of several hundred, and plays a revolutionary role in single-shot ultrafast
optical imaging. However, due to the ultra-high data compression ratio induced
by the extremely large sequence depth as well as the limited fidelities of
traditional reconstruction algorithms over the reconstruction process, HCUP
suffers from a poor image reconstruction quality and fails to capture fine
structures in complex transient scenes. To overcome these restrictions, we
propose a flexible image reconstruction algorithm based on the total variation
(TV) and cascaded denoisers (CD) for HCUP, named the TV-CD algorithm. It
applies the TV denoising model cascaded with several advanced deep
learning-based denoising models in the iterative plug-and-play alternating
direction method of multipliers framework, which can preserve the image
smoothness while utilizing the deep denoising networks to obtain more priori,
and thus solving the common sparsity representation problem in local similarity
and motion compensation. Both simulation and experimental results show that the
proposed TV-CD algorithm can effectively improve the image reconstruction
accuracy and quality of HCUP, and further promote the practical applications of
HCUP in capturing high-dimensional complex physical, chemical and biological
ultrafast optical scenes.
","Zihan Guo, Jiali Yao, Dalong Qi, Pengpeng Ding, Chengzhi Jin, Ning Xu, Zhiling Zhang, Yunhua Yao, Lianzhong Deng, Zhiyong Wang, Zhenrong Sun, Shian Zhang",Shian Zhang,2023-09-06T08:45:26Z
"Super-resolved snapshot hyperspectral imaging of solid-state quantum
  emitters for high-throughput integrated quantum technologies","  Solid-state quantum emitters coupled to integrated photonic nanostructures
are quintessential for exploring fundamental phenomena in cavity quantum
electrodynamics and widely employed in photonic quantum technologies such as
non-classical light sources, quantum repeaters, and quantum transducers, etc.
One of the most exciting promises from integrated quantum photonics is the
potential of scalability that enables massive productions of miniaturized
devices on a single chip. In reality, the yield of efficient and reproducible
light-matter couplings is greatly hindered by the spectral and spatial
mismatches between the single solid-state quantum emitters and confined or
propagating optical modes supported by the photonic nanostructures, preventing
the high-throughput realization of large-scale integrated quantum photonic
circuits for more advanced quantum information processing tasks. In this work,
we introduce the concept of hyperspectral imaging in quantum optics, for the
first time, to address such a long-standing issue. By exploiting the extended
mode with a unique dispersion in a 1D planar cavity, the spectral and spatial
information of each individual quantum dot in an ensemble can be accurately and
reliably extracted from a single wide-field photoluminescence image with
super-resolutions. With the extracted quantum dot positions and emission
wavelengths, surface-emitting quantum light sources and in-plane photonic
circuits can be deterministically fabricated with a high-throughput by etching
the 1D confined planar cavity into 3D confined micropillars and 2D confined
waveguides. Further extension of this technique by employing an open planar
cavity could be exploited for pursuing a variety of compact quantum photonic
devices with expanded functionalities for large-scale integration. Our work is
expected to change the landscape of integrated quantum photonic technology.
","Shunfa Liu, Xueshi Li, Hanqing Liu, Guixin Qiu, Jiantao Ma, Liang Nie, Haiqiao Ni, Zhichuan Niu, Cheng-Wei Qiu, Xuehua Wang, Jin Liu",Jin Liu,2023-11-05T11:51:22Z
"Robust Tumor Segmentation with Hyperspectral Imaging and Graph Neural
  Networks","  Segmenting the boundary between tumor and healthy tissue during surgical
cancer resection poses a significant challenge. In recent years, Hyperspectral
Imaging (HSI) combined with Machine Learning (ML) has emerged as a promising
solution. However, due to the extensive information contained within the
spectral domain, most ML approaches primarily classify individual HSI
(super-)pixels, or tiles, without taking into account their spatial context. In
this paper, we propose an improved methodology that leverages the spatial
context of tiles for more robust and smoother segmentation. To address the
irregular shapes of tiles, we utilize Graph Neural Networks (GNNs) to propagate
context information across neighboring regions. The features for each tile
within the graph are extracted using a Convolutional Neural Network (CNN),
which is trained simultaneously with the subsequent GNN. Moreover, we
incorporate local image quality metrics into the loss function to enhance the
training procedure's robustness against low-quality regions in the training
images. We demonstrate the superiority of our proposed method using a clinical
ex vivo dataset consisting of 51 HSI images from 30 patients. Despite the
limited dataset, the GNN-based model significantly outperforms context-agnostic
approaches, accurately distinguishing between healthy and tumor tissues, even
in images from previously unseen patients. Furthermore, we show that our
carefully designed loss function, accounting for local image quality, results
in additional improvements. Our findings demonstrate that context-aware GNN
algorithms can robustly find tumor demarcations on HSI images, ultimately
contributing to better surgery success and patient outcome.
","Mayar Lotfy, Anna Alperovich, Tommaso Giannantonio, Bjorn Barz, Xiaohan Zhang, Felix Holm, Nassir Navab, Felix Boehm, Carolin Schwamborn, Thomas K. Hoffmann, Patrick J. Schuler",Patrick J. Schuler,2023-11-20T14:07:38Z
"Superpixel-based and Spatially-regularized Diffusion Learning for
  Unsupervised Hyperspectral Image Clustering","  Hyperspectral images (HSIs) provide exceptional spatial and spectral
resolution of a scene, crucial for various remote sensing applications.
However, the high dimensionality, presence of noise and outliers, and the need
for precise labels of HSIs present significant challenges to HSIs analysis,
motivating the development of performant HSI clustering algorithms. This paper
introduces a novel unsupervised HSI clustering algorithm, Superpixel-based and
Spatially-regularized Diffusion Learning (S2DL), which addresses these
challenges by incorporating rich spatial information encoded in HSIs into
diffusion geometry-based clustering. S2DL employs the Entropy Rate Superpixel
(ERS) segmentation technique to partition an image into superpixels, then
constructs a spatially-regularized diffusion graph using the most
representative high-density pixels. This approach reduces computational burden
while preserving accuracy. Cluster modes, serving as exemplars for underlying
cluster structure, are identified as the highest-density pixels farthest in
diffusion distance from other highest-density pixels. These modes guide the
labeling of the remaining representative pixels from ERS superpixels. Finally,
majority voting is applied to the labels assigned within each superpixel to
propagate labels to the rest of the image. This spatial-spectral approach
simultaneously simplifies graph construction, reduces computational cost, and
improves clustering performance. S2DL's performance is illustrated with
extensive experiments on three publicly available, real-world HSIs: Indian
Pines, Salinas, and Salinas A. Additionally, we apply S2DL to landscape-scale,
unsupervised mangrove species mapping in the Mai Po Nature Reserve, Hong Kong,
using a Gaofen-5 HSI. The success of S2DL in these diverse numerical
experiments indicates its efficacy on a wide range of important unsupervised
remote sensing analysis tasks.
","Kangning Cui, Ruoning Li, Sam L. Polk, Yinyi Lin, Hongsheng Zhang, James M. Murphy, Robert J. Plemmons, Raymond H. Chan",Raymond H. Chan,2023-12-24T09:54:40Z
"A Spectral Library and Method for Sparse Unmixing of Hyperspectral
  Images in Fluorescence Guided Resection of Brain Tumors","  Through spectral unmixing, hyperspectral imaging (HSI) in fluorescence-guided
brain tumor surgery has enabled detection and classification of tumor regions
invisible to the human eye. Prior unmixing work has focused on determining a
minimal set of viable fluorophore spectra known to be present in the brain and
effectively reconstructing human data without overfitting. With these
endmembers, non-negative least squares regression (NNLS) was used to compute
the abundances. However, HSI images are heterogeneous, so one small set of
endmember spectra may not fit all pixels well. Additionally, NNLS is the
maximum likelihood estimator only if the measurement is normally distributed,
and it does not enforce sparsity, which leads to overfitting and unphysical
results. Here, we analyzed 555666 HSI fluorescence spectra from 891 ex vivo
measurements of patients with brain tumors to show that a Poisson distribution
models the measured data 82% better than a Gaussian in terms of the
Kullback-Leibler divergence and that the endmember abundance vectors are
sparse. With this knowledge, we introduce (1) a library of 9 endmember spectra,
(2) a sparse, non-negative Poisson regression algorithm to perform
physics-informed unmixing with this library without overfitting, and (3) a
highly realistic spectral measurement simulation with known endmember
abundances. The new unmixing method was then tested on the human and simulated
data and compared to four other candidate methods. It outperforms previous
methods with 25% lower error in the computed abundances on the simulated data
than NNLS, lower reconstruction error on human data, beUer sparsity, and 31
times faster runtime than state-of-the-art Poisson regression. This method and
library of endmember spectra can enable more accurate spectral unmixing to
beUer aid the surgeon during brain tumor resection.
","David Black, Benoit Liquet, Sadahiro Kaneko, Antonio Di leva, Walter Stummer, Eric Suero Molina",Eric Suero Molina,2024-01-30T19:12:46Z
"Rapid hyperspectral photothermal mid-infrared spectroscopic imaging from
  sparse data for gynecologic cancer tissue subtyping","  Ovarian cancer detection has traditionally relied on a multi-step process
that includes biopsy, tissue staining, and morphological analysis by
experienced pathologists. While widely practiced, this conventional approach
suffers from several drawbacks: it is qualitative, time-intensive, and heavily
dependent on the quality of staining. Mid-infrared (MIR) hyperspectral
photothermal imaging is a label-free, biochemically quantitative technology
that, when combined with machine learning algorithms, can eliminate the need
for staining and provide quantitative results comparable to traditional
histology. However, this technology is slow. This work presents a novel
approach to MIR photothermal imaging that enhances its speed by an order of
magnitude. Our method significantly accelerates data collection by capturing a
combination of high-resolution and interleaved, lower-resolution infrared band
images and applying computational techniques for data interpolation. We
effectively minimize data collection requirements by leveraging sparse data
acquisition and employing curvelet-based reconstruction algorithms. This method
enables the reconstruction of high-quality, high-resolution images from
undersampled datasets and achieving a 10X improvement in data acquisition time.
We assessed the performance of our sparse imaging methodology using a variety
of quantitative metrics, including mean squared error (MSE), structural
similarity index (SSIM), and tissue subtype classification accuracies,
employing both random forest and convolutional neural network (CNN) models,
accompanied by ROC curves. Our statistically robust analysis, based on data
from 100 ovarian cancer patient samples and over 65 million data points,
demonstrates the method's capability to produce superior image quality and
accurately distinguish between different gynecological tissue types with
segmentation accuracy exceeding 95%.
","Reza Reihanisaransari, Chalapathi Charan Gajjela, Xinyu Wu, Ragib Ishrak, Sara Corvigno, Yanping Zhong, Jinsong Liu, Anil K. Sood, David Mayerich, Sebastian Berisha, Rohith Reddy",Rohith Reddy,2024-02-28T00:57:35Z
Overcoming Confusion Noise with Hyperspectral Imaging from PRIMAger,"  The PRobe far-Infrared Mission for Astrophysics (PRIMA) concept aims to
perform mapping with spectral coverage and sensitivities inaccessible to
previous FIR space telescopes. PRIMA's imaging instrument, PRIMAger, provides
unique hyperspectral imaging simultaneously covering 25-235 $\mu$m. We
synthesise images representing a deep, 1500 hr deg$^{-2}$ PRIMAger survey, with
realistic instrumental and confusion noise. We demonstrate that we can
construct catalogues of galaxies with a high purity ($>95$ per cent) at a
source density of 42k deg$^{-2}$ using PRIMAger data alone. Using the XID+
deblending tool we show that we measure fluxes with an accuracy better than 20
per cent to flux levels of 0.16, 0.80, 9.7 and 15 mJy at 47.4, 79.7, 172, 235
$\mu$m respectively. These are a factor of $\sim$2 and $\sim$3 fainter than the
classical confusion limits for 72-96 $\mu$m and 126-235 $\mu$m, respectively.
At $1.5 \leq z \leq 2$, we detect and accurately measure fluxes in 8-10 of the
10 channels covering 47-235 $\mu$m for sources with $2 \leq$ log(SFR) $\leq
2.5$, a 0.5 dex improvement on what might be expected from the classical
confusion limit. Recognising that PRIMager will operate in a context where high
quality data will be available at other wavelengths, we investigate the
benefits of introducing additional prior information. We show that by
introducing even weak prior flux information when employing a higher source
density catalogue (more than one source per beam) we can obtain accurate fluxes
an order of magnitude below the classical confusion limit for 96-235 $\mu$m.
","James M. S. Donnellan, Seb J. Oliver, Matthieu Bethermin, Longji Bing, Alberto Bolatto, Charles M. Bradford, Denis Burgarella, Laure Ciesla, Jason Glenn, Alexandra Pope, Stephen Serjeant, Raphael Shirley, JD T. Smith, Chris Sorrell",Chris Sorrell,2024-04-10T11:39:46Z
"Dual-band feature selection for maturity classification of specialty
  crops by hyperspectral imaging","  The maturity classification of specialty crops such as strawberries and
tomatoes is an essential agricultural downstream activity for selective
harvesting and quality control (QC) at production and packaging sites. Recent
advancements in Deep Learning (DL) have produced encouraging results in color
images for maturity classification applications. However, hyperspectral imaging
(HSI) outperforms methods based on color vision. Multivariate analysis methods
and Convolutional Neural Networks (CNN) deliver promising results; however, a
large amount of input data and the associated preprocessing requirements cause
hindrances in practical application. Conventionally, the reflectance intensity
in a given electromagnetic spectrum is employed in estimating fruit maturity.
We present a feature extraction method to empirically demonstrate that the peak
reflectance in subbands such as 500-670 nm (pigment band) and the wavelength of
the peak position, and contrarily, the trough reflectance and its corresponding
wavelength within 671-790 nm (chlorophyll band) are convenient to compute yet
distinctive features for the maturity classification. The proposed feature
selection method is beneficial because preprocessing, such as dimensionality
reduction, is avoided before every prediction. The feature set is designed to
capture these traits. The best SOTA methods, among 3D-CNN, 1D-CNN, and SVM,
achieve at most 90.0 % accuracy for strawberries and 92.0 % for tomatoes on our
dataset. Results show that the proposed method outperforms the SOTA as it
yields an accuracy above 98.0 % in strawberry and 96.0 % in tomato
classification. A comparative analysis of the time efficiency of these methods
is also conducted, which shows the proposed method performs prediction at 13
Frames Per Second (FPS) compared to the maximum 1.16 FPS attained by the
full-spectrum SVM classifier.
","Usman A. Zahidi, Krystian Łukasik, Grzegorz Cielniak",Grzegorz Cielniak,2024-05-16T10:01:16Z
"A transportable hyperspectral imaging setup based on fast, high-density
  spectral scanning for in situ quantitative biochemical mapping of fresh
  tissue biopsies","  Histopathological examination of surgical biopsies, such as in glioma and
glioblastoma resection, is hindered in current clinical practice by the long
times required for the laboratory analysis and pathological screening,
typically taking several days or even weeks to be completed. We propose here a
transportable, high-density, spectral-scanning based hyperspectral imaging
setup, named HyperProbe1, that can provide in situ, fast biochemical analysis
and mapping of fresh surgical tissue samples, right after excision, and without
the need of fixing or staining. HyperProbe1 is based on spectral scanning via
supercontinuum laser illumination filtered with acousto-optic tuneable filters.
Such methodology allows the user to select any number and type of wavelength
bands in the visible and near-infrared range between 510 and 900 nm (up to 79),
and to reconstruct 3D hypercubes composed of high-resolution, widefield images
of the surgical samples, where each pixel is associated with a complete
spectrum. The system is applied on 11 fresh surgical biopsies of glioma from
routine patients, including different grades of tumour classification.
Quantitative analysis of the composition of the tissue is performed via fast
spectral unmixing to reconstruct mapping of major biomarkers. We also provided
a preliminary attempt to infer tumour classification based on differences of
composition in the samples, suggesting the possibility to use lipid content and
differential cytochrome-c-oxidase concentrations to distinguish between lower
and higher grade gliomas. A proof-of-concept of the performances of HyperProbe1
for quantitative, biochemical mapping of surgical biopsies is demonstrated,
paving the way for improving current post-surgical, histopathological practice
via non-destructive, in situ streamlined screening of fresh tissue samples in a
matter of minutes after excision.
","Luca Giannoni, Marta Marradi, Kevin Scibilia, Ivan Ezhov, Camilla Bonaudo, Angelos Artemiou, Anam Toaha, Frederic Lange, Charly Caredda, Bruno Montcel, Alessandro Della Puppa, Ilias Tachtsidis, Daniel Ruckert, Francesco Saverio Pavone",Francesco Saverio Pavone,2024-05-31T12:36:14Z
"EigenSR: Eigenimage-Bridged Pre-Trained RGB Learners for Single
  Hyperspectral Image Super-Resolution","  Single hyperspectral image super-resolution (single-HSI-SR) aims to improve
the resolution of a single input low-resolution HSI. Due to the bottleneck of
data scarcity, the development of single-HSI-SR lags far behind that of RGB
natural images. In recent years, research on RGB SR has shown that models
pre-trained on large-scale benchmark datasets can greatly improve performance
on unseen data, which may stand as a remedy for HSI. But how can we transfer
the pre-trained RGB model to HSI, to overcome the data-scarcity bottleneck?
Because of the significant difference in the channels between the pre-trained
RGB model and the HSI, the model cannot focus on the correlation along the
spectral dimension, thus limiting its ability to utilize on HSI. Inspired by
the HSI spatial-spectral decoupling, we propose a new framework that first
fine-tunes the pre-trained model with the spatial components (known as
eigenimages), and then infers on unseen HSI using an iterative spectral
regularization (ISR) to maintain the spectral correlation. The advantages of
our method lie in: 1) we effectively inject the spatial texture processing
capabilities of the pre-trained RGB model into HSI while keeping spectral
fidelity, 2) learning in the spectral-decorrelated domain can improve the
generalizability to spectral-agnostic data, and 3) our inference in the
eigenimage domain naturally exploits the spectral low-rank property of HSI,
thereby reducing the complexity. This work bridges the gap between pre-trained
RGB models and HSI via eigenimages, addressing the issue of limited HSI
training data, hence the name EigenSR. Extensive experiments show that EigenSR
outperforms the state-of-the-art (SOTA) methods in both spatial and spectral
metrics. Our code will be released.
","Xi Su, Xiangfei Shen, Mingyang Wan, Jing Nie, Lihui Chen, Haijun Liu, Xichuan Zhou",Xichuan Zhou,2024-09-06T06:46:01Z
"Investigation of Hierarchical Spectral Vision Transformer Architecture
  for Classification of Hyperspectral Imagery","  In the past three years, there has been significant interest in hyperspectral
imagery (HSI) classification using vision Transformers for analysis of remotely
sensed data. Previous research predominantly focused on the empirical
integration of convolutional neural networks (CNNs) to augment the network's
capability to extract local feature information. Yet, the theoretical
justification for vision Transformers out-performing CNN architectures in HSI
classification remains a question. To address this issue, a unified
hierarchical spectral vision Transformer architecture, specifically tailored
for HSI classification, is investigated. In this streamlined yet effective
vision Transformer architecture, multiple mixer modules are strategically
integrated separately. These include the CNN-mixer, which executes convolution
operations; the spatial self-attention (SSA)-mixer and channel self-attention
(CSA)-mixer, both of which are adaptations of classical self-attention blocks;
and hybrid models such as the SSA+CNN-mixer and CSA+CNN-mixer, which merge
convolution with self-attention operations. This integration facilitates the
development of a broad spectrum of vision Transformer-based models tailored for
HSI classification. In terms of the training process, a comprehensive analysis
is performed, contrasting classical CNN models and vision Transformer-based
counterparts, with particular attention to disturbance robustness and the
distribution of the largest eigenvalue of the Hessian. From the evaluations
conducted on various mixer models rooted in the unified architecture, it is
concluded that the unique strength of vision Transformers can be attributed to
their overarching architecture, rather than being exclusively reliant on
individual multi-head self-attention (MSA) components.
","Wei Liu, Saurabh Prasad, Melba Crawford",Melba Crawford,2024-09-14T00:53:13Z
Supervised Classification Performance of Multispectral Images,"  Nowadays government and private agencies use remote sensing imagery for a
wide range of applications from military applications to farm development. The
images may be a panchromatic, multispectral, hyperspectral or even
ultraspectral of terra bytes. Remote sensing image classification is one
amongst the most significant application worlds for remote sensing. A few
number of image classification algorithms have proved good precision in
classifying remote sensing data. But, of late, due to the increasing
spatiotemporal dimensions of the remote sensing data, traditional
classification algorithms have exposed weaknesses necessitating further
research in the field of remote sensing image classification. So an efficient
classifier is needed to classify the remote sensing images to extract
information. We are experimenting with both supervised and unsupervised
classification. Here we compare the different classification methods and their
performances. It is found that Mahalanobis classifier performed the best in our
classification.
","K. Perumal, R. Bhaskaran",R. Bhaskaran,2010-02-22T03:12:14Z
"A convex model for non-negative matrix factorization and dimensionality
  reduction on physical space","  A collaborative convex framework for factoring a data matrix $X$ into a
non-negative product $AS$, with a sparse coefficient matrix $S$, is proposed.
We restrict the columns of the dictionary matrix $A$ to coincide with certain
columns of the data matrix $X$, thereby guaranteeing a physically meaningful
dictionary and dimensionality reduction. We use $l_{1,\infty}$ regularization
to select the dictionary from the data and show this leads to an exact convex
relaxation of $l_0$ in the case of distinct noise free data. We also show how
to relax the restriction-to-$X$ constraint by initializing an alternating
minimization approach with the solution of the convex model, obtaining a
dictionary close to but not necessarily in $X$. We focus on applications of the
proposed framework to hyperspectral endmember and abundances identification and
also show an application to blind source separation of NMR data.
","Ernie Esser, Michael Möller, Stanley Osher, Guillermo Sapiro, Jack Xin",Jack Xin,2011-02-04T07:16:10Z
Compressive Principal Component Pursuit,"  We consider the problem of recovering a target matrix that is a superposition
of low-rank and sparse components, from a small set of linear measurements.
This problem arises in compressed sensing of structured high-dimensional
signals such as videos and hyperspectral images, as well as in the analysis of
transformation invariant low-rank recovery. We analyze the performance of the
natural convex heuristic for solving this problem, under the assumption that
measurements are chosen uniformly at random. We prove that this heuristic
exactly recovers low-rank and sparse terms, provided the number of observations
exceeds the number of intrinsic degrees of freedom of the component signals by
a polylogarithmic factor. Our analysis introduces several ideas that may be of
independent interest for the more general problem of compressed sensing and
decomposing superpositions of multiple structured signals.
","John Wright, Arvind Ganesh, Kerui Min, Yi Ma",Yi Ma,2012-02-21T11:12:06Z
"Discriminative variable selection for clustering with the sparse
  Fisher-EM algorithm","  The interest in variable selection for clustering has increased recently due
to the growing need in clustering high-dimensional data. Variable selection
allows in particular to ease both the clustering and the interpretation of the
results. Existing approaches have demonstrated the efficiency of variable
selection for clustering but turn out to be either very time consuming or not
sparse enough in high-dimensional spaces. This work proposes to perform a
selection of the discriminative variables by introducing sparsity in the
loading matrix of the Fisher-EM algorithm. This clustering method has been
recently proposed for the simultaneous visualization and clustering of
high-dimensional data. It is based on a latent mixture model which fits the
data into a low-dimensional discriminative subspace. Three different approaches
are proposed in this work to introduce sparsity in the orientation matrix of
the discriminative subspace through $\ell_{1}$-type penalizations. Experimental
comparisons with existing approaches on simulated and real-world data sets
demonstrate the interest of the proposed methodology. An application to the
segmentation of hyperspectral images of the planet Mars is also presented.
","Charles Bouveyron, Camille Brunet",Camille Brunet,2012-04-10T07:34:07Z
Discriminative Probabilistic Prototype Learning,"  In this paper we propose a simple yet powerful method for learning
representations in supervised learning scenarios where each original input
datapoint is described by a set of vectors and their associated outputs may be
given by soft labels indicating, for example, class probabilities. We represent
an input datapoint as a mixture of probabilities over the corresponding set of
feature vectors where each probability indicates how likely each vector is to
belong to an unknown prototype pattern. We propose a probabilistic model that
parameterizes these prototype patterns in terms of hidden variables and
therefore it can be trained with conventional approaches based on likelihood
maximization. More importantly, both the model parameters and the prototype
patterns can be learned from data in a discriminative way. We show that our
model can be seen as a probabilistic generalization of learning vector
quantization (LVQ). We apply our method to the problems of shape
classification, hyperspectral imaging classification and people's work class
categorization, showing the superior performance of our method compared to the
standard prototype-based classification approach and other competitive
benchmark methods.
","Edwin Bonilla, Antonio Robles-Kelly",Antonio Robles-Kelly,2012-06-18T15:42:34Z
"Blind decomposition of Herschel-HIFI spectral maps of the NGC 7023
  nebula","  Large spatial-spectral surveys are more and more common in astronomy. This
calls for the need of new methods to analyze such mega- to giga-pixel
data-cubes. In this paper we present a method to decompose such observations
into a limited and comprehensive set of components. The original data can then
be interpreted in terms of linear combinations of these components. The method
uses non-negative matrix factorization (NMF) to extract latent spectral
end-members in the data. The number of needed end-members is estimated based on
the level of noise in the data. A Monte-Carlo scheme is adopted to estimate the
optimal end-members, and their standard deviations. Finally, the maps of linear
coefficients are reconstructed using non-negative least squares. We apply this
method to a set of hyperspectral data of the NGC 7023 nebula, obtained recently
with the HIFI instrument onboard the Herschel space observatory, and provide a
first interpretation of the results in terms of 3-dimensional dynamical
structure of the region.
","Olivier Berne, Christine Joblin, Yannick Deville, Paolo Pilleri, Jerome Pety, David Teyssier, Maryvonne Gerin, Asuncion Fuente",Asuncion Fuente,2012-10-12T08:57:59Z
"Alternating proximal gradient method for sparse nonnegative Tucker
  decomposition","  Multi-way data arises in many applications such as electroencephalography
(EEG) classification, face recognition, text mining and hyperspectral data
analysis. Tensor decomposition has been commonly used to find the hidden
factors and elicit the intrinsic structures of the multi-way data. This paper
considers sparse nonnegative Tucker decomposition (NTD), which is to decompose
a given tensor into the product of a core tensor and several factor matrices
with sparsity and nonnegativity constraints. An alternating proximal gradient
method (APG) is applied to solve the problem. The algorithm is then modified to
sparse NTD with missing values. Per-iteration cost of the algorithm is
estimated scalable about the data size, and global convergence is established
under fairly loose conditions. Numerical experiments on both synthetic and real
world data demonstrate its superiority over a few state-of-the-art methods for
(sparse) NTD from partial and/or full observations. The MATLAB code along with
demos are accessible from the author's homepage.
",Yangyang Xu,Yangyang Xu,2013-02-11T18:22:33Z
"An Empirical-Bayes Approach to Recovering Linearly Constrained
  Non-Negative Sparse Signals","  We propose two novel approaches to the recovery of an (approximately) sparse
signal from noisy linear measurements in the case that the signal is a priori
known to be non-negative and obey given linear equality constraints, such as
simplex signals. This problem arises in, e.g., hyperspectral imaging, portfolio
optimization, density estimation, and certain cases of compressive imaging. Our
first approach solves a linearly constrained non-negative version of LASSO
using the max-sum version of the generalized approximate message passing (GAMP)
algorithm, where we consider both quadratic and absolute loss, and where we
propose a novel approach to tuning the LASSO regularization parameter via the
expectation maximization (EM) algorithm. Our second approach is based on the
sum-product version of the GAMP algorithm, where we propose the use of a
Bernoulli non-negative Gaussian-mixture signal prior and a Laplacian
likelihood, and propose an EM-based approach to learning the underlying
statistical parameters. In both approaches, the linear equality constraints are
enforced by augmenting GAMP's generalized-linear observation model with
noiseless pseudo-measurements. Extensive numerical experiments demonstrate the
state-of-the-art performance of our proposed approaches.
","Jeremy Vila, Philip Schniter",Philip Schniter,2013-10-10T13:24:37Z
"Regularization in Relevance Learning Vector Quantization Using l one
  Norms","  We propose in this contribution a method for l one regularization in
prototype based relevance learning vector quantization (LVQ) for sparse
relevance profiles. Sparse relevance profiles in hyperspectral data analysis
fade down those spectral bands which are not necessary for classification. In
particular, we consider the sparsity in the relevance profile enforced by LASSO
optimization. The latter one is obtained by a gradient learning scheme using a
differentiable parametrized approximation of the $l_{1}$-norm, which has an
upper error bound. We extend this regularization idea also to the matrix
learning variant of LVQ as the natural generalization of relevance learning.
","Martin Riedel, Marika Kästner, Fabrice Rossi, Thomas Villmann",Thomas Villmann,2013-10-18T17:00:34Z
"Successive Nonnegative Projection Algorithm for Robust Nonnegative Blind
  Source Separation","  In this paper, we propose a new fast and robust recursive algorithm for
near-separable nonnegative matrix factorization, a particular nonnegative blind
source separation problem. This algorithm, which we refer to as the successive
nonnegative projection algorithm (SNPA), is closely related to the popular
successive projection algorithm (SPA), but takes advantage of the nonnegativity
constraint in the decomposition. We prove that SNPA is more robust than SPA and
can be applied to a broader class of nonnegative matrices. This is illustrated
on some synthetic data sets, and on a real-world hyperspectral image.
",Nicolas Gillis,Nicolas Gillis,2013-10-28T18:41:48Z
Multitask Diffusion Adaptation over Networks,"  Adaptive networks are suitable for decentralized inference tasks, e.g., to
monitor complex natural phenomena. Recent research works have intensively
studied distributed optimization problems in the case where the nodes have to
estimate a single optimum parameter vector collaboratively. However, there are
many important applications that are multitask-oriented in the sense that there
are multiple optimum parameter vectors to be inferred simultaneously, in a
collaborative manner, over the area covered by the network. In this paper, we
employ diffusion strategies to develop distributed algorithms that address
multitask problems by minimizing an appropriate mean-square error criterion
with $\ell_2$-regularization. The stability and convergence of the algorithm in
the mean and in the mean-square sense is analyzed. Simulations are conducted to
verify the theoretical findings, and to illustrate how the distributed strategy
can be used in several useful applications related to spectral sensing, target
localization, and hyperspectral data unmixing.
","Jie Chen, Cédric Richard, Ali. H. Sayed",Ali. H. Sayed,2013-11-02T10:29:50Z
Parallel matrix factorization for low-rank tensor completion,"  Higher-order low-rank tensors naturally arise in many applications including
hyperspectral data recovery, video inpainting, seismic data recon- struction,
and so on. We propose a new model to recover a low-rank tensor by
simultaneously performing low-rank matrix factorizations to the all-mode ma-
tricizations of the underlying tensor. An alternating minimization algorithm is
applied to solve the model, along with two adaptive rank-adjusting strategies
when the exact rank is not known.
  Phase transition plots reveal that our algorithm can recover a variety of
synthetic low-rank tensors from significantly fewer samples than the compared
methods, which include a matrix completion method applied to tensor recovery
and two state-of-the-art tensor completion methods. Further tests on real-
world data show similar advantages. Although our model is non-convex, our
algorithm performs consistently throughout the tests and give better results
than the compared methods, some of which are based on convex models. In
addition, the global convergence of our algorithm can be established in the
sense that the gradient of Lagrangian function converges to zero.
","Yangyang Xu, Ruru Hao, Wotao Yin, Zhixun Su",Zhixun Su,2013-12-04T17:36:49Z
The Why and How of Nonnegative Matrix Factorization,"  Nonnegative matrix factorization (NMF) has become a widely used tool for the
analysis of high-dimensional data as it automatically extracts sparse and
meaningful features from a set of nonnegative data vectors. We first illustrate
this property of NMF on three applications, in image processing, text mining
and hyperspectral imaging --this is the why. Then we address the problem of
solving NMF, which is NP-hard in general. We review some standard NMF
algorithms, and also present a recent subclass of NMF problems, referred to as
near-separable NMF, that can be solved efficiently (that is, in polynomial
time), even in the presence of noise --this is the how. Finally, we briefly
describe some problems in mathematics and computer science closely related to
NMF via the nonnegative rank.
",Nicolas Gillis,Nicolas Gillis,2014-01-21T09:03:12Z
The MARTE VNIR Imaging Spectrometer Experiment: Design and Analysis,"  We report on the design, operation, and data analysis methods employed on the
VNIR imaging spectrometer instrument that was part of the Mars Astrobiology
Research and Technology Experiment (MARTE). The imaging spectrometer is a
hyperspectral scanning pushbroom device sensitive to VNIR wavelengths from
400-1000 nm. During the MARTE project, the spectrometer was deployed to the Rio
Tinto region of Spain. We analyzed subsets of 3 cores from Rio Tinto using a
new band modeling technique. We found most of the MARTE drill cores to contain
predominantly goethite, though spatially coherent areas of hematite were
identified in Core 23. We also distinguished non Fe-bearing minerals that were
subsequently analyzed by X-ray diffraction (XRD) and found to be primarily
muscovite. We present drill core maps that include spectra of goethite,
hematite, and non Fe-bearing minerals.
","Adrian J. Brown, Brad Sutter, Stephen Dunagan",Stephen Dunagan,2014-01-29T08:47:16Z
"A Non-Local Structure Tensor Based Approach for Multicomponent Image
  Recovery Problems","  Non-Local Total Variation (NLTV) has emerged as a useful tool in variational
methods for image recovery problems. In this paper, we extend the NLTV-based
regularization to multicomponent images by taking advantage of the Structure
Tensor (ST) resulting from the gradient of a multicomponent image. The proposed
approach allows us to penalize the non-local variations, jointly for the
different components, through various $\ell_{1,p}$ matrix norms with $p \ge 1$.
To facilitate the choice of the hyper-parameters, we adopt a constrained convex
optimization approach in which we minimize the data fidelity term subject to a
constraint involving the ST-NLTV regularization. The resulting convex
optimization problem is solved with a novel epigraphical projection method.
This formulation can be efficiently implemented thanks to the flexibility
offered by recent primal-dual proximal algorithms. Experiments are carried out
for multispectral and hyperspectral images. The results demonstrate the
interest of introducing a non-local structure tensor regularization and show
that the proposed approach leads to significant improvements in terms of
convergence speed over current state-of-the-art methods.
","Giovanni Chierchia, Nelly Pustelnik, Beatrice Pesquet-Popescu, Jean-Christophe Pesquet",Jean-Christophe Pesquet,2014-03-21T09:30:20Z
"A black phosphorus photo-detector for multispectral, high-resolution
  imaging","  Black phosphorus is a layered semiconductor that is intensely researched in
view of applications in optoelectronics. In this Letter, we investigate a
multi-layer black phosphorus photo-detector that is capable of acquiring
high-contrast (V>0.9) images both in the visible ({\lambda}_{VIS}=532nm) as
well as in the infrared ({\lambda}_{IR}=1550nm) spectral regime. In a first
step, by using photocurrent microscopy, we map the active area of the device
and we characterize responsivity and gain. In a second step, by deploying the
black phosphorus device as a point-like detector in a confocal microsope setup,
we acquire diffraction-limited optical images with sub-micron resolution. The
results demonstrate the usefulness of black phosphorus as an optoelectronic
material for hyperspectral imaging applications.
","Michael Engel, Mathias Steiner, Phaedon Avouris",Phaedon Avouris,2014-07-09T15:47:29Z
"Non-parametric Image Registration of Airborne LiDAR, Hyperspectral and
  Photographic Imagery of Forests","  There is much current interest in using multi-sensor airborne remote sensing
to monitor the structure and biodiversity of forests. This paper addresses the
application of non-parametric image registration techniques to precisely align
images obtained from multimodal imaging, which is critical for the successful
identification of individual trees using object recognition approaches.
Non-parametric image registration, in particular the technique of optimizing
one objective function containing data fidelity and regularization terms,
provides flexible algorithms for image registration. Using a survey of
woodlands in southern Spain as an example, we show that non-parametric image
registration can be successful at fusing datasets when there is little prior
knowledge about how the datasets are interrelated (i.e. in the absence of
ground control points). The validity of non-parametric registration methods in
airborne remote sensing is demonstrated by a series of experiments. Precise
data fusion is a prerequisite to accurate recognition of objects within
airborne imagery, so non-parametric image registration could make a valuable
contribution to the analysis pipeline.
","Juheon Lee, Xiaohao Cai, Carola-Bibiane Schonlieb, David Coomes",David Coomes,2014-07-28T11:21:57Z
"Evaluation of defects in cuprous oxide through exciton luminescence
  imaging","  The various decay mechanisms of excitons in cuprous oxide (Cu2O) are highly
sensitive to defects which can relax selection rules. Here we report cryogenic
hyperspectral imaging of exciton luminescence from cuprous oxide crystals grown
via the floating zone method showing the samples have few defects. Some
locations, however, show strain splitting of the 1s orthoexciton triplet
polariton luminescence. Strain is reduced by annealing. In addition, annealing
causes annihilation of oxygen and copper vacancies, which leads to a negative
correlation between luminescence of unlike vacancies.
","Laszlo Frazer, Erik J. Lenferink, Kelvin B. Chang, Kenneth R. Poeppelmeier, Nathaniel P. Stern, John B. Ketterson",John B. Ketterson,2014-12-08T19:24:00Z
"Bi-Objective Nonnegative Matrix Factorization: Linear Versus
  Kernel-Based Models","  Nonnegative matrix factorization (NMF) is a powerful class of feature
extraction techniques that has been successfully applied in many fields, namely
in signal and image processing. Current NMF techniques have been limited to a
single-objective problem in either its linear or nonlinear kernel-based
formulation. In this paper, we propose to revisit the NMF as a multi-objective
problem, in particular a bi-objective one, where the objective functions
defined in both input and feature spaces are taken into account. By taking the
advantage of the sum-weighted method from the literature of multi-objective
optimization, the proposed bi-objective NMF determines a set of nondominated,
Pareto optimal, solutions instead of a single optimal decomposition. Moreover,
the corresponding Pareto front is studied and approximated. Experimental
results on unmixing real hyperspectral images confirm the efficiency of the
proposed bi-objective NMF compared with the state-of-the-art methods.
","Paul Honeine, Fei Zhu",Fei Zhu,2015-01-22T22:59:47Z
"Robustness Analysis of Preconditioned Successive Projection Algorithm
  for General Form of Separable NMF Problem","  The successive projection algorithm (SPA) has been known to work well for
separable nonnegative matrix factorization (NMF) problems arising in
applications, such as topic extraction from documents and endmember detection
in hyperspectral images. One of the reasons is in that the algorithm is robust
to noise. Gillis and Vavasis showed in [SIAM J. Optim., 25(1), pp. 677-698,
2015] that a preconditioner can further enhance its noise robustness. The proof
rested on the condition that the dimension $d$ and factorization rank $r$ in
the separable NMF problem coincide with each other. However, it may be
unrealistic to expect that the condition holds in separable NMF problems
appearing in actual applications; in such problems, $d$ is usually greater than
$r$. This paper shows, without the condition $d=r$, that the preconditioned SPA
is robust to noise.
",Tomohiko Mizutani,Tomohiko Mizutani,2015-06-28T12:10:27Z
"A spatial compositional model (SCM) for linear unmixing and endmember
  uncertainty estimation","  The normal compositional model (NCM) has been extensively used in
hyperspectral unmixing. However, most of the previous research has focused on
estimation of endmembers and/or their variability. Also, little work has
employed spatial information in NCM. In this paper, we show that NCM can be
used for calculating the uncertainty of the estimated endmembers with spatial
priors incorporated for better unmixing. This results in a spatial
compositional model (SCM) which features (i) spatial priors that force
neighboring abundances to be similar based on their pixel similarity and (ii) a
posterior that is obtained from a likelihood model which does not assume pixel
independence. The resulting algorithm turns out to be easy to implement and
efficient to run. We compared SCM with current state-of-the-art algorithms on
synthetic and real images. The results show that SCM can in the main provide
more accurate endmembers and abundances. Moreover, the estimated uncertainty
can serve as a prediction of endmember error under certain conditions.
","Yuan Zhou, Anand Rangarajan, Paul Gader",Paul Gader,2015-09-30T16:24:45Z
"Ptychographic hyperspectral spectromicroscopy with an extreme
  ultraviolet high harmonic comb","  We demonstrate a new scheme of spectromicroscopy in the extreme ultraviolet
(EUV) spectral range, where the spectral response of the sample at different
wavelengths is imaged simultaneously. It is enabled by applying ptychographical
information multiplexing (PIM) to a tabletop EUV source based on high harmonic
generation, where four spectrally narrow harmonics near 30 nm form a spectral
comb structure. Extending PIM from previously demonstrated visible wavelengths
to the EUV/X-ray wavelengths promises much higher spatial resolution and more
powerful spectral contrast mechanism, making PIM an attractive
spectromicroscopy method in both the microscopy and the spectroscopy aspects.
Besides the sample, the multicolor EUV beam is also imaged in situ, making our
method a powerful beam characterization technique. No hardware is used to
separate or narrow down the wavelengths, leading to efficient use of the EUV
radiation.
","Bosheng Zhang, Dennis F. Gardner, Matthew H. Seaberg, Elisabeth R. Shanblatt, Christina L. Porter, Robert Karl, Jr., Christopher A. Mancuso, Henry C. Kapteyn, Margaret M. Murnane, Daniel E. Adams",Daniel E. Adams,2016-05-30T00:11:05Z
Resonant Thermoelectric Nanophotonics,"  Photodetectors are typically based on photocurrent generation from
electron-hole pairs in semiconductor structures and on bolometry for
wavelengths that are below bandgap absorption. In both cases, resonant
plasmonic and nanophotonic structures have been successfully used to enhance
performance. In this work, we demonstrate subwavelength thermoelectric
nanostructures designed for resonant spectrally selective absorption, which
creates large enough localized temperature gradients to generate easily
measureable thermoelectric voltages. We show that such structures are tunable
and are capable of highly wavelength specific detection, with an input power
responsivity of up to 119 V/W (referenced to incident illumination), and
response times of nearly 3 kHz, by combining resonant absorption and
thermoelectric junctions within a single structure, yielding a
bandgap-independent photodetection mechanism. We report results for both
resonant nanophotonic bismuth telluride-antimony telluride structures and
chromel-alumel structures as examples of a broad class of nanophotonic
thermoelectric structures useful for fast, low-cost and robust optoelectronic
applications such as non-bandgap-limited hyperspectral and broad-band
photodetectors.
","Kelly W. Mauser, Slobodan Mitrovic, Seyoon Kim, Dagny Fleischman, Harry A. Atwater",Harry A. Atwater,2016-06-10T13:15:08Z
"Composite Kernel Local Angular Discriminant Analysis for Multi-Sensor
  Geospatial Image Analysis","  With the emergence of passive and active optical sensors available for
geospatial imaging, information fusion across sensors is becoming ever more
important. An important aspect of single (or multiple) sensor geospatial image
analysis is feature extraction - the process of finding ""optimal"" lower
dimensional subspaces that adequately characterize class-specific information
for subsequent analysis tasks, such as classification, change and anomaly
detection etc. In recent work, we proposed and developed an angle-based
discriminant analysis approach that projected data onto subspaces with maximal
""angular"" separability in the input (raw) feature space and Reproducible Kernel
Hilbert Space (RKHS). We also developed an angular locality preserving variant
of this algorithm. In this letter, we advance this work and make it suitable
for information fusion - we propose and validate a composite kernel local
angular discriminant analysis projection, that can operate on an ensemble of
feature sources (e.g. from different sources), and project the data onto a
unified space through composite kernels where the data are maximally separated
in an angular sense. We validate this method with the multi-sensor University
of Houston hyperspectral and LiDAR dataset, and demonstrate that the proposed
method significantly outperforms other composite kernel approaches to sensor
(information) fusion.
","Saurabh Prasad, Minshan Cui, Lifeng Yan",Lifeng Yan,2016-07-18T02:50:40Z
"Sparse Representation-Based Classification: Orthogonal Least Squares or
  Orthogonal Matching Pursuit?","  Spare representation of signals has received significant attention in recent
years. Based on these developments, a sparse representation-based
classification (SRC) has been proposed for a variety of classification and
related tasks, including face recognition. Recently, a class dependent variant
of SRC was proposed to overcome the limitations of SRC for remote sensing image
classification. Traditionally, greedy pursuit based method such as orthogonal
matching pursuit (OMP) are used for sparse coefficient recovery due to their
simplicity as well as low time-complexity. However, orthogonal least square
(OLS) has not yet been widely used in classifiers that exploit the sparse
representation properties of data. Since OLS produces lower signal
reconstruction error than OMP under similar conditions, we hypothesize that
more accurate signal estimation will further improve the classification
performance of classifiers that exploiting the sparsity of data. In this paper,
we present a classification method based on OLS, which implements OLS in a
classwise manner to perform the classification. We also develop and present its
kernelized variant to handle nonlinearly separable data. Based on two
real-world benchmarking hyperspectral datasets, we demonstrate that class
dependent OLS based methods outperform several baseline methods including
traditional SRC and the support vector machine classifier.
","Minshan Cui, Saurabh Prasad",Saurabh Prasad,2016-07-18T03:05:07Z
"Understanding the Plasmonics of Nanostructured Atomic Force Microscopy
  Tips","  Structured metallic tips are increasingly important for optical
spectroscopies such as tip-enhanced Raman spectroscopy (TERS), with plasmonic
resonances frequently cited as a mechanism for electric field enhancement. We
probe the local optical response of sharp and spherical-tipped atomic force
microscopy (AFM) tips using a scanning hyperspectral imaging technique to
identify plasmonic behaviour. Localised surface plasmon resonances which
radiatively couple with far-field light are found only for spherical AFM tips,
with little response for sharp AFM tips, in agreement with numerical
simulations of the near-field response. The precise tip geometry is thus
crucial for plasmon-enhanced spectroscopies, and the typical sharp cones are
not preferred.
","Alan Sanders, Richard W. Bowman, Liwu Zhang, Vladimir Turek, Daniel O. Sigle, Anna Lombardi, Lee Weller, Jeremy J. Baumberg",Jeremy J. Baumberg,2016-07-22T08:31:57Z
"Robust Volume Minimization-Based Matrix Factorization for Remote Sensing
  and Document Clustering","  This paper considers \emph{volume minimization} (VolMin)-based structured
matrix factorization (SMF). VolMin is a factorization criterion that decomposes
a given data matrix into a basis matrix times a structured coefficient matrix
via finding the minimum-volume simplex that encloses all the columns of the
data matrix. Recent work showed that VolMin guarantees the identifiability of
the factor matrices under mild conditions that are realistic in a wide variety
of applications. This paper focuses on both theoretical and practical aspects
of VolMin. On the theory side, exact equivalence of two independently developed
sufficient conditions for VolMin identifiability is proven here, thereby
providing a more comprehensive understanding of this aspect of VolMin. On the
algorithm side, computational complexity and sensitivity to outliers are two
key challenges associated with real-world applications of VolMin. These are
addressed here via a new VolMin algorithm that handles volume regularization in
a computationally simple way, and automatically detects and {iteratively
downweights} outliers, simultaneously. Simulations and real-data experiments
using a remotely sensed hyperspectral image and the Reuters document corpus are
employed to showcase the effectiveness of the proposed algorithm.
","Xiao Fu, Kejun Huang, Bo Yang, Wing-Kin Ma, Nicholas D. Sidiropoulos",Nicholas D. Sidiropoulos,2016-08-15T14:51:10Z
"Tailoring correlations of the local density of states in disordered
  photonic materials","  We present experimental evidence for the different mechanisms driving the
fluctuations of the local density of states (LDOS) in disordered photonic
systems. We establish a clear link between the microscopic structure of the
material and the frequency correlation function of LDOS accessed by a
near-field hyperspectral imaging technique. We show, in particular, that short-
and long-range frequency correlations of LDOS are controlled by different
physical processes (multiple or single scattering processes, respectively) that
can be---to some extent---manipulated independently. We also demonstrate that
the single scattering contribution to LDOS fluctuations is sensitive to
subwavelength features of the material and, in particular, to the correlation
length of its dielectric function. Our work paves a way towards a complete
control of statistical properties of disordered photonic systems, allowing for
designing materials with predefined correlations of LDOS.
","F. Riboli, F. Uccheddu, G. Monaco, N. Caselli, F. Intonti, M. Gurioli, S. E. Skipetrov",S. E. Skipetrov,2016-09-07T13:32:07Z
"A Fast Gradient Method for Nonnegative Sparse Regression with Self
  Dictionary","  A nonnegative matrix factorization (NMF) can be computed efficiently under
the separability assumption, which asserts that all the columns of the given
input data matrix belong to the cone generated by a (small) subset of them. The
provably most robust methods to identify these conic basis columns are based on
nonnegative sparse regression and self dictionaries, and require the solution
of large-scale convex optimization problems. In this paper we study a
particular nonnegative sparse regression model with self dictionary. As opposed
to previously proposed models, this model yields a smooth optimization problem
where the sparsity is enforced through linear constraints. We show that the
Euclidean projection on the polyhedron defined by these constraints can be
computed efficiently, and propose a fast gradient method to solve our model. We
compare our algorithm with several state-of-the-art methods on synthetic data
sets and real-world hyperspectral images.
","Nicolas Gillis, Robert Luce",Robert Luce,2016-10-05T10:29:10Z
Hyper-Selective Plasmonic Color Filters,"  The subwavelength mode volumes of plasmonic filters are well matched to the
small size of state-of-the-art active pixels (~ 1 {\mu}m) in CMOS image sensor
arrays used in portable electronic devices. Typical plasmonic filters exhibit
broad (> 100 nm) transmission bandwidths. Dramatically reducing the peak width
of filter transmission spectra would allow for the realization of CMOS
hyperspectral imaging arrays, which demand the FWHM of transmission peaks to be
less than 30 nm. We find that the design of 5 layer
metal-insulator-metal-insulator-metal structures gives rise to multi-mode
interference phenomena that suppresses spurious transmission features gives
rise to a single narrow transmission band with FWHM as small as 17 nm. The
transmission peaks of these multilayer slot-mode plasmonic filters (MSPFs) can
be systematically varied throughout the visible and near infrared spectrum, so
the same basic structure can serve as a filter over a large range of
wavelengths.
","Dagny Fleischman, Luke Sweatlock, Hirotaka Murakami, Harry Atwater",Harry Atwater,2016-12-06T03:09:03Z
"Nanobubble induced formation of quantum emitters in monolayer
  semiconductors","  The recent discovery of exciton quantum emitters in transition metal
dichalcogenides (TMDCs) has triggered renewed interest of localized excitons in
low-dimensional systems. Open questions remain about the microscopic origin
previously attributed to dopants and/or defects as well as strain potentials.
Here we show that the quantum emitters can be deliberately induced by
nanobubble formation in WSe2 and BN/WSe2 heterostructures. Correlations of
atomic-force microscope and hyperspectral photoluminescence images reveal that
the origin of quantum emitters and trion disorder is extrinsic and related to
10 nm tall nanobubbles and 70 nm tall wrinkles, respectively. We further
demonstrate that hot stamping results in the absence of 0D quantum emitters and
trion disorder. The demonstrated technique is useful for advances in nanolasers
and deterministic formation of cavity-QED systems in monolayer materials.
","Gabriella D. Shepard, Obafunso Ajayi, Xiangzhi Li, X. -Y. Zhu, James Hone, Stefan Strauf",Stefan Strauf,2016-12-19T21:22:54Z
Deep Blind Compressed Sensing,"  This work addresses the problem of extracting deeply learned features
directly from compressive measurements. There has been no work in this area.
Existing deep learning tools only give good results when applied on the full
signal, that too usually after preprocessing. These techniques require the
signal to be reconstructed first. In this work we show that by learning
directly from the compressed domain, considerably better results can be
obtained. This work extends the recently proposed framework of deep matrix
factorization in combination with blind compressed sensing; hence the term deep
blind compressed sensing. Simulation experiments have been carried out on
imaging via single pixel camera, under-sampled biomedical signals, arising in
wireless body area network and compressive hyperspectral imaging. In all cases,
the superiority of our proposed deep blind compressed sensing can be envisaged.
","Shikha Singh, Vanika Singhal, Angshul Majumdar",Angshul Majumdar,2016-12-22T06:12:43Z
"Understanding Non-optical Remote-sensed Images: Needs, Challenges and
  Ways Forward","  Non-optical remote-sensed images are going to be used more often in man-
aging disaster, crime and precision agriculture. With more small satellites and
unmanned air vehicles planning to carry radar and hyperspectral image sensors
there is going to be an abundance of such data in the recent future.
Understanding these data in real-time will be crucial in attaining some of the
important sustain- able development goals. Processing non-optical images is, in
many ways, different from that of optical images. Most of the recent advances
in the domain of image understanding has been using optical images. In this
article we shall explain the needs for image understanding in non-optical
domain and the typical challenges. Then we shall describe the existing
approaches and how we can move from there to the desired goal of a reliable
real-time image understanding system.
",Amit Kumar Mishra,Amit Kumar Mishra,2016-12-23T10:17:00Z
"Rank-One NMF-Based Initialization for NMF and Relative Error Bounds
  under a Geometric Assumption","  We propose a geometric assumption on nonnegative data matrices such that
under this assumption, we are able to provide upper bounds (both deterministic
and probabilistic) on the relative error of nonnegative matrix factorization
(NMF). The algorithm we propose first uses the geometric assumption to obtain
an exact clustering of the columns of the data matrix; subsequently, it employs
several rank-one NMFs to obtain the final decomposition. When applied to data
matrices generated from our statistical model, we observe that our proposed
algorithm produces factor matrices with comparable relative errors vis-\`a-vis
classical NMF algorithms but with much faster speeds. On face image and
hyperspectral imaging datasets, we demonstrate that our algorithm provides an
excellent initialization for applying other NMF algorithms at a low
computational cost. Finally, we show on face and text datasets that the
combinations of our algorithm and several classical NMF algorithms outperform
other algorithms in terms of clustering performance.
","Zhaoqiang Liu, Vincent Y. F. Tan",Vincent Y. F. Tan,2016-12-27T09:27:10Z
Scene-adapted plug-and-play algorithm with convergence guarantees,"  Recent frameworks, such as the so-called plug-and-play, allow us to leverage
the developments in image denoising to tackle other, and more involved,
problems in image processing. As the name suggests, state-of-the-art denoisers
are plugged into an iterative algorithm that alternates between a denoising
step and the inversion of the observation operator. While these tools offer
flexibility, the convergence of the resulting algorithm may be difficult to
analyse. In this paper, we plug a state-of-the-art denoiser, based on a
Gaussian mixture model, in the iterations of an alternating direction method of
multipliers and prove the algorithm is guaranteed to converge. Moreover, we
build upon the concept of scene-adapted priors where we learn a model targeted
to a specific scene being imaged, and apply the proposed method to address the
hyperspectral sharpening problem.
","Afonso M. Teodoro, José M. Bioucas-Dias, Mário A. T. Figueiredo",Mário A. T. Figueiredo,2017-02-08T14:42:05Z
Derivate-based Component-Trees for Multi-Channel Image Segmentation,"  We introduce the concept of derivate-based component-trees for images with an
arbitrary number of channels. The approach is a natural extension of the
classical component-tree devoted to gray-scale images. The similar structure
enables the translation of many gray-level image processing techniques based on
the component-tree to hyperspectral and color images. As an example
application, we present an image segmentation approach that extracts Maximally
Stable Homogeneous Regions (MSHR). The approach very similar to MSER but can be
applied to images with an arbitrary number of channels. As opposed to MSER, our
approach implicitly segments regions with are both lighter and darker than
their background for gray-scale images and can be used in OCR applications
where MSER will fail. We introduce a local flooding-based immersion for the
derivate-based component-tree construction which is linear in the number of
pixels. In the experiments, we show that the runtime scales favorably with an
increasing number of channels and may improve algorithms which build on MSER.
","Tobias Böttger, Dominik Gutermuth",Dominik Gutermuth,2017-05-04T16:51:33Z
"Joint Learning from Earth Observation and OpenStreetMap Data to Get
  Faster Better Semantic Maps","  In this work, we investigate the use of OpenStreetMap data for semantic
labeling of Earth Observation images. Deep neural networks have been used in
the past for remote sensing data classification from various sensors, including
multispectral, hyperspectral, SAR and LiDAR data. While OpenStreetMap has
already been used as ground truth data for training such networks, this
abundant data source remains rarely exploited as an input information layer. In
this paper, we study different use cases and deep network architectures to
leverage OpenStreetMap data for semantic labeling of aerial and satellite
images. Especially , we look into fusion based architectures and coarse-to-fine
segmentation to include the OpenStreetMap layer into multispectral-based deep
fully convolutional networks. We illustrate how these methods can be
successfully used on two public datasets: ISPRS Potsdam and DFC2017. We show
that OpenStreetMap data can efficiently be integrated into the vision-based
deep learning models and that it significantly improves both the accuracy
performance and the convergence speed of the networks.
","Nicolas Audebert, Bertrand Le Saux, Sébastien Lefèvre",Sébastien Lefèvre,2017-05-17T09:07:08Z
Unsupervised Feature Selection Based on Space Filling Concept,"  The paper deals with the adaptation of a new measure for the unsupervised
feature selection problems. The proposed measure is based on space filling
concept and is called the coverage measure. This measure was used for judging
the quality of an experimental space filling design. In the present work, the
coverage measure is adapted for selecting the smallest informative subset of
variables by reducing redundancy in data. This paper proposes a simple analogy
to apply this measure. It is implemented in a filter algorithm for unsupervised
feature selection problems.
  The proposed filter algorithm is robust with high dimensional data and can be
implemented without extra parameters. Further, it is tested with simulated data
and real world case studies including environmental data and hyperspectral
image. Finally, the results are evaluated by using random forest algorithm.
","Mohamed Laib, Mikhail Kanevski",Mikhail Kanevski,2017-06-27T14:48:39Z
Efficiently Tracking Homogeneous Regions in Multichannel Images,"  We present a method for tracking Maximally Stable Homogeneous Regions (MSHR)
in images with an arbitrary number of channels. MSHR are conceptionally very
similar to Maximally Stable Extremal Regions (MSER) and Maximally Stable Color
Regions (MSCR), but can also be applied to hyperspectral and color images while
remaining extremely efficient. The presented approach makes use of the
edge-based component-tree which can be calculated in linear time. In the
tracking step, the MSHR are localized by matching them to the nodes in the
component-tree. We use rotationally invariant region and gray-value features
that can be calculated through first and second order moments at low
computational complexity. Furthermore, we use a weighted feature vector to
improve the data association in the tracking step. The algorithm is evaluated
on a collection of different tracking scenes from the literature. Furthermore,
we present two different applications: 2D object tracking and the 3D
segmentation of organs.
","Tobias Böttger, Christina Eisenhofer",Christina Eisenhofer,2017-08-16T08:30:47Z
"One-step deposition and in-situ reduction of graphene oxide in glass
  microcapillaries and application to photonics","  Films of graphene oxide (GO) were produced on the inner walls of glass
microcapillaries via insertion of a GO water suspension followed by quick
drying with a hot finger (no previous surface functionalization required).
Individual capillaries from an array could also be selectively GO coated. Raman
hyperspectral images revealed the films to be continuous along tens of
centimeters. Furthermore, the films could be thermally reduced through an
annealing process, which also decreased the concentration of defects. As a
proof of principle application, the microcapillaries of photonic crystal fibers
were covered with a GO film, leading to the demonstration of fiber polarizers
and mode lockers for pulsed fiber lasers. A comparison between GO- and reduced
GO-coated fibers revealed that shorter pulses are obtained with the latter.
","Rodrigo M. Gerosa, Felipe G. Suarez, Sergio H. Domingues, Christiano J. S. de Matos",Christiano J. S. de Matos,2017-08-23T11:11:34Z
"Structured Low-Rank Matrix Factorization: Global Optimality, Algorithms,
  and Applications","  Recently, convex formulations of low-rank matrix factorization problems have
received considerable attention in machine learning. However, such formulations
often require solving for a matrix of the size of the data matrix, making it
challenging to apply them to large scale datasets. Moreover, in many
applications the data can display structures beyond simply being low-rank,
e.g., images and videos present complex spatio-temporal structures that are
largely ignored by standard low-rank methods. In this paper we study a matrix
factorization technique that is suitable for large datasets and captures
additional structure in the factors by using a particular form of
regularization that includes well-known regularizers such as total variation
and the nuclear norm as particular cases. Although the resulting optimization
problem is non-convex, we show that if the size of the factors is large enough,
under certain conditions, any local minimizer for the factors yields a global
minimizer. A few practical algorithms are also provided to solve the matrix
factorization problem, and bounds on the distance from a given approximate
solution of the optimization problem to the global optimum are derived.
Examples in neural calcium imaging video segmentation and hyperspectral
compressed recovery show the advantages of our approach on high-dimensional
datasets.
","Benjamin D. Haeffele, Rene Vidal",Rene Vidal,2017-08-25T18:14:44Z
"Surface temperatures in New York City: Geospatial data enables the
  accurate prediction of radiative heat transfer","  Three decades into the research seeking to derive the urban energy budget,
the dynamics of the thermal exchange between the densely built infrastructure
and the environment are still not well understood. We present a novel hybrid
experimental-numerical approach for the analysis of the radiative heat transfer
in New York City. The aim of this work is to contribute to the calculation of
the urban energy budget, in particular the stored energy. Improved
understanding of urban thermodynamics incorporating the interaction of the
various bodies will have implications on energy conservation at the building
scale, as well as human health and comfort at the urban scale. The platform
presented is based on longwave hyperspectral imaging of nearly 100 blocks of
Manhattan, and a geospatial radiosity model that describes the collective
radiative heat exchange between multiple buildings. The close comparison of
temperature values derived from measurements and the computed surface
temperatures (including streets and roads) implies that this geospatial,
thermodynamic numerical model applied to urban structures, is promising for
accurate and high resolution analysis of urban surface temperatures.
","Masoud Ghandehari, Thorsten Emig, Milad Aghamohamadnia",Milad Aghamohamadnia,2017-08-27T13:49:08Z
"Multilevel Illumination Coding for Fourier Transform Interferometry in
  Fluorescence Spectroscopy","  Fourier Transform Interferometry (FTI) is an interferometric procedure for
acquiring HyperSpectral (HS) data. Recently, it has been observed that the
light source highlighting a (biologic) sample can be coded before the FTI
acquisition in a procedure called Coded Illumination-FTI (CI-FTI). This turns
HS data reconstruction into a Compressive Sensing (CS) problem regularized by
the sparsity of the HS data. CI-FTI combines the high spectral resolution of
FTI with the advantages of reduced-light-exposure imaging in biology.
  In this paper, we leverage multilevel sampling scheme recently developed in
CS theory to adapt the coding strategy of CI-FTI to the spectral sparsity
structure of HS data in Fluorescence Spectroscopy (FS). This structure is
actually extracted from the spectral signatures of actual fluorescent dyes used
in FS. Accordingly, the optimum illumination coding as well as the theoretical
recovery guarantee are derived. We conduct numerous numerical experiments on
synthetic and experimental data that show the faithfulness of the proposed
theory to experimental observations.
","Amirafshar Moshtaghpour, Laurent Jacques",Laurent Jacques,2018-03-08T17:37:35Z
"Low-Shot Learning for the Semantic Segmentation of Remote Sensing
  Imagery","  Recent advances in computer vision using deep learning with RGB imagery
(e.g., object recognition and detection) have been made possible thanks to the
development of large annotated RGB image datasets. In contrast, multispectral
image (MSI) and hyperspectral image (HSI) datasets contain far fewer labeled
images, in part due to the wide variety of sensors used. These annotations are
especially limited for semantic segmentation, or pixel-wise classification, of
remote sensing imagery because it is labor intensive to generate image
annotations. Low-shot learning algorithms can make effective inferences despite
smaller amounts of annotated data. In this paper, we study low-shot learning
using self-taught feature learning for semantic segmentation. We introduce 1)
an improved self-taught feature learning framework for HSI and MSI data and 2)
a semi-supervised classification algorithm. When these are combined, they
achieve state-of-the-art performance on remote sensing datasets that have
little annotated training data available. These low-shot learning frameworks
will reduce the manual image annotation burden and improve semantic
segmentation performance for remote sensing imagery.
","Ronald Kemker, Ryan Luu, Christopher Kanan",Christopher Kanan,2018-03-26T20:17:19Z
Residuum-Condition Diagram and Reduction of Over-Complete Endmember-Sets,"  Extracting reference spectra, or endmembers (EMs) from a given multi- or
hyperspectral image, as well as estimating the size of the EM set, plays an
important role in multispectral image processing. In this paper, we present
condition-residuum-diagrams. By plotting the residuum resulting from the
unmixing and reconstruction and the condition number of various EM sets, the
resulting diagram provides insight into the behavior of the spectral unmixing
under a varying amount of endmembers (EMs). Furthermore, we utilize
condition-residuum-diagrams to realize an EM reduction algorithm that starts
with an initially extracted, over-complete EM set. An over-complete EM set
commonly exhibits a good unmixing result, i.e. a lower reconstruction residuum,
but due to its partial redundancy, the unmixing gets numerically unstable, i.e.
the unmixed abundances values are less reliable. Our greedy reduction scheme
improves the EM set by reducing the condition number, i.e. enhancing the set's
stability, while keeping the reconstruction error as low as possible. The
resulting set sequence gives hint to the optimal EM set and its size. We
demonstrate the benefit of our condition-residuum-diagram and reduction scheme
on well-studied datasets with known reference EM set sizes for several
well-known EE algorithms.
","Christoph Schikora, Markus Plack, Andreas Kolb",Andreas Kolb,2018-09-26T16:01:11Z
"Snapshot fiber spectral imaging using speckle correlations and
  compressive sensing","  Snapshot spectral imaging is rapidly gaining interest for remote sensing
applications. Acquiring spatial and spectral data within one image promotes
fast measurement times, and reduces the need for stabilized scanning imaging
systems. Many current snapshot technologies, which rely on gratings or prisms
to characterize wavelength information, are difficult to reduce in size for
portable hyperspectral imaging. Here, we show that a multicore multimode fiber
can be used as a compact spectral imager with sub-nanometer resolution, by
encoding spectral information within a monochrome CMOS camera. We characterize
wavelength-dependent speckle patterns for up to 3000 fiber cores over a broad
wavelength range. A clustering algorithm is employed in combination with
l$_{1}$-minimization to limit data collection at the acquisition stage for the
reconstruction of spectral images that are sparse in the wavelength domain. We
also show that in the non-compressive regime these techniques are able to
accurately reconstruct broadband information.
","Rebecca French, Sylvain Gigan, Otto L. Muskens",Otto L. Muskens,2018-10-24T16:58:26Z
"Compressive Single-pixel Fourier Transform Imaging using Structured
  Illumination","  Single Pixel (SP) imaging is now a reality in many applications, e.g.,
biomedical ultrathin endoscope and fluorescent spectroscopy. In this context,
many schemes exist to improve the light throughput of these device, e.g., using
structured illumination driven by compressive sensing theory. In this work, we
consider the combination of SP imaging with Fourier Transform Interferometry
(SP-FTI) to reach high-resolution HyperSpectral (HS) imaging, as desirable,
e.g., in fluorescent spectroscopy. While this association is not new, we here
focus on optimizing the spatial illumination, structured as Hadamard patterns,
during the optical path progression. We follow a variable density sampling
strategy for space-time coding of the light illumination, and show
theoretically and numerically that this scheme allows us to reduce the number
of measurements and light-exposure of the observed object compared to
conventional compressive SP-FTI.
","Amirafshar Moshtaghpour, José M. Bioucas-Dias, Laurent Jacques",Laurent Jacques,2018-10-31T10:29:07Z
Fast High-Dimensional Bilateral and Nonlocal Means Filtering,"  Existing fast algorithms for bilateral and nonlocal means filtering mostly
work with grayscale images. They cannot easily be extended to high-dimensional
data such as color and hyperspectral images, patch-based data, flow-fields,
etc. In this paper, we propose a fast algorithm for high-dimensional bilateral
and nonlocal means filtering. Unlike existing approaches, where the focus is on
approximating the data (using quantization) or the filter kernel (via analytic
expansions), we locally approximate the kernel using weighted and shifted
copies of a Gaussian, where the weights and shifts are inferred from the data.
The algorithm emerging from the proposed approximation essentially involves
clustering and fast convolutions, and is easy to implement. Moreover, a variant
of our algorithm comes with a guarantee (bound) on the approximation error,
which is not enjoyed by existing algorithms. We present some results for
high-dimensional bilateral and nonlocal means filtering to demonstrate the
speed and accuracy of our proposal. Moreover, we also show that our algorithm
can outperform state-of-the-art fast approximations in terms of accuracy and
timing.
","Pravin Nair, Kunal. N. Chaudhury",Kunal. N. Chaudhury,2018-11-06T14:20:35Z
Towards Spectral Estimation from a Single RGB Image in the Wild,"  In contrast to the current literature, we address the problem of estimating
the spectrum from a single common trichromatic RGB image obtained under
unconstrained settings (e.g. unknown camera parameters, unknown scene radiance,
unknown scene contents). For this we use a reference spectrum as provided by a
hyperspectral image camera, and propose efficient deep learning solutions for
sensitivity function estimation and spectral reconstruction from a single RGB
image. We further expand the concept of spectral reconstruction such that to
work for RGB images taken in the wild and propose a solution based on a
convolutional network conditioned on the estimated sensitivity function.
Besides the proposed solutions, we study also generic and sensitivity
specialized models and discuss their limitations. We achieve state-of-the-art
competitive results on the standard example-based spectral reconstruction
benchmarks: ICVL, CAVE, NUS and NTIRE. Moreover, our experiments show that, for
the first time, accurate spectral estimation from a single RGB image in the
wild is within our reach.
","Berk Kaya, Yigit Baran Can, Radu Timofte",Radu Timofte,2018-12-03T14:58:26Z
"Randomized Tensor Ring Decomposition and Its Application to Large-scale
  Data Reconstruction","  Dimensionality reduction is an essential technique for multi-way large-scale
data, i.e., tensor. Tensor ring (TR) decomposition has become popular due to
its high representation ability and flexibility. However, the traditional TR
decomposition algorithms suffer from high computational cost when facing
large-scale data. In this paper, taking advantages of the recently proposed
tensor random projection method, we propose two TR decomposition algorithms. By
employing random projection on every mode of the large-scale tensor, the TR
decomposition can be processed at a much smaller scale. The simulation
experiment shows that the proposed algorithms are $4-25$ times faster than
traditional algorithms without loss of accuracy, and our algorithms show
superior performance in deep learning dataset compression and hyperspectral
image reconstruction experiments compared to other randomized algorithms.
","Longhao Yuan, Chao Li, Jianting Cao, Qibin Zhao",Qibin Zhao,2019-01-07T03:01:06Z
Common Mode Patterns for Supervised Tensor Subspace Learning,"  In this work we propose a method for reducing the dimensionality of tensor
objects in a binary classification framework. The proposed Common Mode Patterns
method takes into consideration the labels' information, and ensures that
tensor objects that belong to different classes do not share common features
after the reduction of their dimensionality. We experimentally validate the
proposed supervised subspace learning technique and compared it against
Multilinear Principal Component Analysis using a publicly available
hyperspectral imaging dataset. Experimental results indicate that the proposed
CMP method can efficiently reduce the dimensionality of tensor objects, while,
at the same time, increasing the inter-class separability.
","Konstantinos Makantasis, Anastasios Doulamis, Nikolaos Doulamis, Athanasios Voulodimos",Athanasios Voulodimos,2019-02-06T09:15:02Z
Nanoscale optical and structural characterisation of silk,"  Background: Nanoscale composition of silk defining its unique properties via
a hierarchical structural anisotropy has to be analysed at the highest spatial
resolution of tens-of-nanometers corresponding to the size of fibrils made of
b-sheets, which are the crystalline building blocks of silk. Results: Nanoscale
optical and structural properties of silk have been measured from 100-nm thick
longitudinal slices of silk fibers with ~10 nm resolution, the highest so far.
Optical sub-wavelength resolution in hyperspectral mapping of absorbance and
molecular orientation were carried out for comparison at IR wavelengths 2-10
micrometers using synchrotron radiation. Conclusion: Reliable distinction of
transmission changes by only 1-2% due to anisotropy of amide bands was obtained
from nano-thin slices of silk.
","Meguya Ryu, Reo Honda, Adrian Cernescu, Arturas Vailionis, Armandas Balcytis, Jitraporn Vongsvivut, Jing-Liang Li, Denver P. Linklater, Elena P. Ivanova, Vygantas Mizeikis, Mark J. Tobin, Junko Morikawa, Saulius Juodkazis",Saulius Juodkazis,2019-02-07T15:32:46Z
"Signatures of defect-localized charged excitons in the photoluminescence
  of monolayer molybdenum disulfide","  We study spatial photoluminescence characteristics of neutral and charged
excitons across extended monolayer MoS$_2$ synthesized by chemical vapor
deposition. Using two-dimensional hyperspectral photoluminescence mapping at
cryogenic temperatures we identify regions with increased emission from charged
excitons associated with both spin-orbit split valence subbands. Such regions
are attributed to unintentional doping at defect sites with excess charge that
bind neutral excitons to form defect-pinned trions. Our findings imply
comparable timescales for the formation, relaxation, and radiative decay of $B$
trions, and add defect-localized $A$ and $B$ trions to the realm of
photoexcited quasiparticles in layered semiconductors.
","Andre Neumann, Jessica Lindlau, Manuel Nutz, Aditya D. Mohite, Hisato Yamaguchi, Alexander Högele",Alexander Högele,2019-02-19T03:09:33Z
"Comparison of Possibilistic Fuzzy Local Information C-Means and
  Possibilistic K-Nearest Neighbors for Synthetic Aperture Sonar Image
  Segmentation","  Synthetic aperture sonar (SAS) imagery can generate high resolution images of
the seafloor. Thus, segmentation algorithms can be used to partition the images
into different seafloor environments. In this paper, we compare two
possibilistic segmentation approaches. Possibilistic approaches allow for the
ability to detect novel or outlier environments as well as well known classes.
The Possibilistic Fuzzy Local Information C-Means (PFLICM) algorithm has been
previously applied to segment SAS imagery. Additionally, the Possibilistic
K-Nearest Neighbors (PKNN) algorithm has been used in other domains such as
landmine detection and hyperspectral imagery. In this paper, we compare the
segmentation performance of a semi-supervised approach using PFLICM and a
supervised method using Possibilistic K-NN. We include final segmentation
results on multiple SAS images and a quantitative assessment of each algorithm.
","Joshua Peeples, Matthew Cook, Daniel Suen, Alina Zare, James Keller",James Keller,2019-04-01T16:18:28Z
"T-SVD Based Non-convex Tensor Completion and Robust Principal Component
  Analysis","  Tensor completion and robust principal component analysis have been widely
used in machine learning while the key problem relies on the minimization of a
tensor rank that is very challenging. A common way to tackle this difficulty is
to approximate the tensor rank with the $\ell_1-$norm of singular values based
on its Tensor Singular Value Decomposition (T-SVD). Besides, the sparsity of a
tensor is also measured by its $\ell_1-$norm. However, the $\ell_1$ penalty is
essentially biased and thus the result will deviate. In order to sidestep the
bias, we propose a novel non-convex tensor rank surrogate function and a novel
non-convex sparsity measure. In this new setting by using the concavity instead
of the convexity, a majorization minimization algorithm is further designed for
tensor completion and robust principal component analysis. Furthermore, we
analyze its theoretical properties. Finally, the experiments on natural and
hyperspectral images demonstrate the efficacy and efficiency of our proposed
method.
","Tao Li, Jinwen Ma",Jinwen Ma,2019-04-23T06:09:27Z
Optimal low rank tensor recovery,"  We investigate the sample size requirement for exact recovery of a high order
tensor of low rank from a subset of its entries. In the Tucker decomposition
framework, we show that the Riemannian optimization algorithm with initial
value obtained from a spectral method can reconstruct a tensor of size $n\times
n \times\cdots \times n$ tensor of ranks $(r,\cdots,r)$ with high probability
from as few as $O((r^d+dnr)\log(d))$ entries. In the case of order 3 tensor,
the entries can be asymptotically as few as $O(nr)$ for a low rank large
tensor. We show the theoretical guarantee condition for the recovery. The
analysis relies on the tensor restricted isometry property (tensor RIP) and the
curvature of the low rank tensor manifold. Our algorithm is computationally
efficient and easy to implement. Numerical results verify that the algorithms
are able to recover a low rank tensor from minimum number of measurements. The
experiments on hyperspectral images recovery also show that our algorithm is
capable of real world signal processing problems.
","Jian-Feng Cai, Lizhang Miao, Yang Wang, Yin Xian",Yin Xian,2019-06-12T19:37:40Z
"Determination of the carrier diffusion length in GaN from
  cathodoluminescence maps around threading dislocations: fallacies and
  opportunities","  We investigate, both theoretically and experimentally, the drift, diffusion,
and recombination of excitons in the strain field of an edge threading
dislocation intersecting the GaN{0001} surface. We calculate and measure
hyperspectral cathodoluminescence maps around the dislocation outcrop for
temperatures between 10 to 200 K. Contrary to common belief, the
cathodoluminescence intensity contrast is only weakly affected by exciton
diffusion, but is caused primarily by exciton dissociation in the piezoelectric
field at the dislocation outcrop. Hence, the extension of the dark spots around
dislocations in the luminescence maps cannot be used to determine the exciton
diffusion length. However, the cathodoluminescence energy contrast, reflecting
the local bandgap variation in the dislocation strain field, does sensitively
depend on the exciton diffusion length and hence enables its experimental
determination.
","Vladimir M. Kaganer, Jonas Lähnemann, Carsten Pfüller, Karl K. Sabelfeld, Anastasya E. Kireeva, Oliver Brandt",Oliver Brandt,2019-06-13T13:02:12Z
Robust Tensor Completion Using Transformed Tensor SVD,"  In this paper, we study robust tensor completion by using transformed tensor
singular value decomposition (SVD), which employs unitary transform matrices
instead of discrete Fourier transform matrix that is used in the traditional
tensor SVD. The main motivation is that a lower tubal rank tensor can be
obtained by using other unitary transform matrices than that by using discrete
Fourier transform matrix. This would be more effective for robust tensor
completion. Experimental results for hyperspectral, video and face datasets
have shown that the recovery performance for the robust tensor completion
problem by using transformed tensor SVD is better in PSNR than that by using
Fourier transform and other robust tensor completion methods.
","Guangjing Song, Michael K. Ng, Xiongjun Zhang",Xiongjun Zhang,2019-07-02T00:50:31Z
"Super-localization of excitons in carbon nanotubes at cryogenic
  temperature","  At cryogenic temperature and at the single emitter level, the optical
properties of single-wall carbon nanotubes depart drastically from that of a
one-dimensional (1D) object. In fact, the (usually unintentional) localization
of excitons in local potential wells leads to nearly 0D behaviors such as
photon antibunching, spectral diffusion, inhomogeneous broadening, etc. Here,
we present an hyperspectral imaging of this exciton self-localization effect at
the single nanotube level using a super-resolved optical microscopy approach.
We report on the statistical distribution of the traps localization, depth and
width. We use a quasi-resonant photoluminescence excitation approach to probe
the confined quantum states. Numerical simulations of the quantum states and
exciton diffusion show that the excitonic states are deeply modified by the
interface disorder inducing a remarkable discretization of the excitonic
absorption spectrum and a quenching of the free 1D exciton absorption.
","Christophe Raynaud, Théo Claude, Antoine Borel, Mohamed-Raouf Amara, Arko Graf, Jana Zaumseil, Jean-Sébastien Lauret, Yannick Chassagneux, Christophe Voisin",Christophe Voisin,2019-07-17T13:59:28Z
"Depth thermography: non-invasive 3D temperature profiling using infrared
  thermal emission","  We introduce a technique based on infrared thermal emission, termed depth
thermography, that can remotely measure the temperature distribution beneath
the surface of certain objects. Depth thermography utilizes the
thermal-emission spectrum in the semitransparent spectral region of the target
object to extract its temperature as a function of depth, in contrast with
conventional thermography, which uses the spectrally integrated thermally
emitted power to measure the surface temperature. Coupled with two-dimensional
imaging, e.g., using an infrared hyperspectral camera or scanning a
single-pixel spectrometer, this technique can yield volumetric temperature
distributions. We carried out a proof-of-concept experiment on an
asymmetrically heated fused-silica window, extracting the temperature
distribution throughout the sample. Depth thermography may enable noncontact
volumetric temperature measurements of microscopic objects such as multilayer
electronic devices or macroscopic volumes of liquids and gasses as well as
simultaneous all-optical measurements of optical and thermal properties.
","Yuzhe Xiao, Chenghao Wan, Alireza Shahsafi, Jad Salman, Mikhail A. Kats",Mikhail A. Kats,2019-08-21T02:49:09Z
"Accelerating proximal Markov chain Monte Carlo by using an explicit
  stabilised method","  We present a highly efficient proximal Markov chain Monte Carlo methodology
to perform Bayesian computation in imaging problems. Similarly to previous
proximal Monte Carlo approaches, the proposed method is derived from an
approximation of the Langevin diffusion. However, instead of the conventional
Euler-Maruyama approximation that underpins existing proximal Monte Carlo
methods, here we use a state-of-the-art orthogonal Runge-Kutta-Chebyshev
stochastic approximation that combines several gradient evaluations to
significantly accelerate its convergence speed, similarly to accelerated
gradient optimisation methods. The proposed methodology is demonstrated via a
range of numerical experiments, including non-blind image deconvolution,
hyperspectral unmixing, and tomographic reconstruction, with total-variation
and $\ell_1$-type priors. Comparisons with Euler-type proximal Monte Carlo
methods confirm that the Markov chains generated with our method exhibit
significantly faster convergence speeds, achieve larger effective sample sizes,
and produce lower mean square estimation errors at equal computational budget.
","Luis Vargas, Marcelo Pereyra, Konstantinos C. Zygalakis",Konstantinos C. Zygalakis,2019-08-23T14:44:28Z
"An Application of CNNs to Time Sequenced One Dimensional Data in
  Radiation Detection","  A Convolutional Neural Network architecture was used to classify various
isotopes of time-sequenced gamma-ray spectra, a typical output of a radiation
detection system of a type commonly fielded for security or environmental
measurement purposes. A two-dimensional surface (waterfall plot) in time-energy
space is interpreted as a monochromatic image and standard image-based CNN
techniques are applied. This allows for the time-sequenced aspects of features
in the data to be discovered by the network, as opposed to standard algorithms
which arbitrarily time bin the data to satisfy the intuition of a human
spectroscopist. The CNN architecture and results are presented along with a
comparison to conventional techniques. The results of this novel application of
image processing techniques to radiation data will be presented along with a
comparison to more conventional adaptive methods.
","Eric T. Moore, William P. Ford, Emma J. Hague, Johanna Turk",Johanna Turk,2019-08-28T18:03:48Z
"Correlation-based Initialization Algorithm for Tensor-based HSI
  Compression Methods","  Tensor decomposition (TD) is widely used in hyperspectral image (HSI)
compression. The initialization of factor matrix in tensor decomposition can
determine the HSI compression performance. It is worth noting that HSI is
highly correlated in bands. However, this phenomenon is ignored by the previous
TD method. Aiming at improving the HSI compression performance, we propose a
method called correlation-based TD initialization algorithm. As HSI is well
approximated by means of a reference band. In accordance with the SVD result of
the reference band, the initialized factor matrices of TD are produced. We
compare our methods with random and SVD-based initialization methods. The
experimental results reveal that our correlation-based TD initialization method
is capable of significantly reducing the computational cost of TD while keeping
the initialization quality and compression performance.
","Rui Li, Zhibin Pan, Yang Wang",Yang Wang,2019-08-27T07:11:59Z
"Disentangling the effects of doping, strain and defects in monolayer WS2
  by optical spectroscopy","  Monolayers of transition metal dichalcogenides (TMdC) are promising
candidates for realization of a new generation of optoelectronic devices. The
optical properties of these two-dimensional materials, however, vary from flake
to flake, or even across individual flakes, and change over time, all of which
makes control of the optoelectronic properties challenging. There are many
different perturbations that can alter the optical properties, including charge
doping, defects, strain, oxidation, and water intercalation. Identifying which
perturbations are present is usually not straightforward and requires multiple
measurements using multiple experimental modalities, which presents barriers
when attempting to optimise preparation of these materials. Here, we apply
highresolution photoluminescence and differential reflectance hyperspectral
imaging in situ to CVD-grown WS2 monolayers. By combining these two optical
measurements and using a statistical correlation analysis we are able to
disentangle three contributions modulating optoelectronic properties of these
materials: electron doping, strain and defects. In separating these
contributions, we also observe that the B-exciton energy is less sensitive to
variations in doping density than A-excitons.
","Pavel V. Kolesnichenko, Qianhui Zhang, Changxi Zheng, Michael S. Fuhrer, Jeffrey A. Davis",Jeffrey A. Davis,2019-09-18T05:22:08Z
Distributed Machine Learning with Sparse Heterogeneous Data,"  Motivated by distributed machine learning settings such as Federated
Learning, we consider the problem of fitting a statistical model across a
distributed collection of heterogeneous data sets whose similarity structure is
encoded by a graph topology. Precisely, we analyse the case where each node is
associated with fitting a sparse linear model, and edges join two nodes if the
difference of their solutions is also sparse. We propose a method based on
Basis Pursuit Denoising with a total variation penalty, and provide finite
sample guarantees for sub-Gaussian design matrices. Taking the root of the tree
as a reference node, we show that if the sparsity of the differences across
nodes is smaller than the sparsity at the root, then recovery is successful
with fewer samples than by solving the problems independently, or by using
methods that rely on a large overlap in the signal supports, such as the group
Lasso. We consider both the noiseless and noisy setting, and numerically
investigate the performance of distributed methods based on Distributed
Alternating Direction Methods of Multipliers (ADMM) and hyperspectral unmixing.
","Dominic Richards, Sahand N. Negahban, Patrick Rebeschini",Patrick Rebeschini,2019-12-03T14:39:22Z
Wavelength-multiplexed single-shot ptychography,"  Diagnostics capable of interrogating dynamics in harsh environments such as
plasma have remained essentially unchanged in recent decades. Developments in
advanced microscopy techniques will improve our understanding of the physics
involved in these events. Recently developed single-shot ptychography (SSP)
provides a pathway towards sophisticated plasma metrologies. Here we introduce
wavelength-multiplexed single-shot ptychography (WM-SSP), which allows for
hyperspectral, spatially and temporally resolved phase and amplitude contrast
imaging. Furthermore, we introduce a novel probe constraint common to all
wavelength multiplexed modalities in the single-shot geometry and present
modifications to SSP that improve reconstruction fidelity and robustness.
WM-SSP was experimentally realized and simulations show the technique's ability
to deconvolve the electron and neutral densities within the plasma. WM-SSP will
pave the way to a new generation of quantitative plasma imaging techniques.
","Jonathan Barolak, David Goldberger, Jeff Squier, Yves Bellouard, Charles Durfee, Daniel Adams",Daniel Adams,2020-09-02T20:48:15Z
"Tangent Space Based Alternating Projections for Nonnegative Low Rank
  Matrix Approximation","  In this paper, we develop a new alternating projection method to compute
nonnegative low rank matrix approximation for nonnegative matrices. In the
nonnegative low rank matrix approximation method, the projection onto the
manifold of fixed rank matrices can be expensive as the singular value
decomposition is required. We propose to use the tangent space of the point in
the manifold to approximate the projection onto the manifold in order to reduce
the computational cost. We show that the sequence generated by the alternating
projections onto the tangent spaces of the fixed rank matrices manifold and the
nonnegative matrix manifold, converge linearly to a point in the intersection
of the two manifolds where the convergent point is sufficiently close to
optimal solutions. This convergence result based inexact projection onto the
manifold is new and is not studied in the literature. Numerical examples in
data clustering, pattern recognition and hyperspectral data analysis are given
to demonstrate that the performance of the proposed method is better than that
of nonnegative matrix factorization methods in terms of computational time and
accuracy.
","Guangjing Song, Michael K. Ng, Tai-Xiang Jiang",Tai-Xiang Jiang,2020-09-02T05:25:16Z
"Extracting Optimal Solution Manifolds using Constrained Neural
  Optimization","  Constrained Optimization solution algorithms are restricted to point based
solutions. In practice, single or multiple objectives must be satisfied,
wherein both the objective function and constraints can be non-convex resulting
in multiple optimal solutions. Real world scenarios include intersecting
surfaces as Implicit Functions, Hyperspectral Unmixing and Pareto Optimal
fronts. Local or global convexification is a common workaround when faced with
non-convex forms. However, such an approach is often restricted to a strict
class of functions, deviation from which results in sub-optimal solution to the
original problem. We present neural solutions for extracting optimal sets as
approximate manifolds, where unmodified, non-convex objectives and constraints
are defined as modeler guided, domain-informed $L_2$ loss function. This
promotes interpretability since modelers can confirm the results against known
analytical forms in their specific domains. We present synthetic and realistic
cases to validate our approach and compare against known solvers for
bench-marking in terms of accuracy and computational efficiency.
","Gurpreet Singh, Soumyajit Gupta, Matthew Lease",Matthew Lease,2020-09-13T15:37:44Z
"Low-Rank Subspace Representation from Optimal Coded-Aperture for
  Unsupervised Classification of Hyperspectral Imagery","  This paper aims at developing a clustering approach with spectral images
directly from the compressive measurements of coded aperture snapshot spectral
imager (CASSI). Assuming that compressed measurements often lie approximately
in low dimensional subspaces corresponding to multiple classes, state of the
art methods generally obtains optimal solution for each step separately but
cannot guarantee that it will achieve the globally optimal clustering results.
In this paper, a low-rank subspace representation (LRSR) algorithm is proposed
to perform clustering on the compressed measurements. In addition, a subspace
structured norm is added into the objective of low-rank representation problem
exploiting the fact that each point in a union of subspaces can be expressed as
a sparse linear combination of all other points and that the matrix of the
points within each subspace is low rank. Simulation with real dataset
illustrates the accuracy of the proposed spectral image clustering approach.
",Jianchen Zhu,Jianchen Zhu,2020-09-26T08:47:31Z
"GLOSS: Tensor-Based Anomaly Detection in Spatiotemporal Urban Traffic
  Data","  Anomaly detection in spatiotemporal data is a challenging problem encountered
in a variety of applications including hyperspectral imaging, video
surveillance and urban traffic monitoring. In the case of urban traffic data,
anomalies refer to unusual events such as traffic congestion and unexpected
crowd gatherings. Detecting these anomalies is challenging due to the
dependence of anomaly definition on time and space. In this paper, we introduce
an unsupervised tensor-based anomaly detection method for spatiotemporal urban
traffic data. The proposed method assumes that the anomalies are sparse and
temporally continuous, {i.e.}, anomalies appear as spatially contiguous groups
of locations that show anomalous values consistently for a short duration of
time. Furthermore, a manifold embedding approach is adopted to preserve the
local geometric structure of the data across each mode. The proposed framework,
Graph Regularized Low-rank plus Temporally Smooth Sparse decomposition (GLOSS),
is formulated as an optimization problem and solved using alternating method of
multipliers (ADMM). The resulting algorithm is shown to converge and be robust
against missing data and noise. The proposed framework is evaluated on both
synthetic and real spatiotemporal urban traffic data and compared with baseline
methods.
","Seyyid Emre Sofuoglu, Selin Aviyente",Selin Aviyente,2020-10-06T17:15:39Z
"IRX-1D: A Simple Deep Learning Architecture for Remote Sensing
  Classifications","  We proposes a simple deep learning architecture combining elements of
Inception, ResNet and Xception networks. Four new datasets were used for
classification with both small and large training samples. Results in terms of
classification accuracy suggests improved performance by proposed architecture
in comparison to Bayesian optimised 2D-CNN with small training samples.
Comparison of results using small training sample with Indiana Pines
hyperspectral dataset suggests comparable or better performance by proposed
architecture than nine reported works using different deep learning
architectures. In spite of achieving high classification accuracy with limited
training samples, comparison of classified image suggests different land cover
classes are assigned to same area when compared with the classified image
provided by the model trained using large training samples with all datasets.
","Mahesh Pal,  Akshay, B. Charan Teja",B. Charan Teja,2020-10-08T11:07:02Z
"Hyperspectral Unmixing via Nonnegative Matrix Factorization with
  Handcrafted and Learnt Priors","  Nowadays, nonnegative matrix factorization (NMF) based methods have been
widely applied to blind spectral unmixing. Introducing proper regularizers to
NMF is crucial for mathematically constraining the solutions and physically
exploiting spectral and spatial properties of images. Generally, properly
handcrafting regularizers and solving the associated complex optimization
problem are non-trivial tasks. In our work, we propose an NMF based unmixing
framework which jointly uses a handcrafting regularizer and a learnt
regularizer from data. we plug learnt priors of abundances where the associated
subproblem can be addressed using various image denoisers, and we consider an
l_2,1-norm regularizer to the abundance matrix to promote sparse unmixing
results. The proposed framework is flexible and extendable. Both synthetic data
and real airborne data are conducted to confirm the effectiveness of our
method.
","Min Zhao, Tiande Gao, Jie Chen, Wei Chen",Wei Chen,2020-10-09T14:40:20Z
Tensor Completion via Tensor Networks with a Tucker Wrapper,"  In recent years, low-rank tensor completion (LRTC) has received considerable
attention due to its applications in image/video inpainting, hyperspectral data
recovery, etc. With different notions of tensor rank (e.g., CP, Tucker, tensor
train/ring, etc.), various optimization based numerical methods are proposed to
LRTC. However, tensor network based methods have not been proposed yet. In this
paper, we propose to solve LRTC via tensor networks with a Tucker wrapper. Here
by ""Tucker wrapper"" we mean that the outermost factor matrices of the tensor
network are all orthonormal. We formulate LRTC as a problem of solving a system
of nonlinear equations, rather than a constrained optimization problem. A
two-level alternative least square method is then employed to update the
unknown factors. The computation of the method is dominated by tensor matrix
multiplications and can be efficiently performed. Also, under proper
assumptions, it is shown that with high probability, the method converges to
the exact solution at a linear rate. Numerical simulations show that the
proposed algorithm is comparable with state-of-the-art methods.
","Yunfeng Cai, Ping Li",Ping Li,2020-10-29T17:54:01Z
"SCA-Net: A Self-Correcting Two-Layer Autoencoder for Hyper-spectral
  Unmixing","  Hyperspectral unmixing involves separating a pixel as a weighted combination
of its constituent endmembers and corresponding fractional abundances, with the
current state of the art results achieved by neural models on benchmark
datasets. However, these networks are severely over-parameterized and
consequently, the invariant endmember spectra extracted as decoder weights have
a high variance over multiple runs. These approaches perform substantial
post-processing while requiring an exact specification of the number of
endmembers and specialized initialization of weights from other algorithms like
VCA. We show for the first time that a two-layer autoencoder (SCA), with $2FK$
parameters ($F$ features, $K$ endmembers), achieves error metrics that are
scales apart ($10^{-5})$ from previously reported values $(10^{-2})$. SCA
converges to this low error solution starting from a random initialization of
weights. We also show that SCA, based upon a bi-orthogonal representation,
performs a self-correction when the number of endmembers are over-specified.
Numerical experiments on Samson, Jasper, and Urban datasets demonstrate that
SCA outperforms previously reported error metrics for all the cases while being
robust to noise and outliers.
","Gurpreet Singh, Soumyajit Gupta, Clint Dawson",Clint Dawson,2021-02-10T19:37:52Z
"Core Imaging Library -- Part II: Multichannel reconstruction for dynamic
  and spectral tomography","  The newly developed Core Imaging Library (CIL) is a flexible plug and play
library for tomographic imaging with a specific focus on iterative
reconstruction. CIL provides building blocks for tailored regularised
reconstruction algorithms and explicitly supports multichannel tomographic
data. In the first part of this two-part publication, we introduced the
fundamentals of CIL. This paper focuses on applications of CIL for multichannel
data, e.g., dynamic and spectral. We formalise different optimisation problems
for colour processing, dynamic and hyperspectral tomography and demonstrate
CIL's capabilities for designing state of the art reconstruction methods
through case studies and code snapshots.
","Evangelos Papoutsellis, Evelina Ametova, Claire Delplancke, Gemma Fardell, Jakob S. Jørgensen, Edoardo Pasca, Martin Turner, Ryan Warr, William R. B. Lionheart, Philip J. Withers",Philip J. Withers,2021-02-10T12:21:34Z
"Video-rate multispectral imaging in laparoscopic surgery: First-in-human
  application","  Multispectral and hyperspectral imaging (MSI/HSI) can provide clinically
relevant information on morphological and functional tissue properties.
Application in the operating room (OR), however, has so far been limited by
complex hardware setups and slow acquisition times. To overcome these
limitations, we propose a novel imaging system for video-rate spectral imaging
in the clinical workflow. The system integrates a small snapshot multispectral
camera with a standard laparoscope and a clinically commonly used light source,
enabling the recording of multispectral images with a spectral dimension of 16
at a frame rate of 25 Hz. An ongoing in patient study shows that multispectral
recordings from this system can help detect perfusion changes in partial
nephrectomy surgery, thus opening the doors to a wide range of clinical
applications.
","Leonardo Ayala, Sebastian Wirkert, Anant Vemuri, Tim Adler, Silvia Seidlitz, Sebastian Pirmann, Christina Engels, Dogu Teber, Lena Maier-Hein",Lena Maier-Hein,2021-05-28T15:03:54Z
"Separated-Spectral-Distribution Estimation Based on Bayesian Inference
  with Single RGB Camera","  In this paper, we propose a novel method for separately estimating spectral
distributions from images captured by a typical RGB camera. The proposed method
allows us to separately estimate a spectral distribution of illumination,
reflectance, or camera sensitivity, while recent hyperspectral cameras are
limited to capturing a joint spectral distribution from a scene. In addition,
the use of Bayesian inference makes it possible to take into account prior
information of both spectral distributions and image noise as probability
distributions. As a result, the proposed method can estimate spectral
distributions in a unified way, and it can enhance the robustness of the
estimation against noise, which conventional spectral-distribution estimation
methods cannot. The use of Bayesian inference also enables us to obtain the
confidence of estimation results. In an experiment, the proposed method is
shown not only to outperform conventional estimation methods in terms of RMSE
but also to be robust against noise.
","Yuma Kinoshita, Hitoshi Kiya",Hitoshi Kiya,2021-06-01T08:31:47Z
Multi-resolution Outlier Pooling for Sorghum Classification,"  Automated high throughput plant phenotyping involves leveraging sensors, such
as RGB, thermal and hyperspectral cameras (among others), to make large scale
and rapid measurements of the physical properties of plants for the purpose of
better understanding the difference between crops and facilitating rapid plant
breeding programs. One of the most basic phenotyping tasks is to determine the
cultivar, or species, in a particular sensor product. This simple phenotype can
be used to detect errors in planting and to learn the most differentiating
features between cultivars. It is also a challenging visual recognition task,
as a large number of highly related crops are grown simultaneously, leading to
a classification problem with low inter-class variance. In this paper, we
introduce the Sorghum-100 dataset, a large dataset of RGB imagery of sorghum
captured by a state-of-the-art gantry system, a multi-resolution network
architecture that learns both global and fine-grained features on the crops,
and a new global pooling strategy called Dynamic Outlier Pooling which
outperforms standard global pooling strategies on this task.
","Chao Ren, Justin Dulay, Gregory Rolwes, Duke Pauli, Nadia Shakoor, Abby Stylianou",Abby Stylianou,2021-06-10T13:57:33Z
SISAL Revisited,"  Simplex identification via split augmented Lagrangian (SISAL) is a
popularly-used algorithm in blind unmixing of hyperspectral images. Developed
by Jos\'{e} M. Bioucas-Dias in 2009, the algorithm is fundamentally relevant to
tackling simplex-structured matrix factorization, and by extension,
non-negative matrix factorization, which have many applications under their
umbrellas. In this article, we revisit SISAL and provide new meanings to this
quintessential algorithm. The formulation of SISAL was motivated from a
geometric perspective, with no noise. We show that SISAL can be explained as an
approximation scheme from a probabilistic simplex component analysis framework,
which is statistical and is principally more powerful in accommodating the
presence of noise. The algorithm for SISAL was designed based on a successive
convex approximation method, with a focus on practical utility. It was not
known, by analyses, whether the SISAL algorithm has any kind of guarantee of
convergence to a stationary point. By establishing associations between the
SISAL algorithm and a line-search-based proximal gradient method, we confirm
that SISAL can indeed guarantee convergence to a stationary point. Our
re-explanation of SISAL also reveals new formulations and algorithms. The
performance of these new possibilities is demonstrated by numerical
experiments.
","Chujun Huang, Mingjie Shao, Wing-Kin Ma, Anthony Man-Cho So",Anthony Man-Cho So,2021-07-01T11:53:43Z
"Impact of excitation energy on hot carrier properties in InGaAs MQW
  structure","  Hot carrier solar cells aim to overcome the theoretical limit of
single-junction photovoltaic devices by suppressing the thermalization of hot
carriers and extracting them through energy selective contacts. Designing
efficient hot carrier absorbers requires further investigation on hot carrier
properties in materials. Although the thermalization of hot carriers is
responsible for a large portion of energy loss in solar cells, it is still one
of the least understood phenomena in semiconductors. Here, the impact of
excitation energy on the properties of photo-generated hot carriers in an
InGaAs multi-quantum well (MQW) structure at various lattice temperatures and
excitation powers is studied. Photoluminescence (PL) emission of the sample is
detected by a hyperspectral luminescence imager, which creates spectrally and
spatially resolved PL maps. The thermodynamic properties of hot carriers, such
as temperature and quasi-Fermi level splitting, are carefully determined via
applying full PL spectrum fitting, which solves the Fermi-Dirac integral and
considers the band-filling effect in the nanostructured material. In addition,
the impact of thermalized power density and carrier scattering with
longitudinal optical phonons on the spectral linewidth broadening under two
excitation energies is studied.
","Hamidreza Esmaielpour, Laurent Lombez, Maxime Giteau, Jean-Francois Guillemoles, Daniel Suchet",Daniel Suchet,2021-07-04T15:25:41Z
Ultrafast Coherence Delocalization in Real Space Simulated by Polaritons,"  We investigated coherence delocalization on a coupled-cavity molecular
polariton platform in time, frequency, and spatial domains, enabled by
ultrafast two-dimensional infrared hyperspectral imaging. Unidirectional
coherence delocalization (coherence prepared in one cavity transfer to another
cavity) was observed in frequency and real spaces. This directionality was
enabled by dissipation of delocalized photon from high-energy to low-energy
modes, described by Lindblad dynamics. Further experiments showed that when
coherences were directly prepared across cavities (superpositions between
polaritons from different cavities), only energetically nearby polaritons could
form coherences that survived the long-range environmental fluctuation.
Together with the Lindblad dynamics, this result implied that coherences
delocalized through a one-step mechanism where photons transferred from one
cavity to another, shedding lights to coherence evolution in natural and
artificial quantum systems. This work also demonstrated a way of combining
photon and molecular modes to simulate coherence dynamics.
","Bo Xiang, Zimo Yang, Yi-Zhuang You, Wei Xiong",Wei Xiong,2021-07-09T01:03:39Z
"Robust low-rank covariance matrix estimation with a general pattern of
  missing values","  This paper tackles the problem of robust covariance matrix estimation when
the data is incomplete. Classical statistical estimation methodologies are
usually built upon the Gaussian assumption, whereas existing robust estimation
ones assume unstructured signal models. The former can be inaccurate in
real-world data sets in which heterogeneity causes heavy-tail distributions,
while the latter does not profit from the usual low-rank structure of the
signal. Taking advantage of both worlds, a covariance matrix estimation
procedure is designed on a robust (mixture of scaled Gaussian) low-rank model
by leveraging the observed-data likelihood function within an
expectation-maximization algorithm. It is also designed to handle general
pattern of missing values. The proposed procedure is first validated on
simulated data sets. Then, its interest for classification and clustering
applications is assessed on two real data sets with missing values, which
include multispectral and hyperspectral time series.
","Alexandre Hippert-Ferrer, Mohammed Nabil El Korso, Arnaud Breloy, Guillaume Ginolhac",Guillaume Ginolhac,2021-07-22T07:55:25Z
Two Headed Dragons: Multimodal Fusion and Cross Modal Transactions,"  As the field of remote sensing is evolving, we witness the accumulation of
information from several modalities, such as multispectral (MS), hyperspectral
(HSI), LiDAR etc. Each of these modalities possess its own distinct
characteristics and when combined synergistically, perform very well in the
recognition and classification tasks. However, fusing multiple modalities in
remote sensing is cumbersome due to highly disparate domains. Furthermore, the
existing methods do not facilitate cross-modal interactions. To this end, we
propose a novel transformer based fusion method for HSI and LiDAR modalities.
The model is composed of stacked auto encoders that harness the cross key-value
pairs for HSI and LiDAR, thus establishing a communication between the two
modalities, while simultaneously using the CNNs to extract the spectral and
spatial information from HSI and LiDAR. We test our model on Houston (Data
Fusion Contest - 2013) and MUUFL Gulfport datasets and achieve competitive
results.
","Rupak Bose, Shivam Pande, Biplab Banerjee",Biplab Banerjee,2021-07-24T11:33:37Z
LAConv: Local Adaptive Convolution for Image Fusion,"  The convolution operation is a powerful tool for feature extraction and plays
a prominent role in the field of computer vision. However, when targeting the
pixel-wise tasks like image fusion, it would not fully perceive the
particularity of each pixel in the image if the uniform convolution kernel is
used on different patches. In this paper, we propose a local adaptive
convolution (LAConv), which is dynamically adjusted to different spatial
locations. LAConv enables the network to pay attention to every specific local
area in the learning process. Besides, the dynamic bias (DYB) is introduced to
provide more possibilities for the depiction of features and make the network
more flexible. We further design a residual structure network equipped with the
proposed LAConv and DYB modules, and apply it to two image fusion tasks.
Experiments for pansharpening and hyperspectral image super-resolution (HISR)
demonstrate the superiority of our method over other state-of-the-art methods.
It is worth mentioning that LAConv can also be competent for other
super-resolution tasks with less computation effort.
","Zi-Rong Jin, Liang-Jian Deng, Tai-Xiang Jiang, Tian-Jing Zhang",Tian-Jing Zhang,2021-07-24T14:15:32Z
Stochastic Subsampling for Factorizing Huge Matrices,"  We present a matrix-factorization algorithm that scales to input matrices
with both huge number of rows and columns. Learned factors may be sparse or
dense and/or non-negative, which makes our algorithm suitable for dictionary
learning, sparse component analysis, and non-negative matrix factorization. Our
algorithm streams matrix columns while subsampling them to iteratively learn
the matrix factors. At each iteration, the row dimension of a new sample is
reduced by subsampling, resulting in lower time complexity compared to a simple
streaming algorithm. Our method comes with convergence guarantees to reach a
stationary point of the matrix-factorization problem. We demonstrate its
efficiency on massive functional Magnetic Resonance Imaging data (2 TB), and on
patches extracted from hyperspectral images (103 GB). For both problems, which
involve different penalties on rows and columns, we obtain significant
speed-ups compared to state-of-the-art algorithms.
","Arthur Mensch, Julien Mairal, Bertrand Thirion, Gael Varoquaux",Gael Varoquaux,2017-01-19T10:35:01Z
"Predicting with limited data - Increasing the accuracy in VIS-NIR
  diffuse reflectance spectroscopy by SMOTE","  Diffuse reflectance spectroscopy is a powerful technique to predict soil
properties. It can be used in situ to provide data inexpensively and rapidly
compared to the standard laboratory measurements. Because most spectral data
bases contain air-dried samples scanned in the laboratory, field spectra
acquired in situ are either absent or rare in calibration data sets. However,
when models are calibrated on air-dried spectra, prediction using field spectra
are often inaccurate. We propose a framework to calibrate partial least squares
models when field spectra are rare using synthetic minority oversampling
technique (SMOTE). We calibrated a model to predict soil organic carbon content
using air-dried spectra spiked with synthetic field spectra. The root
mean-squared error of prediction decreased from 6.18 to 2.12 mg g$^{-1}$ and
$R^2$ increased from $-$0.53 to 0.82 compared to the model calibrated on
air-dried spectra only.
","Christina Bogner, Anna Kühnel, Bernd Huwe",Bernd Huwe,2017-03-15T06:42:41Z
Recovering Dense Tissue Multispectral Signal from in vivo RGB Images,"  Hyperspectral/multispectral imaging (HSI/MSI) contains rich information
clinical applications, such as 1) narrow band imaging for vascular
visualisation; 2) oxygen saturation for intraoperative perfusion monitoring and
clinical decision making [1]; 3) tissue classification and identification of
pathology [2]. The current systems which provide pixel-level HSI/MSI signal can
be generally divided into two types: spatial scanning and spectral scanning.
However, the trade-off between spatial/spectral resolution, the acquisition
time, and the hardware complexity hampers implementation in real-world
applications, especially intra-operatively. Acquiring high resolution images in
real-time is important for HSI/MSI in intra-operative imaging, to alleviate the
side effect caused by breathing, heartbeat, and other sources of motion.
Therefore, we developed an algorithm to recover a pixel-level MSI stack using
only the captured snapshot RGB images from a normal camera. We refer to this
technique as ""super-spectral-resolution"". The proposed method enables recovery
of pixel-level-dense MSI signals with 24 spectral bands at ~11 frames per
second (FPS) on a GPU. Multispectral data captured from porcine bowel and
sheep/rabbit uteri in vivo has been used for training, and the algorithm has
been validated using unseen in vivo animal experiments.
","Jianyu Lin, Neil T. Clancy, Daniel S. Elson",Daniel S. Elson,2017-06-20T15:38:44Z
Deep Compressive Macroscopic Fluorescence Lifetime Imaging,"  Compressive Macroscopic Fluorescence Lifetime Imaging (MFLI) is a novel
technical implementation that enables monitoring multiple molecular
interactions in macroscopic scale. Especially, we reported recently on the
development of a hyperspectral wide-field time-resolved single-pixel imaging
platform that facilitates whole-body in vivo lifetime imaging in less than 14
minutes. However, despite efficient data acquisition, the data processing of a
Compressed Sensing (CS) based inversion plus lifetime fitting remain very time
consuming. Herein, we propose to investigate the potential of deep learning for
fast and accurate image formation. More precisely we developed a Convolutional
Neural Network (CNN) called Net-FLICS (Network for Fluorescence Lifetime
Imaging with Compressive Sensing) that reconstructs both intensity and lifetime
images directly from raw CS measurements. Results show that better quality
reconstruction can be obtained using Net-FLICS, for both simulation and
experimental dataset, with almost negligible time compared to the traditional
analytic methods. This first investigation suggests that Net-FLICS may be a
powerful tool to enable CS-based lifetime imaging for real-time applications.
","Ruoyang Yao, Marien Ochoa, Xavier Intes, Pingkun Yan",Pingkun Yan,2017-11-16T16:45:52Z
"Hierarchical Bayesian image analysis: from low-level modeling to robust
  supervised learning","  Within a supervised classification framework, labeled data are used to learn
classifier parameters. Prior to that, it is generally required to perform
dimensionality reduction via feature extraction. These preprocessing steps have
motivated numerous research works aiming at recovering latent variables in an
unsupervised context. This paper proposes a unified framework to perform
classification and low-level modeling jointly. The main objective is to use the
estimated latent variables as features for classification and to incorporate
simultaneously supervised information to help latent variable extraction. The
proposed hierarchical Bayesian model is divided into three stages: a first
low-level modeling stage to estimate latent variables, a second stage
clustering these features into statistically homogeneous groups and a last
classification stage exploiting the (possibly badly) labeled data. Performance
of the model is assessed in the specific context of hyperspectral image
interpretation, unifying two standard analysis techniques, namely unmixing and
classification.
","Adrien Lagrange, Mathieu Fauvel, Stéphane May, Nicolas Dobigeon",Nicolas Dobigeon,2017-12-01T15:32:58Z
"In aqua electrochemistry probed by XPEEM: experimental setup, examples,
  and challenges","  Recent developments in environmental and liquid cells equipped with electron
transparent graphene windows have enabled traditional surface science
spectromicroscopy tools, such as X-ray photoelectron spectroscopy (XPS),
photoemission electron microscopy (PEEM), and scanning electron microscopy
(SEM) to be applied to study solid-liquid and liquid-gas interfaces. Here, we
focus on the experimental implementation of PEEM to probe electrified
graphene-liquid interfaces using electrolyte-filled microchannel arrays as a
new sample platform. We demonstrate the important methodological advantage of
these multi-sample arrays: they enable the combination of the wide field of
view hyperspectral imaging capabilities from PEEM with the use of powerful data
mining algorithms to reveal spectroscopic and temporal behaviors at the level
of the individual microsample or the entire array ensemble
","Slavomír Nemšák, Evgheni Strelcov, Hongxuan Guo, Brian D. Hoskins, Tomáš Duchoň, David N. Mueller, Alexander Yulaev, Ivan Vlassiouk, Alexander Tselev, Claus M. Schneider, Andrei Kolmakov",Andrei Kolmakov,2018-02-07T17:36:30Z
"Digital Fourier transform spectroscopy: a high-performance, scalable
  technology for on-chip spectrum analysis","  Optical spectrum analysis is the cornerstone of spectroscopic sensing,
optical network performance monitoring, and hyperspectral imaging. While
conventional high-performance spectrometers used to perform such analysis are
often large benchtop instruments, on-chip spectrometers have recently emerged
as a promising alternative with apparent Size, Weight, and Power (SWaP)
advantages. Existing on-chip spectrometer designs, however, are limited in
spectral channel count and signal-to-noise ratio (SNR). Here we demonstrate a
transformative on-chip digital Fourier transform (dFT) spectrometer that can
acquire high-resolution spectra via time- domain modulation of a reconfigurable
Mach-Zehnder interferometer. The device, fabricated and packaged using
industry-standard silicon photonics technology, claims the multiplex advantage
to dramatically boost SNR and unprecedented scalability capable of addressing
exponentially increasing numbers of spectral channels. We further implemented
machine learning regularization techniques to spectrum reconstruction and
achieved significant noise suppression and spectral resolution enhancement
beyond the classical Rayleigh criterion.
","Derek M. Kita, Brando Miranda, David Favela, David Bono, Jerome Michon, Hongtao Lin, Tian Gu, Juejun Hu",Juejun Hu,2018-02-15T15:50:10Z
Tensor-based Nonlinear Classifier for High-Order Data Analysis,"  In this paper we propose a tensor-based nonlinear model for high-order data
classification. The advantages of the proposed scheme are that (i) it
significantly reduces the number of weight parameters, and hence of required
training samples, and (ii) it retains the spatial structure of the input
samples. The proposed model, called \textit{Rank}-1 FNN, is based on a
modification of a feedforward neural network (FNN), such that its weights
satisfy the {\it rank}-1 canonical decomposition. We also introduce a new
learning algorithm to train the model, and we evaluate the \textit{Rank}-1 FNN
on third-order hyperspectral data. Experimental results and comparisons
indicate that the proposed model outperforms state of the art classification
methods, including deep learning based ones, especially in cases with small
numbers of available training samples.
","Konstantinos Makantasis, Anastasios Doulamis, Nikolaos Doulamis, Antonis Nikitakis, Athanasios Voulodimos",Athanasios Voulodimos,2018-02-15T09:49:38Z
Graph Laplacian for Image Anomaly Detection,"  Reed-Xiaoli detector (RXD) is recognized as the benchmark algorithm for image
anomaly detection; however, it presents known limitations, namely the
dependence over the image following a multivariate Gaussian model, the
estimation and inversion of a high-dimensional covariance matrix, and the
inability to effectively include spatial awareness in its evaluation. In this
work, a novel graph-based solution to the image anomaly detection problem is
proposed; leveraging the graph Fourier transform, we are able to overcome some
of RXD's limitations while reducing computational cost at the same time. Tests
over both hyperspectral and medical images, using both synthetic and real
anomalies, prove the proposed technique is able to obtain significant gains
over performance by other algorithms in the state of the art.
","Francesco Verdoja, Marco Grangetto",Marco Grangetto,2018-02-27T12:08:06Z
"EarthMapper: A Tool Box for the Semantic Segmentation of Remote Sensing
  Imagery","  Deep learning continues to push state-of-the-art performance for the semantic
segmentation of color (i.e., RGB) imagery; however, the lack of annotated data
for many remote sensing sensors (i.e. hyperspectral imagery (HSI)) prevents
researchers from taking advantage of this recent success. Since generating
sensor specific datasets is time intensive and cost prohibitive, remote sensing
researchers have embraced deep unsupervised feature extraction. Although these
methods have pushed state-of-the-art performance on current HSI benchmarks,
many of these tools are not readily accessible to many researchers. In this
letter, we introduce a software pipeline, which we call EarthMapper, for the
semantic segmentation of non-RGB remote sensing imagery. It includes
self-taught spatial-spectral feature extraction, various standard and deep
learning classifiers, and undirected graphical models for post-processing. We
evaluated EarthMapper on the Indian Pines and Pavia University datasets and
have released this code for public use.
","Ronald Kemker, Utsav B. Gewali, Christopher Kanan",Christopher Kanan,2018-04-01T12:44:20Z
"Fast Optimal Bandwidth Selection for RBF Kernel using Reproducing Kernel
  Hilbert Space Operators for Kernel Based Classifiers","  Kernel based methods have shown effective performance in many remote sensing
classification tasks. However their performance significantly depend on its
hyper-parameters. The conventional technique to estimate the parameter comes
with high computational complexity. Thus, the objective of this letter is to
propose an fast and efficient method to select the bandwidth parameter of the
Gaussian kernel in the kernel based classification methods. The proposed method
is developed based on the operators in the reproducing kernel Hilbert space and
it is evaluated on Support vector machines and PerTurbo classification method.
Experiments conducted with hyperspectral datasets show that our proposed method
outperforms the state-of-art method in terms in computational time and
classification performance.
",Bharath Bhushan Damodaran,Bharath Bhushan Damodaran,2018-04-14T12:42:09Z
"Estimation of Tissue Oxygen Saturation from RGB Images based on
  Pixel-level Image Translation","  Intra-operative measurement of tissue oxygen saturation (StO2) has been
widely explored by pulse oximetry or hyperspectral imaging (HSI) to assess the
function and viability of tissue. In this paper we propose a pixel- level
image-to-image translation approach based on conditional Generative Adversarial
Networks (cGAN) to estimate tissue oxygen saturation (StO2) directly from RGB
images. The real-time performance and non-reliance on additional hardware,
enable a seamless integration of the proposed method into surgical and
diagnostic workflows with standard endoscope systems. For validation, RGB
images and StO2 ground truth were simulated and estimated from HSI images
collected by a liquid crystal tuneable filter (LCTF) endoscope for three tissue
types (porcine bowel, lamb uterus and rabbit uterus). The result show that the
proposed method can achieve visually identical images with comparable accuracy.
","Qing-Biao Li, Xiao-Yun Zhou, Jianyu Lin, Jian-Qing Zheng, Neil T. Clancy, Daniel S. Elson",Daniel S. Elson,2018-04-19T12:41:21Z
"Application of Different Simulated Spectral Data and Machine Learning to
  Estimate the Chlorophyll a Concentration of Several Inland Waters","  Water quality is of great importance for humans and for the environment and
has to be monitored continuously. It is determinable through proxies such as
the chlorophyll a concentration, which can be monitored by remote sensing
techniques. This study focuses on the trade-off between the spatial and the
spectral resolution of six simulated satellite-based data sets when estimating
the chlorophyll a concentration with supervised machine learning models. The
initial dataset for the spectral simulation of the satellite missions contains
spectrometer data and measured chlorophyll a concentration of 13 different
inland waters. Focusing on the regression performance, it appears that the
machine learning models achieve almost as good results with the simulated
Sentinel data as with the simulated hyperspectral data. Regarding the
applicability, the Sentinel 2 mission is the best choice for small inland
waters due to its high spatial and temporal resolution in combination with a
suitable spectral resolution.
","Philipp M. Maier, Sina Keller",Sina Keller,2019-05-29T16:14:52Z
Learning by Active Nonlinear Diffusion,"  This article proposes an active learning method for high dimensional data,
based on intrinsic data geometries learned through diffusion processes on
graphs. Diffusion distances are used to parametrize low-dimensional structures
on the dataset, which allow for high-accuracy labelings of the dataset with
only a small number of carefully chosen labels. The geometric structure of the
data suggests regions that have homogeneous labels, as well as regions with
high label complexity that should be queried for labels. The proposed method
enjoys theoretical performance guarantees on a general geometric data model, in
which clusters corresponding to semantically meaningful classes are permitted
to have nonlinear geometries, high ambient dimensionality, and suffer from
significant noise and outlier corruption. The proposed algorithm is implemented
in a manner that is quasilinear in the number of unlabeled data points, and
exhibits competitive empirical performance on synthetic datasets and real
hyperspectral remote sensing images.
","Mauro Maggioni, James M. Murphy",James M. Murphy,2019-05-30T12:05:33Z
Transport Model for Feature Extraction,"  We present a new feature extraction method for complex and large datasets,
based on the concept of transport operators on graphs. The proposed approach
generalizes and extends the many existing data representation methodologies
built upon diffusion processes, to a new domain where dynamical systems play a
key role. The main advantage of this approach comes from the ability to exploit
different relationships than those arising in the context of e.g., Graph
Laplacians. Fundamental properties of the transport operators are proved. We
demonstrate the flexibility of the method by introducing several diverse
examples of transformations. We close the paper with a series of computational
experiments and applications to the problem of classification of hyperspectral
satellite imagery, to illustrate the practical implications of our algorithm
and its ability to quantify new aspects of relationships within complicated
datasets.
","Wojciech Czaja, Dong Dong, Pierre-Emmanuel Jabin, Franck Olivier Ndjakou Njeunje",Franck Olivier Ndjakou Njeunje,2019-10-31T15:45:07Z
Physically Plausible Spectral Reconstruction from RGB Images,"  Recently Convolutional Neural Networks (CNN) have been used to reconstruct
hyperspectral information from RGB images. Moreover, this spectral
reconstruction problem (SR) can often be solved with good (low) error. However,
these methods are not physically plausible: that is when the recovered spectra
are reintegrated with the underlying camera sensitivities, the resulting
predicted RGB is not the same as the actual RGB, and sometimes this discrepancy
can be large. The problem is further compounded by exposure change. Indeed,
most learning-based SR models train for a fixed exposure setting and we show
that this can result in poor performance when exposure varies.
  In this paper we show how CNN learning can be extended so that physical
plausibility is enforced and the problem resulting from changing exposures is
mitigated. Our SR solution improves the state-of-the-art spectral recovery
performance under varying exposure conditions while simultaneously ensuring
physical plausibility (the recovered spectra reintegrate to the input RGBs
exactly).
","Yi-Tun Lin, Graham D. Finlayson",Graham D. Finlayson,2020-01-02T18:46:26Z
On Recoverability of Randomly Compressed Tensors with Low CP Rank,"  Our interest lies in the recoverability properties of compressed tensors
under the \textit{canonical polyadic decomposition} (CPD) model. The considered
problem is well-motivated in many applications, e.g., hyperspectral image and
video compression. Prior work studied this problem under somewhat special
assumptions---e.g., the latent factors of the tensor are sparse or drawn from
absolutely continuous distributions. We offer an alternative result: We show
that if the tensor is compressed by a subgaussian linear mapping, then the
tensor is recoverable if the number of measurements is on the same order of
magnitude as that of the model parameters---without strong assumptions on the
latent factors. Our proof is based on deriving a \textit{restricted isometry
property} (R.I.P.) under the CPD model via set covering techniques, and thus
exhibits a flavor of classic compressive sensing. The new recoverability result
enriches the understanding to the compressed CP tensor recovery problem; it
offers theoretical guarantees for recovering tensors whose elements are not
necessarily continuous or sparse.
","Shahana Ibrahim, Xiao Fu, Xingguo Li",Xingguo Li,2020-01-08T04:44:13Z
"A Multi-Spatial, Multi-Temporal, Semi-Analytical Model for Bathymetry,
  Water Turbidity and Bottom Composition using Multispectral Imagery","  In this paper we introduce a semi-analytical model for bathymetry, water
turbidity and bottom composition; which is primarily based on the physics-based
model, HOPE, of Lee et al. Unlike the model of Lee, which was originally
designed to use hyperspectral imagery, our model is specifically designed to
use multispectral satellite imagery. In particular, we adapt to the greatly
decreased spectral resolution by introducing temporal and spatial assumptions
on the depth and water turbidity. We validate the extensions to the Lee et al
model with a 260 km2 case study in the area of the Murion Islands off Western
Australia, where we compare the atmospherically-corrected LANDSAT-8 derived
bathymetry against a 2011 single-beam sonar survey by Transport Western
Australia. The model validates well against the single-beam sonar survey, with
R^2 = 0.85, a mean absolute error of 1.17 m and a mean relative error of 7.52%.
This indicates the model could be widely applicable to LANDSAT-8 imagery.
",Sam Blake,Sam Blake,2020-01-24T06:32:36Z
Microscopy with undetected photons in the mid-infrared,"  Owing to its capacity for unique (bio)-chemical specificity, microscopy
withmid-IR illumination holds tremendous promise for a wide range of biomedical
and industrial applications. The primary limitation, however, remains
detection; with current mid-IR detection technology often marrying inferior
technical capabilities with prohibitive costs. This has lead to approaches that
shift detection towavelengths into the visible regime, where vastly superior
silicon-based cameratechnology is available. Here, we experimentally show how
nonlinear interferometry with entangled light can provide a powerful tool for
mid-IR microscopy, while only requiring near-infrared detection with a standard
CMOS camera. In this proof-of-principle implementation, we demonstrate
intensity imaging overa broad wavelength range covering 3.4-4.3um and
demonstrate a spatial resolution of 35um for images containing 650 resolved
elements. Moreover, we demonstrate our technique is fit for purpose, acquiring
microscopic images of biological tissue samples in the mid-IR. These results
open a new perspective for potential relevance of quantum imaging techniques in
the life sciences.
","Inna Kviatkovsky, Helen M. Chrzanowski, Ellen G. Avery, Hendrik Bartolomaeus, Sven Ramelow",Sven Ramelow,2020-02-14T10:40:50Z
"A multimodal laser-scanning nonlinear optical microscope with a rapid
  broadband Fourier-transform coherent Raman modality","  Nonlinear optical microscopy allows rapid high-resolution microscopy with
image contrast generated from intrinsic properties of the sample. Established
modalities such as multiphoton excited fluorescence and second/third-harmonic
generation can be combined with other nonlinear techniques, such as coherent
Raman spectroscopy which typically allow chemical imaging of a single resonant
vibrational mode of a sample. Here, we utilize a single ultrafast laser source
to obtain broadband coherent Raman spectra on a microscope, together with other
nonlinear microscopy approaches on the same instrument. We demonstrate that the
coherent Raman modality allows broadband measurement (>1000 cm-1), with high
spectral resolution (<5 cm-1), with a rapid spectral acquisition rate (3-12
kHz). This enables Raman hyperspectral imaging of > kilo-pixel images at >11
frames per second.
","Faris Sinjab, Kazuki Hashimoto, Venktata Ramaiah Badarla, Junko Omachi, Takuro Ideguchi",Takuro Ideguchi,2020-05-28T14:02:29Z
"Patch Based Classification of Remote Sensing Data: A Comparison of
  2D-CNN, SVM and NN Classifiers","  Pixel based algorithms including back propagation neural networks (NN) and
support vector machines (SVM) have been widely used for remotely sensed image
classifications. Within last few years, deep learning based image classifier
like convolution neural networks (2D-CNN) are becoming popular alternatives to
these classifiers. In this paper, we compare performance of patch based SVM and
NN with that of a deep learning algorithms comprising of 2D-CNN and fully
connected layers. Similar to CNN which utilise image patches to derive features
for further classification, we propose to use patches as an input in place of
individual pixel with both SVM and NN classifiers. Two datasets, one
multispectral and other hyperspectral data was used to compare the performance
of different classifiers. Results with both datasets suggest the effectiveness
of patch based SVM and NN classifiers in comparison to state of art 2D-CNN
classifier.
","Mahesh Pal,  Akshay, Himanshu Rohilla, B. Charan Teja",B. Charan Teja,2020-06-21T11:07:37Z
Online Graph-Based Change Point Detection in Multiband Image Sequences,"  The automatic detection of changes or anomalies between multispectral and
hyperspectral images collected at different time instants is an active and
challenging research topic. To effectively perform change-point detection in
multitemporal images, it is important to devise techniques that are
computationally efficient for processing large datasets, and that do not
require knowledge about the nature of the changes. In this paper, we introduce
a novel online framework for detecting changes in multitemporal remote sensing
images. Acting on neighboring spectra as adjacent vertices in a graph, this
algorithm focuses on anomalies concurrently activating groups of vertices
corresponding to compact, well-connected and spectrally homogeneous image
regions. It fully benefits from recent advances in graph signal processing to
exploit the characteristics of the data that lie on irregular supports.
Moreover, the graph is estimated directly from the images using superpixel
decomposition algorithms. The learning algorithm is scalable in the sense that
it is efficient and spatially distributed. Experiments illustrate the detection
and localization performance of the method.
","Ricardo Augusto Borsoi, Cédric Richard, André Ferrari, Jie Chen, José Carlos Moreira Bermudez",José Carlos Moreira Bermudez,2020-06-24T20:40:53Z
Adaptive Compressive Sampling for Mid-infrared Spectroscopic Imaging,"  Minfrared spectroscopic imaging (MIRSI) is an emerging class of label-free,
biochemically quantitative technologies targeting digital histopathology.
Conventional histopathology relies on chemical stains that alter tissue color.
This approach is qualitative, often making histopathologic examination
subjective and difficult to quantify. MIRSI addresses these challenges through
quantitative and repeatable imaging that leverages native molecular contrast.
Fourier transform infrared (FTIR) imaging, the best-known MIRSI technology, has
two challenges that have hindered its widespread adoption: data collection
speed and spatial resolution. Recent technological breakthroughs, such as
photothermal MIRSI, provide an order of magnitude improvement in spatial
resolution. However, this comes at the cost of acquisition speed, which is
impractical for clinical tissue samples. This paper introduces an adaptive
compressive sampling technique to reduce hyperspectral data acquisition time by
an order of magnitude by leveraging spectral and spatial sparsity. This method
identifies the most informative spatial and spectral features, integrates a
fast tensor completion algorithm to reconstruct megapixel-scale images, and
demonstrates speed advantages over FTIR imaging while providing spatial
resolutions comparable to new photothermal approaches.
","Mahsa Lotfollahi, Nguyen Tran, Sebastian Berisha, Chalapathi Gajjela, Zhu Han, David Mayerich, Rohith Reddy",Rohith Reddy,2020-08-02T21:23:35Z
"A Novel Spatial-Spectral Framework for the Classification of
  Hyperspectral Satellite Imagery","  Hyper-spectral satellite imagery is now widely being used for accurate
disaster prediction and terrain feature classification. However, in such
classification tasks, most of the present approaches use only the spectral
information contained in the images. Therefore, in this paper, we present a
novel framework that takes into account both the spectral and spatial
information contained in the data for land cover classification. For this
purpose, we use the Gaussian Maximum Likelihood (GML) and Convolutional Neural
Network methods for the pixel-wise spectral classification and then, using
segmentation maps generated by the Watershed algorithm, we incorporate the
spatial contextual information into our model with a modified majority vote
technique. The experimental analyses on two benchmark datasets demonstrate that
our proposed methodology performs better than the earlier approaches by
achieving an accuracy of 99.52% and 98.31% on the Pavia University and the
Indian Pines datasets respectively. Additionally, our GML based approach, a
non-deep learning algorithm, shows comparable performance to the
state-of-the-art deep learning techniques, which indicates the importance of
the proposed approach for performing a computationally efficient classification
of hyper-spectral imagery.
","Shriya TP Gupta, Sanjay K Sahay",Sanjay K Sahay,2020-07-22T16:12:08Z
"Wavelength-by-wavelength temperature-independent thermal radiation
  utilizing an insulator-metal transition","  Both the magnitude and spectrum of the blackbody-radiation distribution
change with temperature. Here, we designed the temperature-dependent spectral
emissivity of a coating to counteract all the changes in the
blackbody-radiation distribution over a certain temperature range, enabled by
the nonhysteretic insulator-to-metal phase transition of SmNiO3. At each
wavelength within the long-wave infrared atmospheric-transparency window, the
thermal radiance of our coating remains nearly constant over a temperature
range of at least 20 {\deg}C. Our approach can conceal thermal gradients and
transient temperature changes from infrared imaging systems, including those
that discriminate by wavelength, such as multispectral and hyperspectral
cameras.
","Jonathan King, Alireza Shahsafi, Zhen Zhang, Chenghao Wan, Yuzhe Xiao, Chengzi Huang, Yifei Sun, Patrick J. Roney, Shriram Ramanathan, Mikhail A. Kats",Mikhail A. Kats,2022-04-01T14:53:33Z
"Accelerated Multiplicative Updates and Hierarchical ALS Algorithms for
  Nonnegative Matrix Factorization","  Nonnegative matrix factorization (NMF) is a data analysis technique used in a
great variety of applications such as text mining, image processing,
hyperspectral data analysis, computational biology, and clustering. In this
paper, we consider two well-known algorithms designed to solve NMF problems,
namely the multiplicative updates of Lee and Seung and the hierarchical
alternating least squares of Cichocki et al. We propose a simple way to
significantly accelerate these schemes, based on a careful analysis of the
computational cost needed at each iteration, while preserving their convergence
properties. This acceleration technique can also be applied to other
algorithms, which we illustrate on the projected gradient method of Lin. The
efficiency of the accelerated algorithms is empirically demonstrated on image
and text datasets, and compares favorably with a state-of-the-art alternating
nonnegative least squares algorithm.
","Nicolas Gillis, François Glineur",François Glineur,2011-07-26T12:26:07Z
"The radial distribution of water ice and chromophores across Saturn's
  system","  Over the last eight years, the Visual and Infrared Mapping Spectrometer
(VIMS) aboard the Cassini orbiter has returned hyperspectral images in the
0.35-5.1 micron range of the icy satellites and rings of Saturn. These very
different objects show significant variations in surface composition, roughness
and regolith grain size as a result of their evolutionary histories, endogenic
processes and interactions with exogenic particles. The distributions of
surface water ice and chromophores, i.e. organic and non-icy materials, across
the saturnian system, are traced using specific spectral indicators (spectral
slopes and absorption band depths) obtained from rings mosaics and
disk-integrated satellites observations by VIMS.
","G. Filacchione, F. Capaccioni, R. N. Clark, P. D. Nicholson, D. P. Cruikshank, J. N. Cuzzi, J. I. Lunine, R. H. Brown, P. Cerroni, F. Tosi, M. Ciarniello, B. J. Buratti, M. M. Hedman, E. Flamini",E. Flamini,2013-01-28T17:06:49Z
"Design, optimization and realization of FLC based Stokes polarimeters
  and Mueller matrix ellipsometer using a genetic algorithm","  The design of broad-band polarimeters with high performance is challenging
due to the wavelength dependence of optical components. An efficient Genetic
Algorithm (GA) computer code was recently developed in order to design and
re-optimize complete broadband Stokes polarimeters and Mueller matrix
ellipsometers (MME). Our results are improvements of previous patented designs
based on two and three ferroelectric liquid crystals (FLC), and are suited for
broad-band hyperspectral imaging, or multichannel spectroscopy applications. We
have realized and implemented one design using two FLCs and compare the
spectral range and precision with previous designs.
","Lars Martin S. Aas, Daniel G. Skåre, Pål G. Ellingsen, Paul Anton Letnes, Morten Kildemo",Morten Kildemo,2013-09-02T12:36:34Z
Fast Spectral Unmixing based on Dykstra's Alternating Projection,"  This paper presents a fast spectral unmixing algorithm based on Dykstra's
alternating projection. The proposed algorithm formulates the fully constrained
least squares optimization problem associated with the spectral unmixing task
as an unconstrained regression problem followed by a projection onto the
intersection of several closed convex sets. This projection is achieved by
iteratively projecting onto each of the convex sets individually, following
Dyktra's scheme. The sequence thus obtained is guaranteed to converge to the
sought projection. Thanks to the preliminary matrix decomposition and variable
substitution, the projection is implemented intrinsically in a subspace, whose
dimension is very often much lower than the number of bands. A benefit of this
strategy is that the order of the computational complexity for each projection
is decreased from quadratic to linear time. Numerical experiments considering
diverse spectral unmixing scenarios provide evidence that the proposed
algorithm competes with the state-of-the-art, namely when the number of
endmembers is relatively small, a circumstance often observed in real
hyperspectral applications.
","Qi Wei, Jose Bioucas-Dias, Nicolas Dobigeon, Jean-Yves Tourneret",Jean-Yves Tourneret,2015-05-07T15:22:33Z
Sequential Dimensionality Reduction for Extracting Localized Features,"  Linear dimensionality reduction techniques are powerful tools for image
analysis as they allow the identification of important features in a data set.
In particular, nonnegative matrix factorization (NMF) has become very popular
as it is able to extract sparse, localized and easily interpretable features by
imposing an additive combination of nonnegative basis elements. Nonnegative
matrix underapproximation (NMU) is a closely related technique that has the
advantage to identify features sequentially. In this paper, we propose a
variant of NMU that is particularly well suited for image analysis as it
incorporates the spatial information, that is, it takes into account the fact
that neighboring pixels are more likely to be contained in the same features,
and favors the extraction of localized features by looking for sparse basis
elements. We show that our new approach competes favorably with comparable
state-of-the-art techniques on synthetic, facial and hyperspectral image data
sets.
","Gabriella Casalino, Nicolas Gillis",Nicolas Gillis,2015-05-26T14:06:16Z
Sensing tensors with Gaussian filters,"  Sparse recovery from linear Gaussian measurements has been the subject of
much investigation since the breaktrough papers \cite{CRT:IEEEIT06} and
\cite{donoho2006compressed} on Compressed Sensing. Application to sparse
vectors and sparse matrices via least squares penalized with sparsity promoting
norms is now well understood using tools such as Gaussian mean width,
statistical dimension and the notion of descent cones \cite{tropp2014convex}
\cite{Vershynin:ArXivEstimation14}. Extention of these ideas to low rank tensor
recovery is starting to enjoy considerable interest due to its many potential
applications to Independent Component Analysis, Hidden Markov Models and
Gaussian Mixture Models \cite{AnandkumarEtAl:JMLR14}, hyperspectral image
analysis \cite{zhang2008tensor}, to name a few. In this paper, we demonstrate
that the recent approach of \cite{Vershynin:ArXivEstimation14} provides very
useful error bounds in the tensor setting using the nuclear norm or the
Romera-Paredes--Pontil \cite{RomeraParedesPontil:NIPS13} penalization.
","Stéphane Chrétien, Tianwen Wei",Tianwen Wei,2015-05-29T14:04:58Z
Multilinear Low-Rank Tensors on Graphs & Applications,"  We propose a new framework for the analysis of low-rank tensors which lies at
the intersection of spectral graph theory and signal processing. As a first
step, we present a new graph based low-rank decomposition which approximates
the classical low-rank SVD for matrices and multi-linear SVD for tensors. Then,
building on this novel decomposition we construct a general class of convex
optimization problems for approximately solving low-rank tensor inverse
problems, such as tensor Robust PCA. The whole framework is named as
'Multilinear Low-rank tensors on Graphs (MLRTG)'. Our theoretical analysis
shows: 1) MLRTG stands on the notion of approximate stationarity of
multi-dimensional signals on graphs and 2) the approximation error depends on
the eigen gaps of the graphs. We demonstrate applications for a wide variety of
4 artificial and 12 real tensor datasets, such as EEG, FMRI, BCI, surveillance
videos and hyperspectral images. Generalization of the tensor concepts to
non-euclidean domain, orders of magnitude speed-up, low-memory requirement and
significantly enhanced performance at low SNR are the key aspects of our
framework.
","Nauman Shahid, Francesco Grassi, Pierre Vandergheynst",Pierre Vandergheynst,2016-11-15T14:05:43Z
"Gold-Patched Graphene Nanoribbons for High-Responsivity and Ultrafast
  Photodetection from Visible to Infrared Regimes","  Graphene is a very attractive material for broadband photodetection in
hyperspectral imaging and sensing systems. However, its potential use has been
hindered by tradeoffs between the responsivity, bandwidth, and operation speed
of existing graphene photodetectors. Here, we present engineered
photoconductive nanostructures based on gold-patched graphene nanoribbons,
which enable simultaneous broadband and ultrafast photodetection with high
responsivity. These nanostructures merge the advantages of broadband optical
absorption, ultrafast photocarrier transport, and carrier multiplication in
graphene nanoribbons with the ultrafast transport of photocarriers to the gold
patches before recombination. Through this approach, high-responsivity
operation is achieved without the use of bandwidth- and speed-limiting quantum
dots, defect states, or tunneling barriers. We demonstrate high-responsivity
photodetection from the visible to the infrared regime (0.6 A/W at 0.8 {\mu}m
and 11.5 A/W at 20 {\mu}m) with operation speeds exceeding 50 GHz. Our results
demonstrate an improvement of the response times by more than seven orders of
magnitude and an increase in bandwidths of one order of magnitude compared to
those of higher-responsivity graphene photodetectors based on quantum dots and
tunneling barriers.
","Semih Cakmakyapan, Ping Keng Lu, Aryan Navabi, Mona Jarrahi",Mona Jarrahi,2017-09-28T05:47:42Z
"Measurement Context Extraction from Text: Discovering Opportunities and
  Gaps in Earth Science","  We propose Marve, a system for extracting measurement values, units, and
related words from natural language text. Marve uses conditional random fields
(CRF) to identify measurement values and units, followed by a rule-based system
to find related entities, descriptors and modifiers within a sentence. Sentence
tokens are represented by an undirected graphical model, and rules are based on
part-of-speech and word dependency patterns connecting values and units to
contextual words. Marve is unique in its focus on measurement context and early
experimentation demonstrates Marve's ability to generate high-precision
extractions with strong recall. We also discuss Marve's role in refining
measurement requirements for NASA's proposed HyspIRI mission, a hyperspectral
infrared imaging satellite that will study the world's ecosystems. In general,
our work with HyspIRI demonstrates the value of semantic measurement
extractions in characterizing quantitative discussion contained in large
corpuses of natural language text. These extractions accelerate broad,
cross-cutting research and expose scientists new algorithmic approaches and
experimental nuances. They also facilitate identification of scientific
opportunities enabled by HyspIRI leading to more efficient scientific
investment and research.
","Kyle Hundman, Chris A. Mattmann",Chris A. Mattmann,2017-10-11T21:37:07Z
"Robust Model Order Selection in Large Dimensional Elliptically Symmetric
  Noise","  This paper deals with model order selection in context of correlated noise.
More precisely, one considers sources embedded in an additive Complex
Elliptically Symmetric (CES) noise, with unknown parameters. The main
difficultly for estimating the model order lies into the noise correlation,
namely the scatter matrix of the corresponding CES distribution. In this work,
to tackle that problem, one adopts a two-step approach: first, we develop two
different methods based on a Toeplitz-structured model for estimating this
unknown scatter matrix and for whitening the correlated noise. Then, we apply
Maronna's $M$-estimators on the whitened signal to estimate the covariance
matrix of the ""decorrelated"" signal in order to estimate the model order. The
proposed methodology is based both on robust estimation theory as well as large
Random Matrix Theory, and original results are derived, proving the efficiency
of this methodology. Indeed, the main theoretical contribution is to derive
consistent robust estimators for the covariance matrix of the
signal-plus-correlated noise in a large dimensional regime and to propose
efficient methodology to estimate the rank of signal subspace. Finally, as
shown in the analysis, these results show a great improvement compared to the
state-of-the-art, on both simulated and real hyperspectral images.
","Eugénie Terreaux, Jean-Philippe Ovarlez, Frédéric Pascal",Frédéric Pascal,2017-10-18T13:56:54Z
Generalized linear mixing model accounting for endmember variability,"  Endmember variability is an important factor for accurately unveiling vital
information relating the pure materials and their distribution in hyperspectral
images. Recently, the extended linear mixing model (ELMM) has been proposed as
a modification of the linear mixing model (LMM) to consider endmember
variability effects resulting mainly from illumination changes. In this paper,
we further generalize the ELMM leading to a new model (GLMM) to account for
more complex spectral distortions where different wavelength intervals can be
affected unevenly. We also extend the existing methodology to jointly estimate
the variability and the abundances for the GLMM. Simulations with real and
synthetic data show that the unmixing process can benefit from the extra
flexibility introduced by the GLMM.
","Tales Imbiriba, Ricardo Augusto Borsoi, José Carlos Moreira Bermudez",José Carlos Moreira Bermudez,2017-10-20T22:46:12Z
"Scene-Adapted Plug-and-Play Algorithm with Guaranteed Convergence:
  Applications to Data Fusion in Imaging","  The recently proposed plug-and-play (PnP) framework allows leveraging recent
developments in image denoising to tackle other, more involved, imaging inverse
problems. In a PnP method, a black-box denoiser is plugged into an iterative
algorithm, taking the place of a formal denoising step that corresponds to the
proximity operator of some convex regularizer. While this approach offers
flexibility and excellent performance, convergence of the resulting algorithm
may be hard to analyze, as most state-of-the-art denoisers lack an explicit
underlying objective function. In this paper, we propose a PnP approach where a
scene-adapted prior (i.e., where the denoiser is targeted to the specific scene
being imaged) is plugged into ADMM (alternating direction method of
multipliers), and prove convergence of the resulting algorithm. Finally, we
apply the proposed framework in two different imaging inverse problems:
hyperspectral sharpening/fusion and image deblurring from blurred/noisy image
pairs.
","Afonso M. Teodoro, José M. Bioucas-Dias, Mário A. T. Figueiredo",Mário A. T. Figueiredo,2018-01-02T10:59:10Z
Visualization of Hyperspectral Images Using Moving Least Squares,"  Displaying the large number of bands in a hyper spectral image on a
trichromatic monitor has been an active research topic. The visualized image
shall convey as much information as possible form the original data and
facilitate image interpretation. Most existing methods display HSIs in false
colors which contradict with human's experience and expectation. In this paper,
we propose a nonlinear approach to visualize an input HSI with natural colors
by taking advantage of a corresponding RGB image. Our approach is based on
Moving Least Squares, an interpolation scheme for reconstructing a surface from
a set of control points, which in our case is a set of matching pixels between
the HSI and the corresponding RGB image. Based on MLS, the proposed method
solves for each spectral signature a unique transformation so that the non
linear structure of the HSI can be preserved. The matching pixels between a
pair of HSI and RGB image can be reused to display other HSIs captured b the
same imaging sensor with natural colors. Experiments show that the output image
of the proposed method no only have natural colors but also maintain the visual
information necessary for human analysis.
","Danping Liao, Siyu Chen, Yuntao Qian",Yuntao Qian,2018-01-20T07:01:27Z
"Structural Coloration of Transmission Light through Self-Aligned and
  Complementary Plasmonic Nanostructures","  Structural coloration of natural surfaces often originates from the change of
reflected colors depending on the viewing or illumination angle. Recently, the
structural coloration of nanoplasmonic structures have attracted a great deal
of attention due to high compactness, robust stability and high
color-tunability, as well as high sensitivity to an incident angle. Here we
report complementary plasmonic structures (CPS) for transmission structural
coloration by tailoring a single spectral peak depending on the incident angle
of light. The CPS features self-aligned silver nanohole and nanodisk arrays,
supported by dielectric nanopillar arrays of hydrogen silsesquioxane. Unlike
conventional hybridized nanostructures of plasmonic nanohole and nanodisk
arrays, the nanodisks of CPS effectively attenuate undesired spectral peaks of
nanoholes by exploiting an extinction peak of nanodisks, serving as a spectral
suppressor. As a result, a single transmission spectral peak becomes
red-shifted from 736 nm to 843 nm as the incident angle varies from 0{\deg} to
30{\deg}. This unique configuration provides a new direction for tunable
filters that can be utilized for compact multispectral or hyperspectral imaging
applications.
","Myeong-Su Ahn, Taerin Chung, Ki-Hun Jeong",Ki-Hun Jeong,2018-01-23T04:43:25Z
Stochastic Block Models are a Discrete Surface Tension,"  Networks, which represent agents and interactions between them, arise in
myriad applications throughout the sciences, engineering, and even the
humanities. To understand large-scale structure in a network, a common task is
to cluster a network's nodes into sets called ""communities"", such that there
are dense connections within communities but sparse connections between them. A
popular and statistically principled method to perform such clustering is to
use a family of generative models known as stochastic block models (SBMs). In
this paper, we show that maximum likelihood estimation in an SBM is a network
analog of a well-known continuum surface-tension problem that arises from an
application in metallurgy. To illustrate the utility of this relationship, we
implement network analogs of three surface-tension algorithms, with which we
successfully recover planted community structure in synthetic networks and
which yield fascinating insights on empirical networks that we construct from
hyperspectral videos.
","Zachary M. Boyd, Mason A. Porter, Andrea L. Bertozzi",Andrea L. Bertozzi,2018-06-07T01:56:03Z
"Classification of remote sensing images using attribute profiles and
  feature profiles from different trees: a comparative study","  The motivation of this paper is to conduct a comparative study on remote
sensing image classification using the morphological attribute profiles (APs)
and feature profiles (FPs) generated from different types of tree structures.
Over the past few years, APs have been among the most effective methods to
model the image's spatial and contextual information. Recently, a novel
extension of APs called FPs has been proposed by replacing pixel gray-levels
with some statistical and geometrical features when forming the output
profiles. FPs have been proved to be more efficient than the standard APs when
generated from component trees (max-tree and min-tree). In this work, we
investigate their performance on the inclusion tree (tree of shapes) and
partition trees (alpha tree and omega tree). Experimental results from both
panchromatic and hyperspectral images again confirm the efficiency of FPs
compared to APs.
","Minh-Tan Pham, Erchan Aptoula, Sébastien Lefèvre",Sébastien Lefèvre,2018-06-18T23:34:55Z
Parallel Nonnegative CP Decomposition of Dense Tensors,"  The CP tensor decomposition is a low-rank approximation of a tensor. We
present a distributed-memory parallel algorithm and implementation of an
alternating optimization method for computing a CP decomposition of dense
tensor data that can enforce nonnegativity of the computed low-rank factors.
The principal task is to parallelize the matricized-tensor times Khatri-Rao
product (MTTKRP) bottleneck subcomputation. The algorithm is computation
efficient, using dimension trees to avoid redundant computation across MTTKRPs
within the alternating method. Our approach is also communication efficient,
using a data distribution and parallel algorithm across a multidimensional
processor grid that can be tuned to minimize communication. We benchmark our
software on synthetic as well as hyperspectral image and neuroscience dynamic
functional connectivity data, demonstrating that our algorithm scales well to
100s of nodes (up to 4096 cores) and is faster and more general than the
currently available parallel software.
","Grey Ballard, Koby Hayashi, Ramakrishnan Kannan",Ramakrishnan Kannan,2018-06-19T13:52:12Z
Graph Regularized Tensor Train Decomposition,"  With the advances in data acquisition technology, tensor objects are
collected in a variety of applications including multimedia, medical and
hyperspectral imaging. As the dimensionality of tensor objects is usually very
high, dimensionality reduction is an important problem. Most of the current
tensor dimensionality reduction methods rely on finding low-rank linear
representations using different generative models. However, it is well-known
that high-dimensional data often reside in a low-dimensional manifold.
Therefore, it is important to find a compact representation, which uncovers the
low dimensional tensor structure while respecting the intrinsic geometry. In
this paper, we propose a graph regularized tensor train (GRTT) decomposition
that learns a low-rank tensor train model that preserves the local
relationships between tensor samples. The proposed method is formulated as a
nonconvex optimization problem on the Stiefel manifold and an efficient
algorithm is proposed to solve it. The proposed method is compared to existing
tensor based dimensionality reduction methods as well as tensor manifold
embedding methods for unsupervised learning applications.
","Seyyid Emre Sofuoglu, Selin Aviyente",Selin Aviyente,2019-11-05T03:19:02Z
"Spatially regularized active diffusion learning for high-dimensional
  images","  An active learning algorithm for the classification of high-dimensional
images is proposed in which spatially-regularized nonlinear diffusion geometry
is used to characterize cluster cores. The proposed method samples from
estimated cluster cores in order to generate a small but potent set of training
labels which propagate to the remainder of the dataset via the underlying
diffusion process. By spatially regularizing the rich, high-dimensional
spectral information of the image to efficiently estimate the most significant
and influential points in the data, our approach avoids redundancy in the
training dataset. This allows it to produce high-accuracy labelings with a very
small number of training labels. The proposed algorithm admits an efficient
numerical implementation that scales essentially linearly in the number of data
points under a suitable data model and enjoys state-of-the-art performance on
real hyperspectral images.
",James M. Murphy,James M. Murphy,2019-11-06T00:58:24Z
"Laser-induced fluorescence study of medieval frescoes by Giusto de'
  Menabuoi","  Laser induced fluorescence (LIF) is a powerful remote and non-invasive
analysis technique that has been successfully applied to the real-time
diagnosis of historical artworks. Hyperspectral images collection on fresco' s
and their false colours processing allowed to reveal features invisible to the
naked eye and to obtain specific information on pigments composition and
consolidants utilization, the latter also related to former restorations. This
report presents the results obtained by ENEA LIF scanning system during a field
campaign conducted in June 2010 on fresco's by Giusto de' Menabuoi in the Padua
Baptistery. The data collected by LidArt allowed the detection of Paraloid B72
and Movilith/Primal AC33, guiding the restorers in their conservation actions.
","Roberta Fantoni, Luisa Caneve, Francesco Colao, Luca Fiorani, Antonio Palucci, Ramiro dell'Erba, Vasco Fassina",Vasco Fassina,2020-04-22T07:51:37Z
Hierarchical Tensor Ring Completion,"  Tensor completion can estimate missing values of a high-order data from its
partially observed entries. Recent works show that low rank tensor ring
approximation is one of the most powerful tools to solve tensor completion
problem. However, existing algorithms need predefined tensor ring rank which
may be hard to determine in practice. To address the issue, we propose a
hierarchical tensor ring decomposition for more compact representation. We use
the standard tensor ring to decompose a tensor into several 3-order sub-tensors
in the first layer, and each sub-tensor is further factorized by tensor
singular value decomposition (t-SVD) in the second layer. In the low rank
tensor completion based on the proposed decomposition, the zero elements in the
3-order core tensor are pruned in the second layer, which helps to
automatically determinate the tensor ring rank. To further enhance the recovery
performance, we use total variation to exploit the locally piece-wise
smoothness data structure. The alternating direction method of multiplier can
divide the optimization model into several subproblems, and each one can be
solved efficiently. Numerical experiments on color images and hyperspectral
images demonstrate that the proposed algorithm outperforms state-of-the-arts
ones in terms of recovery accuracy.
","Abdul Ahad, Zhen Long, Ce Zhu, Yipeng Liu",Yipeng Liu,2020-04-22T11:10:17Z
Lasing from multipole topological corner states,"  Topological photonics provides a fundamental framework for robust
manipulation of light, including directional transport and localization with
built-in immunity to disorder. Combined with an optical gain, active
topological cavities hold special promise for a design of light-emitting
devices. Most studies to date have focused on lasing at topological edges of
finite systems or domain walls. Recently discovered higher-order topological
phases enable strong high-quality confinement of light at the corners. Here we
demonstrate lasing action of corner states in a nanophotonic topological
cavity. We identify four multipole corner modes with distinct emission profiles
via hyperspectral imaging and discern signatures of non-Hermitian radiative
coupling of leaky topological states. In addition, depending on the pump
position in a large-size cavity, we selectively generate lasing from either
edge or corner states within the topological bandgap. Our findings introduce
pathways to engineer collective resonances and tailor generation of light in
active topological circuits.
","Ha-Reem Kim, Min-Soo Hwang, Daria Smirnova, Kwang-Yong Jeong, Yuri Kivshar, Hong-Gyu Park",Hong-Gyu Park,2020-04-29T07:15:47Z
"Simplex-Structured Matrix Factorization: Sparsity-based Identifiability
  and Provably Correct Algorithms","  In this paper, we provide novel algorithms with identifiability guarantees
for simplex-structured matrix factorization (SSMF), a generalization of
nonnegative matrix factorization. Current state-of-the-art algorithms that
provide identifiability results for SSMF rely on the sufficiently scattered
condition (SSC) which requires the data points to be well spread within the
convex hull of the basis vectors. The conditions under which our proposed
algorithms recover the unique decomposition is in most cases much weaker than
the SSC. We only require to have $d$ points on each facet of the convex hull of
the basis vectors whose dimension is $d-1$. The key idea is based on extracting
facets containing the largest number of points. We illustrate the effectiveness
of our approach on synthetic data sets and hyperspectral images, showing that
it outperforms state-of-the-art SSMF algorithms as it is able to handle higher
noise levels, rank deficient matrices, outliers, and input data that highly
violates the SSC.
","Maryam Abdolali, Nicolas Gillis",Nicolas Gillis,2020-07-22T14:01:58Z
Multi-modality imaging with structure-promoting regularisers,"  Imaging with multiple modalities or multiple channels is becoming
increasingly important for our modern society. A key tool for understanding and
early diagnosis of cancer and dementia is PET-MR, a combined positron emission
tomography and magnetic resonance imaging scanner which can simultaneously
acquire functional and anatomical data. Similarly in remote sensing, while
hyperspectral sensors may allow to characterise and distinguish materials,
digital cameras offer high spatial resolution to delineate objects. In both of
these examples, the imaging modalities can be considered individually or
jointly. In this chapter we discuss mathematical approaches which allow to
combine information from several imaging modalities so that multi-modality
imaging can be more than just the sum of its components.
",Matthias J. Ehrhardt,Matthias J. Ehrhardt,2020-07-22T21:26:37Z
Guided Deep Decoder: Unsupervised Image Pair Fusion,"  The fusion of input and guidance images that have a tradeoff in their
information (e.g., hyperspectral and RGB image fusion or pansharpening) can be
interpreted as one general problem. However, previous studies applied a
task-specific handcrafted prior and did not address the problems with a unified
approach. To address this limitation, in this study, we propose a guided deep
decoder network as a general prior. The proposed network is composed of an
encoder-decoder network that exploits multi-scale features of a guidance image
and a deep decoder network that generates an output image. The two networks are
connected by feature refinement units to embed the multi-scale features of the
guidance image into the deep decoder network. The proposed network allows the
network parameters to be optimized in an unsupervised way without training
data. Our results show that the proposed network can achieve state-of-the-art
performance in various image fusion problems.
","Tatsumi Uezato, Danfeng Hong, Naoto Yokoya, Wei He",Wei He,2020-07-23T03:06:06Z
"Multi-mode Core Tensor Factorization based Low-Rankness and Its
  Applications to Tensor Completion","  Low-rank tensor completion has been widely used in computer vision and
machine learning. This paper develops a novel multi-modal core tensor
factorization (MCTF) method combined with a tensor low-rankness measure and a
better nonconvex relaxation form of this measure (NC-MCTF). The proposed models
encode low-rank insights for general tensors provided by Tucker and T-SVD, and
thus are expected to simultaneously model spectral low-rankness in multiple
orientations and accurately restore the data of intrinsic low-rank structure
based on few observed entries. Furthermore, we study the MCTF and NC-MCTF
regularization minimization problem, and design an effective block successive
upper-bound minimization (BSUM) algorithm to solve them. This efficient solver
can extend MCTF to various tasks, such as tensor completion. A series of
experiments, including hyperspectral image (HSI), video and MRI completion,
confirm the superior performance of the proposed method.
",Haijin Zeng,Haijin Zeng,2020-12-03T13:57:00Z
Kernel Anomalous Change Detection for Remote Sensing Imagery,"  Anomalous change detection (ACD) is an important problem in remote sensing
image processing. Detecting not only pervasive but also anomalous or extreme
changes has many applications for which methodologies are available. This paper
introduces a nonlinear extension of a full family of anomalous change
detectors. In particular, we focus on algorithms that utilize Gaussian and
elliptically contoured (EC) distribution and extend them to their nonlinear
counterparts based on the theory of reproducing kernels' Hilbert space. We
illustrate the performance of the kernel methods introduced in both pervasive
and ACD problems with real and simulated changes in multispectral and
hyperspectral imagery with different resolutions (AVIRIS, Sentinel-2,
WorldView-2, and Quickbird). A wide range of situations is studied in real
examples, including droughts, wildfires, and urbanization. Excellent
performance in terms of detection accuracy compared to linear formulations is
achieved, resulting in improved detection accuracy and reduced false-alarm
rates. Results also reveal that the EC assumption may be still valid in Hilbert
spaces. We provide an implementation of the algorithms as well as a database of
natural anomalous changes in real scenarios http://isp.uv.es/kacd.html.
","José A. Padrón-Hidalgo, Valero Laparra, Nathan Longbotham, Gustau Camps-Valls",Gustau Camps-Valls,2020-12-09T08:57:36Z
Efficient Nonlinear RX Anomaly Detectors,"  Current anomaly detection algorithms are typically challenged by either
accuracy or efficiency. More accurate nonlinear detectors are typically slow
and not scalable. In this letter, we propose two families of techniques to
improve the efficiency of the standard kernel Reed-Xiaoli (RX) method for
anomaly detection by approximating the kernel function with either {\em
data-independent} random Fourier features or {\em data-dependent} basis with
the Nystr\""om approach. We compare all methods for both real multi- and
hyperspectral images. We show that the proposed efficient methods have a lower
computational cost and they perform similar (or outperform) the standard kernel
RX algorithm thanks to their implicit regularization effect. Last but not
least, the Nystr\""om approach has an improved power of detection.
","José A. Padrón Hidalgo, Adrián Pérez-Suay, Fatih Nar, Gustau Camps-Valls",Gustau Camps-Valls,2020-12-07T21:57:54Z
Planck spectroscopy,"  All spectrometers rely on some mechanism to achieve spectral selectivity;
common examples include gratings, prisms, and interferometers with moving
mirrors. We experimentally demonstrated and validated a spectroscopic technique
-- here dubbed Planck spectroscopy -- that measures the spectral emissivity of
a surface using only a temperature-controlled stage and a detector, without any
wavelength-selective optical components. Planck spectroscopy involves the
measurement of temperature-dependent thermally emitted power, where the
spectral selectivity is realized via the temperature- and wavelength dependence
of Planck's law. We experimentally demonstrated and validated Planck
spectroscopy in the mid infrared, for wavelengths from 3 to 13 um -- limited
primarily by the bandwidth of our detector -- with resolution of approximately
1 um. The minimalistic setup of Planck spectroscopy can be implemented using
infrared cameras to achieve low-cost infrared hyperspectral imaging and imaging
ellipsometry.
","Yuzhe Xiao, Chenghao Wan, Jad Salman, Ian J. Maywar, Jonathan King, Alireza Shahsafi, Mikhail A. Kats",Mikhail A. Kats,2020-12-10T18:52:27Z
"Spectral band selection for vegetation properties retrieval using
  Gaussian processes regression","  With current and upcoming imaging spectrometers, automated band analysis
techniques are needed to enable efficient identification of most informative
bands to facilitate optimized processing of spectral data into estimates of
biophysical variables. This paper introduces an automated spectral band
analysis tool (BAT) based on Gaussian processes regression (GPR) for the
spectral analysis of vegetation properties. The GPR-BAT procedure sequentially
backwards removes the least contributing band in the regression model for a
given variable until only one band is kept. GPR-BAT is implemented within the
framework of the free ARTMO's MLRA (machine learning regression algorithms)
toolbox, which is dedicated to the transforming of optical remote sensing
images into biophysical products. GPR-BAT allows (1) to identify the most
informative bands in relating spectral data to a biophysical variable, and (2)
to find the least number of bands that preserve optimized accurate predictions.
This study concludes that a wise band selection of hyperspectral data is
strictly required for optimal vegetation properties mapping.
","Jochem Verrelst, Juan Pablo Rivera, Anatoly Gitelson, Jesus Delegido, José Moreno, Gustau Camps-Valls",Gustau Camps-Valls,2020-12-07T09:28:33Z
"Warped Gaussian Processes in Remote Sensing Parameter Estimation and
  Causal Inference","  This paper introduces warped Gaussian processes (WGP) regression in remote
sensing applications. WGP models output observations as a parametric nonlinear
transformation of a GP. The parameters of such prior model are then learned via
standard maximum likelihood. We show the good performance of the proposed model
for the estimation of oceanic chlorophyll content from multispectral data,
vegetation parameters (chlorophyll, leaf area index, and fractional vegetation
cover) from hyperspectral data, and in the detection of the causal direction in
a collection of 28 bivariate geoscience and remote sensing causal problems. The
model consistently performs better than the standard GP and the more advanced
heteroscedastic GP model, both in terms of accuracy and more sensible
confidence intervals.
","Anna Mateo-Sanchis, Jordi Muñoz-Marí, Adrián Pérez-Suay, Gustau Camps-Valls",Gustau Camps-Valls,2020-12-09T09:02:59Z
Probabilistic Simplex Component Analysis,"  This study presents PRISM, a probabilistic simplex component analysis
approach to identifying the vertices of a data-circumscribing simplex from
data. The problem has a rich variety of applications, the most notable being
hyperspectral unmixing in remote sensing and non-negative matrix factorization
in machine learning. PRISM uses a simple probabilistic model, namely, uniform
simplex data distribution and additive Gaussian noise, and it carries out
inference by maximum likelihood. The inference model is sound in the sense that
the vertices are provably identifiable under some assumptions, and it suggests
that PRISM can be effective in combating noise when the number of data points
is large. PRISM has strong, but hidden, relationships with simplex volume
minimization, a powerful geometric approach for the same problem. We study
these fundamental aspects, and we also consider algorithmic schemes based on
importance sampling and variational inference. In particular, the variational
inference scheme is shown to resemble a matrix factorization problem with a
special regularizer, which draws an interesting connection to the matrix
factorization approach. Numerical results are provided to demonstrate the
potential of PRISM.
","Ruiyuan Wu, Wing-Kin Ma, Yuening Li, Anthony Man-Cho So, Nicholas D. Sidiropoulos",Nicholas D. Sidiropoulos,2021-03-18T05:39:00Z
"Probelab ReImager: An Open-Source Software for Streamlining Image
  Processing in an Electron Microscopy Laboratory","  Providing high-quality electron images and hyperspectral X-ray maps is a
focus of many modern electron microscopy laboratories. Nevertheless, further
image processing and annotations are often needed to prepare them for
publications and reports. For multi-user facilities, accessibility to
processing software can be a limitation either through license costs or
availability of processing stations. Open-source software running on multiple
platforms allows for post-acquisition data processing in-lab or on user-owned
devices. We developed Probelab ReImager to supersede our vendor-supplied
acquisition software's exportation by being efficient and highly customizable.
This article describes its main features and capabilities.
","Noah Kraft, Anette von der Handt",Anette von der Handt,2021-03-21T05:40:29Z
"Rank-R FNN: A Tensor-Based Learning Model for High-Order Data
  Classification","  An increasing number of emerging applications in data science and engineering
are based on multidimensional and structurally rich data. The irregularities,
however, of high-dimensional data often compromise the effectiveness of
standard machine learning algorithms. We hereby propose the Rank-R Feedforward
Neural Network (FNN), a tensor-based nonlinear learning model that imposes
Canonical/Polyadic decomposition on its parameters, thereby offering two core
advantages compared to typical machine learning methods. First, it handles
inputs as multilinear arrays, bypassing the need for vectorization, and can
thus fully exploit the structural information along every data dimension.
Moreover, the number of the model's trainable parameters is substantially
reduced, making it very efficient for small sample setting problems. We
establish the universal approximation and learnability properties of Rank-R
FNN, and we validate its performance on real-world hyperspectral datasets.
Experimental evaluations show that Rank-R FNN is a computationally inexpensive
alternative of ordinary FNN that achieves state-of-the-art performance on
higher-order tensor data.
","Konstantinos Makantasis, Alexandros Georgogiannis, Athanasios Voulodimos, Ioannis Georgoulas, Anastasios Doulamis, Nikolaos Doulamis",Nikolaos Doulamis,2021-04-11T16:37:32Z
"A survey of active learning algorithms for supervised remote sensing
  image classification","  Defining an efficient training set is one of the most delicate phases for the
success of remote sensing image classification routines. The complexity of the
problem, the limited temporal and financial resources, as well as the high
intraclass variance can make an algorithm fail if it is trained with a
suboptimal dataset. Active learning aims at building efficient training sets by
iteratively improving the model performance through sampling. A user-defined
heuristic ranks the unlabeled pixels according to a function of the uncertainty
of their class membership and then the user is asked to provide labels for the
most uncertain pixels. This paper reviews and tests the main families of active
learning algorithms: committee, large margin and posterior probability-based.
For each of them, the most recent advances in the remote sensing community are
discussed and some heuristics are detailed and tested. Several challenging
remote sensing scenarios are considered, including very high spatial resolution
and hyperspectral image classification. Finally, guidelines for choosing the
good architecture are provided for new and/or unexperienced user.
","Devis Tuia, Michele Volpi, Loris Copa, Mikhail Kanevski, Jordi Munoz-Mari",Jordi Munoz-Mari,2021-04-15T21:36:59Z
"Iterative optimal solutions of linear matrix equations for Hyperspectral
  and Multispectral image fusing","  For a linear matrix function $f$ in $X \in \R^{m\times n}$ we consider
inhomogeneous linear matrix equations $f(X) = E$ for $E \neq 0$ that have or do
not have solutions. For such systems we compute optimal norm constrained
solutions iteratively using the Conjugate Gradient and Lanczos' methods in
combination with the More-Sorensen optimizer. We build codes for ten linear
matrix equations, of Sylvester, Lyapunov, Stein and structured types and their
T-versions, that differ only in two five times repeated equation specific code
lines. Numerical experiments with linear matrix equations are performed that
illustrate universality and efficiency of our method for dense and small data
matrices, as well as for sparse and certain structured input matrices.
Specifically we show how to adapt our universal method for sparse inputs and
for structured data such as encountered when fusing image data sets via a
Sylvester equation algorithm to obtain an image of higher resolution.
","Frank Uhlig, An-Bao Xu",An-Bao Xu,2021-08-01T18:57:29Z
"Self-supervised Neural Networks for Spectral Snapshot Compressive
  Imaging","  We consider using {\bf\em untrained neural networks} to solve the
reconstruction problem of snapshot compressive imaging (SCI), which uses a
two-dimensional (2D) detector to capture a high-dimensional (usually 3D)
data-cube in a compressed manner. Various SCI systems have been built in recent
years to capture data such as high-speed videos, hyperspectral images, and the
state-of-the-art reconstruction is obtained by the deep neural networks.
However, most of these networks are trained in an end-to-end manner by a large
amount of corpus with sometimes simulated ground truth, measurement pairs. In
this paper, inspired by the untrained neural networks such as deep image priors
(DIP) and deep decoders, we develop a framework by integrating DIP into the
plug-and-play regime, leading to a self-supervised network for spectral SCI
reconstruction. Extensive synthetic and real data results show that the
proposed algorithm without training is capable of achieving competitive results
to the training based networks. Furthermore, by integrating the proposed method
with a pre-trained deep denoising prior, we have achieved state-of-the-art
results. {Our code is available at
\url{https://github.com/mengziyi64/CASSI-Self-Supervised}.}
","Ziyi Meng, Zhenming Yu, Kun Xu, Xin Yuan",Xin Yuan,2021-08-28T14:17:38Z
"Refinement of Hottopixx Method for Nonnegative Matrix Factorization
  Under Noisy Separability","  Hottopixx, proposed by Bittorf et al. at NIPS 2012, is an algorithm for
solving nonnegative matrix factorization (NMF) problems under the separability
assumption. Separable NMFs have important applications, such as topic
extraction from documents and unmixing of hyperspectral images. In such
applications, the robustness of the algorithm to noise is the key to the
success. Hottopixx has been shown to be robust to noise, and its robustness can
be further enhanced through postprocessing. However, there is a drawback.
Hottopixx and its postprocessing require us to estimate the noise level
involved in the matrix we want to factorize before running, since they use it
as part of the input data. The noise-level estimation is not an easy task. In
this paper, we overcome this drawback. We present a refinement of Hottopixx and
its postprocessing that runs without prior knowledge of the noise level. We
show that the refinement has almost the same robustness to noise as the
original algorithm.
",Tomohiko Mizutani,Tomohiko Mizutani,2021-09-07T04:43:53Z
"Tailoring the degree of entanglement of two coherently coupled quantum
  emitters","  The control and manipulation of quantum-entangled non-local states is a
crucial step for the development of quantum information processing. A promising
route to achieve such states on a wide scale is to couple solid-state quantum
emitters through their coherent dipole-dipole interactions. Entanglement in
itself is challenging, as it requires both nanometric distances between
emitters and nearly degenerate electronic transitions. Implementing
hyperspectral imaging to identify pairs of coupled organic molecules trapped in
a low temperature matrix, we reach distinctive spectral signatures of maximal
molecular entanglement by tuning the optical resonances of the quantum emitters
by Stark effect. We also demonstrate far-field selective excitation of the
long-lived subradiant delocalized states with a laser field tailored in
amplitude and phase. Interestingly, optical nanoscopy images of the entangled
molecules unveil novel spatial signatures that result from quantum
interferences in their excitation pathways and reveal the exact locations of
each quantum emitter. Controlled molecular entanglement can serve as a
test-bench to decipher more complex physical or biological mechanisms governed
by the coherent coupling and paves the way towards the realization of new
quantum information processing platforms.
","J. -B Trebbia, Q Deplano, P Tamarat, B Lounis",B Lounis,2021-09-22T08:30:59Z
Programmable Spectral Filter Arrays using Phase Spatial Light Modulator,"  Spatially varying spectral modulation can be implemented using a liquid
crystal spatial light modulator (SLM) since it provides an array of liquid
crystal cells, each of which can be purposed to act as a programmable spectral
filter array. However, such an optical setup suffers from strong optical
aberrations due to the unintended phase modulation, precluding spectral
modulation at high spatial resolutions. In this work, we propose a novel
computational approach for the practical implementation of phase SLMs for
implementing spatially varying spectral filters. We provide a careful and
systematic analysis of the aberrations arising out of phase SLMs for the
purposes of spatially varying spectral modulation. The analysis naturally leads
us to a set of ""good patterns"" that minimize the optical aberrations. We then
train a deep network that overcomes any residual aberrations, thereby achieving
ideal spectral modulation at high spatial resolution. We show a number of
unique operating points with our prototype including dynamic spectral
filtering, material classification, and single- and multi-image hyperspectral
imaging.
","Vishwanath Saragadam, Vijay Rengarajan, Ryuichi Tadano, Tuo Zhuang, Hideki Oyaizu, Jun Murayama, Aswin C. Sankaranarayanan",Aswin C. Sankaranarayanan,2021-09-29T14:30:55Z
"Real space visualization of entangled excitonic states in charged
  molecular assemblies","  Entanglement of excitons holds great promise for the future of quantum
computing, which would use individual molecular dyes as building blocks of
their circuitry. Even though entangled excitonic eigenstates emerging in
coupled molecular assemblies can be detected by far-field spectroscopies,
access to the individual modes in real space will bring the much needed insight
into the photophysics of these fascinating quantum phenomena. Here we combine
tip-enhanced spectromicroscopy with atomic force microscopy to inspect
delocalized single-exciton states of charged molecular assemblies engineered
from individual perylenetetracarboxylic dianhydride molecules. Hyperspectral
mapping of the eigenstates and comparison with calculated many-body optical
transitions reveals a second low-lying excited state of the anion monomers and
its role in the exciton entanglement within the assemblies. We also demonstrate
control over the coupling by switching the assembly charge states. Our results
reveal the possibility of tailoring excitonic properties of organic dye
aggregates for advanced functionalities and establish the methodology to
address them individually at the nanoscale.
","Jiří Doležal, Sofia Canola, Prokop Hapala, Rodrigo C. de Campos Ferreira, Pablo Merino, Martin Švec",Martin Švec,2021-10-01T10:51:23Z
Hyperspectral Neutron CT with Material Decomposition,"  Energy resolved neutron imaging (ERNI) is an advanced neutron radiography
technique capable of non-destructively extracting spatial isotopic information
within a given material. Energy-dependent radiography image sequences can be
created by utilizing neutron time-of-flight techniques. In combination with
uniquely characteristic isotopic neutron cross-section spectra, isotopic areal
densities can be determined on a per-pixel basis, thus resulting in a set of
areal density images for each isotope present in the sample. By preforming ERNI
measurements over several rotational views, an isotope decomposed 3D computed
tomography is possible. We demonstrate a method involving a robust and
automated background estimation based on a linear programming formulation. The
extremely high noise due to low count measurements is overcome using a sparse
coding approach. It allows for a significant computation time improvement, from
weeks to a few hours compared to existing neutron evaluation tools, enabling at
the present stage a semi-quantitative, user-friendly routine application.
","Thilo Balke, Alexander M. Long, Sven C. Vogel, Brendt Wohlberg, Charles A. Bouman",Charles A. Bouman,2021-10-06T00:52:30Z
"Introduction to the calibration ringing effect in satellite
  hyperspectral atmospheric spectrometry","  Atmospheric remote spectrometry from space has become in the last 20 years a
key component of the Earth monitoring system: their large coverage and
deci-kelvin stability have demonstrated their usefulness for weather
prediction, atmospheric composition monitoring as well as climate monitoring.
It is thus critical to investigate the possible sources of errors associated to
this technique. One of them is the so-called ""calibration ringing error"" that
appears in Fourier transform spectrometers at the radiometric calibration step
when the instrument transmission varies at the scale of the spectral resolution
and is not accounted by the data users. This paper exposes the theoretical
basis of this particular type of radiometric uncertainty. Its sensitivity to
instrumental parameters as well as the impact on the radiometrically calibrated
measurements is assessed in the context of atmospheric infrared sounding using
Fourier transform spectrometers. It is shown that this error is an intrinsic
feature of such instruments that could safely be ignored in early-generation
instruments but will have to be taken into account in the new generation ones
as it can yield a significant degradation of the radiometric error budget.
","Pierre Dussarrat, Bertrand Theodore, Dorothee Coppens, Carsten Standfuss, Bernard Tournier",Bernard Tournier,2021-11-16T15:52:33Z
Disorder of Excitons and Trions in Monolayer MoSe2,"  The optical spectra of transition metal dichalcogenide (TMDC) monolayers are
dominated by excitons and trions. Here we establish the dependences of these
optical transitions on disorder from hyperspectral imaging of h-BN encapsulated
monolayer MoSe2. While both exciton and trion energies vary spatially, these
two quantities are almost perfectly correlated, with spatial variation in the
trion binding energy of only ~0.18 meV. In contrast, variation in the energy
splitting between the two lowest energy exciton states is one order of
magnitude larger at ~1.7 meV. Statistical analysis and theoretical modeling
reveal that disorder results from dielectric and bandgap fluctuations, not
electrostatic fluctuations. Our results shed light on disorder in high quality
TMDC monolayers, its impact on optical transitions, and the many-body nature of
excitons and trions.
","Jue Wang, Christina Manolatou, Yusong Bai, James Hone, Farhan Rana, Xiaoyang Zhu",Xiaoyang Zhu,2021-11-18T13:38:16Z
"Dictionary-based Low-Rank Approximations and the Mixed Sparse Coding
  problem","  Constrained tensor and matrix factorization models allow to extract
interpretable patterns from multiway data. Therefore identifiability properties
and efficient algorithms for constrained low-rank approximations are nowadays
important research topics. This work deals with columns of factor matrices of a
low-rank approximation being sparse in a known and possibly overcomplete basis,
a model coined as Dictionary-based Low-Rank Approximation (DLRA). While earlier
contributions focused on finding factor columns inside a dictionary of
candidate columns, i.e. one-sparse approximations, this work is the first to
tackle DLRA with sparsity larger than one. I propose to focus on the
sparse-coding subproblem coined Mixed Sparse-Coding (MSC) that emerges when
solving DLRA with an alternating optimization strategy. Several algorithms
based on sparse-coding heuristics (greedy methods, convex relaxations) are
provided to solve MSC. The performance of these heuristics is evaluated on
simulated data. Then, I show how to adapt an efficient MSC solver based on the
LASSO to compute Dictionary-based Matrix Factorization and Canonical Polyadic
Decomposition in the context of hyperspectral image processing and
chemometrics. These experiments suggest that DLRA extends the modeling
capabilities of low-rank approximations, helps reducing estimation variance and
enhances the identifiability and interpretability of estimated factors.
",Jeremy E. Cohen,Jeremy E. Cohen,2021-11-24T10:32:48Z
"Attention Mechanism Meets with Hybrid Dense Network for Hyperspectral
  Image Classification","  Convolutional Neural Networks (CNN) are more suitable, indeed. However, fixed
kernel sizes make traditional CNN too specific, neither flexible nor conducive
to feature learning, thus impacting on the classification accuracy. The
convolution of different kernel size networks may overcome this problem by
capturing more discriminating and relevant information. In light of this, the
proposed solution aims at combining the core idea of 3D and 2D Inception net
with the Attention mechanism to boost the HSIC CNN performance in a hybrid
scenario. The resulting \textit{attention-fused hybrid network} (AfNet) is
based on three attention-fused parallel hybrid sub-nets with different kernels
in each block repeatedly using high-level features to enhance the final
ground-truth maps. In short, AfNet is able to selectively filter out the
discriminative features critical for classification. Several tests on HSI
datasets provided competitive results for AfNet compared to state-of-the-art
models. The proposed pipeline achieved, indeed, an overall accuracy of 97\% for
the Indian Pines, 100\% for Botswana, 99\% for Pavia University, Pavia Center,
and Salinas datasets.
","Muhammad Ahmad, Adil Mehmood Khan, Manuel Mazzara, Salvatore Distefano, Swalpa Kumar Roy, Xin Wu",Xin Wu,2022-01-04T06:30:24Z
"Hyperspectral Image Denoising Using Non-convex Local Low-rank and Sparse
  Separation with Spatial-Spectral Total Variation Regularization","  In this paper, we propose a novel nonconvex approach to robust principal
component analysis for HSI denoising, which focuses on simultaneously
developing more accurate approximations to both rank and column-wise sparsity
for the low-rank and sparse components, respectively. In particular, the new
method adopts the log-determinant rank approximation and a novel
$\ell_{2,\log}$ norm, to restrict the local low-rank or column-wisely sparse
properties for the component matrices, respectively. For the
$\ell_{2,\log}$-regularized shrinkage problem, we develop an efficient,
closed-form solution, which is named $\ell_{2,\log}$-shrinkage operator. The
new regularization and the corresponding operator can be generally used in
other problems that require column-wise sparsity. Moreover, we impose the
spatial-spectral total variation regularization in the log-based nonconvex RPCA
model, which enhances the global piece-wise smoothness and spectral consistency
from the spatial and spectral views in the recovered HSI. Extensive experiments
on both simulated and real HSIs demonstrate the effectiveness of the proposed
method in denoising HSIs.
","Chong Peng, Yang Liu, Yongyong Chen, Xinxin Wu, Andrew Cheng, Zhao Kang, Chenglizhao Chen, Qiang Cheng",Qiang Cheng,2022-01-08T11:48:46Z
"Hyperbolic Metamaterial Filter for Angle-independent TM-Transmission in
  Imaging Applications","  With conventional narrowband filters, the center-wavelength of the narrow
transmission band undergoes large shifts as the angle of incident light
changes. In this project, we designed and experimentally verified a type of
hyperbolic metamaterial Bragg stack that eliminates, or vastly reduces, this
angle-of-incidence dependence (i.e., dispersion) of the transmission band for
TM polarized beam. The filter developed in this project is composed of array of
subwavelength sized metal wires vertically penetrating in the dielectric layers
of the Bragg stack. We first discuss the physical reasons why such a structure
is expected to minimize dispersion, then we performed detailed electromagnetic
modeling, fabrication of proof-of-concept structures, and optical testing of
the structures. The filter is fabricated by CMOS fabrication techniques and
optical characterized using Fourier-transform infrared spectroscopy. Both
simulated and experimental data show that narrow band transmission filters can
be designed such that the center-wavelength of the transmission peak for TM
polarized incident light does not change as the angle of incidence of an
incoming beam changes. These types of narrowband notch filters have been used
in many sensing and imaging applications, including remote sensing and
hyperspectral imaging.
",Golsa Mirbagheri,Golsa Mirbagheri,2022-01-15T00:26:48Z
"Low-energy electron microscopy intensity-voltage data -- factorization,
  sparse sampling, and classification","  Low-energy electron microscopy (LEEM) taken as intensity-voltage (I-V) curves
provides hyperspectral images of surfaces, which can be used to identify the
surface type, but are difficult to analyze. Here, we demonstrate the use of an
algorithm for factorizing the data into spectra and concentrations of
characteristic components (FSC3) for identifying distinct physical surface
phases. Importantly, FSC3 is an unsupervised and fast algorithm. As example
data we use experiments on the growth of praseodymium oxide or ruthenium oxide
on ruthenium single crystal substrates, both featuring a complex distribution
of coexisting surface components, varying in both chemical composition and
crystallographic structure. With the factorization result a sparse sampling
method is demonstrated, reducing the measurement time by 1-2 orders of
magnitude, relevant for dynamic surface studies. The FSC3 concentrations are
providing the features for a support vector machine (SVM) based supervised
classification of the types. Here, specific surface regions which have been
identified structurally, via their diffraction pattern, as well as chemically
by complementary spectro-microscopic techniques, are used as training sets. A
reliable classification is demonstrated on both exemplary LEEM I-V datasets.
","Francesco Masia, Wolfgang Langbein, Simon Fischer, Jon-Olaf Krisponeit, Jens Falta",Jens Falta,2022-03-23T12:09:21Z
Enhanced versatility of table-top X-rays from van der Waals structures,"  Van der Waals (vdW) materials have attracted much interest for their myriad
unique electronic, mechanical and thermal properties. In particular, they are
promising candidates for monochromatic, table-top X-ray sources. This work
reveals that the versatility of the table-top vdW X-ray source goes beyond what
has been demonstrated so far. By introducing a tilt angle between the vdW
structure and the incident electron beam, it is theoretically and
experimentally shown that the accessible photon energy range is more than
doubled. This allows for greater versatility in real-time tuning of the vdW
X-ray source. Furthermore, this work shows that the accessible photon energy
range is maximized by simultaneously controlling both the electron energy and
the vdW structure tilt. These results should pave the way for highly tunable,
compact X-ray sources, with potential applications including hyperspectral
X-ray fluoroscopy and X-ray quantum optics.
","Sunchao Huang, Ruihuan Duan, Nikhil Pramanik, Chris Boothroyd, Zheng Liu, Liang Jie Wong",Liang Jie Wong,2022-03-28T14:01:34Z
"A Fast Alternating Minimization Algorithm for Coded Aperture Snapshot
  Spectral Imaging Based on Sparsity and Deep Image Priors","  Coded aperture snapshot spectral imaging (CASSI) is a technique used to
reconstruct three-dimensional hyperspectral images (HSIs) from one or several
two-dimensional projection measurements. However, fewer projection measurements
or more spectral channels leads to a severly ill-posed problem, in which case
regularization methods have to be applied. In order to significantly improve
the accuracy of reconstruction, this paper proposes a fast alternating
minimization algorithm based on the sparsity and deep image priors (Fama-SDIP)
of natural images. By integrating deep image prior (DIP) into the principle of
compressive sensing (CS) reconstruction, the proposed algorithm can achieve
state-of-the-art results without any training dataset. Extensive experiments
show that Fama-SDIP method significantly outperforms prevailing leading methods
on simulation and real HSI datasets.
","Qile Zhao, Xianhong Zhao, Xu Ma, Xudong Chen, Gonzalo R. Arce",Gonzalo R. Arce,2022-06-12T03:29:14Z
A consistent and flexible framework for deep matrix factorizations,"  Deep matrix factorizations (deep MFs) are recent unsupervised data mining
techniques inspired by constrained low-rank approximations. They aim to extract
complex hierarchies of features within high-dimensional datasets. Most of the
loss functions proposed in the literature to evaluate the quality of deep MF
models and the underlying optimization frameworks are not consistent because
different losses are used at different layers. In this paper, we introduce two
meaningful loss functions for deep MF and present a generic framework to solve
the corresponding optimization problems. We illustrate the effectiveness of
this approach through the integration of various constraints and
regularizations, such as sparsity, nonnegativity and minimum-volume. The models
are successfully applied on both synthetic and real data, namely for
hyperspectral unmixing and extraction of facial features.
","Pierre De Handschutter, Nicolas Gillis",Nicolas Gillis,2022-06-21T19:20:35Z
"Underwater autonomous mapping and characterization of marine debris in
  urban water bodies","  Marine debris originating from human activity has been accumulating in
underwater environments such as oceans, lakes, and rivers for decades. The
extent, type, and amount of waste is hard to assess as the exact mechanisms for
spread are not understood, yielding unknown consequences for the marine
environment and human health. Methods for detecting and mapping marine debris
is therefore vital in order to gain insight into pollution dynamics, which in
turn can be used to effectively plan and execute physical removal. Using an
autonomous underwater vehicle (AUV), equipped with an underwater hyperspectral
imager (UHI) and stereo-camera, marine debris was autonomously detected, mapped
and quantified in the sheltered bay Store Lungegaardsvann in Bergen, Norway.
","Trygve Olav Fossum, Øystein Sture, Petter Norgren-Aamot, Ingrid Myrnes Hansen, Bjørn Christian Kvisvik, Anne Christine Knag",Anne Christine Knag,2022-08-01T12:36:38Z
"Tree species classification from hyperspectral data using
  graph-regularized neural networks","  We propose a novel graph-regularized neural network (GRNN) algorithm for tree
species classification. The proposed algorithm encompasses superpixel-based
segmentation for graph construction, a pixel-wise neural network classifier,
and the label propagation technique to generate an accurate and realistic
(emulating tree crowns) classification map on a sparsely annotated data set.
GRNN outperforms several state-of-the-art techniques not only for the standard
Indian Pines HSI but also achieves a high classification accuracy (approx. 92%)
on a new HSI data set collected over the heterogeneous forests of French Guiana
(FG) when less than 1% of the pixels are labeled. We further show that GRNN is
competitive with the state-of-the-art semi-supervised methods and exhibits a
small deviation in accuracy for different numbers of training samples and over
repeated trials with randomly sampled labeled pixels for training.
","Debmita Bandyopadhyay, Subhadip Mukherjee, James Ball, Grégoire Vincent, David A. Coomes, Carola-Bibiane Schönlieb",Carola-Bibiane Schönlieb,2022-08-18T07:17:40Z
"Low-rank nonnegative tensor approximation via alternating projections
  and sketching","  We show how to construct nonnegative low-rank approximations of nonnegative
tensors in Tucker and tensor train formats. We use alternating projections
between the nonnegative orthant and the set of low-rank tensors, using STHOSVD
and TTSVD algorithms, respectively, and further accelerate the alternating
projections using randomized sketching. The numerical experiments on both
synthetic data and hyperspectral images show the decay of the negative elements
and that the error of the resulting approximation is close to the initial error
obtained with STHOSVD and TTSVD. The proposed method for the Tucker case is
superior to the previous ones in terms of computational complexity and decay of
negative elements. The tensor train case, to the best of our knowledge, has not
been studied before.
","Azamat Sultonov, Sergey Matveev, Stanislav Budzinskiy",Stanislav Budzinskiy,2022-09-05T17:12:12Z
"Least-squares methods for nonnegative matrix factorization over rational
  functions","  Nonnegative Matrix Factorization (NMF) models are widely used to recover
linearly mixed nonnegative data. When the data is made of samplings of
continuous signals, the factors in NMF can be constrained to be samples of
nonnegative rational functions, which allow fairly general models; this is
referred to as NMF using rational functions (R-NMF). We first show that, under
mild assumptions, R-NMF has an essentially unique factorization unlike NMF,
which is crucial in applications where ground-truth factors need to be
recovered such as blind source separation problems. Then we present different
approaches to solve R-NMF: the R-HANLS, R-ANLS and R-NLS methods. From our
tests, no method significantly outperforms the others, and a trade-off should
be done between time and accuracy. Indeed, R-HANLS is fast and accurate for
large problems, while R-ANLS is more accurate, but also more resources
demanding, both in time and memory. R-NLS is very accurate but only for small
problems. Moreover, we show that R-NMF outperforms NMF in various tasks
including the recovery of semi-synthetic continuous signals, and a
classification problem of real hyperspectral signals.
","Cécile Hautecoeur, Lieven De Lathauwer, Nicolas Gillis, François Glineur",François Glineur,2022-09-26T10:43:47Z
"Convolutional Neural Networks: Basic Concepts and Applications in
  Manufacturing","  We discuss basic concepts of convolutional neural networks (CNNs) and outline
uses in manufacturing. We begin by discussing how different types of data
objects commonly encountered in manufacturing (e.g., time series, images,
micrographs, videos, spectra, molecular structures) can be represented in a
flexible manner using tensors and graphs. We then discuss how CNNs use
convolution operations to extract informative features (e.g., geometric
patterns and textures) from the such representations to predict emergent
properties and phenomena and/or to identify anomalies. We also discuss how CNNs
can exploit color as a key source of information, which enables the use of
modern computer vision hardware (e.g., infrared, thermal, and hyperspectral
cameras). We illustrate the concepts using diverse case studies arising in
spectral analysis, molecule design, sensor design, image-based control, and
multivariate process monitoring.
","Shengli Jiang, Shiyi Qin, Joshua L. Pulsipher, Victor M. Zavala",Victor M. Zavala,2022-10-14T14:18:51Z
Aboveground carbon biomass estimate with Physics-informed deep network,"  The global carbon cycle is a key process to understand how our climate is
changing. However, monitoring the dynamics is difficult because a
high-resolution robust measurement of key state parameters including the
aboveground carbon biomass (AGB) is required. Here, we use deep neural network
to generate a wall-to-wall map of AGB within the Continental USA (CONUS) with
30-meter spatial resolution for the year 2021. We combine radar and optical
hyperspectral imagery, with a physical climate parameter of SIF-based GPP.
Validation results show that a masked variation of UNet has the lowest
validation RMSE of 37.93 $\pm$ 1.36 Mg C/ha, as compared to 52.30 $\pm$ 0.03 Mg
C/ha for random forest algorithm. Furthermore, models that learn from SIF-based
GPP in addition to radar and optical imagery reduce validation RMSE by almost
10% and the standard deviation by 40%. Finally, we apply our model to measure
losses in AGB from the recent 2021 Caldor wildfire in California, and validate
our analysis with Sentinel-based burn index.
","Juan Nathaniel, Levente J. Klein, Campbell D. Watson, Gabrielle Nyirjesy, Conrad M. Albrecht",Conrad M. Albrecht,2022-10-25T03:38:23Z
"Mixture-Net: Low-Rank Deep Image Prior Inspired by Mixture Models for
  Spectral Image Recovery","  This paper proposes a non-data-driven deep neural network for spectral image
recovery problems such as denoising, single hyperspectral image
super-resolution, and compressive spectral imaging reconstruction. Unlike
previous methods, the proposed approach, dubbed Mixture-Net, implicitly learns
the prior information through the network. Mixture-Net consists of a deep
generative model whose layers are inspired by the linear and non-linear
low-rank mixture models, where the recovered image is composed of a weighted
sum between the linear and non-linear decomposition. Mixture-Net also provides
a low-rank decomposition interpreted as the spectral image abundances and
endmembers, helpful in achieving remote sensing tasks without running
additional routines. The experiments show the MixtureNet effectiveness
outperforming state-of-the-art methods in recovery quality with the advantage
of architecture interpretability.
","Tatiana Gelvez-Barrera, Jorge Bacca, Henry Arguello",Henry Arguello,2022-11-05T21:32:25Z
DiSC: Differential Spectral Clustering of Features,"  Selecting subsets of features that differentiate between two conditions is a
key task in a broad range of scientific domains. In many applications, the
features of interest form clusters with similar effects on the data at hand. To
recover such clusters we develop DiSC, a data-driven approach for detecting
groups of features that differentiate between conditions. For each condition,
we construct a graph whose nodes correspond to the features and whose weights
are functions of the similarity between them for that condition. We then apply
a spectral approach to compute subsets of nodes whose connectivity differs
significantly between the condition-specific feature graphs. On the theoretical
front, we analyze our approach with a toy example based on the stochastic block
model. We evaluate DiSC on a variety of datasets, including MNIST,
hyperspectral imaging, simulated scRNA-seq and task fMRI, and demonstrate that
DiSC uncovers features that better differentiate between conditions compared to
competing methods.
","Ram Dyuthi Sristi, Gal Mishne, Ariel Jaffe",Ariel Jaffe,2022-11-10T03:32:17Z
"ABANICCO: A New Color Space for Multi-Label Pixel Classification and
  Color Segmentation","  In any computer vision task involving color images, a necessary step is
classifying pixels according to color and segmenting the respective areas.
However, the development of methods able to successfully complete this task has
proven challenging, mainly due to the gap between human color perception,
linguistic color terms, and digital representation. In this paper, we propose a
novel method combining geometric analysis of color theory, fuzzy color spaces,
and multi-label systems for the automatic classification of pixels according to
12 standard color categories (Green, Yellow, Light Orange, Deep Orange, Red,
Pink, Purple, Ultramarine, Blue, Teal, Brown, and Neutral). Moreover, we
present a robust, unsupervised, unbiased strategy for color naming based on
statistics and color theory. ABANICCO was tested against the state of the art
in color classification and with the standarized ISCC-NBS color system,
providing accurate classification and a standard, easily understandable
alternative for hue naming recognizable by humans and machines. We expect this
solution to become the base to successfully tackle a myriad of problems in all
fields of computer vision, such as region characterization, histopathology
analysis, fire detection, product quality prediction, object description, and
hyperspectral imaging.
","Laura Nicolás-Sáenz, Agapito Ledezma, Javier Pascau, Arrate Muñoz-Barrutia",Arrate Muñoz-Barrutia,2022-11-15T19:26:51Z
"Ultra-Sensitive Extinction Measurements of Optically Active Defects in
  Monolayer MoS$_2$","  We utilize cavity-enhanced extinction spectroscopy to directly quantify the
optical absorption of defects in MoS$_2$ generated by helium ion bombardment.
We achieve hyperspectral imaging of specific defect patterns with a detection
limit below 0.01% extinction, corresponding to a detectable defect density
below $10^{11}$ cm$^{-2}$. The corresponding spectra reveal a broad sub-gap
absorption, being consistent with theoretical predictions related to sulfur
vacancy-bound excitons in MoS$_2$. Our results highlight cavity-enhanced
extinction spectroscopy as efficient means for the detection of optical
transitions in nanoscale thin films with weak absorption, applicable to a broad
range of materials.
","Florian Sigger, Ines Amersdorffer, Alexander Hötger, Manuel Nutz, Jonas Kiemle, Takashi Taniguchi, Kenji Watanabe, Michael Förg, Jonathan Noe, Jonathan J. Finley, Alexander Högele, Alexander W. Holleitner, Thomas Hümmer, David Hunger, Christoph Kastl",Christoph Kastl,2022-12-20T13:14:26Z
Nanoimprint strain-engineering of 2D semiconductors,"  Mechanical strain is a powerful tool to tune the optical and optoelectronic
properties of atomically thin semiconductors. Inhomogeneous strain plays an
important role in exciton funneling and the activation of single-photon
emitters in 2D materials. Here, we create an inhomogeneous strain profile in a
2D semiconductor on a micrometer scale by a nanoimprint process. We present a
nanoimprint setup, where a mold is used to apply pressure in a controlled way
to a WS2 monolayer on a heated polymer layer. After printing, the strain
created in the 2D semiconductor is verified by hyperspectral optical imaging.
The developed nanoimprint technique is scalable and could be transferred to
commercial nanoimprint machines.
","Jannis Bensmann, Robert Schmidt, Robert Schneider, Johannes Kern, Paul Steeger, Mohammad Adnan, Steffen Michaelis de Vasconcellos, Rudolf Bratschitsch",Rudolf Bratschitsch,2022-12-22T17:06:52Z
Plasmonic properties of individual gallium nanoparticles,"  Gallium is a plasmonic material offering ultraviolet to near-infrared
tunability, facile and scalable preparation, and good stability of
nanoparticles. In our contribution, we experimentally demonstrate the link
between the shape and size of individual gallium nanoparticles and their
optical properties. To this end, we utilize scanning transmission electron
microscopy combined with electron energy loss spectroscopy. Lens-shaped gallium
nanoparticles with a diameter between 10 nm and 200 nm were grown directly on a
silicon nitride membrane using an in-house developed effusion cell operated at
ultra-high vacuum conditions. We have experimentally proved that they support
localized surface plasmon resonances and their dipole mode can be tuned through
their size from ultraviolet to near-infrared spectral region. The measurements
are supported by numerical simulations using realistic particle shapes and
sizes. Our results open the way for future applications of gallium
nanoparticles such as hyperspectral absorption of sunlight in energy harvesting
or plasmon-enhanced luminescence of ultraviolet emitters.
","Michal Horák, Vojtěch Čalkovský, Jindřich Mach, Vlastimil Křápek, Tomáš Šikola",Tomáš Šikola,2022-12-28T16:21:27Z
Bond-Selective Full-Field Optical Coherence Tomography,"  Optical coherence tomography (OCT) is a label-free, non-invasive 3D imaging
tool widely used in both biological research and clinical diagnosis. Current
OCT modalities can only visualize specimen tomography without chemical
information. Here, we report a bondselective full-field OCT (BS-FF-OCT), in
which a pulsed mid-infrared laser is used to modulate the OCT signal through
the photothermal effect, achieving label-free bond-selective 3D sectioned
imaging of highly scattering samples. We first demonstrate BS-FF-OCT imaging of
1 {\mu}m PMMA beads embedded in agarose gel. Next, we then show 3D
hyperspectral imaging of polypropylene fiber mattress from a standard surgical
mask. We then demonstrate BS-FFOCT imaging on biological samples, including
cancer cell spheroids and C. elegans. Using an alternative pulse timing
configuration, we finally demonstrate the capability of BS-FF-OCT on a bulky
and highly scattering 150 {\mu}m thick mouse brain slice.
","Haonan Zong, Celalettin Yurdakul, Jian Zhao, Zian Wang, Fukai Chen, M. Selim Ünlü, Ji-Xin Cheng",Ji-Xin Cheng,2023-01-31T01:15:32Z
Physiological Imaging: When the Pixel Size Matters,"  With the proliferation of inexpensive CMOS cameras, medical imaging
experiences a noticeable influx of new technologies. While anatomical imaging
is based on well-established principles of photography, physiological optical
imaging is a relatively novel range of technologies that requires considering a
new set of technical and physiological aspects. We discuss several factors
(binning, spatial frequency sampling, and distance to the target area)
indispensable to getting quantifiable and reproducible results, which are the
essence of physiological imaging. We also discussed their implications for
several commonly used physiological imaging modalities, including
hyperspectral/multispectral imaging, fluorescence imaging, and thermography.
Physiological imaging technologies are in their infancy. Thus, the proper
design, which considers technical and physiological aspects, is paramount to
establishing their credibility and driving clinical adoption.
",Gennadi Saiko,Gennadi Saiko,2023-02-01T12:44:59Z
Advances and Challenges in Multimodal Remote Sensing Image Registration,"  Over the past few decades, with the rapid development of global aerospace and
aerial remote sensing technology, the types of sensors have evolved from the
traditional monomodal sensors (e.g., optical sensors) to the new generation of
multimodal sensors [e.g., multispectral, hyperspectral, light detection and
ranging (LiDAR) and synthetic aperture radar (SAR) sensors]. These advanced
devices can dynamically provide various and abundant multimodal remote sensing
images with different spatial, temporal, and spectral resolutions according to
different application requirements. Since then, it is of great scientific
significance to carry out the research of multimodal remote sensing image
registration, which is a crucial step for integrating the complementary
information among multimodal data and making comprehensive observations and
analysis of the Earths surface. In this work, we will present our own
contributions to the field of multimodal image registration, summarize the
advantages and limitations of existing multimodal image registration methods,
and then discuss the remaining challenges and make a forward-looking prospect
for the future development of the field.
","Bai Zhu, Liang Zhou, Simiao Pu, Jianwei Fan, Yuanxin Ye",Yuanxin Ye,2023-02-02T07:07:35Z
Approximation of radiative transfer for surface spectral features,"  Remote sensing hyperspectral and more generally spectral instruments are
common tools to decipher surface features in Earth and Planetary science. While
linear mixture is the most common approximation for compounds detection
(mineral, water, ice, etc...), the transfer of light in surface and atmospheric
medium are highly non-linear. The exact simulation of non-linearities can be
estimated at very high numerical cost. Here I propose a very simple non-linear
form (that includes the regular linear area mixture) of radiative transfer to
approximate surface spectral feature. I demonstrate that this analytical form
is able to approximate the grain size and intimate mixture dependence of
surface features. In addition, the same analytical form can approximate the
effect of Martian mineral aerosols. Unfortunately, Earth aerosols are more
complex (water droplet, water ice, soot,...) and are not expected to follow the
same trend.
",Frédéric Schmidt,Frédéric Schmidt,2023-02-06T09:22:58Z
"Scanning Reflectance Anisotropy Microscopy for Multi-Material Strain
  Mapping","  Strain-engineering of materials encompasses significant elastic deformation
and leads to breaking of the lattice symmetry and as a consequence to the
emergence of optical anisotropy. However, the capability to image and map local
strain fields by optical microscopy is currently limited to specific materials.
Here, we introduce a broadband scanning reflectance anisotropy microscope as a
phase-sensitive multi-material optical platform for strain mapping. The
microscope produces hyperspectral images with diffraction-limited sub-micron
resolution of the near-normal incidence ellipsometric response of the sample,
which is related to elastic strain by means of the elasto-optic effect. We
demonstrate cutting edge strain sensitivity using a variety of materials, such
as metasurfaces, semiconductors and metals. The versatility of the method to
study the breaking of the lattice symmetry by simple reflectance measurements
opens up the possibility to carry out non-destructive mechanical
characterization of multi-material components, such as wearable electronics and
optical semiconductor devices.
","Joan Sendra, Fabian Haake, Micha Calvo, Henning Galinski, Ralph Spolenak",Ralph Spolenak,2023-02-08T14:45:23Z
"Combining Variational Autoencoders and Physical Bias for Improved
  Microscopy Data Analysis","  Electron and scanning probe microscopy produce vast amounts of data in the
form of images or hyperspectral data, such as EELS or 4D STEM, that contain
information on a wide range of structural, physical, and chemical properties of
materials. To extract valuable insights from these data, it is crucial to
identify physically separate regions in the data, such as phases, ferroic
variants, and boundaries between them. In order to derive an easily
interpretable feature analysis, combining with well-defined boundaries in a
principled and unsupervised manner, here we present a physics augmented machine
learning method which combines the capability of Variational Autoencoders to
disentangle factors of variability within the data and the physics driven loss
function that seeks to minimize the total length of the discontinuities in
images corresponding to latent representations. Our method is applied to
various materials, including NiO-LSMO, BiFeO3, and graphene. The results
demonstrate the effectiveness of our approach in extracting meaningful
information from large volumes of imaging data. The fully notebook containing
implementation of the code and analysis workflow is available at
https://github.com/arpanbiswas52/PaperNotebooks
","Arpan Biswas, Maxim Ziatdinov, Sergei V. Kalinin",Sergei V. Kalinin,2023-02-08T17:35:38Z
"Riemannian preconditioned algorithms for tensor completion via tensor
  ring decomposition","  We propose Riemannian preconditioned algorithms for the tensor completion
problem via tensor ring decomposition. A new Riemannian metric is developed on
the product space of the mode-2 unfolding matrices of the core tensors in
tensor ring decomposition. The construction of this metric aims to approximate
the Hessian of the cost function by its diagonal blocks, paving the way for
various Riemannian optimization methods. Specifically, we propose the
Riemannian gradient descent and Riemannian conjugate gradient algorithms. We
prove that both algorithms globally converge to a stationary point. In the
implementation, we exploit the tensor structure and adopt an economical
procedure to avoid large matrix formulation and computation in gradients, which
significantly reduces the computational cost. Numerical experiments on various
synthetic and real-world datasets -- movie ratings, hyperspectral images, and
high-dimensional functions -- suggest that the proposed algorithms are more
efficient and have better reconstruction ability than other candidates.
","Bin Gao, Renfeng Peng, Ya-xiang Yuan",Ya-xiang Yuan,2023-02-28T10:00:56Z
Hyperspectral Compressive Wavefront Sensing,"  Presented is a novel way to combine snapshot compressive imaging and lateral
shearing interferometry in order to capture the spatio-spectral phase of an
ultrashort laser pulse in a single shot. A deep unrolling algorithm is utilised
for the snapshot compressive imaging reconstruction due to its parameter
efficiency and superior speed relative to other methods, potentially allowing
for online reconstruction. The algorithm's regularisation term is represented
using neural network with 3D convolutional layers, to exploit the
spatio-spectral correlations that exist in laser wavefronts. Compressed sensing
is not typically applied to modulated signals, but we demonstrate its success
here. Furthermore, we train a neural network to predict the wavefronts from a
lateral shearing interferogram in terms of Zernike polynomials, which again
increases the speed of our technique without sacrificing fidelity. This method
is supported with simulation-based results. While applied to the example of
lateral shearing interferometry, the methods presented here are generally
applicable to a wide range of signals, including Shack-Hartmann-type sensors.
The results may be of interest beyond the context of laser wavefront
characterization, including within quantitative phase imaging.
","Sunny Howard, Jannik Esslinger, Robin H. W. Wang, Peter Norreys, Andreas Doepp",Andreas Doepp,2023-03-06T23:50:24Z
"Nonlinear Hyperspectral Unmixing based on Multilinear Mixing Model using
  Convolutional Autoencoders","  Unsupervised spectral unmixing consists of representing each observed pixel
as a combination of several pure materials called endmembers with their
corresponding abundance fractions. Beyond the linear assumption, various
nonlinear unmixing models have been proposed, with the associated optimization
problems solved either by traditional optimization algorithms or deep learning
techniques. Current deep learning-based nonlinear unmixing focuses on the
models in additive, bilinear-based formulations. By interpreting the reflection
process using the discrete Markov chain, the multilinear mixing model (MLM)
successfully accounts for the up to infinite-order interactions between
endmembers. However, to simulate the physics process of MLM by neural networks
explicitly is a challenging problem that has not been approached by far. In
this article, we propose a novel autoencoder-based network for unsupervised
unmixing based on MLM. Benefitting from an elaborate network design, the
relationships among all the model parameters {\em i.e.}, endmembers,
abundances, and transition probability parameters are explicitly modeled. There
are two modes: MLM-1DAE considers only pixel-wise spectral information, and
MLM-3DAE exploits the spectral-spatial correlations within input patches.
Experiments on both the synthetic and real datasets demonstrate the
effectiveness of the proposed method as it achieves competitive performance to
the classic solutions of MLM.
","Tingting Fang, Fei Zhu, Jie Chen",Jie Chen,2023-03-14T18:11:52Z
"MMFormer: Multimodal Transformer Using Multiscale Self-Attention for
  Remote Sensing Image Classification","  To benefit the complementary information between heterogeneous data, we
introduce a new Multimodal Transformer (MMFormer) for Remote Sensing (RS) image
classification using Hyperspectral Image (HSI) accompanied by another source of
data such as Light Detection and Ranging (LiDAR). Compared with traditional
Vision Transformer (ViT) lacking inductive biases of convolutions, we first
introduce convolutional layers to our MMFormer to tokenize patches from
multimodal data of HSI and LiDAR. Then we propose a Multi-scale Multi-head
Self-Attention (MSMHSA) module to address the problem of compatibility which
often limits to fuse HSI with high spectral resolution and LiDAR with
relatively low spatial resolution. The proposed MSMHSA module can incorporate
HSI to LiDAR data in a coarse-to-fine manner enabling us to learn a
fine-grained representation. Extensive experiments on widely used benchmarks
(e.g., Trento and MUUFL) demonstrate the effectiveness and superiority of our
proposed MMFormer for RS image classification.
","Bo Zhang, Zuheng Ming, Wei Feng, Yaqian Liu, Liang He, Kaixing Zhao",Kaixing Zhao,2023-03-23T08:34:24Z
Surface Passivation Suppresses Local Ion Motion in Halide Perovskites,"  We use scanning probe microscopy to study ion migration in the formamidinium
(FA)-containing halide perovskite semiconductor
$Cs_{0.22}FA_{0.78}Pb(I_{0.85}Br_{0.15})_3$ in the presence and absence of
chemical surface passivation. We measure the evolving contact potential
difference (CPD) using scanning Kelvin probe microscopy (SKPM) following
voltage poling. We find that ion migration leads to a ~100 mV shift in the CPD
of control films after poling with 3V for only a few seconds. Moreover, we find
that ion migration is heterogeneous, with domain interfaces leading to a larger
shift in the CPD. Application of (3-aminopropyl)trimethoxysilane (APTMS) as a
surface passivator further leads to 5-fold reduction in the CPD shift from ~100
meV to ~20 meV. We use hyperspectral microscopy to show that APTMS-treated
perovskite films undergo less photoinduced halide migration than control films.
We interpret these results as due to a reduction in halide vacancy
concentration due to passivation with APTMS.
","Justin Pothoof, Robert J. E. Westbrook, Rajiv Giridharagopal, Madeleine D. Breshears, David S. Ginger",David S. Ginger,2023-04-12T00:41:19Z
"Learning Sentinel-2 reflectance dynamics for data-driven assimilation
  and forecasting","  Over the last few years, massive amounts of satellite multispectral and
hyperspectral images covering the Earth's surface have been made publicly
available for scientific purpose, for example through the European Copernicus
project. Simultaneously, the development of self-supervised learning (SSL)
methods has sparked great interest in the remote sensing community, enabling to
learn latent representations from unlabeled data to help treating downstream
tasks for which there is few annotated examples, such as interpolation,
forecasting or unmixing. Following this line, we train a deep learning model
inspired from the Koopman operator theory to model long-term reflectance
dynamics in an unsupervised way. We show that this trained model, being
differentiable, can be used as a prior for data assimilation in a
straightforward way. Our datasets, which are composed of Sentinel-2
multispectral image time series, are publicly released with several levels of
treatment.
","Anthony Frion, Lucas Drumetz, Guillaume Tochon, Mauro Dalla Mura, Abdeldjalil Aïssa El Bey",Abdeldjalil Aïssa El Bey,2023-05-05T10:04:03Z
"Nonnegative Low-Rank Tensor Completion via Dual Formulation with
  Applications to Image and Video Completion","  Recent approaches to the tensor completion problem have often overlooked the
nonnegative structure of the data. We consider the problem of learning a
nonnegative low-rank tensor, and using duality theory, we propose a novel
factorization of such tensors. The factorization decouples the nonnegative
constraints from the low-rank constraints. The resulting problem is an
optimization problem on manifolds, and we propose a variant of Riemannian
conjugate gradients to solve it. We test the proposed algorithm across various
tasks such as colour image inpainting, video completion, and hyperspectral
image completion. Experimental results show that the proposed method
outperforms many state-of-the-art tensor completion algorithms.
","Tanmay Kumar Sinha, Jayadev Naram, Pawan Kumar",Pawan Kumar,2023-05-13T17:51:00Z
"A Range-Null Space Decomposition Approach for Fast and Flexible Spectral
  Compressive Imaging","  We present RND-SCI, a novel framework for compressive hyperspectral image
(HSI) reconstruction. Our framework decomposes the reconstructed object into
range-space and null-space components, where the range-space part ensures the
solution conforms to the compression process, and the null-space term
introduces a deep HSI prior to constraining the output to have satisfactory
properties. RND-SCI is not only simple in design with strong interpretability
but also can be easily adapted to various HSI reconstruction networks,
improving the quality of HSIs with minimal computational overhead. RND-SCI
significantly boosts the performance of HSI reconstruction networks in
retraining, fine-tuning or plugging into a pre-trained off-the-shelf model.
Based on the framework and SAUNet, we design an extremely fast HSI
reconstruction network, RND-SAUNet, which achieves an astounding 91 frames per
second while maintaining superior reconstruction accuracy compared to other
less time-consuming methods. Code and models are available at
https://github.com/hustvl/RND-SCI.
","Junyu Wang, Shijie Wang, Ruijie Zhang, Zengqiang Zheng, Wenyu Liu, Xinggang Wang",Xinggang Wang,2023-05-16T18:37:58Z
Automatic Illumination Spectrum Recovery,"  We develop a deep learning network to estimate the illumination spectrum of
hyperspectral images under various lighting conditions. To this end, a dataset,
IllumNet, was created. Images were captured using a Specim IQ camera under
various illumination conditions, both indoor and outdoor. Outdoor images were
captured in sunny, overcast, and shady conditions and at different times of the
day. For indoor images, halogen and LED light sources were used, as well as
mixed light sources, mainly halogen or LED and fluorescent. The ResNet18
network was employed in this study, but with the 2D kernel changed to a 3D
kernel to suit the spectral nature of the data. As well as fitting the actual
illumination spectrum well, the predicted illumination spectrum should also be
smooth, and this is achieved by the cubic smoothing spline error cost function.
Experimental results indicate that the trained model can infer an accurate
estimate of the illumination spectrum.
","Nariman Habili, Jeremy Oorloff, Lars Petersson",Lars Petersson,2023-05-31T03:56:31Z
Integrated Photonic Encoder for Terapixel Image Processing,"  Modern lens designs are capable of resolving >10 gigapixels, while advances
in camera frame-rate and hyperspectral imaging have made Terapixel/s data
acquisition a real possibility. The main bottlenecks preventing such high
data-rate systems are power consumption and data storage. In this work, we show
that analog photonic encoders could address this challenge, enabling high-speed
image compression using orders-of-magnitude lower power than digital
electronics. Our approach relies on a silicon-photonics front-end to compress
raw image data, foregoing energy-intensive image conditioning and reducing data
storage requirements. The compression scheme uses a passive disordered photonic
structure to perform kernel-type random projections of the raw image data with
minimal power consumption and low latency. A back-end neural network can then
reconstruct the original images with structural similarity exceeding 90%. This
scheme has the potential to process Terapixel/s data streams using less than
100 fJ/pixel, providing a path to ultra-high-resolution data and image
acquisition systems.
","Xiao Wang, Brandon Redding, Nicholas Karl, Christopher Long, Zheyuan Zhu, Shuo Pang, David Brady, Raktim Sarma",Raktim Sarma,2023-06-07T16:02:01Z
"High-resolution acoustic field mapping of GHz phononic crystals with
  atomic force microscopy","  On-chip technology based on acoustic waves is a strong asset in modern
telecommunication with the prospects of becoming a cornerstone of
next-generation devices. In this context, mapping and manipulating acoustic
waves through coherent scattering is pivotal for a non-trivial control of the
flow of acoustic energy, which could consequently enable advanced information
manipulation. To this end, here a technique for mapping acoustic fields is
introduced and used for characterizing $\mu$m-sized phononic crystals defined
in GaAs slabs and excited by GHz surface acoustic waves (SAWs) based on atomic
force microscopy. It is shown that incoherent scattering excites a wide
distribution of modes, which enables the mapping of the dispersion relation of
the two-dimensional structures, while the phononic crystal symmetry directly
correlates with coherent scattering effects. Enabling the use of acoustic
atomic force microscopy and understanding the role of scattering are of
paramount importance for the versatile use of GHz acoustic waves in
technological applications, setting the baseline for advanced operations like
hyperspectral filtering, beam steering or spatial-division multiplexing.
"," Pitanti,  Alessandro,  Yuan,  Mingyun,  Zanotto,  Simone,  Santos, Paulo V",Paulo V,2023-06-23T15:29:15Z
"Shortest Length Total Orders Do Not Minimize Irregularity in
  Vector-Valued Mathematical Morphology","  Mathematical morphology is a theory concerned with non-linear operators for
image processing and analysis. The underlying framework for mathematical
morphology is a partially ordered set with well-defined supremum and infimum
operations. Because vectors can be ordered in many ways, finding appropriate
ordering schemes is a major challenge in mathematical morphology for
vector-valued images, such as color and hyperspectral images. In this context,
the irregularity issue plays a key role in designing effective morphological
operators. Briefly, the irregularity follows from a disparity between the
ordering scheme and a metric in the value set. Determining an ordering scheme
using a metric provide reasonable approaches to vector-valued mathematical
morphology. Because total orderings correspond to paths on the value space, one
attempt to reduce the irregularity of morphological operators would be defining
a total order based on the shortest length path. However, this paper shows that
the total ordering associated with the shortest length path does not
necessarily imply minimizing the irregularity.
","Samuel Francisco, Marcos Eduardo Valle",Marcos Eduardo Valle,2023-06-30T01:26:44Z
"Unsupervised Spectral Demosaicing with Lightweight Spectral Attention
  Networks","  This paper presents a deep learning-based spectral demosaicing technique
trained in an unsupervised manner. Many existing deep learning-based techniques
relying on supervised learning with synthetic images, often underperform on
real-world images especially when the number of spectral bands increases.
According to the characteristics of the spectral mosaic image, this paper
proposes a mosaic loss function, the corresponding model structure, a
transformation strategy, and an early stopping strategy, which form a complete
unsupervised spectral demosaicing framework. A challenge in real-world spectral
demosaicing is inconsistency between the model parameters and the computational
resources of the imager. We reduce the complexity and parameters of the
spectral attention module by dividing the spectral attention tensor into
spectral attention matrices in the spatial dimension and spectral attention
vector in the channel dimension, which is more suitable for unsupervised
framework. This paper also presents Mosaic25, a real 25-band hyperspectral
mosaic image dataset of various objects, illuminations, and materials for
benchmarking. Extensive experiments on synthetic and real-world datasets
demonstrate that the proposed method outperforms conventional unsupervised
methods in terms of spatial distortion suppression, spectral fidelity,
robustness, and computational cost.
","Kai Feng, Yongqiang Zhao, Seong G. Kong, Haijin Zeng",Haijin Zeng,2023-07-05T02:45:44Z
"Feature selection simultaneously preserving both class and cluster
  structures","  When a data set has significant differences in its class and cluster
structure, selecting features aiming only at the discrimination of classes
would lead to poor clustering performance, and similarly, feature selection
aiming only at preserving cluster structures would lead to poor classification
performance. To the best of our knowledge, a feature selection method that
simultaneously considers class discrimination and cluster structure
preservation is not available in the literature. In this paper, we have tried
to bridge this gap by proposing a neural network-based feature selection method
that focuses both on class discrimination and structure preservation in an
integrated manner. In addition to assessing typical classification problems, we
have investigated its effectiveness on band selection in hyperspectral images.
Based on the results of the experiments, we may claim that the proposed
feature/band selection can select a subset of features that is good for both
classification and clustering.
","Suchismita Das, Nikhil R. Pal",Nikhil R. Pal,2023-07-08T04:49:51Z
"DMDC: Dynamic-mask-based dual camera design for snapshot Hyperspectral
  Imaging","  Deep learning methods are developing rapidly in coded aperture snapshot
spectral imaging (CASSI). The number of parameters and FLOPs of existing
state-of-the-art methods (SOTA) continues to increase, but the reconstruction
accuracy improves slowly. Current methods still face two problems: 1) The
performance of the spatial light modulator (SLM) is not fully developed due to
the limitation of fixed Mask coding. 2) The single input limits the network
performance. In this paper we present a dynamic-mask-based dual camera system,
which consists of an RGB camera and a CASSI system running in parallel. First,
the system learns the spatial feature distribution of the scene based on the
RGB images, then instructs the SLM to encode each scene, and finally sends both
RGB and CASSI images to the network for reconstruction. We further designed the
DMDC-net, which consists of two separate networks, a small-scale CNN-based
dynamic mask network for dynamic adjustment of the mask and a multimodal
reconstruction network for reconstruction using RGB and CASSI measurements.
Extensive experiments on multiple datasets show that our method achieves more
than 9 dB improvement in PSNR over the SOTA.
(https://github.com/caizeyu1992/DMDC)
","Zeyu Cai, Chengqian Jin, Feipeng Da",Feipeng Da,2023-08-03T05:10:58Z
Probabilistic Mixture Model-Based Spectral Unmixing,"  Identifying pure components in mixtures is a common yet challenging problem.
The associated unmixing process requires the pure components, also known as
endmembers, to be sufficiently spectrally distinct. Even with this requirement
met, extracting the endmembers from a single mixture is impossible; an ensemble
of mixtures with sufficient diversity is needed. Several spectral unmixing
approaches have been proposed, many of which are connected to hyperspectral
imaging. However, most of them assume highly diverse collections of mixtures
and extremely low-loss spectroscopic measurements. Additionally, non-Bayesian
frameworks do not incorporate the uncertainty inherent in unmixing. We propose
a probabilistic inference approach that explicitly incorporates noise and
uncertainty, enabling us to unmix endmembers in collections of mixtures with
limited diversity. We use a Bayesian mixture model to jointly extract endmember
spectra and mixing parameters while explicitly modeling observation noise and
the resulting inference uncertainties. We obtain approximate distributions over
endmember coordinates for each set of observed spectra while remaining robust
to inference biases from the lack of pure observations and presence of
non-isotropic Gaussian noise. Access to reliable uncertainties on the unmixing
solutions would enable robust solutions as well as informed decision making.
","Oliver Hoidn, Aashwin Mishra, Apurva Mehta",Apurva Mehta,2023-08-24T23:46:16Z
"Linking the Dynamic PicoProbe Analytical Electron-Optical Beam Line /
  Microscope to Supercomputers","  The Dynamic PicoProbe at Argonne National Laboratory is undergoing upgrades
that will enable it to produce up to 100s of GB of data per day. While this
data is highly important for both fundamental science and industrial
applications, there is currently limited on-site infrastructure to handle these
high-volume data streams. We address this problem by providing a software
architecture capable of supporting large-scale data transfers to the
neighboring supercomputers at the Argonne Leadership Computing Facility. To
prepare for future scientific workflows, we implement two instructive use cases
for hyperspectral and spatiotemporal datasets, which include: (i) off-site data
transfer, (ii) machine learning/artificial intelligence and traditional data
analysis approaches, and (iii) automatic metadata extraction and cataloging of
experimental results. This infrastructure supports expected workloads and also
provides domain scientists the ability to reinterrogate data from past
experiments to yield additional scientific value and derive new insights.
","Alexander Brace, Rafael Vescovi, Ryan Chard, Nickolaus D. Saint, Arvind Ramanathan, Nestor J. Zaluzec, Ian Foster",Ian Foster,2023-08-25T23:07:58Z
Deep Nonnegative Matrix Factorization with Beta Divergences,"  Deep Nonnegative Matrix Factorization (deep NMF) has recently emerged as a
valuable technique for extracting multiple layers of features across different
scales. However, all existing deep NMF models and algorithms have primarily
centered their evaluation on the least squares error, which may not be the most
appropriate metric for assessing the quality of approximations on diverse
datasets. For instance, when dealing with data types such as audio signals and
documents, it is widely acknowledged that $\beta$-divergences offer a more
suitable alternative. In this paper, we develop new models and algorithms for
deep NMF using some $\beta$-divergences, with a focus on the Kullback-Leibler
divergence. Subsequently, we apply these techniques to the extraction of facial
features, the identification of topics within document collections, and the
identification of materials within hyperspectral images.
","Valentin Leplat, Le Thi Khanh Hien, Akwum Onwunta, Nicolas Gillis",Nicolas Gillis,2023-09-15T08:46:53Z
"Non-negative Matrix Factorization using Partial Prior Knowledge for
  Radiation Dosimetry","  Hyperspectral unmixing aims at decomposing a given signal into its spectral
signatures and its associated fractional abundances. To improve the accuracy of
this decomposition, algorithms have included different assumptions depending on
the application. The goal of this study is to develop a new unmixing algorithm
that can be applied for the calibration of multi-point scintillation dosimeters
used in the field of radiation therapy. This new algorithm is based on a
non-negative matrix factorization. It incorporates a partial prior knowledge on
both the abundances and the endmembers of a given signal. It is shown herein
that, following a precise calibration routine, it is possible to use partial
prior information about the fractional abundances, as well as on the
endmembers, in order to perform a simplified yet precise calibration of these
dosimeters. Validation and characterization of this algorithm is made using
both simulations and experiments. The experimental validation shows an
improvement in accuracy compared to previous algorithms with a mean spectral
angle distance (SAD) on the estimated endmembers of 0.0766, leading to an
average error of $(0.25 \pm 0.73)$ % on dose measurements.
","Boby Lessard, Frédéric Marcotte, Arthur Lalonde, François Therriault-Proulx, Simon Lambert-Girard, Luc Beaulieu, Louis Archambault",Louis Archambault,2023-09-17T19:50:52Z
"SSIF: Learning Continuous Image Representation for Spatial-Spectral
  Super-Resolution","  Existing digital sensors capture images at fixed spatial and spectral
resolutions (e.g., RGB, multispectral, and hyperspectral images), and each
combination requires bespoke machine learning models. Neural Implicit Functions
partially overcome the spatial resolution challenge by representing an image in
a resolution-independent way. However, they still operate at fixed, pre-defined
spectral resolutions. To address this challenge, we propose Spatial-Spectral
Implicit Function (SSIF), a neural implicit model that represents an image as a
function of both continuous pixel coordinates in the spatial domain and
continuous wavelengths in the spectral domain. We empirically demonstrate the
effectiveness of SSIF on two challenging spatio-spectral super-resolution
benchmarks. We observe that SSIF consistently outperforms state-of-the-art
baselines even when the baselines are allowed to train separate models at each
spectral resolution. We show that SSIF generalizes well to both unseen spatial
resolutions and spectral resolutions. Moreover, SSIF can generate
high-resolution images that improve the performance of downstream tasks (e.g.,
land use classification) by 1.7%-7%.
","Gengchen Mai, Ni Lao, Weiwei Sun, Yuchi Ma, Jiaming Song, Chenlin Meng, Hongxu Ma, Jinmeng Rao, Ziyuan Li, Stefano Ermon",Stefano Ermon,2023-09-30T15:23:30Z
"Analyzing Near-Infrared Hyperspectral Imaging for Protein Content
  Regression and Grain Variety Classification Using Bulk References and Varying
  Grain-to-Background Ratios","  Based on previous work, we assess the use of NIR-HSI images for calibrating
models on two datasets, focusing on protein content regression and grain
variety classification. Limited reference data for protein content is expanded
by subsampling and associating it with the bulk sample. However, this method
introduces significant biases due to skewed leptokurtic prediction
distributions, affecting both PLS-R and deep CNN models. We propose adjustments
to mitigate these biases, improving mean protein reference predictions.
Additionally, we investigate the impact of grain-to-background ratios on both
tasks. Higher ratios yield more accurate predictions, but including lower-ratio
images in calibration enhances model robustness for such scenarios.
","Ole-Christian Galbo Engstrøm, Erik Schou Dreier, Birthe Møller Jespersen, Kim Steenstrup Pedersen",Kim Steenstrup Pedersen,2023-11-07T14:54:46Z
"Spectral and Polarization Vision: Spectro-polarimetric Real-world
  Dataset","  Image datasets are essential not only in validating existing methods in
computer vision but also in developing new methods. Most existing image
datasets focus on trichromatic intensity images to mimic human vision. However,
polarization and spectrum, the wave properties of light that animals in harsh
environments and with limited brain capacity often rely on, remain
underrepresented in existing datasets. Although spectro-polarimetric datasets
exist, these datasets have insufficient object diversity, limited illumination
conditions, linear-only polarization data, and inadequate image count. Here, we
introduce two spectro-polarimetric datasets: trichromatic Stokes images and
hyperspectral Stokes images. These novel datasets encompass both linear and
circular polarization; they introduce multiple spectral channels; and they
feature a broad selection of real-world scenes. With our dataset in hand, we
analyze the spectro-polarimetric image statistics, develop efficient
representations of such high-dimensional data, and evaluate spectral dependency
of shape-from-polarization methods. As such, the proposed dataset promises a
foundation for data-driven spectro-polarimetric imaging and vision research.
Dataset and code will be publicly available.
","Yujin Jeon, Eunsue Choi, Youngchan Kim, Yunseong Moon, Khalid Omer, Felix Heide, Seung-Hwan Baek",Seung-Hwan Baek,2023-11-29T06:53:23Z
"Embedding theory in ML toward real-time tracking of structural dynamics
  through hyperspectral datasets","  In-situ Electron Energy Loss Spectroscopy (EELS) is an instrumental technique
that has traditionally been used to understand how the choice of materials
processing has the ability to change local structure and composition. However,
more recent advances to observe and react to transient changes occurring at the
ultrafast timescales that are now possible with EELS and Transmission Electron
Microscopy (TEM) will require new frameworks for characterization and analysis.
We describe a machine learning (ML) framework for the rapid assessment and
characterization of in operando EELS Spectrum Images (EELS-SI) without the need
for many labeled training datapoints as typically required for deep learning
classification methods. By embedding computationally generated structures and
experimental datasets into an equivalent latent space through Variational
Autoencoders (VAE), we effectively predict the structural changes at latency
scales relevant to closed-loop processing within the TEM. The framework
described in this study is a critical step in enabling automated, on-the-fly
synthesis and characterization which will greatly advance capabilities for
materials discovery and precision engineering of functional materials at the
atomic scale.
","Jonathan D Hollenbach, Cassandra M Pate, Haili Jia, James L Hart, Paulette Clancy, Mitra L Taheri",Mitra L Taheri,2023-12-08T17:43:08Z
"Super-resolution of THz time-domain images based on low-rank
  representation","  Terahertz time-domain spectroscopy (THz-TDS) employs sub-picosecond pulses to
probe dielectric properties of materials giving as a result a 3-dimensional
hyperspectral data cube. The spatial resolution of THz images is primarily
limited by two sources: a non-zero THz beam waist and the acquisition step
size. Acquisition with a small step size allows for the visualisation of
smaller details in images at the expense of acquisition time, but the
frequency-dependent point-spread function remains the biggest bottleneck for
THz imaging. This work presents a super-resolution approach to restore THz
time-domain images acquired with medium-to-big step sizes. The results show the
optimized and robust performance for different frequency bands (from 0.5 to 3.5
THz) obtaining higher resolution and additionally removing effects of blur at
lower frequencies and noise at higher frequencies.
","Marina Ljubenovic, Alessia Artesani, Stefano Bonetti, Arianna Traviglia",Arianna Traviglia,2023-12-21T13:11:57Z
Hyperspectral Lightcurve Inversion for Attitude Determination,"  Spectral lightcurves consisting of time series single-pixel spectral
measurements of spacecraft are used to infer the spacecraft's attitude and
rotation. Two methods are used. One based on numerical optimisation of a
regularised least squares cost function, and another based on machine learning
with a neural network model. The aim is to work with minimal information, thus
no prior is available on the attitude nor on the inertia tensor. The
theoretical and practical aspects of this task are investigated, and the
methodology is tested on synthetic data. Results are shown based on synthetic
data.
","Simão da Graça Marto, Massimiliano Vasile, Andrew Campbell, Paul Murray, Stephen Marshall, Vasili Savitski",Vasili Savitski,2023-12-19T16:06:50Z
Dropout Concrete Autoencoder for Band Selection on HSI Scenes,"  Deep learning-based informative band selection methods on hyperspectral
images (HSI) recently have gained intense attention to eliminate spectral
correlation and redundancies. However, the existing deep learning-based methods
either need additional post-processing strategies to select the descriptive
bands or optimize the model indirectly, due to the parameterization inability
of discrete variables for the selection procedure. To overcome these
limitations, this work proposes a novel end-to-end network for informative band
selection. The proposed network is inspired by the advances in concrete
autoencoder (CAE) and dropout feature ranking strategy. Different from the
traditional deep learning-based methods, the proposed network is trained
directly given the required band subset eliminating the need for further
post-processing. Experimental results on four HSI scenes show that the proposed
dropout CAE achieves substantial and effective performance levels outperforming
the competing methods.
","Lei Xu, Mete Ahishali, Moncef Gabbouj",Moncef Gabbouj,2024-01-29T19:53:17Z
"Measuring, processing, and generating partially coherent light with
  self-configuring optics","  Optical phenomena always display some degree of partial coherence between
their respective degrees of freedom. Partial coherence is of particular
interest in multimodal systems, where classical and quantum correlations
between spatial, polarization, and spectral degrees of freedom can lead to
fascinating phenomena (e.g., entanglement) and be leveraged for advanced
imaging and sensing modalities (e.g., in hyperspectral, polarization, and ghost
imaging). Here, we present a universal method to analyze, process, and generate
spatially partially coherent light in multimode systems by using
self-configuring optical networks. Our method relies on cascaded
self-configuring layers whose average power outputs are sequentially optimized.
Once optimized, the network separates the input light into its mutually
incoherent components, which is formally equivalent to a diagonalization of the
input density matrix. We illustrate our method with arrays of Mach-Zehnder
interferometers and show how this method can be used to perform partially
coherent environmental light sensing, generation of multimode partially
coherent light with arbitrary coherency matrices, and unscrambling of quantum
optical mixtures. We provide guidelines for the experimental realization of
this method, paving the way for self-configuring photonic devices that can
automatically learn optimal modal representations of partially coherent light
fields.
","Charles Roques-Carmes, Shanhui Fan, David Miller",David Miller,2024-02-01T15:59:49Z
"Checking the Sufficiently Scattered Condition using a Global Non-Convex
  Optimization Software","  The sufficiently scattered condition (SSC) is a key condition in the study of
identifiability of various matrix factorization problems, including
nonnegative, minimum-volume, symmetric, simplex-structured, and polytopic
matrix factorizations. The SSC allows one to guarantee that the computed matrix
factorization is unique/identifiable, up to trivial ambiguities. However, this
condition is NP-hard to check in general. In this paper, we show that it can
however be checked in a reasonable amount of time in realistic scenarios, when
the factorization rank is not too large. This is achieved by formulating the
problem as a non-convex quadratic optimization problem over a bounded set. We
use the global non-convex optimization software Gurobi, and showcase the
usefulness of this code on synthetic data sets and on real-world hyperspectral
images.
","Nicolas Gillis, Robert Luce",Robert Luce,2024-02-08T19:41:38Z
Hybrid CNN Bi-LSTM neural network for Hyperspectral image classification,"  Hyper spectral images have drawn the attention of the researchers for its
complexity to classify. It has nonlinear relation between the materials and the
spectral information provided by the HSI image. Deep learning methods have
shown superiority in learning this nonlinearity in comparison to traditional
machine learning methods. Use of 3-D CNN along with 2-D CNN have shown great
success for learning spatial and spectral features. However, it uses
comparatively large number of parameters. Moreover, it is not effective to
learn inter layer information. Hence, this paper proposes a neural network
combining 3-D CNN, 2-D CNN and Bi-LSTM. The performance of this model has been
tested on Indian Pines(IP) University of Pavia(PU) and Salinas Scene(SA) data
sets. The results are compared with the state of-the-art deep learning-based
models. This model performed better in all three datasets. It could achieve
99.83, 99.98 and 100 percent accuracy using only 30 percent trainable
parameters of the state-of-art model in IP, PU and SA datasets respectively.
","Alok Ranjan Sahoo, Pavan Chakraborty",Pavan Chakraborty,2024-02-15T15:46:13Z
"Multiview Subspace Clustering of Hyperspectral Images based on Graph
  Convolutional Networks","  High-dimensional and complex spectral structures make clustering of
hy-perspectral images (HSI) a challenging task. Subspace clustering has been
shown to be an effective approach for addressing this problem. However, current
subspace clustering algorithms are mainly designed for a single view and do not
fully exploit spatial or texture feature information in HSI. This study
proposed a multiview subspace clustering of HSI based on graph convolutional
networks. (1) This paper uses the powerful classification ability of graph
convolutional network and the learning ability of topologi-cal relationships
between nodes to analyze and express the spatial relation-ship of HSI. (2)
Pixel texture and pixel neighbor spatial-spectral infor-mation were sent to
construct two graph convolutional subspaces. (3) An attention-based fusion
module was used to adaptively construct a more discriminative feature map. The
model was evaluated on three popular HSI datasets, including Indian Pines,
Pavia University, and Houston. It achieved overall accuracies of 92.38%,
93.43%, and 83.82%, respectively and significantly outperformed the
state-of-the-art clustering methods. In conclusion, the proposed model can
effectively improve the clustering ac-curacy of HSI.
","Xianju Li, Renxiang Guan, Zihao Li, Hao Liu, Jing Yang",Jing Yang,2024-03-03T10:19:18Z
High throughput spectroscopy of pL droplets,"  Droplet microfluidics offers a versatile platform for analyzing liquid
samples. Despite its potential, there is a lack of techniques that allow to
reliably probe individual circulating droplets. The prospect of combining
droplet microfluidics with sensitive, broadband spectroscopic techniques would
therefore unlock new capabilities for various disciplines, including
biomedicine and biochemistry. Here we present an integrated optofluidic
platform that seamlessly combines droplet microfluidics and advanced
hyperspectral imaging. This enables high-resolution, label-free analysis of
single picolitre-sized droplets, providing valuable insights into their
content. As a proof-of-principle, we demonstrate the ability of our platform to
study rapid dynamic changes in a heterogeneous population of plasmonic
nanoparticles with millisecond-time resolution. Furthermore, we demonstrate the
effectiveness of the platform in biosensing applied to short DNA strands,
achieving a detection sensitivity in the range of 100 pM. Finally, we show that
the platform provides the flexibility to monitor samples over extended periods
of time (hours) in a multiplexed manner.
","Marc Sulliger, Jaime Ortega Arroyo, Romain Quidant",Romain Quidant,2024-03-06T20:18:14Z
"Advancing Hyperspectral Targeted Alpha Therapy with Adversarial Machine
  Learning","  Targeted Alpha Therapy (TAT) has emerged as a promising modality for the
treatment of various malignancies, leveraging the high linear energy transfer
(LET) and short range of alpha particles to selectively irradiate cancer cells
while sparing healthy tissue. Monitoring and optimizing TAT delivery is crucial
for its clinical success. Hyper-spectral Single Photon Imaging (HSPI) presents
a novel and versatile approach for the real-time assessment of TAT in vivo.
This study introduces a comprehensive framework for HSPI in TAT, encompassing
spectral unmixing, quantitative dosimetry, and spatiotemporal visualization. We
report the development of a dedicated HSPI system tailored to alpha-emitting
radionuclides, enabling the simultaneous acquisition of high-resolution
spectral data and single-photon localization. Utilizing advanced spectral
unmixing algorithms, we demonstrate the discrimination of alpha-induced
scintillation from background fluorescence, facilitating precise alpha particle
tracking with adversarial machine learning.
","Jim Zhao, Greg Leadman",Greg Leadman,2024-03-11T20:36:35Z
"FSDR: A Novel Deep Learning-based Feature Selection Algorithm for Pseudo
  Time-Series Data using Discrete Relaxation","  Conventional feature selection algorithms applied to Pseudo Time-Series (PTS)
data, which consists of observations arranged in sequential order without
adhering to a conventional temporal dimension, often exhibit impractical
computational complexities with high dimensional data. To address this
challenge, we introduce a Deep Learning (DL)-based feature selection algorithm:
Feature Selection through Discrete Relaxation (FSDR), tailored for PTS data.
Unlike the existing feature selection algorithms, FSDR learns the important
features as model parameters using discrete relaxation, which refers to the
process of approximating a discrete optimisation problem with a continuous one.
FSDR is capable of accommodating a high number of feature dimensions, a
capability beyond the reach of existing DL-based or traditional methods.
Through testing on a hyperspectral dataset (i.e., a type of PTS data), our
experimental results demonstrate that FSDR outperforms three commonly used
feature selection algorithms, taking into account a balance among execution
time, $R^2$, and $RMSE$.
","Mohammad Rahman, Manzur Murshed, Shyh Wei Teng, Manoranjan Paul",Manoranjan Paul,2024-03-13T10:37:52Z
"Neural Plasticity-Inspired Multimodal Foundation Model for Earth
  Observation","  The development of foundation models has revolutionized our ability to
interpret the Earth's surface using satellite observational data. Traditional
models have been siloed, tailored to specific sensors or data types like
optical, radar, and hyperspectral, each with its own unique characteristics.
This specialization hinders the potential for a holistic analysis that could
benefit from the combined strengths of these diverse data sources. Our novel
approach introduces the Dynamic One-For-All (DOFA) model, leveraging the
concept of neural plasticity in brain science to integrate various data
modalities into a single framework adaptively. This dynamic hypernetwork,
adjusting to different wavelengths, enables a single versatile Transformer
jointly trained on data from five sensors to excel across 12 distinct Earth
observation tasks, including sensors never seen during pretraining. DOFA's
innovative design offers a promising leap towards more accurate, efficient, and
unified Earth observation analysis, showcasing remarkable adaptability and
performance in harnessing the potential of multimodal Earth observation data.
","Zhitong Xiong, Yi Wang, Fahong Zhang, Adam J. Stewart, Joëlle Hanna, Damian Borth, Ioannis Papoutsis, Bertrand Le Saux, Gustau Camps-Valls, Xiao Xiang Zhu",Xiao Xiang Zhu,2024-03-22T17:11:47Z
SpectralWaste Dataset: Multimodal Data for Waste Sorting Automation,"  The increase in non-biodegradable waste is a worldwide concern. Recycling
facilities play a crucial role, but their automation is hindered by the complex
characteristics of waste recycling lines like clutter or object deformation. In
addition, the lack of publicly available labeled data for these environments
makes developing robust perception systems challenging. Our work explores the
benefits of multimodal perception for object segmentation in real waste
management scenarios. First, we present SpectralWaste, the first dataset
collected from an operational plastic waste sorting facility that provides
synchronized hyperspectral and conventional RGB images. This dataset contains
labels for several categories of objects that commonly appear in sorting plants
and need to be detected and separated from the main trash flow for several
reasons, such as security in the management line or reuse. Additionally, we
propose a pipeline employing different object segmentation architectures and
evaluate the alternatives on our dataset, conducting an extensive analysis for
both multimodal and unimodal alternatives. Our evaluation pays special
attention to efficiency and suitability for real-time processing and
demonstrates how HSI can bring a boost to RGB-only perception in these
realistic industrial settings without much computational overhead.
","Sara Casao, Fernando Peña, Alberto Sabater, Rosa Castillón, Darío Suárez, Eduardo Montijano, Ana C. Murillo",Ana C. Murillo,2024-03-26T18:39:38Z
"Dual Simplex Volume Maximization for Simplex-Structured Matrix
  Factorization","  Simplex-structured matrix factorization (SSMF) is a generalization of
nonnegative matrix factorization, a fundamental interpretable data analysis
model, and has applications in hyperspectral unmixing and topic modeling. To
obtain identifiable solutions, a standard approach is to find minimum-volume
solutions. By taking advantage of the duality/polarity concept for polytopes,
we convert minimum-volume SSMF in the primal space to a maximum-volume problem
in the dual space. We first prove the identifiability of this maximum-volume
dual problem. Then, we use this dual formulation to provide a novel
optimization approach which bridges the gap between two existing families of
algorithms for SSMF, namely volume minimization and facet identification.
Numerical experiments show that the proposed approach performs favorably
compared to the state-of-the-art SSMF algorithms.
","Maryam Abdolali, Giovanni Barbarino, Nicolas Gillis",Nicolas Gillis,2024-03-29T14:19:26Z
Controlling the False Discovery Rate in Subspace Selection,"  Controlling the false discovery rate (FDR) is a popular approach to multiple
testing, variable selection, and related problems of simultaneous inference. In
many contemporary applications, models are not specified by discrete variables,
which necessitates a broadening of the scope of the FDR control paradigm.
Motivated by the ubiquity of low-rank models for high-dimensional matrices, we
present methods for subspace selection in principal components analysis that
provide control on a geometric analog of FDR that is adapted to subspace
selection. Our methods crucially rely on recently-developed tools from random
matrix theory, in particular on a characterization of the limiting behavior of
eigenvectors and the gaps between successive eigenvalues of large random
matrices. Our procedure is parameter-free, and we show that it provides FDR
control in subspace selection for common noise models considered in the
literature. We demonstrate the utility of our algorithm with numerical
experiments on synthetic data and on problems arising in single-cell RNA
sequencing and hyperspectral imaging.
","Mateo Díaz, Venkat Chandrasekaran",Venkat Chandrasekaran,2024-04-14T05:10:05Z
"Random matrix theory improved Fréchet mean of symmetric positive
  definite matrices","  In this study, we consider the realm of covariance matrices in machine
learning, particularly focusing on computing Fr\'echet means on the manifold of
symmetric positive definite matrices, commonly referred to as Karcher or
geometric means. Such means are leveraged in numerous machine-learning tasks.
Relying on advanced statistical tools, we introduce a random matrix
theory-based method that estimates Fr\'echet means, which is particularly
beneficial when dealing with low sample support and a high number of matrices
to average. Our experimental evaluation, involving both synthetic and
real-world EEG and hyperspectral datasets, shows that we largely outperform
state-of-the-art methods.
","Florent Bouchard, Ammar Mian, Malik Tiomoko, Guillaume Ginolhac, Frédéric Pascal",Frédéric Pascal,2024-05-10T16:00:29Z
Confidence Estimation in Unsupervised Deep Change Vector Analysis,"  Unsupervised transfer learning-based change detection methods exploit the
feature extraction capability of pre-trained networks to distinguish changed
pixels from the unchanged ones. However, their performance may vary
significantly depending on several geographical and model-related aspects. In
many applications, it is of utmost importance to provide trustworthy or
confident results, even if over a subset of pixels. The core challenge in this
problem is to identify changed pixels and confident pixels in an unsupervised
manner. To address this, we propose a two-network model - one tasked with mere
change detection and the other with confidence estimation. While the change
detection network can be used in conjunction with popular transfer
learning-based change detection methods such as Deep Change Vector Analysis,
the confidence estimation network operates similarly to a randomized smoothing
model. By ingesting ensembles of inputs perturbed by noise, it creates a
distribution over the output and assigns confidence to each pixel's outcome. We
tested the proposed method on three different Earth observation sensors:
optical, Synthetic Aperture Radar, and hyperspectral sensors.
",Sudipan Saha,Sudipan Saha,2024-05-16T08:36:20Z
"Supervised Contrastive Learning for Snapshot Spectral Imaging Face
  Anti-Spoofing","  This study reveals a cutting-edge re-balanced contrastive learning strategy
aimed at strengthening face anti-spoofing capabilities within facial
recognition systems, with a focus on countering the challenges posed by printed
photos, and highly realistic silicone or latex masks. Leveraging the HySpeFAS
dataset, which benefits from Snapshot Spectral Imaging technology to provide
hyperspectral images, our approach harmonizes class-level contrastive learning
with data resampling and an innovative real-face oriented reweighting
technique. This method effectively mitigates dataset imbalances and reduces
identity-related biases. Notably, our strategy achieved an unprecedented
0.0000\% Average Classification Error Rate (ACER) on the HySpeFAS dataset,
ranking first at the Chalearn Snapshot Spectral Imaging Face Anti-spoofing
Challenge on CVPR 2024.
","Chuanbiao Song, Yan Hong, Jun Lan, Huijia Zhu, Weiqiang Wang, Jianfu Zhang",Jianfu Zhang,2024-05-29T08:03:52Z
"Broadband Fourier-Transform Optical Photothermal Infrared Spectroscopy
  and Imaging","  Optical photothermal microscopy is a powerful, emerging method that overcomes
the diffraction limit in infrared hyperspectral imaging by utilizing a visible
probe laser beam to detect local temperature-induced modulation at the visible
diffraction limit. However, the spectral range of this technique has been
limited by the tuning range of infrared sources, which is generally restricted
to the fingerprint window with commercially available quantum cascade lasers.
In this work, ultra-broadband synchrotron infrared radiation was used for
infrared photothermal imaging and spectroscopy, spanning the entire
mid-infrared range. Both optical- and fluorescence-detected photothermal
modalities were performed, demonstrating improved spectral range when compared
to optical photothermal microscopy using commercial sources and improved
spatial resolution when compared to synchrotron micro-spectroscopy
measurements. Following these initial validation studies, synchrotron
Fourier-transform optical photothermal infrared spectroscopy (FT-OPTIR) in
combination with synchrotron micro-spectroscopy measurements were used to
differentiate cells in mouse brain tissue sections.
","Aleksandr Razumtcev, Gwendylan A. Turner, Sergey Zayats, Ferenc Borondics, Aris Polyzos, Garth J. Simpson, Hans A. Bechtel",Hans A. Bechtel,2024-06-20T19:23:51Z
"Unsupervised Few-Shot Continual Learning for Remote Sensing Image Scene
  Classification","  A continual learning (CL) model is desired for remote sensing image analysis
because of varying camera parameters, spectral ranges, resolutions, etc. There
exist some recent initiatives to develop CL techniques in this domain but they
still depend on massive labelled samples which do not fully fit remote sensing
applications because ground truths are often obtained via field-based surveys.
This paper addresses this problem with a proposal of unsupervised flat-wide
learning approach (UNISA) for unsupervised few-shot continual learning
approaches of remote sensing image scene classifications which do not depend on
any labelled samples for its model updates. UNISA is developed from the idea of
prototype scattering and positive sampling for learning representations while
the catastrophic forgetting problem is tackled with the flat-wide learning
approach combined with a ball generator to address the data scarcity problem.
Our numerical study with remote sensing image scene datasets and a
hyperspectral dataset confirms the advantages of our solution. Source codes of
UNISA are shared publicly in \url{https://github.com/anwarmaxsum/UNISA} to
allow convenient future studies and reproductions of our numerical results.
","Muhammad Anwar Ma'sum, Mahardhika Pratama, Ramasamy Savitha, Lin Liu,  Habibullah, Ryszard Kowalczyk",Ryszard Kowalczyk,2024-06-04T03:06:41Z
Quantum Frequency Mixing using an NV Diamond Microscope,"  Wide-field magnetic microscopy using nitrogen-vacancy (NV) centers in diamond
can yield high-quality magnetic images of DC and AC magnetic fields. The unique
combination of micron-scale spatial resolution of scalar or vector fields at
room temperature and parallel camera readout make this an appealing technique
for applications in biology, geology, condensed-matter physics, and
electronics. However, while NV magnetic microscopy has achieved great success
in these areas, historically the accessible frequency range has been limited.
In this paper, we overcome this limitation by implementing the recently
developed technique of quantum frequency mixing. With this approach, we
generate wide-field magnetic images of test structures driven by alternating
currents up to 70 MHz, well outside the reach of DC and Rabi magnetometry
methods. With further improvements, this approach could find utility in
hyperspectral imaging for electronics power spectrum analysis, electronics
diagnostics and troubleshooting, and quantum computing hardware validation.
","Samuel J. Karlson, Pauli Kehayias, Jennifer M. Schloss, Andrew C. Maccabe, David F. Phillips, Guoqing Wang, Paola Cappellaro, Danielle A. Braje",Danielle A. Braje,2024-07-09T16:46:00Z
XAI-Guided Enhancement of Vegetation Indices for Crop Mapping,"  Vegetation indices allow to efficiently monitor vegetation growth and
agricultural activities. Previous generations of satellites were capturing a
limited number of spectral bands, and a few expert-designed vegetation indices
were sufficient to harness their potential. New generations of multi- and
hyperspectral satellites can however capture additional bands, but are not yet
efficiently exploited. In this work, we propose an explainable-AI-based method
to select and design suitable vegetation indices. We first train a deep neural
network using multispectral satellite data, then extract feature importance to
identify the most influential bands. We subsequently select suitable existing
vegetation indices or modify them to incorporate the identified bands and
retrain our model. We validate our approach on a crop classification task. Our
results indicate that models trained on individual indices achieve comparable
results to the baseline model trained on all bands, while the combination of
two indices surpasses the baseline in certain cases.
","Hiba Najjar, Francisco Mena, Marlon Nuske, Andreas Dengel",Andreas Dengel,2024-07-11T08:44:43Z
"Hyperspectral electromechanical imaging at the nanoscale: Dynamical
  backaction, dissipation and quantum fluctuations","  We report a new scanning nanomechanical noise microscopy platform enabling to
both heat and acquire the fluctuations of mechanical nanostructures with
nanometric resolution. We use this platform to image the thermally activated
nanomechanical dynamics of a model system consisting of a $40\,\mathrm{nm}$
diameter single-defect nanowire, while scanning a localized heat source across
its surface. We develop a thermal backaction model, which we use to demonstrate
a close connection between the structure of the nanowire, its thermal response,
its dissipation and its fluctuations. We notably show that the defect behaves
as a single fluctuation hub, whose e-beam excitation yields a far
off-equilibrium vibrational state, largely dominated by the quantum
fluctuations of the heating source. Our platform is of interest for future
quantitative investigation of fundamental nanoscale dynamical phenomena, and
appears as a new playground for investigating quantum thermodynamics in the
strongly dissipative regime and at room temperature.
","Clément Chardin, Sébastien Pairis, Sabine Douillet, Moïra Hocevar, Julien Claudon, Jean-Philippe Poizat, Ludovic Bellon, Pierre Verlot",Pierre Verlot,2024-07-30T11:17:31Z
Multi-head Spatial-Spectral Mamba for Hyperspectral Image Classification,"  Spatial-Spectral Mamba (SSM) improves computational efficiency and captures
long-range dependencies, addressing Transformer limitations. However,
traditional Mamba models overlook rich spectral information in HSIs and
struggle with high dimensionality and sequential data. To address these issues,
we propose the SSM with multi-head self-attention and token enhancement
(MHSSMamba). This model integrates spectral and spatial information by
enhancing spectral tokens and using multi-head attention to capture complex
relationships between spectral bands and spatial locations. It also manages
long-range dependencies and the sequential nature of HSI data, preserving
contextual information across spectral bands. MHSSMamba achieved remarkable
classification accuracies of 97.62\% on Pavia University, 96.92\% on the
University of Houston, 96.85\% on Salinas, and 99.49\% on Wuhan-longKou
datasets. The source code is available at
\href{https://github.com/MHassaanButt/MHA\_SS\_Mamba}{GitHub}.
","Muhammad Ahmad, Muhammad Hassaan Farooq Butt, Muhammad Usama, Hamad Ahmed Altuwaijri, Manuel Mazzara, Salvatore Distefano",Salvatore Distefano,2024-08-02T12:27:15Z
"Active Inference in Contextual Multi-Armed Bandits for Autonomous
  Robotic Exploration","  Autonomous selection of optimal options for data collection from multiple
alternatives is challenging in uncertain environments. When secondary
information about options is accessible, such problems can be framed as
contextual multi-armed bandits (CMABs). Neuro-inspired active inference has
gained interest for its ability to balance exploration and exploitation using
the expected free energy objective function. Unlike previous studies that
showed the effectiveness of active inference based strategy for CMABs using
synthetic data, this study aims to apply active inference to realistic
scenarios, using a simulated mineralogical survey site selection problem.
Hyperspectral data from AVIRIS-NG at Cuprite, Nevada, serves as contextual
information for predicting outcome probabilities, while geologists' mineral
labels represent outcomes. Monte Carlo simulations assess the robustness of
active inference against changing expert preferences. Results show that active
inference requires fewer iterations than standard bandit approaches with
real-world noisy and biased data, and performs better when outcome preferences
vary online by adapting the selection strategy to align with expert shifts.
","Shohei Wakayama, Alberto Candela, Paul Hayne, Nisar Ahmed",Nisar Ahmed,2024-08-07T23:00:03Z
"Multi-watt long-wavelength infrared femtosecond lasers and resonant
  enamel ablation","  High-power broadband tunable long-wavelength infrared (LWIR) femtosecond
lasers operating at fingerprint wavelengths of 7-14 {\mu}m hold significant
promise across a range of applications, including molecular hyperspectral
imaging, strong-field light-matter interaction, and resonant tissue ablation.
Here we present 6-12 {\mu}m broadband tunable parametric amplifier based on
LiGaS2 or BaGa4S7, generating new record output power of 2.4 W at 7.5 {\mu}m,
and 1.5 W at 9.5 {\mu}m, pumped by a simple and effective thin-square-rod
Yb:YAG amplifier producing 110 W 274 fs output pulses. As a proof of concept,
we showcase efficient resonant ablation and microstructure fabrication on
enamel at the hydroxyapatite resonant wavelength of 9.5 {\mu}m, with a laser
intensity two orders-of-magnitude lower than that required by non-resonant
femtosecond lasers, which could foster more precision surgical applications
with superior biosafety.
","Xuemei Yang, Dunxiang Zhang, Weizhe Wang, Kan Tian, Linzhen He, Jinmiao Guo, Bo Hu, Tao Pu, Wenlong Li, Shiran Sun, Chunmei Ding, Han Wu, Kenkai Li, Yujie Peng, Jianshu Li, Yuxin Leng, Houkun Liang",Houkun Liang,2024-08-25T09:37:26Z
"Advancing Cucumber Disease Detection in Agriculture through Machine
  Vision and Drone Technology","  This study uses machine vision and drone technologies to propose a unique
method for the diagnosis of cucumber disease in agriculture. The backbone of
this research is a painstakingly curated dataset of hyperspectral photographs
acquired under genuine field conditions. Unlike earlier datasets, this study
included a wide variety of illness types, allowing for precise early-stage
detection. The model achieves an excellent 87.5\% accuracy in distinguishing
eight unique cucumber illnesses after considerable data augmentation. The
incorporation of drone technology for high-resolution images improves disease
evaluation. This development has enormous potential for improving crop
management, lowering labor costs, and increasing agricultural productivity.
This research, which automates disease detection, represents a significant step
toward a more efficient and sustainable agricultural future.
","Syada Tasfia Rahman, Nishat Vasker, Amir Khabbab Ahammed, Mahamudul Hasan",Mahamudul Hasan,2024-09-18T22:54:23Z
"Orthogonal Nonnegative Matrix Factorization with the Kullback-Leibler
  divergence","  Orthogonal nonnegative matrix factorization (ONMF) has become a standard
approach for clustering. As far as we know, most works on ONMF rely on the
Frobenius norm to assess the quality of the approximation. This paper presents
a new model and algorithm for ONMF that minimizes the Kullback-Leibler (KL)
divergence. As opposed to the Frobenius norm which assumes Gaussian noise, the
KL divergence is the maximum likelihood estimator for Poisson-distributed data,
which can model better sparse vectors of word counts in document data sets and
photo counting processes in imaging. We develop an algorithm based on
alternating optimization, KL-ONMF, and show that it performs favorably with the
Frobenius-norm based ONMF for document classification and hyperspectral image
unmixing.
","Jean Pacifique Nkurunziza, Fulgence Nahayo, Nicolas Gillis",Nicolas Gillis,2024-10-10T10:17:54Z
Fourier Synthetic Aperture-based Time-resolved Terahertz Imaging,"  Terahertz microscopy has attracted attention owing to distinctive
characteristics of the THz frequency region, particularly non-ionizing photon
energy, spectral fingerprint, and transparency to most nonpolar materials.
Nevertheless, the well-known Rayleigh diffraction limit imposed on THz waves
commonly constrains the resultant imaging resolution to values beyond the
millimeter scale, consequently limiting the applicability in numerous emerging
applications for chemical sensing and complex media imaging. In this
theoretical and numerical work, we address this challenge by introducing a new
imaging approach, based on acquiring high-spatial frequencies by adapting the
Fourier synthetic aperture approach to the terahertz spectral range, thus
surpassing the diffraction-limited resolution. Our methodology combines
multi-angle terahertz pulsed illumination with time-resolved field
measurements, as enabled by the state-of-the-art time-domain spectroscopy
technique. We demonstrate the potential of the approach for hyperspectral
terahertz imaging of semi-transparent samples and show that the technique can
reconstruct spatial and temporal features of complex inhomogeneous samples with
subwavelength resolution.
","Vivek Kumar, Pitambar Mukherjee, Lorenzo Valzania, Amaury Badon, Patrick Mounaix, Sylvain Gigan",Sylvain Gigan,2024-10-04T13:05:02Z
"Elliptical Wishart distributions: information geometry, maximum
  likelihood estimator, performance analysis and statistical learning","  This paper deals with Elliptical Wishart distributions - which generalize the
Wishart distribution - in the context of signal processing and machine
learning. Two algorithms to compute the maximum likelihood estimator (MLE) are
proposed: a fixed point algorithm and a Riemannian optimization method based on
the derived information geometry of Elliptical Wishart distributions. The
existence and uniqueness of the MLE are characterized as well as the
convergence of both estimation algorithms. Statistical properties of the MLE
are also investigated such as consistency, asymptotic normality and an
intrinsic version of Fisher efficiency. On the statistical learning side, novel
classification and clustering methods are designed. For the $t$-Wishart
distribution, the performance of the MLE and statistical learning algorithms
are evaluated on both simulated and real EEG and hyperspectral data, showcasing
the interest of our proposed methods.
","Imen Ayadi, Florent Bouchard, Frédéric Pascal",Frédéric Pascal,2024-11-05T01:52:27Z
"Insights into Lunar Mineralogy: An Unsupervised Approach for Clustering
  of the Moon Mineral Mapper (M3) spectral data","  This paper presents a novel method for mapping spectral features of the Moon
using machine learning-based clustering of hyperspectral data from the Moon
Mineral Mapper (M3) imaging spectrometer. The method uses a convolutional
variational autoencoder to reduce the dimensionality of the spectral data and
extract features of the spectra. Then, a k-means algorithm is applied to
cluster the latent variables into five distinct groups, corresponding to
dominant spectral features, which are related to the mineral composition of the
Moon's surface. The resulting global spectral cluster map shows the
distribution of the five clusters on the Moon, which consist of a mixture of,
among others, plagioclase, pyroxene, olivine, and Fe-bearing minerals across
the Moon's surface. The clusters are compared to the mineral maps from the
Kaguya mission, which showed that the locations of the clusters overlap with
the locations of high wt% of minerals such as plagioclase, clinopyroxene, and
olivine. The paper demonstrates the usefulness of unbiased unsupervised
learning for lunar mineral exploration and provides a comprehensive analysis of
lunar mineralogy.
","Freja Thoresen, Igor Drozdovskiy, Aidan Cowley, Magdelena Laban, Sebastien Besse, Sylvain Blunier",Sylvain Blunier,2024-11-05T15:31:16Z
"Robust deep learning-based semantic organ segmentation in hyperspectral
  images","  Semantic image segmentation is an important prerequisite for
context-awareness and autonomous robotics in surgery. The state of the art has
focused on conventional RGB video data acquired during minimally invasive
surgery, but full-scene semantic segmentation based on spectral imaging data
and obtained during open surgery has received almost no attention to date. To
address this gap in the literature, we are investigating the following research
questions based on hyperspectral imaging (HSI) data of pigs acquired in an open
surgery setting: (1) What is an adequate representation of HSI data for neural
network-based fully automated organ segmentation, especially with respect to
the spatial granularity of the data (pixels vs. superpixels vs. patches vs.
full images)? (2) Is there a benefit of using HSI data compared to other
modalities, namely RGB data and processed HSI data (e.g. tissue parameters like
oxygenation), when performing semantic organ segmentation? According to a
comprehensive validation study based on 506 HSI images from 20 pigs, annotated
with a total of 19 classes, deep learning-based segmentation performance
increases, consistently across modalities, with the spatial context of the
input data. Unprocessed HSI data offers an advantage over RGB data or processed
data from the camera provider, with the advantage increasing with decreasing
size of the input to the neural network. Maximum performance (HSI applied to
whole images) yielded a mean DSC of 0.90 ((standard deviation (SD)) 0.04),
which is in the range of the inter-rater variability (DSC of 0.89 ((standard
deviation (SD)) 0.07)). We conclude that HSI could become a powerful image
modality for fully-automatic surgical scene understanding with many advantages
over traditional imaging, including the ability to recover additional
functional tissue information. Code and pre-trained models:
https://github.com/IMSY-DKFZ/htc.
","Silvia Seidlitz, Jan Sellner, Jan Odenthal, Berkin Özdemir, Alexander Studier-Fischer, Samuel Knödler, Leonardo Ayala, Tim J. Adler, Hannes G. Kenngott, Minu Tizabi, Martin Wagner, Felix Nickel, Beat P. Müller-Stich, Lena Maier-Hein",Lena Maier-Hein,2021-11-09T20:37:38Z
"Deep learning denoising by dimension reduction: Application to the
  ORION-B line cubes","  Context. The availability of large bandwidth receivers for millimeter radio
telescopes allows the acquisition of position-position-frequency data cubes
over a wide field of view and a broad frequency coverage. These cubes contain
much information on the physical, chemical, and kinematical properties of the
emitting gas. However, their large size coupled with inhomogenous
signal-to-noise ratio (SNR) are major challenges for consistent analysis and
interpretation.Aims. We search for a denoising method of the low SNR regions of
the studied data cubes that would allow to recover the low SNR emission without
distorting the signals with high SNR.Methods. We perform an in-depth data
analysis of the 13 CO and C 17 O (1 -- 0) data cubes obtained as part of the
ORION-B large program performed at the IRAM 30m telescope. We analyse the
statistical properties of the noise and the evolution of the correlation of the
signal in a given frequency channel with that of the adjacent channels. This
allows us to propose significant improvements of typical autoassociative neural
networks, often used to denoise hyperspectral Earth remote sensing data.
Applying this method to the 13 CO (1 -- 0) cube, we compare the denoised data
with those derived with the multiple Gaussian fitting algorithm ROHSA,
considered as the state of the art procedure for data line cubes.Results. The
nature of astronomical spectral data cubes is distinct from that of the
hyperspectral data usually studied in the Earth remote sensing literature
because the observed intensities become statistically independent beyond a
short channel separation. This lack of redundancy in data has led us to adapt
the method, notably by taking into account the sparsity of the signal along the
spectral axis. The application of the proposed algorithm leads to an increase
of the SNR in voxels with weak signal, while preserving the spectral shape of
the data in high SNR voxels.Conclusions. The proposed algorithm that combines a
detailed analysis of the noise statistics with an innovative autoencoder
architecture is a promising path to denoise radio-astronomy line data cubes. In
the future, exploring whether a better use of the spatial correlations of the
noise may further improve the denoising performances seems a promising avenue.
In addition,
","Lucas Einig, Jérôme Pety, Antoine Roueff, Paul Vandame, Jocelyn Chanussot, Maryvonne Gerin, Jan H. Orkisz, Pierre Palud, Miriam Garcia Santa-Maria, Victor de Souza Magalhaes, Ivana Bešlić, Sébastien Bardeau, Emeric E. Bron, Pierre Chainais, Javier R Goicoechea, Pierre Gratier, Viviana Guzman Veloso, Annie Hughes, Jouni Kainulainen, David Languignon, Rosine Lallement, François Levrier, Dariuscz C. Lis, Harvey Liszt, Jacques Le Bourlot, Franck Le Petit, Karin Danielsson Öberg, Nicolas Peretto, Evelyne Roueff, Albrecht Sievers, Pierre-Antoine Thouvenin, Pascal Tremblin",Pascal Tremblin,2023-07-24T13:02:31Z
"Fast Poisson Noise Removal by Biorthogonal Haar Domain Hypothesis
  Testing","  Methods based on hypothesis tests (HTs) in the Haar domain are widely used to
denoise Poisson count data. Facing large datasets or real-time applications,
Haar-based denoisers have to use the decimated transform to meet limited-memory
or computation-time constraints. Unfortunately, for regular underlying
intensities, decimation yields discontinuous estimates and strong ""staircase""
artifacts. In this paper, we propose to combine the HT framework with the
decimated biorthogonal Haar (Bi-Haar) transform instead of the classical Haar.
The Bi-Haar filter bank is normalized such that the p-values of Bi-Haar
coefficients (pBH) provide good approximation to those of Haar (pH) for
high-intensity settings or large scales; for low-intensity settings and small
scales, we show that pBH are essentially upper-bounded by pH. Thus, we may
apply the Haar-based HTs to Bi-Haar coefficients to control a prefixed false
positive rate. By doing so, we benefit from the regular Bi-Haar filter bank to
gain a smooth estimate while always maintaining a low computational complexity.
A Fisher-approximation-based threshold imple- menting the HTs is also
established. The efficiency of this method is illustrated on an example of
hyperspectral-source-flux estimation.
","Bo Zhang, Jalal Fadili, Jean Luc Starck, Seth W. Digel",Seth W. Digel,2006-08-25T12:44:01Z
Treelets--An adaptive multi-scale basis for sparse unordered data,"  In many modern applications, including analysis of gene expression and text
documents, the data are noisy, high-dimensional, and unordered--with no
particular meaning to the given order of the variables. Yet, successful
learning is often possible due to sparsity: the fact that the data are
typically redundant with underlying structures that can be represented by only
a few features. In this paper we present treelets--a novel construction of
multi-scale bases that extends wavelets to nonsmooth signals. The method is
fully adaptive, as it returns a hierarchical tree and an orthonormal basis
which both reflect the internal structure of the data. Treelets are especially
well-suited as a dimensionality reduction and feature selection tool prior to
regression and classification, in situations where sample sizes are small and
the data are sparse with unknown groupings of correlated or collinear
variables. The method is also simple to implement and analyze theoretically.
Here we describe a variety of situations where treelets perform better than
principal component analysis, as well as some common variable selection and
cluster averaging schemes. We illustrate treelets on a blocked covariance model
and on several data sets (hyperspectral image data, DNA microarray data, and
internet advertisements) with highly complex dependencies between variables.
","Ann B. Lee, Boaz Nadler, Larry Wasserman",Larry Wasserman,2007-07-03T19:22:35Z
Minimum mean square distance estimation of a subspace,"  We consider the problem of subspace estimation in a Bayesian setting. Since
we are operating in the Grassmann manifold, the usual approach which consists
of minimizing the mean square error (MSE) between the true subspace $U$ and its
estimate $\hat{U}$ may not be adequate as the MSE is not the natural metric in
the Grassmann manifold. As an alternative, we propose to carry out subspace
estimation by minimizing the mean square distance (MSD) between $U$ and its
estimate, where the considered distance is a natural metric in the Grassmann
manifold, viz. the distance between the projection matrices. We show that the
resulting estimator is no longer the posterior mean of $U$ but entails
computing the principal eigenvectors of the posterior mean of $U U^{T}$.
Derivation of the MMSD estimator is carried out in a few illustrative examples
including a linear Gaussian model for the data and a Bingham or von Mises
Fisher prior distribution for $U$. In all scenarios, posterior distributions
are derived and the MMSD estimator is obtained either analytically or
implemented via a Markov chain Monte Carlo simulation method. The method is
shown to provide accurate estimates even when the number of samples is lower
than the dimension of $U$. An application to hyperspectral imagery is finally
investigated.
","Olivier Besson, Nicolas Dobigeon, Jean-Yves Tourneret",Jean-Yves Tourneret,2011-01-18T14:33:22Z
"An Alternating Direction Algorithm for Matrix Completion with
  Nonnegative Factors","  This paper introduces an algorithm for the nonnegative matrix
factorization-and-completion problem, which aims to find nonnegative low-rank
matrices X and Y so that the product XY approximates a nonnegative data matrix
M whose elements are partially known (to a certain accuracy). This problem
aggregates two existing problems: (i) nonnegative matrix factorization where
all entries of M are given, and (ii) low-rank matrix completion where
nonnegativity is not required. By taking the advantages of both nonnegativity
and low-rankness, one can generally obtain superior results than those of just
using one of the two properties. We propose to solve the non-convex constrained
least-squares problem using an algorithm based on the classic alternating
direction augmented Lagrangian method. Preliminary convergence properties of
the algorithm and numerical simulation results are presented. Compared to a
recent algorithm for nonnegative matrix factorization, the proposed algorithm
produces factorizations of similar quality using only about half of the matrix
entries. On tasks of recovering incomplete grayscale and hyperspectral images,
the proposed algorithm yields overall better qualities than those produced by
two recent matrix-completion algorithms that do not exploit nonnegativity.
","Yangyang Xu, Wotao Yin, Zaiwen Wen, Yin Zhang",Yin Zhang,2011-03-06T22:27:52Z
Compressed Sensing of Simultaneous Low-Rank and Joint-Sparse Matrices,"  In this paper we consider the problem of recovering a high dimensional data
matrix from a set of incomplete and noisy linear measurements. We introduce a
new model that can efficiently restrict the degrees of freedom of the problem
and is generic enough to find a lot of applications, for instance in
multichannel signal compressed sensing (e.g. sensor networks, hyperspectral
imaging) and compressive sparse principal component analysis (s-PCA). We assume
data matrices have a simultaneous low-rank and joint sparse structure, and we
propose a novel approach for efficient compressed sensing (CS) of such data.
Our CS recovery approach is based on a convex minimization problem that
incorporates this restrictive structure by jointly regularizing the solutions
with their nuclear (trace) norm and l2/l1 mixed norm. Our theoretical analysis
uses a new notion of restricted isometry property (RIP) and shows that, for
sampling schemes satisfying RIP, our approach can stably recover all low-rank
and joint-sparse matrices. For a certain class of random sampling schemes
satisfying a particular concentration bound (e.g. the subgaussian ensembles) we
derive a lower bound on the number of CS measurements indicating the
near-optimality of our recovery approach as well as a significant enhancement
compared to the state-of-the-art. We introduce an iterative algorithm based on
proximal calculus in order to solve the joint nuclear and l2/l1 norms
minimization problem and, finally, we illustrate the empirical recovery phase
transition of this approach by series of numerical experiments.
","Mohammad Golbabaee, Pierre Vandergheynst",Pierre Vandergheynst,2012-11-21T15:24:13Z
Excitonic recombinations in hBN: from bulk to exfoliated layers,"  Hexagonal boron nitride (h-BN) and graphite are structurally similar but with
very different properties. Their combination in graphene-based devices meets
now a huge research focus, and it becomes particularly important to evaluate
the role played by crystalline defects in them. In this work, the
cathodoluminescence (CL) properties of hexagonal boron nitride crystallites are
reported and compared to those of nanosheets mechanically exfoliated from them.
First the link between the presence of structural defects and the recombination
intensity of bound-excitons, the so-called D series, is confirmed. Low
defective h-BN regions are further evidenced by CL spectral mapping
(hyperspectral imaging), allowing us to observe new features in the
near-band-edge region, tentatively attributed to phonon replica of exciton
recombinations. Second the h-BN thickness was reduced down to six atomic
layers, using mechanical exfoliation, as evidenced by atomic force microscopy.
Even at these low thicknesses, the luminescence remains intense and exciton
recombination energies are not strongly modified with respect to the bulk, as
expected from theoretical calculations indicating extremely compact excitons in
h-BN.
","Aurélie Pierret, Jorge Loayza, Bruno Berini, Andreas Betz, Bernard Plaçais, François Ducastelle, Julien Barjon, Annick Loiseau",Annick Loiseau,2013-06-12T14:56:00Z
"A normalized scaled gradient method to solve non-negativity and equality
  constrained linear inverse problem - Application to spectral mixture analysis","  This paper addresses the problem of minimizing a convex cost function under
non-negativity and equality constraints, with the aim of solving the linear
unmixing problem encountered in hyperspectral imagery. This problem can be
formulated as a linear regression problem whose regression coefficients
(abundances) satisfy sum-to-one and positivity constraints. A normalized scaled
gradient iterative method (NSGM) is proposed for estimating the abundances of
the linear mixing model. The positivity constraint is ensured by the Karush
Kuhn Tucker conditions whereas the sum-to-one constraint is fulfilled by
introducing normalized variables in the algorithm. The convergence is ensured
by a one-dimensional search of the step size. Note that NSGM can be applied to
any convex cost function with non negativity and flux constraints. In order to
compare the NSGM with the well-known fully constraint least squares (FCLS)
algorithm, this latter is reformulated in term of a penalized function, which
reveals its suboptimality. Simulations on synthetic data illustrate the
performances of the proposed algorithm in comparison with other unmixing
algorithms and, more particulary, demonstrate its efficiency when compared to
the popular FCLS. Finally, results on real data are given.
","Céline Theys, Henri Lantéri, Nicolas Dobigeon, Cédric Richard, Jean-Yves Tourneret, André Ferrari",André Ferrari,2013-10-02T12:18:18Z
"Kernel Multivariate Analysis Framework for Supervised Subspace Learning:
  A Tutorial on Linear and Kernel Multivariate Methods","  Feature extraction and dimensionality reduction are important tasks in many
fields of science dealing with signal processing and analysis. The relevance of
these techniques is increasing as current sensory devices are developed with
ever higher resolution, and problems involving multimodal data sources become
more common. A plethora of feature extraction methods are available in the
literature collectively grouped under the field of Multivariate Analysis (MVA).
This paper provides a uniform treatment of several methods: Principal Component
Analysis (PCA), Partial Least Squares (PLS), Canonical Correlation Analysis
(CCA) and Orthonormalized PLS (OPLS), as well as their non-linear extensions
derived by means of the theory of reproducing kernel Hilbert spaces. We also
review their connections to other methods for classification and statistical
dependence estimation, and introduce some recent developments to deal with the
extreme cases of large-scale and low-sized problems. To illustrate the wide
applicability of these methods in both classification and regression problems,
we analyze their performance in a benchmark of publicly available data sets,
and pay special attention to specific real applications involving audio
processing for music genre prediction and hyperspectral satellite images for
Earth and climate monitoring.
","Jerónimo Arenas-García, Kaare Brandt Petersen, Gustavo Camps-Valls, Lars Kai Hansen",Lars Kai Hansen,2013-10-18T16:44:05Z
"A Novel Rate Control Algorithm for Onboard Predictive Coding of
  Multispectral and Hyperspectral Images","  Predictive coding is attractive for compression onboard of spacecrafts thanks
to its low computational complexity, modest memory requirements and the ability
to accurately control quality on a pixel-by-pixel basis. Traditionally,
predictive compression focused on the lossless and near-lossless modes of
operation where the maximum error can be bounded but the rate of the compressed
image is variable. Rate control is considered a challenging problem for
predictive encoders due to the dependencies between quantization and prediction
in the feedback loop, and the lack of a signal representation that packs the
signal's energy into few coefficients. In this paper, we show that it is
possible to design a rate control scheme intended for onboard implementation.
In particular, we propose a general framework to select quantizers in each
spatial and spectral region of an image so as to achieve the desired target
rate while minimizing distortion. The rate control algorithm allows to achieve
lossy, near-lossless compression, and any in-between type of compression, e.g.,
lossy compression with a near-lossless constraint. While this framework is
independent of the specific predictor used, in order to show its performance,
in this paper we tailor it to the predictor adopted by the CCSDS-123 lossless
compression standard, obtaining an extension that allows to perform lossless,
near-lossless and lossy compression in a single package. We show that the rate
controller has excellent performance in terms of accuracy in the output rate,
rate-distortion characteristics and is extremely competitive with respect to
state-of-the-art transform coding.
","Diego Valsesia, Enrico Magli",Enrico Magli,2014-01-14T18:45:29Z
MR PRISM - Spectral Analysis Tool for the CRISM,"  We describe a computer application designed to analyze hyperspectral data
collected by the Compact Infrared Spectrometer for Mars (CRISM). The
application links the spectral, imaging and mapping perspectives on the
eventual CRISM dataset by presenting the user with three different ways to
analyze the data.
  One of the goals when developing this instrument is to build in the latest
algorithms for detection of spectrally compelling targets on the surface of the
Red Planet, so they may be available to the Planetary Science community without
cost and with a minimal learning barrier to cross. This will allow the
Astrobiology community to look for targets of interest such as hydrothermal
minerals, sulfate minerals and hydrous minerals and be able to map the extent
of these minerals using the most up-to-date and effective algorithms.
  The application is programmed in Java and will be made available for Windows,
Mac and Linux platforms. Users will be able to embed Groovy scripts into the
program in order to extend its functionality. The first collection of CRISM
data will occur in September of 2006 and this data will be made publicly
available six months later via the Planetary Datasystem (PDS). Potential users
in the community should therefore look forward to a release date mid-2007.
  Although exploration of the CRISM data set is the motivating force for
developing these software tools, the ease of writing additional Groovy scripts
to access other data sets makes the tools useful for mineral exploration, crop
management, and characterization of extreme environments here on Earth or other
terrestrial planets. The system can be easily implemented for use by high
school, college, and graduate level students.
","Adrian J. Brown, Michael Storrie-Lombardi",Michael Storrie-Lombardi,2014-01-28T05:47:28Z
Enhancing Pure-Pixel Identification Performance via Preconditioning,"  In this paper, we analyze different preconditionings designed to enhance
robustness of pure-pixel search algorithms, which are used for blind
hyperspectral unmixing and which are equivalent to near-separable nonnegative
matrix factorization algorithms. Our analysis focuses on the successive
projection algorithm (SPA), a simple, efficient and provably robust algorithm
in the pure-pixel algorithm class. Recently, a provably robust preconditioning
was proposed by Gillis and Vavasis (arXiv:1310.2273) which requires the
resolution of a semidefinite program (SDP) to find a data points-enclosing
minimum volume ellipsoid. Since solving the SDP in high precisions can be time
consuming, we generalize the robustness analysis to approximate solutions of
the SDP, that is, solutions whose objective function values are some
multiplicative factors away from the optimal value. It is shown that a high
accuracy solution is not crucial for robustness, which paves the way for faster
preconditionings (e.g., based on first-order optimization methods). This first
contribution also allows us to provide a robustness analysis for two other
preconditionings. The first one is pre-whitening, which can be interpreted as
an optimal solution of the same SDP with additional constraints. We analyze
robustness of pre-whitening which allows us to characterize situations in which
it performs competitively with the SDP-based preconditioning. The second one is
based on SPA itself and can be interpreted as an optimal solution of a
relaxation of the SDP. It is extremely fast while competing with the SDP-based
preconditioning on several synthetic data sets.
","Nicolas Gillis, Wing-Kin Ma",Wing-Kin Ma,2014-06-20T06:45:24Z
"Quantitative, Comparable Coherent Anti-Stokes Raman Scattering (CARS)
  Spectroscopy: Correcting Errors in Phase Retrieval","  Coherent anti-Stokes Raman scattering (CARS) microspectroscopy has
demonstrated significant potential for biological and materials imaging. To
date, however, the primary mechanism of disseminating CARS spectroscopic
information is through pseudocolor imagery, which explicitly neglects a vast
majority of the hyperspectral data. Furthermore, current paradigms in CARS
spectral processing do not lend themselves to quantitative sample-to-sample
comparability. The primary limitation stems from the need to accurately measure
the so-called nonresonant background (NRB) that is used to extract the
chemically-sensitive Raman information from the raw spectra. Measurement of the
NRB on a pixel-by-pixel basis is a nontrivial task; thus, reference NRB from
glass or water are typically utilized, resulting in error between the actual
and estimated amplitude and phase. In this manuscript, we present a new
methodology for extracting the Raman spectral features that significantly
suppresses these errors through phase detrending and scaling. Classic methods
of error-correction, such as baseline detrending, are demonstrated to be
inaccurate and to simply mask the underlying errors. The theoretical
justification is presented by re-developing the theory of phase retrieval via
the Kramers-Kronig relation, and we demonstrate that these results are also
applicable to maximum entropy method-based phase retrieval. This new
error-correction approach is experimentally applied to glycerol spectra and
tissue images, demonstrating marked consistency between spectra obtained using
different NRB estimates, and between spectra obtained on different instruments.
Additionally, in order to facilitate implementation of these approaches, we
have made many of the tools described herein available free for download.
","Charles H. Camp Jr., Young Jong Lee, Marcus T. Cicerone",Marcus T. Cicerone,2015-07-23T15:55:07Z
"A new hybrid spectral similarity measure for discrimination of Vigna
  species","  The reflectance spectrum of the species in a hyperspectral data can be
modelled as an n-dimensional vector. The spectral angle mapper computes the
angle between the vectors which is used to discriminate the species. The
spectral information divergence models the data as a probability distribution
so that the spectral variability between the bands can be extracted using the
stochastic measures. The hybrid approach of spectral angle mapper and spectral
information divergence is found to be better discriminator than spectral angle
mapper or spectral information divergence alone. The spectral correlation angle
is computed as a cosine of the angle of the Pearsonian correlation coefficient
between the vectors. The spectral correlation angle is a better measure than
the spectral angle mapper as it considers only standardized values of the
vectors rather than the absolute values of the vector. In the present paper a
new hybrid measure is proposed which is based on the spectral correlation angle
and the spectral information divergence. The proposed method has been compared
with the hybrid approach of spectral information divergence and spectral angle
mapper for discrimination of crops belonging to Vigna species using measures
like relative spectral discriminatory power, relative discriminatory
probability and relative discriminatory entropy in different spectral regions.
Experimental results using the laboratory spectra show that the proposed method
gives higher relative discriminatory power in 400nm-700nm spectral region.
","M. Naresh Kumar, M. V. R Seshasai, K. S Vara Prasad, V. Kamala, K. V Ramana, R. S. Dwivedi, P. S. Roy",P. S. Roy,2015-09-18T04:17:11Z
Low-rank Matrix Factorization under General Mixture Noise Distributions,"  Many computer vision problems can be posed as learning a low-dimensional
subspace from high dimensional data. The low rank matrix factorization (LRMF)
represents a commonly utilized subspace learning strategy. Most of the current
LRMF techniques are constructed on the optimization problems using L1-norm and
L2-norm losses, which mainly deal with Laplacian and Gaussian noises,
respectively. To make LRMF capable of adapting more complex noise, this paper
proposes a new LRMF model by assuming noise as Mixture of Exponential Power
(MoEP) distributions and proposes a penalized MoEP (PMoEP) model by combining
the penalized likelihood method with MoEP distributions. Such setting
facilitates the learned LRMF model capable of automatically fitting the real
noise through MoEP distributions. Each component in this mixture is adapted
from a series of preliminary super- or sub-Gaussian candidates. Moreover, by
facilitating the local continuity of noise components, we embed Markov random
field into the PMoEP model and further propose the advanced PMoEP-MRF model. An
Expectation Maximization (EM) algorithm and a variational EM (VEM) algorithm
are also designed to infer the parameters involved in the proposed PMoEP and
the PMoEP-MRF model, respectively. The superseniority of our methods is
demonstrated by extensive experiments on synthetic data, face modeling,
hyperspectral image restoration and background subtraction.
","Xiangyong Cao, Qian Zhao, Deyu Meng, Yang Chen, Zongben Xu",Zongben Xu,2016-01-06T02:52:30Z
"Radiatively limited dephasing and exciton dynamics in MoSe$_2$
  monolayers","  By implementing four-wave mixing (FWM) micro-spectroscopy we measure
coherence and population dynamics of the exciton transitions in monolayers of
MoSe$_2$. We reveal their dephasing times T$_2$ and radiative lifetime T$_1$ in
a sub-picosecond (ps) range, approaching T$_2$=2T$_1$, and thus indicating
radiatively limited dephasing at a temperature of 6$\,$K. We elucidate the
dephasing mechanisms by varying the temperature and by probing various
locations on the flake exhibiting a different local disorder. At a nanosecond
range, we observe the residual FWM produced by the incoherent excitons, which
initially disperse towards the dark states, but then relax back to the
optically active states within the light cone. By introducing
polarization-resolved excitation, we infer inter-valley exciton dynamics,
showing an initial polarization degree of around 30$\,\%$, constant during the
initial sub-picosecond decay, followed by the depolarization on a picosecond
timescale. The FWM hyperspectral imaging reveals the doped and undoped areas of
the sample, allowing to investigate the neutral exciton, the charged one or
both transitions at the same time. In the latter case, we observe the
exciton-trion beating in the coherence evolution indicating their coherent
coupling.
","Tomasz Jakubczyk, Valentin Delmonte, Maciej Koperski, Karol Nogajewski, Clément Faugeras, Wolfgang Langbein, Marek Potemski, Jacek Kasprzak",Jacek Kasprzak,2016-06-24T10:52:54Z
"On Clustering and Embedding Mixture Manifolds using a Low Rank
  Neighborhood Approach","  Samples from intimate (non-linear) mixtures are generally modeled as being
drawn from a smooth manifold. Scenarios where the data contains multiple
intimate mixtures with some constituent materials in common can be thought of
as manifolds which share a boundary. Two important steps in the processing of
such data are (i) to identify (cluster) the different mixture-manifolds present
in the data and (ii) to eliminate the non-linearities present the data by
mapping each mixture-manifold into some low-dimensional euclidean space
(embedding). Manifold clustering and embedding techniques appear to be an ideal
tool for this task, but the present state-of-the-art algorithms perform poorly
for hyperspectral data, particularly in the embedding task. We propose a novel
reconstruction-based algorithm for improved clustering and embedding of
mixture-manifolds. The algorithms attempts to reconstruct each target-point as
an affine combination of its nearest neighbors with an additional rank penalty
on the neighborhood to ensure that only neighbors on the same manifold as the
target-point are used in the reconstruction. The reconstruction matrix
generated by using this technique is block-diagonal and can be used for
clustering (using spectral clustering) and embedding. The improved performance
of the algorithms vis-a-vis its competitors is exhibited on a variety of
simulated and real mixture datasets.
","Arun M. Saranathan, Mario Parente",Mario Parente,2016-08-23T23:40:14Z
"Detecting Changes Between Optical Images of Different Spatial and
  Spectral Resolutions: a Fusion-Based Approach","  Change detection is one of the most challenging issues when analyzing
remotely sensed images. Comparing several multi-date images acquired through
the same kind of sensor is the most common scenario. Conversely, designing
robust, flexible and scalable algorithms for change detection becomes even more
challenging when the images have been acquired by two different kinds of
sensors. This situation arises in case of emergency under critical constraints.
This paper presents, to the best of authors' knowledge, the first strategy to
deal with optical images characterized by dissimilar spatial and spectral
resolutions. Typical considered scenarios include change detection between
panchromatic or multispectral and hyperspectral images. The proposed strategy
consists of a 3-step procedure: i) inferring a high spatial and spectral
resolution image by fusion of the two observed images characterized one by a
low spatial resolution and the other by a low spectral resolution, ii)
predicting two images with respectively the same spatial and spectral
resolutions as the observed images by degradation of the fused one and iii)
implementing a decision rule to each pair of observed and predicted images
characterized by the same spatial and spectral resolutions to identify changes.
The performance of the proposed framework is evaluated on real images with
simulated realistic changes.
","Vinicius Ferraris, Nicolas Dobigeon, Qi Wei, Marie Chabert",Marie Chabert,2016-09-20T09:58:35Z
"Robust Fusion of Multi-Band Images with Different Spatial and Spectral
  Resolutions for Change Detection","  Archetypal scenarios for change detection generally consider two images
acquired through sensors of the same modality. However, in some specific cases
such as emergency situations, the only images available may be those acquired
through different kinds of sensors. More precisely, this paper addresses the
problem of detecting changes between two multi-band optical images
characterized by different spatial and spectral resolutions. This sensor
dissimilarity introduces additional issues in the context of operational change
detection. To alleviate these issues, classical change detection methods are
applied after independent preprocessing steps (e.g., resampling) used to get
the same spatial and spectral resolutions for the pair of observed images.
Nevertheless, these preprocessing steps tend to throw away relevant
information. Conversely, in this paper, we propose a method that more
effectively uses the available information by modeling the two observed images
as spatial and spectral versions of two (unobserved) latent images
characterized by the same high spatial and high spectral resolutions. As they
cover the same scene, these latent images are expected to be globally similar
except for possible changes in sparse spatial locations. Thus, the change
detection task is envisioned through a robust multi-band image fusion method
which enforces the differences between the estimated latent images to be
spatially sparse. This robust fusion problem is formulated as an inverse
problem which is iteratively solved using an efficient block-coordinate descent
algorithm. The proposed method is applied to real panchormatic/multispectral
and hyperspectral images with simulated realistic changes. A comparison with
state-of-the-art change detection methods evidences the accuracy of the
proposed strategy.
","Vinicius Ferraris, Nicolas Dobigeon, Qi Wei, Marie Chabert",Marie Chabert,2016-09-20T10:04:04Z
Silicon-chip-based mid-infrared dual-comb spectroscopy,"  On-chip spectroscopy that could realize real-time fingerprinting with
label-free and high-throughput detection of trace molecules is one of the 'holy
grails"" of sensing. Such miniaturized spectrometers would greatly enable
applications in chemistry, bio-medicine, material science or space
instrumentation, such as hyperspectral microscopy of live cells or
pharmaceutical quality control. Dual-comb spectroscopy (DCS), a recent
technique of Fourier transform spectroscopy without moving parts, is
particularly promising since it measures high-precision spectra in the gas
phase using only a single detector. Here, we present a microresonator-based
platform designed for mid-infrared (mid-IR) DCS. A single continuous-wave (CW)
low-power pump source generates two mutually coherent mode-locked frequency
combs spanning from 2.6 $\mu$m to 4.1 $\mu$m in two silicon micro-resonators.
Thermal control and free-carrier injection control modelocking of each comb and
tune the dual-comb parameters. The large line spacing of the combs (127 GHz)
and its precise tuning over tens of MHz, unique features of chip-scale comb
generators, are exploited for a proof-of-principle experiment of vibrational
absorption DCS in the liquid phase, with spectra of acetone spanning from 2870
nm to 3170 nm at 127-GHz (4.2-cm$^{-1}$) resolution. We take a significant step
towards a broadband, mid-IR spectroscopy instrument on a chip. With further
system development, our concept holds promise for real-time and time-resolved
spectral acquisition on the nanosecond time scale.
","Mengjie Yu, Yoshitomo Okawachi, Austin G. Griffith, Nathalie Picqué, Michal Lipson, Alexander L. Gaeta",Alexander L. Gaeta,2016-10-04T18:41:21Z
"Exploring coherence of individual excitons in InAs quantum dots embedded
  in natural photonic defects: influence of the excitation intensity","  The exact optical response of quantum few-level systems depends crucially on
the exact choice of the incoming pulse areas. We use four-wave mixing (FWM)
spectroscopy to infer the coherent response and dynamics of single InAs quantum
dots (QDs) and study their pulse area dependence. By combining atomic force
microscopy with FWM hyperspectral imaging, we show that the retrieved FWM
signals originate from individual QDs enclosed in natural photonic defects. The
optimized light-matter coupling in these defects allows us to perform our
studies in a wide range of driving field amplitudes. When varying the pulse
areas of the exciting laser pulses the so-called Rabi rotations can be resolved
by the two-pulse FWM technique. We investigate these Rabi rotations within two-
and three-level systems, both theoretically and experimentally, and explain
their damping by the coupling to acoustic phonons. To highlight the importance
of the pulse area influence, we show that the phonon-induced dephasing of QD
excitons depends on the pulse intensity.
","Daniel Wigger, Valentin Delmonte, Quentin Mermillod, Tomasz Jakubczyk, François Fras, Simon Le-Denmat, Doris E. Reiter, Sven Höfling, Martin Kamp, Gilles Nogues, Christian Schneider, Tilmann Kuhn, Jacek Kasprzak",Jacek Kasprzak,2017-04-11T14:01:54Z
"JP3D compression of solar data-cubes: photospheric imaging and
  spectropolarimetry","  Hyperspectral imaging is an ubiquitous technique in solar physics
observations and the recent advances in solar instrumentation enabled us to
acquire and record data at an unprecedented rate. The huge amount of data which
will be archived in the upcoming solar observatories press us to compress the
data in order to reduce the storage space and transfer times. The correlation
present over all dimensions, spatial, temporal and spectral, of solar data-sets
suggests the use of a 3D base wavelet decomposition, to achieve higher
compression rates. In this work, we evaluate the performance of the recent
JPEG2000 Part 10 standard, known as JP3D, for the lossless compression of
several types of solar data-cubes. We explore the differences in: a) The
compressibility of broad-band or narrow-band time-sequence; I or V stokes
profiles in spectropolarimetric data-sets; b) Compressing data in
[x,y,$\lambda$] packages at different times or data in [x,y,t] packages of
different wavelength; c) Compressing a single large data-cube or several
smaller data-cubes; d) Compressing data which is under-sampled or super-sampled
with respect to the diffraction cut-off.
","Dario Del Moro, Luca Giovannelli, Ermanno Pietropaolo, Francesco Berrilli",Francesco Berrilli,2017-05-18T14:19:57Z
"Maximum Volume Inscribed Ellipsoid: A New Simplex-Structured Matrix
  Factorization Framework via Facet Enumeration and Convex Optimization","  Consider a structured matrix factorization model where one factor is
restricted to have its columns lying in the unit simplex. This
simplex-structured matrix factorization (SSMF) model and the associated
factorization techniques have spurred much interest in research topics over
different areas, such as hyperspectral unmixing in remote sensing, topic
discovery in machine learning, to name a few. In this paper we develop a new
theoretical SSMF framework whose idea is to study a maximum volume ellipsoid
inscribed in the convex hull of the data points. This maximum volume inscribed
ellipsoid (MVIE) idea has not been attempted in prior literature, and we show a
sufficient condition under which the MVIE framework guarantees exact recovery
of the factors. The sufficient recovery condition we show for MVIE is much more
relaxed than that of separable non-negative matrix factorization (or pure-pixel
search); coincidentally it is also identical to that of minimum volume
enclosing simplex, which is known to be a powerful SSMF framework for
non-separable problem instances. We also show that MVIE can be practically
implemented by performing facet enumeration and then by solving a convex
optimization problem. The potential of the MVIE framework is illustrated by
numerical results.
","Chia-Hsiang Lin, Ruiyuan Wu, Wing-Kin Ma, Chong-Yung Chi, Yue Wang",Yue Wang,2017-08-09T15:48:58Z
"Block-Simultaneous Direction Method of Multipliers: A proximal
  primal-dual splitting algorithm for nonconvex problems with multiple
  constraints","  We introduce a generalization of the linearized Alternating Direction Method
of Multipliers to optimize a real-valued function $f$ of multiple arguments
with potentially multiple constraints $g_\circ$ on each of them. The function
$f$ may be nonconvex as long as it is convex in every argument, while the
constraints $g_\circ$ need to be convex but not smooth. If $f$ is smooth, the
proposed Block-Simultaneous Direction Method of Multipliers (bSDMM) can be
interpreted as a proximal analog to inexact coordinate descent methods under
constraints. Unlike alternative approaches for joint solvers of
multiple-constraint problems, we do not require linear operators $L$ of a
constraint function $g(L\ \cdot)$ to be invertible or linked between each
other. bSDMM is well-suited for a range of optimization problems, in particular
for data analysis, where $f$ is the likelihood function of a model and $L$
could be a transformation matrix describing e.g. finite differences or basis
transforms. We apply bSDMM to the Non-negative Matrix Factorization task of a
hyperspectral unmixing problem and demonstrate convergence and effectiveness of
multiple constraints on both matrix factors. The algorithms are implemented in
python and released as an open-source package.
","Fred Moolekamp, Peter Melchior",Peter Melchior,2017-08-30T00:15:50Z
"Boosting with Lexicographic Programming: Addressing Class Imbalance
  without Cost Tuning","  A large amount of research effort has been dedicated to adapting boosting for
imbalanced classification. However, boosting methods are yet to be
satisfactorily immune to class imbalance, especially for multi-class problems.
This is because most of the existing solutions for handling class imbalance
rely on expensive cost set tuning for determining the proper level of
compensation. We show that the assignment of weights to the component
classifiers of a boosted ensemble can be thought of as a game of Tug of War
between the classes in the margin space. We then demonstrate how this insight
can be used to attain a good compromise between the rare and abundant classes
without having to resort to cost set tuning, which has long been the norm for
imbalanced classification. The solution is based on a lexicographic linear
programming framework which requires two stages. Initially, class-specific
component weight combinations are found so as to minimize a hinge loss
individually for each of the classes. Subsequently, the final component weights
are assigned so that the maximum deviation from the class-specific minimum loss
values (obtained in the previous stage) is minimized. Hence, the proposal is
not only restricted to two-class situations, but is also readily applicable to
multi-class problems. Additionally,we also derive the dual formulation
corresponding to the proposed framework. Experiments conducted on artificial
and real-world imbalanced datasets as well as on challenging applications such
as hyperspectral image classification and ImageNet classification establish the
efficacy of the proposal.
","Shounak Datta, Sayak Nag, Swagatam Das",Swagatam Das,2017-08-31T12:41:29Z
"Extension of PCA to Higher Order Data Structures: An Introduction to
  Tensors, Tensor Decompositions, and Tensor PCA","  The widespread use of multisensor technology and the emergence of big data
sets have brought the necessity to develop more versatile tools to represent
higher-order data with multiple aspects and high dimensionality. Data in the
form of multidimensional arrays, also referred to as tensors, arises in a
variety of applications including chemometrics, hyperspectral imaging, high
resolution videos, neuroimaging, biometrics, and social network analysis. Early
multiway data analysis approaches reformatted such tensor data as large vectors
or matrices and then resorted to dimensionality reduction methods developed for
classical two-way analysis such as PCA. However, one cannot discover hidden
components within multiway data using conventional PCA. To this end, tensor
decomposition methods which are flexible in the choice of the constraints and
that extract more general latent components have been proposed. In this paper,
we review the major tensor decomposition methods with a focus on problems
targeted by classical PCA. In particular, we present tensor methods that aim to
solve three important challenges typically addressed by PCA: dimensionality
reduction, i.e. low-rank tensor approximation, supervised learning, i.e.
learning linear subspaces for feature extraction, and robust low-rank tensor
recovery. We also provide experimental results to compare different tensor
models for both dimensionality reduction and supervised learning applications.
","Ali Zare, Alp Ozdemir, Mark A. Iwen, Selin Aviyente",Selin Aviyente,2018-03-02T03:48:07Z
"Nonnegative Matrix Factorization for Signal and Data Analytics:
  Identifiability, Algorithms, and Applications","  Nonnegative matrix factorization (NMF) has become a workhorse for signal and
data analytics, triggered by its model parsimony and interpretability. Perhaps
a bit surprisingly, the understanding to its model identifiability---the major
reason behind the interpretability in many applications such as topic mining
and hyperspectral imaging---had been rather limited until recent years.
Beginning from the 2010s, the identifiability research of NMF has progressed
considerably: Many interesting and important results have been discovered by
the signal processing (SP) and machine learning (ML) communities. NMF
identifiability has a great impact on many aspects in practice, such as
ill-posed formulation avoidance and performance-guaranteed algorithm design. On
the other hand, there is no tutorial paper that introduces NMF from an
identifiability viewpoint. In this paper, we aim at filling this gap by
offering a comprehensive and deep tutorial on model identifiability of NMF as
well as the connections to algorithms and applications. This tutorial will help
researchers and graduate students grasp the essence and insights of NMF,
thereby avoiding typical `pitfalls' that are often times due to unidentifiable
NMF formulations. This paper will also help practitioners pick/design suitable
factorization tools for their own problems.
","Xiao Fu, Kejun Huang, Nicholas D. Sidiropoulos, Wing-Kin Ma",Wing-Kin Ma,2018-03-03T22:48:14Z
"Tiling and Stitching Segmentation Output for Remote Sensing: Basic
  Challenges and Recommendations","  In this work we consider the application of convolutional neural networks
(CNNs) for pixel-wise labeling (a.k.a., semantic segmentation) of remote
sensing imagery (e.g., aerial color or hyperspectral imagery). Remote sensing
imagery is usually stored in the form of very large images, referred to as
""tiles"", which are too large to be segmented directly using most CNNs and their
associated hardware. As a result, during label inference, smaller sub-images,
called ""patches"", are processed individually and then ""stitched"" (concatenated)
back together to create a tile-sized label map. This approach suffers from
computational ineffiency and can result in discontinuities at output
boundaries. We propose a simple alternative approach in which the input size of
the CNN is dramatically increased only during label inference. This does not
avoid stitching altogether, but substantially mitigates its limitations. We
evaluate the performance of the proposed approach against a vonventional
stitching approach using two popular segmentation CNN models and two
large-scale remote sensing imagery datasets. The results suggest that the
proposed approach substantially reduces label inference time, while also
yielding modest overall label accuracy increases. This approach contributed to
our wining entry (overall performance) in the INRIA building labeling
competition.
","Bohao Huang, Daniel Reichman, Leslie M. Collins, Kyle Bradbury, Jordan M. Malof",Jordan M. Malof,2018-05-30T20:34:07Z
A Survey on Surrogate Approaches to Non-negative Matrix Factorization,"  Motivated by applications in hyperspectral imaging we investigate methods for
approximating a high-dimensional non-negative matrix $\mathbf{\mathit{Y}}$ by a
product of two lower-dimensional, non-negative matrices $\mathbf{\mathit{K}}$
and $\mathbf{\mathit{X}}.$ This so-called non-negative matrix factorization is
based on defining suitable Tikhonov functionals, which combine a discrepancy
measure for $\mathbf{\mathit{Y}}\approx\mathbf{\mathit{KX}}$ with penalty terms
for enforcing additional properties of $\mathbf{\mathit{K}}$ and
$\mathbf{\mathit{X}}$. The minimization is based on alternating minimization
with respect to $\mathbf{\mathit{K}}$ or $\mathbf{\mathit{X}}$, where in each
iteration step one replaces the original Tikhonov functional by a locally
defined surrogate functional. The choice of surrogate functionals is crucial:
It should allow a comparatively simple minimization and simultaneously its
first order optimality condition should lead to multiplicative update rules,
which automatically preserve non-negativity of the iterates. We review the most
standard construction principles for surrogate functionals for Frobenius-norm
and Kullback-Leibler discrepancy measures. We extend the known surrogate
constructions by a general framework, which allows to add a large variety of
penalty terms. The paper finishes by deriving the corresponding alternating
minimization schemes explicitely and by applying these methods to MALDI imaging
data.
","Pascal Fernsel, Peter Maass",Peter Maass,2018-08-06T16:12:04Z
"Multivariate Extension of Matrix-based Renyi's α-order Entropy
  Functional","  The matrix-based Renyi's \alpha-order entropy functional was recently
introduced using the normalized eigenspectrum of a Hermitian matrix of the
projected data in a reproducing kernel Hilbert space (RKHS). However, the
current theory in the matrix-based Renyi's \alpha-order entropy functional only
defines the entropy of a single variable or mutual information between two
random variables. In information theory and machine learning communities, one
is also frequently interested in multivariate information quantities, such as
the multivariate joint entropy and different interactive quantities among
multiple variables. In this paper, we first define the matrix-based Renyi's
\alpha-order joint entropy among multiple variables. We then show how this
definition can ease the estimation of various information quantities that
measure the interactions among multiple variables, such as interactive
information and total correlation. We finally present an application to feature
selection to show how our definition provides a simple yet powerful way to
estimate a widely-acknowledged intractable quantity from data. A real example
on hyperspectral image (HSI) band selection is also provided.
","Shujian Yu, Luis Gonzalo Sanchez Giraldo, Robert Jenssen, Jose C. Principe",Jose C. Principe,2018-08-23T19:19:16Z
"An Entropic Optimal Transport Loss for Learning Deep Neural Networks
  under Label Noise in Remote Sensing Images","  Deep neural networks have established as a powerful tool for large scale
supervised classification tasks. The state-of-the-art performances of deep
neural networks are conditioned to the availability of large number of
accurately labeled samples. In practice, collecting large scale accurately
labeled datasets is a challenging and tedious task in most scenarios of remote
sensing image analysis, thus cheap surrogate procedures are employed to label
the dataset. Training deep neural networks on such datasets with inaccurate
labels easily overfits to the noisy training labels and degrades the
performance of the classification tasks drastically. To mitigate this effect,
we propose an original solution with entropic optimal transportation. It allows
to learn in an end-to-end fashion deep neural networks that are, to some
extent, robust to inaccurately labeled samples. We empirically demonstrate on
several remote sensing datasets, where both scene and pixel-based hyperspectral
images are considered for classification. Our method proves to be highly
tolerant to significant amounts of label noise and achieves favorable results
against state-of-the-art methods.
","Bharath Bhushan Damodaran, Rémi Flamary, Viven Seguy, Nicolas Courty",Nicolas Courty,2018-10-02T10:31:37Z
"Design and Application of a Relativistic Kramers-Kronig Analysis
  Algorithm","  Low-loss electron energy loss spectroscopy (EELS) in the scanning
transmission electron microscope (STEM) probes the valence electron density and
relevant optoelectronic properties such as band gap energies and other band
structure transitions. The measured spectra can be formulated in a dielectric
theory framework, comparable to optical spectroscopies and ab-initio
simulations. Moreover, Kramers-Kronig analysis (KKA), an inverse algorithm
based on the homonym relations, can be employed for the retrieval of the
complex dielectric function (CDF). However, spurious contributions
traditionally not considered in this framework typically impact low-loss EELS
modifying the spectral shapes and precluding the correct measurement and
retrieval of the dielectric information. A relativistic KKA algorithm is able
to account for the bulk and surface radiative-loss contributions to low-loss
EELS, revealing the correct dielectric properties. Using a synthetic low-loss
EELS model, we propose some modifications on the naive implementation of this
algorithm that broadens its range of application. The robustness of the
algorithm is improved by regularization, appliying previous knowledge about the
shape and smoothness of the correction term. Additionally, our efficient
numerical integration methodology allows processing hyperspectral datasets in a
reasonable amount of time. Harnessing these abilities, we show how simultaneous
relativistic KKA processing of several spectra can share information to produce
an improved result.
","Alberto Eljarrat, Christoph T. Koch",Christoph T. Koch,2018-11-19T09:43:19Z
"Unsupervised Deep Slow Feature Analysis for Change Detection in
  Multi-Temporal Remote Sensing Images","  Change detection has been a hotspot in remote sensing technology for a long
time. With the increasing availability of multi-temporal remote sensing images,
numerous change detection algorithms have been proposed. Among these methods,
image transformation methods with feature extraction and mapping could
effectively highlight the changed information and thus has better change
detection performance. However, changes of multi-temporal images are usually
complex, existing methods are not effective enough. In recent years, deep
network has shown its brilliant performance in many fields including feature
extraction and projection. Therefore, in this paper, based on deep network and
slow feature analysis (SFA) theory, we proposed a new change detection
algorithm for multi-temporal remotes sensing images called Deep Slow Feature
Analysis (DSFA). In DSFA model, two symmetric deep networks are utilized for
projecting the input data of bi-temporal imagery. Then, the SFA module is
deployed to suppress the unchanged components and highlight the changed
components of the transformed features. The CVA pre-detection is employed to
find unchanged pixels with high confidence as training samples. Finally, the
change intensity is calculated with chi-square distance and the changes are
determined by threshold algorithms. The experiments are performed on two
real-world datasets and a public hyperspectral dataset. The visual comparison
and quantitative evaluation have both shown that DSFA could outperform the
other state-of-the-art algorithms, including other SFA-based and deep learning
methods.
","Bo Du, Lixiang Ru, Chen Wu, Liangpei Zhang",Liangpei Zhang,2018-12-03T10:22:59Z
Generating Hard Examples for Pixel-wise Classification,"  Pixel-wise classification in remote sensing identifies entities in
large-scale satellite-based images at the pixel level. Few fully annotated
large-scale datasets for pixel-wise classification exist due to the challenges
of annotating individual pixels. Training data scarcity inevitably ensues from
the annotation challenge, leading to overfitting classifiers and degraded
classification performance. The lack of annotated pixels also necessarily
results in few hard examples of various entities critical for generating a
robust classification hyperplane. To overcome the problem of the data scarcity
and lack of hard examples in training, we introduce a two-step hard example
generation (HEG) approach that first generates hard example candidates and then
mines actual hard examples. In the first step, a generator that creates hard
example candidates is learned via the adversarial learning framework by fooling
a discriminator and a pixel-wise classification model at the same time. In the
second step, mining is performed to build a fixed number of hard examples from
a large pool of real and artificially generated examples. To evaluate the
effectiveness of the proposed HEG approach, we design a 9-layer fully
convolutional network suitable for pixel-wise classification. Experiments show
that using generated hard examples from the proposed HEG approach improves the
pixel-wise classification model's accuracy on red tide detection and
hyperspectral image classification tasks.
","Hyungtae Lee, Heesung Kwon, Wonkook Kim",Wonkook Kim,2018-12-13T14:29:25Z
Stereoscopic Dark Flash for Low-light Photography,"  In this work, we present a camera configuration for acquiring ""stereoscopic
dark flash"" images: a simultaneous stereo pair in which one camera is a
conventional RGB sensor, but the other camera is sensitive to near-infrared and
near-ultraviolet instead of R and B. When paired with a ""dark"" flash (i.e., one
having near-infrared and near-ultraviolet light, but no visible light) this
camera allows us to capture the two images in a flash/no-flash image pair at
the same time, all while not disturbing any human subjects or onlookers with a
dazzling visible flash. We present a hardware prototype of this camera that
approximates an idealized camera, and we present an imaging procedure that let
us acquire dark flash stereo pairs that closely resemble those we would get
from that idealized camera. We then present a technique for fusing these stereo
pairs, first by performing registration and warping, and then by using recent
advances in hyperspectral image fusion and deep learning to produce a final
image. Because our camera configuration and our data acquisition process allow
us to capture true low-noise long exposure RGB images alongside our dark flash
stereo pairs, our learned model can be trained end-to-end to produce a fused
image that retains the color and tone of a real RGB image while having the
low-noise properties of a flash image.
","Jian Wang, Tianfan Xue, Jonathan T. Barron, Jiawen Chen",Jiawen Chen,2019-01-05T05:26:27Z
"Deep Generative Endmember Modeling: An Application to Unsupervised
  Spectral Unmixing","  Endmember (EM) spectral variability can greatly impact the performance of
standard hyperspectral image analysis algorithms. Extended parametric models
have been successfully applied to account for the EM spectral variability.
However, these models still lack the compromise between flexibility and
low-dimensional representation that is necessary to properly explore the fact
that spectral variability is often confined to a low-dimensional manifold in
real scenes. In this paper we propose to learn a spectral variability model
directly form the observed data, instead of imposing it \emph{a priori}. This
is achieved through a deep generative EM model, which is estimated using a
variational autoencoder (VAE). The encoder and decoder that compose the
generative model are trained using pure pixel information extracted directly
from the observed image, what allows for an unsupervised formulation. The
proposed EM model is applied to the solution of a spectral unmixing problem,
which we cast as an alternating nonlinear least-squares problem that is solved
iteratively with respect to the abundances and to the low-dimensional
representations of the EMs in the latent space of the deep generative model.
Simulations using both synthetic and real data indicate that the proposed
strategy can outperform the competing state-of-the-art algorithms.
","Ricardo Augusto Borsoi, Tales Imbiriba, José Carlos Moreira Bermudez",José Carlos Moreira Bermudez,2019-02-14T18:08:22Z
Pixel-aware Deep Function-mixture Network for Spectral Super-Resolution,"  Spectral super-resolution (SSR) aims at generating a hyperspectral image
(HSI) from a given RGB image. Recently, a promising direction for SSR is to
learn a complicated mapping function from the RGB image to the HSI counterpart
using a deep convolutional neural network. This essentially involves mapping
the RGB context within a size-specific receptive field centered at each pixel
to its spectrum in the HSI. The focus thereon is to appropriately determine the
receptive field size and establish the mapping function from RGB context to the
corresponding spectrum. Due to their differences in category or spatial
position, pixels in HSIs often require different-sized receptive fields and
distinct mapping functions. However, few efforts have been invested to
explicitly exploit this prior.
  To address this problem, we propose a pixel-aware deep function-mixture
network for SSR, which is composed of a new class of modules, termed
function-mixture (FM) blocks. Each FM block is equipped with some basis
functions, i.e., parallel subnets of different-sized receptive fields. Besides,
it incorporates an extra subnet as a mixing function to generate pixel-wise
weights, and then linearly mixes the outputs of all basis functions with those
generated weights. This enables us to pixel-wisely determine the receptive
field size and the mapping function. Moreover, we stack several such FM blocks
to further increase the flexibility of the network in learning the pixel-wise
mapping. To encourage feature reuse, intermediate features generated by the FM
blocks are fused in late stage, which proves to be effective for boosting the
SSR performance. Experimental results on three benchmark HSI datasets
demonstrate the superiority of the proposed method.
","Lei Zhang, Zhiqiang Lang, Peng Wang, Wei Wei, Shengcai Liao, Ling Shao, Yanning Zhang",Yanning Zhang,2019-03-24T13:42:05Z
"Total variation vs L1 regularization: a comparison of compressive
  sensing optimization methods for chemical detection","  One of the fundamental assumptions of compressive sensing (CS) is that a
signal can be reconstructed from a small number of samples by solving an
optimization problem with the appropriate regularization term. Two standard
regularization terms are the L1 norm and the total variation (TV) norm. We
present a comparison of CS reconstruction results based on these two approaches
in the context of chemical detection, and we demonstrate that optimization
based on the L1 norm outperforms optimization based on the TV norm. Our
comparison is driven by CS sampling, reconstruction, and chemical detection in
two real-world datasets: the Physical Sciences Inc. Fabry-P\'{e}rot
interferometer sensor multispectral dataset and the Johns Hopkins Applied
Physics Lab FTIR-based longwave infrared sensor hyperspectral dataset. Both
datasets contain the release of a chemical simulant such as glacial acetic
acid, triethyl phosphate, and sulfur hexafluoride. For chemical detection we
use the adaptive coherence estimator (ACE) and bulk coherence, and we propose
algorithmic ACE thresholds to define the presence or absence of a chemical of
interest in both un-compressed data cubes and reconstructed data cubes. The
un-compressed data cubes provide an approximate ground truth. We demonstrate
that optimization based on either the L1 norm or TV norm results in successful
chemical detection at a compression rate of 90%, but we show that L1
optimization is preferable. We present quantitative comparisons of chemical
detection on reconstructions from the two methods, with an emphasis on the
number of pixels with an ACE value above the threshold.
","Elin Farnell, Henry Kvinge, Julia R. Dupuis, Michael Kirby, Chris Peterson, Elizabeth C. Schundler",Elizabeth C. Schundler,2019-06-25T15:24:20Z
Needles in Haystacks: On Classifying Tiny Objects in Large Images,"  In some important computer vision domains, such as medical or hyperspectral
imaging, we care about the classification of tiny objects in large images.
However, most Convolutional Neural Networks (CNNs) for image classification
were developed using biased datasets that contain large objects, in mostly
central image positions. To assess whether classical CNN architectures work
well for tiny object classification we build a comprehensive testbed containing
two datasets: one derived from MNIST digits and one from histopathology images.
This testbed allows controlled experiments to stress-test CNN architectures
with a broad spectrum of signal-to-noise ratios. Our observations indicate
that: (1) There exists a limit to signal-to-noise below which CNNs fail to
generalize and that this limit is affected by dataset size - more data leading
to better performances; however, the amount of training data required for the
model to generalize scales rapidly with the inverse of the object-to-image
ratio (2) in general, higher capacity models exhibit better generalization; (3)
when knowing the approximate object sizes, adapting receptive field is
beneficial; and (4) for very small signal-to-noise ratio the choice of global
pooling operation affects optimization, whereas for relatively large
signal-to-noise values, all tested global pooling operations exhibit similar
performance.
","Nick Pawlowski, Suvrat Bhooshan, Nicolas Ballas, Francesco Ciompi, Ben Glocker, Michal Drozdzal",Michal Drozdzal,2019-08-16T15:42:55Z
"A Blind Multiscale Spatial Regularization Framework for Kernel-based
  Spectral Unmixing","  Introducing spatial prior information in hyperspectral imaging (HSI) analysis
has led to an overall improvement of the performance of many HSI methods
applied for denoising, classification, and unmixing. Extending such
methodologies to nonlinear settings is not always straightforward, specially
for unmixing problems where the consideration of spatial relationships between
neighboring pixels might comprise intricate interactions between their
fractional abundances and nonlinear contributions. In this paper, we consider a
multiscale regularization strategy for nonlinear spectral unmixing with
kernels. The proposed methodology splits the unmixing problem into two
sub-problems at two different spatial scales: a coarse scale containing
low-dimensional structures, and the original fine scale. The coarse spatial
domain is defined using superpixels that result from a multiscale
transformation. Spectral unmixing is then formulated as the solution of
quadratically constrained optimization problems, which are solved efficiently
by exploring their strong duality and a reformulation of their dual cost
functions in the form of root-finding problems. Furthermore, we employ a
theory-based statistical framework to devise a consistent strategy to estimate
all required parameters, including both the regularization parameters of the
algorithm and the number of superpixels of the transformation, resulting in a
truly blind (from the parameters setting perspective) unmixing method.
Experimental results attest the superior performance of the proposed method
when comparing with other, state-of-the-art, related strategies.
","Ricardo Augusto Borsoi, Tales Imbiriba, José Carlos Moreira Bermudez, Cédric Richard",Cédric Richard,2019-08-19T16:52:14Z
"Online Sensor Hallucination via Knowledge Distillation for Multimodal
  Image Classification","  We deal with the problem of information fusion driven satellite image/scene
classification and propose a generic hallucination architecture considering
that all the available sensor information are present during training while
some of the image modalities may be absent while testing. It is well-known that
different sensors are capable of capturing complementary information for a
given geographical area and a classification module incorporating information
from all the sources are expected to produce an improved performance as
compared to considering only a subset of the modalities. However, the classical
classifier systems inherently require all the features used to train the module
to be present for the test instances as well, which may not always be possible
for typical remote sensing applications (say, disaster management). As a
remedy, we provide a robust solution in terms of a hallucination module that
can approximate the missing modalities from the available ones during the
decision-making stage. In order to ensure better knowledge transfer during
modality hallucination, we explicitly incorporate concepts of knowledge
distillation for the purpose of exploring the privileged (side) information in
our framework and subsequently introduce an intuitive modular training
approach. The proposed network is evaluated extensively on a large-scale corpus
of PAN-MS image pairs (scene recognition) as well as on a benchmark
hyperspectral image dataset (image classification) where we follow different
experimental scenarios and find that the proposed hallucination based module
indeed is capable of capturing the multi-source information, albeit the
explicit absence of some of the sensor information, and aid in improved scene
characterization.
","Saurabh Kumar, Biplab Banerjee, Subhasis Chaudhuri",Subhasis Chaudhuri,2019-08-28T05:55:09Z
"The Urban Observatory: a Multi-Modal Imaging Platform for the Study of
  Dynamics in Complex Urban Systems","  We describe an ""Urban Observatory"" facility designed for the study of complex
urban systems via persistent, synoptic, and granular imaging of dynamical
processes in cities. An initial deployment of the facility has been
demonstrated in New York City and consists of a suite of imaging systems - both
broadband and hyperspectral - sensitive to wavelengths from the visible (~400
nm) to the infrared (~13 micron) operating at cadences of ~0.01 - 30 Hz
(characteristically ~0.1 Hz). Much like an astronomical survey, the facility
generates a large imaging catalog from which we have extracted observables
(e.g., time-dependent brightnesses, spectra, temperatures, chemical species,
etc.), collecting them in a parallel source catalog. We have demonstrated that,
in addition to the urban science of cities as systems, these data are
applicable to a myriad of domain-specific scientific inquiries related to urban
functioning including energy consumption and end use, environmental impacts of
cities, and patterns of life and public health. We show that an Urban
Observatory facility of this type has the potential to improve both a city's
operations and the quality of life of its inhabitants.
","Gregory Dobler, Federica B. Bianco, Mohit S. Sharma, Andreas Karpf, Julien Baur, Masoud Ghandehari, Jonathan S. Wurtele, Steven E. Koonin",Steven E. Koonin,2019-09-12T20:38:34Z
"Multidimensional Analysis of Excitonic Spectra of Monolayers of Tungsten
  Disulphide: Towards Computer Aided Identification of Structural and
  Environmental Perturbations of 2D Materials","  Despite 2D materials holding great promise for a broad range of applications,
the proliferation of devices and their fulfillment of real-life demands are
still far from being realized. Experimentally obtainable samples commonly
experience a wide range of perturbations (ripples and wrinkles, point and line
defects, grain boundaries, strain field, doping, water intercalation,
oxidation, edge reconstructions) significantly deviating the properties from
idealistic models. These perturbations, in general, can be entangled or occur
in groups with each group forming a complex perturbation making the
interpretations of observable physical properties and the disentanglement of
simultaneously acting effects a highly non-trivial task even for an experienced
researcher. Here we generalise statistical correlation analysis of excitonic
spectra of monolayer WS2, acquired by hyperspectral absorption and
photoluminescence imaging, to a multidimensional case, and examine
multidimensional correlations via unsupervised machine learning algorithms.
Using principle component analysis we are able to identify 4 dominant
components that are correlated with tensile strain, disorder induced by
adsorption or intercalation of environmental molecules, multi-layer regions and
charge doping, respectively. This approach has the potential to determine the
local environment of WS2 monolayers or other 2D materials from simple optical
measurements, and paves the way towards advanced, machine-aided,
characterisation of monolayer matter.
","Pavel V. Kolesnichenko, Qianhui Zhang, Changxi Zheng, Michael S. Fuhrer, Jeffrey A. Davis",Jeffrey A. Davis,2020-03-04T05:47:11Z
Learning to Exploit Multiple Vision Modalities by Using Grafted Networks,"  Novel vision sensors such as thermal, hyperspectral, polarization, and event
cameras provide information that is not available from conventional intensity
cameras. An obstacle to using these sensors with current powerful deep neural
networks is the lack of large labeled training datasets. This paper proposes a
Network Grafting Algorithm (NGA), where a new front end network driven by
unconventional visual inputs replaces the front end network of a pretrained
deep network that processes intensity frames. The self-supervised training uses
only synchronously-recorded intensity frames and novel sensor data to maximize
feature similarity between the pretrained network and the grafted network. We
show that the enhanced grafted network reaches competitive average precision
(AP50) scores to the pretrained network on an object detection task using
thermal and event camera datasets, with no increase in inference costs.
Particularly, the grafted network driven by thermal frames showed a relative
improvement of 49.11% over the use of intensity frames. The grafted front end
has only 5--8% of the total parameters and can be trained in a few hours on a
single GPU equivalent to 5% of the time that would be needed to train the
entire object detector from labeled data. NGA allows new vision sensors to
capitalize on previously pretrained powerful deep models, saving on training
cost and widening a range of applications for novel sensors.
","Yuhuang Hu, Tobi Delbruck, Shih-Chii Liu",Shih-Chii Liu,2020-03-24T16:37:52Z
"Dictionary Learning with Low-rank Coding Coefficients for Tensor
  Completion","  In this paper, we propose a novel tensor learning and coding model for
third-order data completion. Our model is to learn a data-adaptive dictionary
from the given observations, and determine the coding coefficients of
third-order tensor tubes. In the completion process, we minimize the
low-rankness of each tensor slice containing the coding coefficients. By
comparison with the traditional pre-defined transform basis, the advantages of
the proposed model are that (i) the dictionary can be learned based on the
given data observations so that the basis can be more adaptively and accurately
constructed, and (ii) the low-rankness of the coding coefficients can allow the
linear combination of dictionary features more effectively. Also we develop a
multi-block proximal alternating minimization algorithm for solving such tensor
learning and coding model, and show that the sequence generated by the
algorithm can globally converge to a critical point. Extensive experimental
results for real data sets such as videos, hyperspectral images, and traffic
data are reported to demonstrate these advantages and show the performance of
the proposed tensor learning and coding method is significantly better than the
other tensor completion methods in terms of several evaluation metrics.
","Tai-Xiang Jiang, Xi-Le Zhao, Hao Zhang, Michael K. Ng",Michael K. Ng,2020-09-26T02:43:43Z
Infrared detection of aliphatic organics on a cometary nucleus,"  The ESA Rosetta mission has acquired unprecedented measurements of comet
67/P-Churyumov-Gerasimenko (hereafter 67P) nucleus surface, whose composition,
as determined by in situ and remote sensing instruments including VIRTIS
(Visible, InfraRed and Thermal Imaging Spectrometer) appears to be made by an
assemblage of ices, minerals, and organic material. We performed a refined
analysis of infrared observations of the nucleus of comet 67P carried out by
the VIRTIS-M hyperspectral imager. We found that the overall shape of the 67P
infrared spectrum is similar to that of other carbon-rich outer solar system
objects suggesting a possible genetic link with them. More importantly, we are
also able to confirm the complex spectral structure of the wide 2.8-3.6 micron
absorption feature populated by fainter bands. Among these, we unambiguously
identified the presence of aliphatic organics by their ubiquitous 3.38, 3.42
and 3.47 micron bands. This novel infrared detection of aliphatic species on a
cometary surface has strong implications for the evolutionary history of the
primordial solar system and give evidence that comets provide an evolutionary
link between interstellar material and solar system bodies.
","A. Raponi, M. Ciarniello, F. Capaccioni, V. Mennella, G. Filacchione, V. Vinogradoff, O. Poch, P. Beck, E. Quirico, M. C. De Sanctis, L. Moroz, D. Kappel, S. Erard, D. Bockelée-Morvan, A. Longobardo, F. Tosi, E. Palomba, J. -P. Combe, B. Rousseau, G. Arnold, R. W. Carlson, A. Pommerol, C. Pilorget, S. Fornasier, G. Bellucci, A. Barucci, F. Mancarella, M. Formisan, G. Rinaldi, I. Istiqomah, C. Leyrat",C. Leyrat,2020-09-30T07:23:50Z
"Remote Sensing Image Scene Classification with Self-Supervised Paradigm
  under Limited Labeled Samples","  With the development of deep learning, supervised learning methods perform
well in remote sensing images (RSIs) scene classification. However, supervised
learning requires a huge number of annotated data for training. When labeled
samples are not sufficient, the most common solution is to fine-tune the
pre-training models using a large natural image dataset (e.g. ImageNet).
However, this learning paradigm is not a panacea, especially when the target
remote sensing images (e.g. multispectral and hyperspectral data) have
different imaging mechanisms from RGB natural images. To solve this problem, we
introduce new self-supervised learning (SSL) mechanism to obtain the
high-performance pre-training model for RSIs scene classification from large
unlabeled data. Experiments on three commonly used RSIs scene classification
datasets demonstrated that this new learning paradigm outperforms the
traditional dominant ImageNet pre-trained model. Moreover, we analyze the
impacts of several factors in SSL on RSIs scene classification tasks, including
the choice of self-supervised signals, the domain difference between the source
and target dataset, and the amount of pre-training data. The insights distilled
from our studies can help to foster the development of SSL in the remote
sensing community. Since SSL could learn from unlabeled massive RSIs which are
extremely easy to obtain, it will be a potentially promising way to alleviate
dependence on labeled samples and thus efficiently solve many problems, such as
global mapping.
","Chao Tao, Ji Qi, Weipeng Lu, Hao Wang, Haifeng Li",Haifeng Li,2020-10-02T09:27:19Z
"Gaussianizing the Earth: Multidimensional Information Measures for Earth
  Data Analysis","  Information theory is an excellent framework for analyzing Earth system data
because it allows us to characterize uncertainty and redundancy, and is
universally interpretable. However, accurately estimating information content
is challenging because spatio-temporal data is high-dimensional, heterogeneous
and has non-linear characteristics. In this paper, we apply multivariate
Gaussianization for probability density estimation which is robust to
dimensionality, comes with statistical guarantees, and is easy to apply. In
addition, this methodology allows us to estimate information-theoretic measures
to characterize multivariate densities: information, entropy, total
correlation, and mutual information. We demonstrate how information theory
measures can be applied in various Earth system data analysis problems. First
we show how the method can be used to jointly Gaussianize radar backscattering
intensities, synthesize hyperspectral data, and quantify of information content
in aerial optical images. We also quantify the information content of several
variables describing the soil-vegetation status in agro-ecosystems, and
investigate the temporal scales that maximize their shared information under
extreme events such as droughts. Finally, we measure the relative information
content of space and time dimensions in remote sensing products and model
simulations involving long records of key variables such as precipitation,
sensible heat and evaporation. Results confirm the validity of the method, for
which we anticipate a wide use and adoption. Code and demos of the implemented
algorithms and information-theory measures are provided.
","J. Emmanuel Johnson, Valero Laparra, Maria Piles, Gustau Camps-Valls",Gustau Camps-Valls,2020-10-13T15:30:34Z
"Low-rank on Graphs plus Temporally Smooth Sparse Decomposition for
  Anomaly Detection in Spatiotemporal Data","  Anomaly detection in spatiotemporal data is a challenging problem encountered
in a variety of applications including hyperspectral imaging, video
surveillance, and urban traffic monitoring. Existing anomaly detection methods
are most suited for point anomalies in sequence data and cannot deal with
temporal and spatial dependencies that arise in spatiotemporal data. In recent
years, tensor-based methods have been proposed for anomaly detection to address
this problem. These methods rely on conventional tensor decomposition models,
not taking the structure of the anomalies into account, and are supervised or
semi-supervised. We introduce an unsupervised tensor-based anomaly detection
method that takes the sparse and temporally continuous nature of anomalies into
account. In particular, the anomaly detection problem is formulated as a robust
lowrank + sparse tensor decomposition with a regularization term that minimizes
the temporal variation of the sparse part, so that the extracted anomalies are
temporally persistent. We also approximate rank minimization with graph total
variation minimization to reduce the complexity of the optimization algorithm.
The resulting optimization problem is convex, scalable, and is shown to be
robust against missing data and noise. The proposed framework is evaluated on
both synthetic and real spatiotemporal urban traffic data and compared with
baseline methods.
","Seyyid Emre Sofuoglu, Selin Aviyente",Selin Aviyente,2020-10-23T19:34:40Z
"Tip-induced strain, bandgap, and radiative decay engineering of a single
  metal halide perovskite quantum dot","  Strain engineering of perovskite quantum dots (pQDs) enables widely-tunable
photonic device applications. However, manipulation at the single-emitter level
has never been attempted. Here, we present a tip-induced control approach
combined with tip-enhanced photoluminescence (TEPL) spectroscopy to engineer
strain, bandgap, and emission quantum yield of a single pQD. Single
CsPbBr$_{x}$I$_{3-x}$ pQDs are clearly resolved through hyperspectral TEPL
imaging with $\sim$10 nm spatial resolution. The plasmonic tip then directly
applies pressure to a single pQD to facilitate a bandgap shift up to $\sim$62
meV with Purcell-enhanced PL quantum yield as high as $\sim$10$^5$ for the
strain-induced pQD. Furthermore, by systematically modulating the tip-induced
compressive strain of a single pQD, we achieve dynamical bandgap engineering in
a reversible manner. In addition, we facilitate the quantum dot coupling for a
pQD ensemble with $\sim$0.8 GPa tip pressure at the nanoscale. Our approach
presents a new strategy to tune the nano-opto-electro-mechanical properties of
pQDs at the single-crystal level.
","Hyeongwoo Lee, Ju Young Woo, Dae Young Park, Inho Jo, Jusun Park, Yeunhee Lee, Yeonjeong Koo, Jinseong Choi, Hyojung Kim, Yong-Hyun Kim, Mun Seok Jeong, Sohee Jeong, Kyoung-Duck Park",Kyoung-Duck Park,2021-02-04T04:11:23Z
"Conformational heterogeneity of molecules physisorbed on a gold surface
  at room temperature","  A quantitative single-molecule tip-enhanced Raman spectroscopy (TERS) study
at room temperature remained a challenge due to the rapid structural dynamics
of molecules exposed to air. Here, we demonstrate the hyperspectral TERS
imaging of single or a few brilliant cresyl blue (BCB) molecules at room
temperature, along with quantitative spectral analyses. Robust chemical imaging
is enabled by the freeze-frame approach using a thin Al$_{2}$O$_{3}$ capping
layer, which suppresses spectral diffusions and inhibits chemical reactions and
contaminations in air. For the molecules resolved spatially in the TERS image,
a clear Raman peak variation up to 7.5 cm$^{-1}$ is observed, which cannot be
found in molecular ensembles. From density functional theory-based quantitative
analyses of the varied TERS peaks, we reveal the conformational heterogeneity
at the single-molecule level. This work provides a facile way to investigate
the single-molecule properties in interacting media, expanding the scope of
single-molecule vibrational spectroscopy studies.
","Mingu Kang, Hyunwoo Kim, Elham Oleiki, Yeonjeong Koo, Hyeongwoo Lee, Huitae Joo, Jinseong Choi, Taeyong Eom, Geunsik Lee, Yung Doug Suh, Kyoung-Duck Park",Kyoung-Duck Park,2021-02-04T04:33:46Z
"Towards advancing the earthquake forecasting by machine learning of
  satellite data","  Amongst the available technologies for earthquake research, remote sensing
has been commonly used due to its unique features such as fast imaging and wide
image-acquisition range. Nevertheless, early studies on pre-earthquake and
remote-sensing anomalies are mostly oriented towards anomaly identification and
analysis of a single physical parameter. Many analyses are based on singular
events, which provide a lack of understanding of this complex natural
phenomenon because usually, the earthquake signals are hidden in the
environmental noise. The universality of such analysis still is not being
demonstrated on a worldwide scale. In this paper, we investigate physical and
dynamic changes of seismic data and thereby develop a novel machine learning
method, namely Inverse Boosting Pruning Trees (IBPT), to issue short-term
forecast based on the satellite data of 1,371 earthquakes of magnitude six or
above due to their impact on the environment. We have analyzed and compared our
proposed framework against several states of the art machine learning methods
using ten different infrared and hyperspectral measurements collected between
2006 and 2013. Our proposed method outperforms all the six selected baselines
and shows a strong capability in improving the likelihood of earthquake
forecasting across different earthquake databases.
","Pan Xiong, Lei Tong, Kun Zhang, Xuhui Shen, Roberto Battiston, Dimitar Ouzounov, Roberto Iuppa, Danny Crookes, Cheng Long, Huiyu Zhou",Huiyu Zhou,2021-01-31T02:29:48Z
Expanding boundaries of Gap Safe screening,"  Sparse optimization problems are ubiquitous in many fields such as
statistics, signal/image processing and machine learning. This has led to the
birth of many iterative algorithms to solve them. A powerful strategy to boost
the performance of these algorithms is known as safe screening: it allows the
early identification of zero coordinates in the solution, which can then be
eliminated to reduce the problem's size and accelerate convergence. In this
work, we extend the existing Gap Safe screening framework by relaxing the
global strong-concavity assumption on the dual cost function. Instead, we
exploit local regularity properties, that is, strong concavity on well-chosen
subsets of the domain. The non-negativity constraint is also integrated to the
existing framework. Besides making safe screening possible to a broader class
of functions that includes beta-divergences (e.g., the Kullback-Leibler
divergence), the proposed approach also improves upon the existing Gap Safe
screening rules on previously applicable cases (e.g., logistic regression). The
proposed general framework is exemplified by some notable particular cases:
logistic function, beta = 1.5 and Kullback-Leibler divergences. Finally, we
showcase the effectiveness of the proposed screening rules with different
solvers (coordinate descent, multiplicative-update and proximal gradient
algorithms) and different data sets (binary classification, hyperspectral and
count data).
","Cassio F. Dantas, Emmanuel Soubies, Cédric Févotte",Cédric Févotte,2021-02-22T09:23:31Z
Imaging Seebeck drift of excitons and trions in MoSe2 monolayers,"  Hyperspectral imaging at cryogenic temperatures is used to investigate
exciton and trion propagation in MoSe$_2$ monolayers encapsulated with
hexagonal boron nitride (hBN). Under a tightly focused, continuous-wave laser
excitation, the spatial distribution of neutral excitons and charged trions
strongly differ at high excitation densities. Remarkably, in this regime the
trion distribution develops a halo shape, similar to that previously observed
in WS2 monolayers at room temperature and under pulsed excitation. In contrast,
the exciton distribution only presents a moderate broadening without the
appereance of a halo. Spatially and spectrally resolved luminescence spectra
reveal the buildup of a significant temperature gradient at high excitation
power, that is attributed to the energy relaxation of photoinduced hot
carriers. We show, via a numerical resolution of the transport equations for
excitons and trions, that the halo can be interpreted as thermal drift of
trions due to a Seebeck term in the particle current. The model shows that the
difference between trion and exciton profiles is simply understood in terms of
the very different lifetimes of these two quasiparticles.
","Sangjun Park, Bo Han, Caroline Boule, Daniel Paget, Alistair Rowe, Fausto Sirotti, Takashi Taniguchi, Kenji Watanabe, Cedric Robert, Laurent Lombez, Bernhard Urbaszek, Xavier Marie, Fabian Cadiz",Fabian Cadiz,2021-05-20T09:20:16Z
"Identifiability-Guaranteed Simplex-Structured Post-Nonlinear Mixture
  Learning via Autoencoder","  This work focuses on the problem of unraveling nonlinearly mixed latent
components in an unsupervised manner. The latent components are assumed to
reside in the probability simplex, and are transformed by an unknown
post-nonlinear mixing system. This problem finds various applications in signal
and data analytics, e.g., nonlinear hyperspectral unmixing, image embedding,
and nonlinear clustering. Linear mixture learning problems are already
ill-posed, as identifiability of the target latent components is hard to
establish in general. With unknown nonlinearity involved, the problem is even
more challenging. Prior work offered a function equation-based formulation for
provable latent component identification. However, the identifiability
conditions are somewhat stringent and unrealistic. In addition, the
identifiability analysis is based on the infinite sample (i.e., population)
case, while the understanding for practical finite sample cases has been
elusive. Moreover, the algorithm in the prior work trades model expressiveness
with computational convenience, which often hinders the learning performance.
Our contribution is threefold. First, new identifiability conditions are
derived under largely relaxed assumptions. Second, comprehensive sample
complexity results are presented -- which are the first of the kind. Third, a
constrained autoencoder-based algorithmic framework is proposed for
implementation, which effectively circumvents the challenges in the existing
algorithm. Synthetic and real experiments corroborate our theoretical analyses.
","Qi Lyu, Xiao Fu",Xiao Fu,2021-06-16T18:20:58Z
"Joint Majorization-Minimization for Nonnegative Matrix Factorization
  with the $β$-divergence","  This article proposes new multiplicative updates for nonnegative matrix
factorization (NMF) with the $\beta$-divergence objective function. Our new
updates are derived from a joint majorization-minimization (MM) scheme, in
which an auxiliary function (a tight upper bound of the objective function) is
built for the two factors jointly and minimized at each iteration. This is in
contrast with the classic approach in which a majorizer is derived for each
factor separately. Like that classic approach, our joint MM algorithm also
results in multiplicative updates that are simple to implement. They however
yield a significant drop of computation time (for equally good solutions), in
particular for some $\beta$-divergences of important applicative interest, such
as the squared Euclidean distance and the Kullback-Leibler or Itakura-Saito
divergences. We report experimental results using diverse datasets: face
images, an audio spectrogram, hyperspectral data and song play counts.
Depending on the value of $\beta$ and on the dataset, our joint MM approach can
yield CPU time reductions from about $13\%$ to $78\%$ in comparison to the
classic alternating scheme.
","Arthur Marmin, José Henrique de Morais Goulart, Cédric Févotte",Cédric Févotte,2021-06-29T09:58:21Z
"HYPER-SNN: Towards Energy-efficient Quantized Deep Spiking Neural
  Networks for Hyperspectral Image Classification","  Hyper spectral images (HSI) provide rich spectral and spatial information
across a series of contiguous spectral bands. However, the accurate processing
of the spectral and spatial correlation between the bands requires the use of
energy-expensive 3-D Convolutional Neural Networks (CNNs). To address this
challenge, we propose the use of Spiking Neural Networks (SNNs) that are
generated from iso-architecture CNNs and trained with quantization-aware
gradient descent to optimize their weights, membrane leak, and firing
thresholds. During both training and inference, the analog pixel values of a
HSI are directly applied to the input layer of the SNN without the need to
convert to a spike-train. The reduced latency of our training technique
combined with high activation sparsity yields significant improvements in
computational efficiency. We evaluate our proposal using three HSI datasets on
a 3-D and a 3-D/2-D hybrid convolutional architecture. We achieve overall
accuracy, average accuracy, and kappa coefficient of 98.68%, 98.34%, and 98.20%
respectively with 5 time steps (inference latency) and 6-bit weight
quantization on the Indian Pines dataset. In particular, our models achieved
accuracies similar to state-of-the-art (SOTA) with 560.6 and 44.8 times less
compute energy on average over three HSI datasets than an iso-architecture
full-precision and 6-bit quantized CNN, respectively.
","Gourav Datta, Souvik Kundu, Akhilesh R. Jaiswal, Peter A. Beerel",Peter A. Beerel,2021-07-26T06:17:10Z
Spectral mixture analysis of EELS spectrum-images,"  Recent advances in detectors and computer science have enabled the
acquisition and the processing of multidimensional datasets, in particular in
the field of spectral imaging. Benefiting from these new developments, earth
scientists try to recover the reflectance spectra of macroscopic materials
(e.g., water, grass, mineral types...) present in an observed scene and to
estimate their respective proportions in each mixed pixel of the acquired
image. This task is usually referred to as spectral mixture analysis or
spectral unmixing (SU). SU aims at decomposing the measured pixel spectrum into
a collection of constituent spectra, called endmembers, and a set of
corresponding fractions (abundances) that indicate the proportion of each
endmember present in the pixel. Similarly, when processing spectrum-images,
microscopists usually try to map elemental, physical and chemical state
information of a given material. This paper reports how a SU algorithm
dedicated to remote sensing hyperspectral images can be successfully applied to
analyze spectrum-image resulting from electron energy-loss spectroscopy (EELS).
SU generally overcomes standard limitations inherent to other multivariate
statistical analysis methods, such as principal component analysis (PCA) or
independent component analysis (ICA), that have been previously used to analyze
EELS maps. Indeed, ICA and PCA may perform poorly for linear spectral mixture
analysis due to the strong dependence between the abundances of the different
materials. One example is presented here to demonstrate the potential of this
technique for EELS analysis.
","Nicolas Dobigeon, Nathalie Brun",Nathalie Brun,2012-05-23T11:56:33Z
Perfect Recovery Conditions For Non-Negative Sparse Modeling,"  Sparse modeling has been widely and successfully used in many applications
such as computer vision, machine learning, and pattern recognition. Accompanied
with those applications, significant research has studied the theoretical
limits and algorithm design for convex relaxations in sparse modeling. However,
theoretical analyses on non-negative versions of sparse modeling are limited in
the literature either to a noiseless setting or a scenario with a specific
statistical noise model such as Gaussian noise. This paper studies the
performance of non-negative sparse modeling in a more general scenario where
the observed signals have an unknown arbitrary distortion, especially focusing
on non-negativity constrained and L1-penalized least squares, and gives an
exact bound for which this problem can recover the correct signal elements. We
pose two conditions to guarantee the correct signal recovery: minimum
coefficient condition (MCC) and nonlinearity vs. subset coherence condition
(NSCC). The former defines the minimum weight for each of the correct atoms
present in the signal and the latter defines the tolerable deviation from the
linear model relative to the positive subset coherence (PSC), a novel type of
""coherence"" metric. We provide rigorous performance guarantees based on these
conditions and experimentally verify their precise predictive power in a
hyperspectral data unmixing application.
","Yuki Itoh, Marco F. Duarte, Mario Parente",Mario Parente,2015-12-09T03:51:19Z
"Dissecting the molecular structure of the Orion B cloud: Insight from
  Principal Component Analysis","  Context. The combination of wideband receivers and spectrometers currently
available in (sub-)millimeter observatories deliver wide- field hyperspectral
imaging of the interstellar medium. Tens of spectral lines can be observed over
degree wide fields in about fifty hours. This wealth of data calls for
restating the physical questions about the interstellar medium in statistical
terms. Aims. We aim at gaining information on the physical structure of the
interstellar medium from a statistical analysis of many lines from different
species over a large field of view, without requiring detailed radiative
transfer or astrochemical modeling. Methods. We coupled a nonlinear rescaling
of the data with one of the simplest multivariate analysis methods, namely the
Principal Component Analysis, to decompose the observed signal into components
that we interpret first qualitatively and then quantitatively based on our deep
knowledge of the observed region and of the astrochemistry at play. Results. We
identify 3 principal components, linear compositions of line brightness
temperatures, that are correlated at various levels with the column density,
the volume density and the UV radiation field. Conclusions. When sampling a
sufficiently diverse mixture of physical parameters, it is possible to
decompose the molecular emission in order to gain physical insight on the
observed interstellar medium. This opens a new avenue for future studies of the
interstellar medium.
","Pierre Gratier, Emeric Bron, Maryvonne Gerin, Jérôme Pety, Viviana V. Guzman, Jan Orkisz, Sébastien Bardeau, Javier R. Goicoechea, Franck Le Petit, Harvey Liszt, Karin Öberg, Nicolas Peretto, Evelyne Roueff, Albrech Sievers, Pascal Tremblin",Pascal Tremblin,2017-01-16T09:03:04Z
Learned Spectral Super-Resolution,"  We describe a novel method for blind, single-image spectral super-resolution.
While conventional super-resolution aims to increase the spatial resolution of
an input image, our goal is to spectrally enhance the input, i.e., generate an
image with the same spatial resolution, but a greatly increased number of
narrow (hyper-spectral) wave-length bands. Just like the spatial statistics of
natural images has rich structure, which one can exploit as prior to predict
high-frequency content from a low resolution image, the same is also true in
the spectral domain: the materials and lighting conditions of the observed
world induce structure in the spectrum of wavelengths observed at a given
pixel. Surprisingly, very little work exists that attempts to use this
diagnosis and achieve blind spectral super-resolution from single images. We
start from the conjecture that, just like in the spatial domain, we can learn
the statistics of natural image spectra, and with its help generate finely
resolved hyper-spectral images from RGB input. Technically, we follow the
current best practice and implement a convolutional neural network (CNN), which
is trained to carry out the end-to-end mapping from an entire RGB image to the
corresponding hyperspectral image of equal size. We demonstrate spectral
super-resolution both for conventional RGB images and for multi-spectral
satellite data, outperforming the state-of-the-art.
","Silvano Galliani, Charis Lanaras, Dimitrios Marmanis, Emmanuel Baltsavias, Konrad Schindler",Konrad Schindler,2017-03-28T09:17:38Z
Simplified Energy Landscape for Modularity Using Total Variation,"  Networks capture pairwise interactions between entities and are frequently
used in applications such as social networks, food networks, and protein
interaction networks, to name a few. Communities, cohesive groups of nodes,
often form in these applications, and identifying them gives insight into the
overall organization of the network. One common quality function used to
identify community structure is modularity. In Hu et al. [SIAM J. App. Math.,
73(6), 2013], it was shown that modularity optimization is equivalent to
minimizing a particular nonconvex total variation (TV) based functional over a
discrete domain. They solve this problem, assuming the number of communities is
known, using a Merriman, Bence, Osher (MBO) scheme.
  We show that modularity optimization is equivalent to minimizing a convex
TV-based functional over a discrete domain, again, assuming the number of
communities is known. Furthermore, we show that modularity has no convex
relaxation satisfying certain natural conditions. We therefore, find a
manageable non-convex approximation using a Ginzburg Landau functional, which
provably converges to the correct energy in the limit of a certain parameter.
We then derive an MBO algorithm with fewer hand-tuned parameters than in Hu et
al. and which is 7 times faster at solving the associated diffusion equation
due to the fact that the underlying discretization is unconditionally stable.
Our numerical tests include a hyperspectral video whose associated graph has
2.9x10^7 edges, which is roughly 37 times larger than was handled in the paper
of Hu et al.
","Zachary Boyd, Egil Bae, Xue-Cheng Tai, Andrea L. Bertozzi",Andrea L. Bertozzi,2017-07-28T15:39:03Z
Unmixing dynamic PET images with variable specific binding kinetics,"  To analyze dynamic positron emission tomography (PET) images, various generic
multivariate data analysis techniques have been considered in the literature,
such as principal component analysis (PCA), independent component analysis
(ICA), factor analysis and nonnegative matrix factorization (NMF).
Nevertheless, these conventional approaches neglect any possible nonlinear
variations in the time activity curves describing the kinetic behavior of
tissues with specific binding, which limits their ability to recover a
reliable, understandable and interpretable description of the data. This paper
proposes an alternative analysis paradigm that accounts for spatial
fluctuations in the exchange rate of the tracer between a free compartment and
a specifically bound ligand compartment. The method relies on the concept of
linear unmixing, usually applied on the hyperspectral domain, which combines
NMF with a sum-to-one constraint that ensures an exhaustive description of the
mixtures. The spatial variability of the signature corresponding to the
specific binding tissue is explicitly modeled through a perturbed component.
The performance of the method is assessed on both synthetic and real data and
is shown to compete favorably when compared to other conventional analysis
methods. The proposed method improved both factor estimation and proportions
extraction for specific binding. Modeling the variability of the specific
binding factor has a strong potential impact for dynamic PET image analysis.
","Yanna Cruz Cavalcanti, Thomas Oberlin, Nicolas Dobigeon, Simon Stute, Maria Ribeiro, Clovis Tauber",Clovis Tauber,2017-07-19T12:17:57Z
"Selective excitation and imaging of ultraslow phonon polaritons in thin
  hexagonal boron nitride crystals","  Polaritons in 2D and van der Waals (vdW) materials have been investigated in
several recent works as an innovative platform for light-matter interaction,
rich of new physical phenomena.Hexagonal Boron Nitride (h-BN), in particular,
is an out of plane anisotropic material (while it is in-plane isotropic) with
two very strong phonon polaritons bands where the permittivity becomes
negative. In the first restrahlen band (RS1, 780-830 cm-1) the relative out of
plane permittivity is negative, while in the second restrahlen band (RS2,
1370-1610 cm-1) the relative in-plane permittivity is negative. Due to these
optical properties, thin h-BN flakes support guided modes which have been
observed experimentally both via far field and near field methods. In this
work, we show how selectively excite the more confined modes in the RS1 and RS2
bands. The supported guided modes have phase and group velocities respectively
tens and hundreds of times slower than the speed of light. We also show the
possibility of full hyperspectral nano-imaging of modes in RS1 band by means of
photo-induced force microscopy (PiFM). Moreover, a direct comparison of (PiFM)
and scattering-type near-field microscopy (s-SNOM) is obtained by imaging the
modes of the RS2 band with both techniques implemented on the same platform.
The possibility of addressing ultraslow (ultraconfined) polaritonic modes of
h-BN crystal flakes together with the possibility of optical nano-imaging in
both the restrahlen bands have many innovative aspects that can lead to
unprecedented schemes for strong light-matter interaction, slow and confined
light.
","Antonio Ambrosio, Michele Tamagnone, Kundan Chaudhary, Luis A. Jauregui, Philip Kim, William L. Wilson, Federico Capasso",Federico Capasso,2017-11-12T17:32:51Z
Small Drone Field Experiment: Data Collection & Processing,"  Following an initiative formalized in April 2016 formally known as ARL West
between the U.S. Army Research Laboratory (ARL) and University of Southern
California's Institute for Creative Technologies (USC ICT), a field experiment
was coordinated and executed in the summer of 2016 by ARL, USC ICT, and
Headwall Photonics. The purpose was to image part of the USC main campus in Los
Angeles, USA, using two portable COTS (commercial off the shelf) aerial drone
solutions for data acquisition, for photogrammetry (3D reconstruction from
images), and fusion of hyperspectral data with the recovered set of 3D point
clouds representing the target area. The research aims for determining the
viability of having a machine capable of segmenting the target area into key
material classes (e.g., manmade structures, live vegetation, water) for use in
multiple purposes, to include providing the user with a more accurate scene
understanding and enabling the unsupervised automatic sampling of meaningful
material classes from the target area for adaptive semi-supervised machine
learning. In the latter, a target set library may be used for automatic machine
training with data of local material classes, as an example, to increase the
prediction chances of machines recognizing targets. The field experiment and
associated data post processing approach to correct for reflectance,
geo-rectify, recover the area's dense point clouds from images, register
spectral with elevation properties of scene surfaces from the independently
collected datasets, and generate the desired scene segmented maps are
discussed. Lessons learned from the experience are also highlighted throughout
the paper.
","Dalton Rosario, Christoph Borel, Damon Conover, Ryan McAlinden, Anthony Ortiz, Sarah Shiver, Blair Simon",Blair Simon,2017-11-29T06:08:16Z
Constrained Manifold Learning for Hyperspectral Imagery Visualization,"  Displaying the large number of bands in a hyper- spectral image (HSI) on a
trichromatic monitor is important for HSI processing and analysis system. The
visualized image shall convey as much information as possible from the original
HSI and meanwhile facilitate image interpretation. However, most existing
methods display HSIs in false color, which contradicts with user experience and
expectation. In this paper, we propose a visualization approach based on
constrained manifold learning, whose goal is to learn a visualized image that
not only preserves the manifold structure of the HSI but also has natural
colors. Manifold learning preserves the image structure by forcing pixels with
similar signatures to be displayed with similar colors. A composite kernel is
applied in manifold learning to incorporate both the spatial and spectral
information of HSI in the embedded space. The colors of the output image are
constrained by a corresponding natural-looking RGB image, which can either be
generated from the HSI itself (e.g., band selection from the visible
wavelength) or be captured by a separate device. Our method can be done at
instance-level and feature-level. Instance-level learning directly obtains the
RGB coordinates for the pixels in the HSI while feature-level learning learns
an explicit mapping function from the high dimensional spectral space to the
RGB space. Experimental results demonstrate the advantage of the proposed
method in information preservation and natural color visualization.
","Danping Liao, Yuntao Qian, Yuan Yan Tang",Yuan Yan Tang,2017-11-24T07:04:04Z
Sketch Layer Separation in Multi-Spectral Historical Document Images,"  High-resolution imaging has delivered new prospects for detecting the
material composition and structure of cultural treasures. Despite the various
techniques for analysis, a significant diagnostic gap remained in the range of
available research capabilities for works on paper. Old master drawings were
mostly composed in a multi-step manner with various materials. This resulted in
the overlapping of different layers which made the subjacent strata difficult
to differentiate. The separation of stratified layers using imaging methods
could provide insights into the artistic work processes and help answer
questions about the object, its attribution, or in identifying forgeries. The
pattern recognition procedure was tested with mock replicas to achieve the
separation and the capability of displaying concealed red chalk under ink. In
contrast to RGB-sensor based imaging, the multi- or hyperspectral technology
allows accurate layer separation by recording the characteristic signatures of
the material's reflectance. The risk of damage to the artworks as a result of
the examination can be reduced by using combinations of defined spectra for
lightning and image capturing. By guaranteeing the maximum level of
readability, our results suggest that the technique can be applied to a broader
range of objects and assist in diagnostic research into cultural treasures in
the future.
","AmirAbbas Davari, Armin Häberle, Vincent Christlein, Andreas Maier, Christian Riess",Christian Riess,2017-12-10T21:36:43Z
Compact Folded Metasurface Spectrometer,"  Recent advances in optical metasurfaces enable control of the wavefront,
polarization and dispersion of optical waves beyond the capabilities of
conventional diffractive optics. An optical design space that is poised to
highly benefit from these developments is the folded optics architecture where
light is confined between reflective surfaces and the wavefront is controlled
at the reflective interfaces. In this manuscript we introduce the concept of
folded metasurface optics by demonstrating a compact high resolution optical
spectrometer made from a 1-mm-thick glass slab with a volume of 7 cubic
millimeters. The spectrometer has a resolution of 1.2 nm, resolving more than
80 spectral points in a 100-nm bandwidth centered around 810 nm. The device is
composed of three different reflective dielectric metasurfaces, all fabricated
in a single lithographic step on one side of a transparent optical substrate,
which simultaneously acts as the propagation space for light. An image sensor,
parallel to the spectrometer substrate, can be directly integrated on top of it
to achieve a compact mono- lithic device including all the active and passive
components. Multiple spectrometers, with similar or different characteristics
and operation bandwidths may also be integrated on the same chip and fabricated
in a batch process, significantly reducing their costs and increas- ing their
functionalities and integration potential. In addition, the folded metasystems
design can be applied to many optical systems, such as optical signal
processors, interferometers, hyperspectral imagers and computational optical
systems, significantly reducing their sizes and increasing their mechanical
robustness and potential for integration.
","MohammadSadegh Faraji-Dana, Ehsan Arbabi, Amir Arbabi, Seyedeh Mahsa Kamali, Hyounghan Kwon, Andrei Faraon",Andrei Faraon,2018-07-29T00:27:39Z
Multilinear Compressive Learning,"  Compressive Learning is an emerging topic that combines signal acquisition
via compressive sensing and machine learning to perform inference tasks
directly on a small number of measurements. Many data modalities naturally have
a multi-dimensional or tensorial format, with each dimension or tensor mode
representing different features such as the spatial and temporal information in
video sequences or the spatial and spectral information in hyperspectral
images. However, in existing compressive learning frameworks, the compressive
sensing component utilizes either random or learned linear projection on the
vectorized signal to perform signal acquisition, thus discarding the
multi-dimensional structure of the signals. In this paper, we propose
Multilinear Compressive Learning, a framework that takes into account the
tensorial nature of multi-dimensional signals in the acquisition step and
builds the subsequent inference model on the structurally sensed measurements.
Our theoretical complexity analysis shows that the proposed framework is more
efficient compared to its vector-based counterpart in both memory and
computation requirement. With extensive experiments, we also empirically show
that our Multilinear Compressive Learning framework outperforms the
vector-based framework in object classification and face recognition tasks, and
scales favorably when the dimensionalities of the original signals increase,
making it highly efficient for high-dimensional multi-dimensional signals.
","Dat Thanh Tran, Mehmet Yamac, Aysen Degerli, Moncef Gabbouj, Alexandros Iosifidis",Alexandros Iosifidis,2019-05-17T21:04:44Z
Generalized Separable Nonnegative Matrix Factorization,"  Nonnegative matrix factorization (NMF) is a linear dimensionality technique
for nonnegative data with applications such as image analysis, text mining,
audio source separation and hyperspectral unmixing. Given a data matrix $M$ and
a factorization rank $r$, NMF looks for a nonnegative matrix $W$ with $r$
columns and a nonnegative matrix $H$ with $r$ rows such that $M \approx WH$.
NMF is NP-hard to solve in general. However, it can be computed efficiently
under the separability assumption which requires that the basis vectors appear
as data points, that is, that there exists an index set $\mathcal{K}$ such that
$W = M(:,\mathcal{K})$. In this paper, we generalize the separability
assumption: We only require that for each rank-one factor $W(:,k)H(k,:)$ for
$k=1,2,\dots,r$, either $W(:,k) = M(:,j)$ for some $j$ or $H(k,:) = M(i,:)$ for
some $i$. We refer to the corresponding problem as generalized separable NMF
(GS-NMF). We discuss some properties of GS-NMF and propose a convex
optimization model which we solve using a fast gradient method. We also propose
a heuristic algorithm inspired by the successive projection algorithm. To
verify the effectiveness of our methods, we compare them with several
state-of-the-art separable NMF algorithms on synthetic, document and image data
sets.
","Junjun Pan, Nicolas Gillis",Nicolas Gillis,2019-05-30T12:18:25Z
Near-Convex Archetypal Analysis,"  Nonnegative matrix factorization (NMF) is a widely used linear dimensionality
reduction technique for nonnegative data. NMF requires that each data point is
approximated by a convex combination of basis elements. Archetypal analysis
(AA), also referred to as convex NMF, is a well-known NMF variant imposing that
the basis elements are themselves convex combinations of the data points. AA
has the advantage to be more interpretable than NMF because the basis elements
are directly constructed from the data points. However, it usually suffers from
a high data fitting error because the basis elements are constrained to be
contained in the convex cone of the data points. In this letter, we introduce
near-convex archetypal analysis (NCAA) which combines the advantages of both AA
and NMF. As for AA, the basis vectors are required to be linear combinations of
the data points and hence are easily interpretable. As for NMF, the additional
flexibility in choosing the basis elements allows NCAA to have a low data
fitting error. We show that NCAA compares favorably with a state-of-the-art
minimum-volume NMF method on synthetic datasets and on a real-world
hyperspectral image.
","Pierre De Handschutter, Nicolas Gillis, Arnaud Vandaele, Xavier Siebert",Xavier Siebert,2019-10-02T08:16:14Z
"Spatially-resolved luminescence and crystal structure of single
  core-shell nanowires measured in the as-grown geometry","  We report on the direct correlation between the structural and optical
properties of single, as-grown core-multi-shell
GaAs/In$_{0.15}$Ga$_{0.85}$As/GaAs/AlAs/GaAs nanowires. Fabricated by molecular
beam epitaxy on a pre-patterned Si(111) substrate, on a row of well separated
nucleation sites, it was possible to access individual nanowires in the
as-grown geometry. The polytype distribution along the growth axis of the
nanowires was revealed by synchrotron-based nanoprobe X-ray diffraction
techniques monitoring the axial 111 Bragg reflection. For the same nanowires,
the spatially-resolved emission properties were obtained by cathodoluminescence
hyperspectral linescans in a scanning electron microscope. Correlating both
measurements, we reveal a blueshift of the shell quantum well emission energy
combined with an increased emission intensity for segments exhibiting a mixed
structure of alternating wurtzite and zincblende stacking compared with the
pure crystal polytypes. The presence of this mixed structure was independently
confirmed by cross-sectional transmission electron microscopy.
","Ali AlHassan, Jonas Lähnemann, Steven Leake, Hanno Küpers, Michael Niehle, Danial Bahrami, Florian Bertram, Ryan B. Lewis, Arman Davtyan, Tobias Schülli, Lutz Geelhaar, Ullrich Pietsch",Ullrich Pietsch,2020-02-19T13:32:28Z
"Photometrically-corrected global infrared mosaics of Enceladus: New
  implications for its spectral diversity and geological activity","  Between 2004 and 2017, spectral observations have been gathered by the Visual
and Infrared Mapping Spectrometer (VIMS) on-board Cassini (Brown et al., 2004)
during 23 Enceladus close encounters, in addition to more distant surveys. The
objective of the present study is to produce a global hyperspectral mosaic of
the complete VIMS data set of Enceladus in order to highlight spectral
variations among the different geological units. This requires the selection of
the best observations in terms of spatial resolution and illumination
conditions. We have carried out a detailed investigation of the photometric
behavior at several key wavelengths (1.35, 1.5, 1.65, 1.8, 2.0, 2.25, 2.55 and
3.6 ${\mu}$m), characteristics of the infrared spectra of water ice. We propose
a new photometric function, based on the model of Shkuratov et al. (2011). When
combined, corrected mosaics at different wavelengths reveal heterogeneous
areas, in particular in the terrains surrounding the Tiger Stripes on the South
Pole and in the northern hemisphere around 30{\deg}N, 90{\deg}W. Those areas
appear mainly correlated to tectonized units, indicating an endogenous origin,
potentially driven by seafloor hotspots.
","Rozenn Robinel, Stéphane Le Mouélic, Gabriel Tobie, Marion Massé, Benoît Seignovert, Christophe Sotin, Sébastien Rodriguez",Sébastien Rodriguez,2020-05-30T01:59:05Z
"Collective near-field coupling in infrared-phononic metasurfaces for
  nano-light canalization","  Polaritons, coupled excitations of photons and dipolar matter excitations,
can propagate along anisotropic metasurfaces with either hyperbolic or
elliptical dispersion. At the transition from hyperbolic to elliptical
dispersion (corresponding to a topological transition), various intriguing
phenomena are found, such as an enhancement of the photonic density of states,
polariton canalization and hyperlensing. Here we investigate theoretically and
experimentally the topological transition and the polaritonic coupling of
deeply subwavelength elements in a uniaxial infrared-phononic metasurface, a
grating of hexagonal boron nitride (hBN) nanoribbons. By hyperspectral infrared
nanoimaging, we observe, for the first time, a synthetic transverse optical
phonon resonance (that is, the strong collective near-field coupling of the
nanoribbons) in the middle of the hBN Reststrahlen band, yielding a topological
transition from hyperbolic to elliptical dispersion. We further visualize and
characterize the spatial evolution of a deeply subwavelength canalization mode
near the transition frequency, which is a collimated polariton that is the
basis for hyperlensing and diffraction-less propagation. Our results provide
fundamental insights into the role of polaritonic near-field coupling in
metasurfaces for creating topological transitions and polariton canalization.
","Peining Li, Guangwei Hu, Irene Dolado, Mykhailo Tymchenko, Cheng-Wei Qiu, Francisco Javier Alfaro-Mozaz, Felix Casanova, Luis E. Hueso, Song Liu, James H. Edgar, Saül Vélez, Andrea Alu, Rainer Hillenbrand",Rainer Hillenbrand,2020-06-02T10:16:34Z
"A universal smartphone add-on for portable spectroscopy and polarimetry:
  iSPEX 2","  Spectropolarimetry is a powerful technique for remote sensing of the
environment. It enables the retrieval of particle shape and size distributions
in air and water to an extent that traditional spectroscopy cannot. SPEX is an
instrument concept for spectropolarimetry through spectral modulation,
providing snapshot, and hence accurate, hyperspectral intensity and degree and
angle of linear polarization. Successful SPEX instruments have included
groundSPEX and SPEX airborne, which both measure aerosol optical thickness with
high precision, and soon SPEXone, which will fly on PACE. Here, we present a
low-cost variant for consumer cameras, iSPEX 2, with universal smartphone
support. Smartphones enable citizen science measurements which are
significantly more scaleable, in space and time, than professional instruments.
Universal smartphone support is achieved through a modular hardware design and
SPECTACLE data processing. iSPEX 2 will be manufactured through injection
molding and 3D printing. A smartphone app for data acquisition and processing
is in active development. Production, calibration, and validation will commence
in the summer of 2020. Scientific applications will include citizen science
measurements of aerosol optical thickness and surface water reflectance, as
well as low-cost laboratory and portable spectroscopy.
","Olivier Burggraaff, Armand B. Perduijn, Robert F. van Hek, Norbert Schmidt, Christoph U. Keller, Frans Snik",Frans Snik,2020-06-02T11:00:27Z
"X-ModalNet: A Semi-Supervised Deep Cross-Modal Network for
  Classification of Remote Sensing Data","  This paper addresses the problem of semi-supervised transfer learning with
limited cross-modality data in remote sensing. A large amount of multi-modal
earth observation images, such as multispectral imagery (MSI) or synthetic
aperture radar (SAR) data, are openly available on a global scale, enabling
parsing global urban scenes through remote sensing imagery. However, their
ability in identifying materials (pixel-wise classification) remains limited,
due to the noisy collection environment and poor discriminative information as
well as limited number of well-annotated training images. To this end, we
propose a novel cross-modal deep-learning framework, called X-ModalNet, with
three well-designed modules: self-adversarial module, interactive learning
module, and label propagation module, by learning to transfer more
discriminative information from a small-scale hyperspectral image (HSI) into
the classification task using a large-scale MSI or SAR data. Significantly,
X-ModalNet generalizes well, owing to propagating labels on an updatable graph
constructed by high-level features on the top of the network, yielding
semi-supervised cross-modality learning. We evaluate X-ModalNet on two
multi-modal remote sensing datasets (HSI-MSI and HSI-SAR) and achieve a
significant improvement in comparison with several state-of-the-art methods.
","Danfeng Hong, Naoto Yokoya, Gui-Song Xia, Jocelyn Chanussot, Xiao Xiang Zhu",Xiao Xiang Zhu,2020-06-24T15:29:41Z
DeepTensor: Low-Rank Tensor Decomposition with Deep Network Priors,"  DeepTensor is a computationally efficient framework for low-rank
decomposition of matrices and tensors using deep generative networks. We
decompose a tensor as the product of low-rank tensor factors (e.g., a matrix as
the outer product of two vectors), where each low-rank tensor is generated by a
deep network (DN) that is trained in a self-supervised manner to minimize the
mean-squared approximation error. Our key observation is that the implicit
regularization inherent in DNs enables them to capture nonlinear signal
structures (e.g., manifolds) that are out of the reach of classical linear
methods like the singular value decomposition (SVD) and principal component
analysis (PCA). Furthermore, in contrast to the SVD and PCA, whose performance
deteriorates when the tensor's entries deviate from additive white Gaussian
noise, we demonstrate that the performance of DeepTensor is robust to a wide
range of distributions. We validate that DeepTensor is a robust and
computationally efficient drop-in replacement for the SVD, PCA, nonnegative
matrix factorization (NMF), and similar decompositions by exploring a range of
real-world applications, including hyperspectral image denoising, 3D MRI
tomography, and image classification. In particular, DeepTensor offers a 6dB
signal-to-noise ratio improvement over standard denoising methods for signals
corrupted by Poisson noise and learns to decompose 3D tensors 60 times faster
than a single DN equipped with 3D convolutions.
","Vishwanath Saragadam, Randall Balestriero, Ashok Veeraraghavan, Richard G. Baraniuk",Richard G. Baraniuk,2022-04-07T01:09:58Z
"A3CLNN: Spatial, Spectral and Multiscale Attention ConvLSTM Neural
  Network for Multisource Remote Sensing Data Classification","  The problem of effectively exploiting the information multiple data sources
has become a relevant but challenging research topic in remote sensing. In this
paper, we propose a new approach to exploit the complementarity of two data
sources: hyperspectral images (HSIs) and light detection and ranging (LiDAR)
data. Specifically, we develop a new dual-channel spatial, spectral and
multiscale attention convolutional long short-term memory neural network
(called dual-channel A3CLNN) for feature extraction and classification of
multisource remote sensing data. Spatial, spectral and multiscale attention
mechanisms are first designed for HSI and LiDAR data in order to learn
spectral- and spatial-enhanced feature representations, and to represent
multiscale information for different classes. In the designed fusion network, a
novel composite attention learning mechanism (combined with a three-level
fusion strategy) is used to fully integrate the features in these two data
sources. Finally, inspired by the idea of transfer learning, a novel stepwise
training strategy is designed to yield a final classification result. Our
experimental results, conducted on several multisource remote sensing data
sets, demonstrate that the newly proposed dual-channel A3CLNN exhibits better
feature representation ability (leading to more competitive classification
performance) than other state-of-the-art methods.
","Heng-Chao Li, Wen-Shuai Hu, Wei Li, Jun Li, Qian Du, Antonio Plaza",Antonio Plaza,2022-04-09T12:43:32Z
"MST++: Multi-stage Spectral-wise Transformer for Efficient Spectral
  Reconstruction","  Existing leading methods for spectral reconstruction (SR) focus on designing
deeper or wider convolutional neural networks (CNNs) to learn the end-to-end
mapping from the RGB image to its hyperspectral image (HSI). These CNN-based
methods achieve impressive restoration performance while showing limitations in
capturing the long-range dependencies and self-similarity prior. To cope with
this problem, we propose a novel Transformer-based method, Multi-stage
Spectral-wise Transformer (MST++), for efficient spectral reconstruction. In
particular, we employ Spectral-wise Multi-head Self-attention (S-MSA) that is
based on the HSI spatially sparse while spectrally self-similar nature to
compose the basic unit, Spectral-wise Attention Block (SAB). Then SABs build up
Single-stage Spectral-wise Transformer (SST) that exploits a U-shaped structure
to extract multi-resolution contextual information. Finally, our MST++,
cascaded by several SSTs, progressively improves the reconstruction quality
from coarse to fine. Comprehensive experiments show that our MST++
significantly outperforms other state-of-the-art methods. In the NTIRE 2022
Spectral Reconstruction Challenge, our approach won the First place. Code and
pre-trained models are publicly available at
https://github.com/caiyuanhao1998/MST-plus-plus.
","Yuanhao Cai, Jing Lin, Zudi Lin, Haoqian Wang, Yulun Zhang, Hanspeter Pfister, Radu Timofte, Luc Van Gool",Luc Van Gool,2022-04-17T02:39:32Z
"Unmixing urban hyperspectral imagery with a Gaussian mixture model on
  endmember variability","  In this paper, we model a pixel as a linear combination of endmembers sampled
from probability distributions of Gaussian mixture models (GMM). The parameters
of the GMM distributions are estimated using spectral libraries. Abundances are
estimated based on the distribution parameters. The advantage of this algorithm
is that the model size grows very slowly as a function of the library size. To
validate this method, we used data collected by the AVIRIS sensor over the
Santa Barbara region: two 16 m spatial resolution and two 4 m spatial
resolution images. 64 validated regions of interest (ROI) (180 m by 180 m) were
used to assess estimate accuracy. Ground truth was obtained using 1 m images
leading to the following 6 classes: turfgrass, non-photosynthetic vegetation
(NPV), paved, roof, soil, and tree. Spectral libraries were built by manually
identifying and extracting pure spectra from both resolution images, resulting
in 3,287 spectra at 16 m and 15,426 spectra at 4 m. We then unmixed ROIs of
each resolution using the following unmixing algorithms: the set-based
algorithms MESMA and AAM, and the distribution-based algorithms GMM, NCM, and
BCM. The original libraries were used for the distribution-based algorithms
whereas set-based methods required a sophisticated reduction method, resulting
in reduced libraries of 61 spectra at 16 m and 95 spectra at 4 m. The results
show that GMM performs best among the distribution-based methods, producing
comparable accuracy to MESMA, and may be more robust across datasets.
","Yuan Zhou, Erin B. Wetherley, Paul D. Gader",Paul D. Gader,2018-01-25T18:22:22Z
"Three dimensional Deep Learning approach for remote sensing image
  classification","  Recently, a variety of approaches has been enriching the field of Remote
Sensing (RS) image processing and analysis. Unfortunately, existing methods
remain limited faced to the rich spatio-spectral content of today's large
datasets. It would seem intriguing to resort to Deep Learning (DL) based
approaches at this stage with regards to their ability to offer accurate
semantic interpretation of the data. However, the specificity introduced by the
coexistence of spectral and spatial content in the RS datasets widens the scope
of the challenges presented to adapt DL methods to these contexts. Therefore,
the aim of this paper is firstly to explore the performance of DL architectures
for the RS hyperspectral dataset classification and secondly to introduce a new
three-dimensional DL approach that enables a joint spectral and spatial
information process. A set of three-dimensional schemes is proposed and
evaluated. Experimental results based on well knownhyperspectral datasets
demonstrate that the proposed method is able to achieve a better classification
rate than state of the art methods with lower computational costs.
","Amina Ben Hamida, A Benoit, Patrick Lambert, Chokri Ben Amar",Chokri Ben Amar,2018-06-15T06:35:47Z
Cumulo: A Dataset for Learning Cloud Classes,"  One of the greatest sources of uncertainty in future climate projections
comes from limitations in modelling clouds and in understanding how different
cloud types interact with the climate system. A key first step in reducing this
uncertainty is to accurately classify cloud types at high spatial and temporal
resolution. In this paper, we introduce Cumulo, a benchmark dataset for
training and evaluating global cloud classification models. It consists of one
year of 1km resolution MODIS hyperspectral imagery merged with pixel-width
'tracks' of CloudSat cloud labels. Bringing these complementary datasets
together is a crucial first step, enabling the Machine-Learning community to
develop innovative new techniques which could greatly benefit the Climate
community. To showcase Cumulo, we provide baseline performance analysis using
an invertible flow generative model (IResNet), which further allows us to
discover new sub-classes for a given cloud class by exploring the latent space.
To compare methods, we introduce a set of evaluation criteria, to identify
models that are not only accurate, but also physically-realistic. CUMULO can be
download from
https://www.dropbox.com/sh/i3s9q2v2jjyk2it/AACxXnXfMF5wuIqLXqH4NJOra?dl=0 .
","Valentina Zantedeschi, Fabrizio Falasca, Alyson Douglas, Richard Strange, Matt J. Kusner, Duncan Watson-Parris",Duncan Watson-Parris,2019-11-05T09:36:16Z
"Maximum likelihood estimation of regularisation parameters in
  high-dimensional inverse problems: an empirical Bayesian approach. Part I:
  Methodology and Experiments","  Many imaging problems require solving an inverse problem that is
ill-conditioned or ill-posed. Imaging methods typically address this difficulty
by regularising the estimation problem to make it well-posed. This often
requires setting the value of the so-called regularisation parameters that
control the amount of regularisation enforced. These parameters are notoriously
difficult to set a priori, and can have a dramatic impact on the recovered
estimates. In this work, we propose a general empirical Bayesian method for
setting regularisation parameters in imaging problems that are convex w.r.t.
the unknown image. Our method calibrates regularisation parameters directly
from the observed data by maximum marginal likelihood estimation, and can
simultaneously estimate multiple regularisation parameters. Furthermore, the
proposed algorithm uses the same basic operators as proximal optimisation
algorithms, namely gradient and proximal operators, and it is therefore
straightforward to apply to problems that are currently solved by using
proximal optimisation techniques. Our methodology is demonstrated with a range
of experiments and comparisons with alternative approaches from the literature.
The considered experiments include image denoising, non-blind image
deconvolution, and hyperspectral unmixing, using synthesis and analysis priors
involving the L1, total-variation, total-variation and L1, and
total-generalised-variation pseudo-norms. A detailed theoretical analysis of
the proposed method is presented in the companion paper arXiv:2008.05793.
","Ana F. Vidal, Valentin De Bortoli, Marcelo Pereyra, Alain Durmus",Alain Durmus,2019-11-26T17:31:00Z
Multi-Resolution Beta-Divergence NMF for Blind Spectral Unmixing,"  Many datasets are obtained as a resolution trade-off between two adversarial
dimensions; for example between the frequency and the temporal resolutions for
the spectrogram of an audio signal, and between the number of wavelengths and
the spatial resolution for a hyper/multi-spectral image. To perform blind
source separation using observations with different resolutions, a standard
approach is to use coupled nonnegative matrix factorizations (NMF). Most
previous works have focused on the least squares error measure, which is the
$\beta$-divergence for $\beta = 2$. In this paper, we formulate this
multi-resolution NMF problem for any $\beta$-divergence, and propose an
algorithm based on multiplicative updates (MU). We show on numerical
experiments that the MU are able to obtain high resolutions in both dimensions
on two applications: (1) blind unmixing of audio spectrograms: to the best of
our knowledge, this is the first time a coupled NMF model is used in this
context, and (2) the fusion of hyperspectral and multispectral images: we show
that the MU compete favorable with state-of-the-art algorithms in particular in
the presence of non-Gaussian noise.
","Valentin Leplat, Nicolas Gillis, Cédric Févotte",Cédric Févotte,2020-07-08T04:50:05Z
Point-to-set distance functions for weakly supervised segmentation,"  When pixel-level masks or partial annotations are not available for training
neural networks for semantic segmentation, it is possible to use higher-level
information in the form of bounding boxes, or image tags. In the imaging
sciences, many applications do not have an object-background structure and
bounding boxes are not available. Any available annotation typically comes from
ground truth or domain experts. A direct way to train without masks is using
prior knowledge on the size of objects/classes in the segmentation. We present
a new algorithm to include such information via constraints on the network
output, implemented via projection-based point-to-set distance functions. This
type of distance functions always has the same functional form of the
derivative, and avoids the need to adapt penalty functions to different
constraints, as well as issues related to constraining properties typically
associated with non-differentiable functions. Whereas object size information
is known to enable object segmentation from bounding boxes from datasets with
many general and medical images, we show that the applications extend to the
imaging sciences where data represents indirect measurements, even in the case
of single examples. We illustrate the capabilities in case of a) one or more
classes do not have any annotation; b) there is no annotation at all; c) there
are bounding boxes. We use data for hyperspectral time-lapse imaging, object
segmentation in corrupted images, and sub-surface aquifer mapping from
airborne-geophysical remote-sensing data. The examples verify that the
developed methodology alleviates difficulties with annotating non-visual
imagery for a range of experimental settings.
",Bas Peters,Bas Peters,2020-07-27T00:15:13Z
Randomized kernels for large scale Earth observation applications,"  Dealing with land cover classification of the new image sources has also
turned to be a complex problem requiring large amount of memory and processing
time. In order to cope with these problems, statistical learning has greatly
helped in the last years to develop statistical retrieval and classification
models that can ingest large amounts of Earth observation data. Kernel methods
constitute a family of powerful machine learning algorithms, which have found
wide use in remote sensing and geosciences. However, kernel methods are still
not widely adopted because of the high computational cost when dealing with
large scale problems, such as the inversion of radiative transfer models or the
classification of high spatial-spectral-temporal resolution data. This paper
introduces an efficient kernel method for fast statistical retrieval of
bio-geo-physical parameters and image classification problems. The method
allows to approximate a kernel matrix with a set of projections on random bases
sampled from the Fourier domain. The method is simple, computationally very
efficient in both memory and processing costs, and easily parallelizable. We
show that kernel regression and classification is now possible for datasets
with millions of examples and high dimensionality. Examples on atmospheric
parameter retrieval from hyperspectral infrared sounders like IASI/Metop; large
scale emulation and inversion of the familiar PROSAIL radiative transfer model
on Sentinel-2 data; and the identification of clouds over landmarks in time
series of MSG/Seviri images show the efficiency and effectiveness of the
proposed technique.
","Adrián Pérez-Suay, Julia Amorós-López, Luis Gómez-Chova, Valero Laparra, Jordi Muñoz-Marí, Gustau Camps-Valls",Gustau Camps-Valls,2020-12-07T12:23:56Z
"Aalto-1, multi-payload CubeSat: design, integration and launch","  The design, integration, testing, and launch of the first Finnish satellite
Aalto-1 is briefly presented in this paper. Aalto-1, a three-unit CubeSat,
launched into Sun-synchronous polar orbit at an altitude of approximately 500
km, is operational since June 2017. It carries three experimental payloads:
Aalto Spectral Imager (AaSI), Radiation Monitor (RADMON), and Electrostatic
Plasma Brake (EPB). AaSI is a hyperspectral imager in visible and near-infrared
(NIR) wavelength bands, RADMON is an energetic particle detector and EPB is a
de-orbiting technology demonstration payload. The platform was designed to
accommodate multiple payloads while ensuring sufficient data, power, radio,
mechanical and electrical interfaces. The design strategy of platform and
payload subsystems consists of in-house development and commercial subsystems.
The CubeSat Assembly, Integration & Test (AIT) followed Flatsat --
Engineering-Qualification Model (EQM) -- Flight Model (FM) model philosophy for
qualification and acceptance.
  The paper briefly describes the design approach of platform and payload
subsystems, their integration and test campaigns, and spacecraft launch. The
paper also describes the ground segment & services that were developed by the
Aalto-1 team.
","J. Praks, M. Rizwan Mughal, R. Vainio, P. Janhunen, J. Envall, P. Oleynik, A. Näsilä, H. Leppinen, P. Niemelä, A. Slavinskis, J. Gieseler, P. Toivanen, T. Tikka, T. Peltola, A. Bosser, G. Schwarzkopf, N. Jovanovic, B. Riwanto, A. Kestilä, A. Punkkinen, R. Punkkinen, H. -P. Hedman, T. Säntti, J. -O. Lill, J. M. K. Slotte, H. Kettunen, A. Virtanen",A. Virtanen,2021-01-26T10:33:22Z
"LADMM-Net: An Unrolled Deep Network For Spectral Image Fusion From
  Compressive Data","  Image fusion aims at estimating a high-resolution spectral image from a
low-spatial-resolution hyperspectral image and a low-spectral-resolution
multispectral image. In this regard, compressive spectral imaging (CSI) has
emerged as an acquisition framework that captures the relevant information of
spectral images using a reduced number of measurements. Recently, various image
fusion methods from CSI measurements have been proposed. However, these methods
exhibit high running times and face the challenging task of choosing
sparsity-inducing bases. In this paper, a deep network under the algorithm
unrolling approach is proposed for fusing spectral images from compressive
measurements. This architecture, dubbed LADMM-Net, casts each iteration of a
linearized version of the alternating direction method of multipliers into a
processing layer whose concatenation deploys a deep network. The linearized
approach enables obtaining fusion estimates without resorting to costly matrix
inversions. Furthermore, this approach exploits the benefits of learnable
transforms to estimate the image details included in both the auxiliary
variable and the Lagrange multiplier. Finally, the performance of the proposed
technique is evaluated on two spectral image databases and one dataset captured
at the laboratory. Extensive simulations show that the proposed method
outperforms the state-of-the-art approaches that fuse spectral images from
compressive measurements.
","Juan Marcos Ramírez, José Ignacio Martínez Torre, Henry Arguello Fuentes",Henry Arguello Fuentes,2021-03-01T12:04:42Z
"CG-CNN: Self-Supervised Feature Extraction Through Contextual Guidance
  and Transfer Learning","  Contextually Guided Convolutional Neural Networks (CG-CNNs) employ
self-supervision and contextual information to develop transferable features
across diverse domains, including visual, tactile, temporal, and textual data.
This work showcases the adaptability of CG-CNNs through applications to various
datasets such as Caltech and Brodatz textures, the VibTac-12 tactile dataset,
hyperspectral images, and challenges like the XOR problem and text analysis. In
text analysis, CG-CNN employs an innovative embedding strategy that utilizes
the context of neighboring words for classification, while in visual and signal
data, it enhances feature extraction by exploiting spatial information. CG-CNN
mimics the context-guided unsupervised learning mechanisms of biological neural
networks and it can be trained to learn its features on limited-size datasets.
Our experimental results on natural images reveal that CG-CNN outperforms
comparable first-layer features of well-known deep networks such as AlexNet,
ResNet, and GoogLeNet in terms of transferability and classification accuracy.
In text analysis, CG-CNN learns word embeddings that outperform traditional
models like Word2Vec in tasks such as the 20 Newsgroups text classification.
Furthermore, ongoing development involves training CG-CNN on outputs from
another CG-CNN to explore multi-layered architectures, aiming to construct more
complex and descriptive features. This scalability and adaptability to various
data types underscore the potential of CG-CNN to handle a wide range of
applications, making it a promising architecture for tackling diverse data
representation challenges.
","Olcay Kursun, Ahmad Patooghy, Peyman Poursani, Oleg V. Favorov",Oleg V. Favorov,2021-03-02T08:41:12Z
"Snapshot Compressive Imaging: Principle, Implementation, Theory,
  Algorithms and Applications","  Capturing high-dimensional (HD) data is a long-term challenge in signal
processing and related fields. Snapshot compressive imaging (SCI) uses a
two-dimensional (2D) detector to capture HD ($\ge3$D) data in a {\em snapshot}
measurement. Via novel optical designs, the 2D detector samples the HD data in
a {\em compressive} manner; following this, algorithms are employed to
reconstruct the desired HD data-cube. SCI has been used in hyperspectral
imaging, video, holography, tomography, focal depth imaging, polarization
imaging, microscopy, \etc.~Though the hardware has been investigated for more
than a decade, the theoretical guarantees have only recently been derived.
Inspired by deep learning, various deep neural networks have also been
developed to reconstruct the HD data-cube in spectral SCI and video SCI. This
article reviews recent advances in SCI hardware, theory and algorithms,
including both optimization-based and deep-learning-based algorithms. Diverse
applications and the outlook of SCI are also discussed.
","Xin Yuan, David J. Brady, Aggelos K. Katsaggelos",Aggelos K. Katsaggelos,2021-03-07T18:31:47Z
Deep Gaussian Scale Mixture Prior for Spectral Compressive Imaging,"  In coded aperture snapshot spectral imaging (CASSI) system, the real-world
hyperspectral image (HSI) can be reconstructed from the captured compressive
image in a snapshot. Model-based HSI reconstruction methods employed
hand-crafted priors to solve the reconstruction problem, but most of which
achieved limited success due to the poor representation capability of these
hand-crafted priors. Deep learning based methods learning the mappings between
the compressive images and the HSIs directly achieved much better results. Yet,
it is nontrivial to design a powerful deep network heuristically for achieving
satisfied results. In this paper, we propose a novel HSI reconstruction method
based on the Maximum a Posterior (MAP) estimation framework using learned
Gaussian Scale Mixture (GSM) prior. Different from existing GSM models using
hand-crafted scale priors (e.g., the Jeffrey's prior), we propose to learn the
scale prior through a deep convolutional neural network (DCNN). Furthermore, we
also propose to estimate the local means of the GSM models by the DCNN. All the
parameters of the MAP estimation algorithm and the DCNN parameters are jointly
optimized through end-to-end training. Extensive experimental results on both
synthetic and real datasets demonstrate that the proposed method outperforms
existing state-of-the-art methods. The code is available at
https://see.xidian.edu.cn/faculty/wsdong/Projects/DGSM-SCI.htm.
","Tao Huang, Weisheng Dong, Xin Yuan, Jinjian Wu, Guangming Shi",Guangming Shi,2021-03-12T08:57:06Z
"An Efficient Method for the Classification of Croplands in Scarce-Label
  Regions","  Two of the main challenges for cropland classification by satellite
time-series images are insufficient ground-truth data and inaccessibility of
high-quality hyperspectral images for under-developed areas. Unlabeled
medium-resolution satellite images are abundant, but how to benefit from them
is an open question. We will show how to leverage their potential for cropland
classification using self-supervised tasks. Self-supervision is an approach
where we provide simple training signals for the samples, which are apparent
from the data's structure. Hence, they are cheap to acquire and explain a
simple concept about the data. We introduce three self-supervised tasks for
cropland classification. They reduce epistemic uncertainty, and the resulting
model shows superior accuracy in a wide range of settings compared to SVM and
Random Forest. Subsequently, we use the self-supervised tasks to perform
unsupervised domain adaptation and benefit from the labeled samples in other
regions. It is crucial to know what information to transfer to avoid degrading
the performance. We show how to automate the information selection and transfer
process in cropland classification even when the source and target areas have a
very different feature distribution. We improved the model by about 24%
compared to a baseline architecture without any labeled sample in the target
domain. Our method is amenable to gradual improvement, works with
medium-resolution satellite images, and does not require complicated models.
Code and data are available.
",Houtan Ghaffari,Houtan Ghaffari,2021-03-17T12:10:11Z
"Revealing the chemical bonding in adatoms arrays via machine learning of
  3D scanning tunneling spectroscopy data","  The adatom arrays on surfaces offer an ideal playground to explore the
mechanisms of chemical bonding via changes in the local electronic tunneling
spectra. While this information is readily available in hyperspectral scanning
tunneling spectroscopy data, its analysis has been considerably impeded by a
lack of suitable analytical tools. Here we develop a machine learning based
workflow combining supervised feature identification in the spatial domain and
un-supervised clustering in the energy domain to reveal the details of
structure-dependent changes of the electronic structure in adatom arrays on the
Co3Sn2S2 cleaved surface. This approach, in combination with first-principles
calculations, provides insight for using artificial neural networks to detect
adatoms and classifies each based on their local neighborhood comprised of
other adatoms. These structurally classified adatoms are further spectrally
deconvolved. The unexpected inhomogeneity of electronic structures among
adatoms in similar configurations is unveiled using this method, suggesting
there is not a single atomic species of adatoms, but rather multiple types of
adatoms on the Co3Sn2S2 surface. This is further supported by a slight contrast
difference in the images (or slight size variation) of the topography of the
adatoms.
","Kevin M. Roccapriore, Qiang Zou, Lizhi Zhang, Rui Xue, Jiaqiang Yan, Maxim Ziatdinov, Mingming Fu, David Mandrus, Mina Yoon, Bobby Sumpter, Zheng Gai, Sergei V. Kalinin",Sergei V. Kalinin,2021-03-30T00:10:06Z
"Background-Suppressed High-Throughput Mid-Infrared Photothermal
  Microscopy via Pupil Engineering","  Mid-infrared photothermal (MIP) microscopy has been a promising label-free
chemical imaging technique for functional characterization of specimens owing
to its enhanced spatial resolution and high specificity. Recently developed
wide-field MIP imaging modalities have drastically improved speed and enabled
high-throughput imaging of micron-scale subjects. However, the weakly scattered
signal from sub-wavelength particles becomes indistinguishable from the
shot-noise as a consequence of the strong background light, leading to limited
sensitivity. Here, we demonstrate background-suppressed chemical fingerprinting
at a single nanoparticle level by selectively attenuating the reflected light
through pupil engineering in the collection path. Our technique provides over
three orders of magnitude background suppression by quasi-darkfield
illumination in epi-configuration without sacrificing lateral resolution. We
demonstrate 6-fold signal-to-background noise ratio improvement, allowing for
simultaneous detection and discrimination of hundreds of nanoparticles across a
field of view of 70 um x 70 um. A comprehensive theoretical framework for
photothermal image formation is provided and experimentally validated with 300
and 500~nm PMMA beads. The versatility and utility of our technique are
demonstrated via hyperspectral dark-field MIP imaging of S. aureus and E. coli
bacteria.
","Haonan Zong, Celalettin Yurdakul, Yeran Bai, Meng Zhang, M. Selim Unlu, Ji-Xin Cheng",Ji-Xin Cheng,2021-04-13T14:42:58Z
"A fast and Accurate Similarity-constrained Subspace Clustering Framework
  for Unsupervised Hyperspectral Image Classification","  Accurate land cover segmentation of spectral images is challenging and has
drawn widespread attention in remote sensing due to its inherent complexity.
Although significant efforts have been made for developing a variety of
methods, most of them rely on supervised strategies. Subspace clustering
methods, such as Sparse Subspace Clustering (SSC), have become a popular tool
for unsupervised learning due to their high performance. However, the
computational complexity of SSC methods prevents their use on large spectral
remotely sensed datasets. Furthermore, since SSC ignores the spatial
information in the spectral images, its discrimination capability is limited,
hampering the clustering results' spatial homogeneity. To address these two
relevant issues, in this paper, we propose a fast algorithm that obtains a
sparse representation coefficient matrix by first selecting a small set of
pixels that best represent their neighborhood. Then, it performs spatial
filtering to enforce the connectivity of neighboring pixels and uses fast
spectral clustering to get the final segmentation. Extensive simulations with
our method demonstrate its effectiveness in land cover segmentation, obtaining
remarkable high clustering performance compared with state-of-the-art SSC-based
algorithms and even novel unsupervised-deep-learning-based methods. Besides,
the proposed method is up to three orders of magnitude faster than SSC when
clustering more than $2 \times 10^4$ spectral pixels.
","Carlos Hinojosa, Esteban Vera, Henry Arguello",Henry Arguello,2021-04-14T16:58:12Z
"ASPCNet: A Deep Adaptive Spatial Pattern Capsule Network for
  Hyperspectral Image Classification","  Previous studies have shown the great potential of capsule networks for the
spatial contextual feature extraction from {hyperspectral images (HSIs)}.
However, the sampling locations of the convolutional kernels of capsules are
fixed and cannot be adaptively changed according to the inconsistent semantic
information of HSIs. Based on this observation, this paper proposes an adaptive
spatial pattern capsule network (ASPCNet) architecture by developing an
adaptive spatial pattern (ASP) unit, that can rotate the sampling location of
convolutional kernels on the basis of an enlarged receptive field. Note that
this unit can learn more discriminative representations of HSIs with fewer
parameters. Specifically, two cascaded ASP-based convolution operations
(ASPConvs) are applied to input images to learn relatively high-level semantic
features, transmitting hierarchical structures among capsules more accurately
than the use of the most fundamental features. Furthermore, the semantic
features are fed into ASP-based conv-capsule operations (ASPCaps) to explore
the shapes of objects among the capsules in an adaptive manner, further
exploring the potential of capsule networks. Finally, the class labels of image
patches centered on test samples can be determined according to the fully
connected capsule layer. Experiments on three public datasets demonstrate that
ASPCNet can yield competitive performance with higher accuracies than
state-of-the-art methods.
","Jinping Wang, Xiaojun Tan, Jianhuang Lai, Jun Li, Canqun Xiang",Canqun Xiang,2021-04-25T07:10:55Z
Two New Low Rank Tensor Completion Methods Based on Sum Nuclear Norm,"  The low rank tensor completion (LRTC) problem has attracted great attention
in computer vision and signal processing. How to acquire high quality image
recovery effect is still an urgent task to be solved at present. This paper
proposes a new tensor $L_{2,1}$ norm minimization model (TLNM) that integrates
sum nuclear norm (SNN) method, differing from the classical tensor nuclear norm
(TNN)-based tensor completion method, with $L_{2,1}$ norm and Qatar Riyal
decomposition for solving the LRTC problem. To improve the utilization rate of
the local prior information of the image, a total variation (TV) regularization
term is introduced, resulting in a new class of tensor $L_{2,1}$ norm
minimization with total variation model (TLNMTV). Both proposed models are
convex and therefore have global optimal solutions. Moreover, we adopt the
Alternating Direction Multiplier Method (ADMM) to obtain the closed-form
solution of each variable, thus ensuring the feasibility of the algorithm.
Numerical experiments show that the two proposed algorithms are convergent and
outperform compared methods. In particular, our method significantly
outperforms the contrastive methods when the sampling rate of hyperspectral
images is 2.5\%.
","Hongbing Zhang, Xinyi Liu, Hongtao Fan, Yajing Li, Yinlin Ye",Yinlin Ye,2021-08-06T08:35:33Z
"Deep Amended Gradient Descent for Efficient Spectral Reconstruction from
  Single RGB Images","  This paper investigates the problem of recovering hyperspectral (HS) images
from single RGB images. To tackle such a severely ill-posed problem, we propose
a physically-interpretable, compact, efficient, and end-to-end learning-based
framework, namely AGD-Net. Precisely, by taking advantage of the imaging
process, we first formulate the problem explicitly based on the classic
gradient descent algorithm. Then, we design a lightweight neural network with a
multi-stage architecture to mimic the formed amended gradient descent process,
in which efficient convolution and novel spectral zero-mean normalization are
proposed to effectively extract spatial-spectral features for regressing an
initialization, a basic gradient, and an incremental gradient. Besides, based
on the approximate low-rank property of HS images, we propose a novel rank loss
to promote the similarity between the global structures of reconstructed and
ground-truth HS images, which is optimized with our singular value weighting
strategy during training. Moreover, AGD-Net, a single network after one-time
training, is flexible to handle the reconstruction with various spectral
response functions. Extensive experiments over three commonly-used benchmark
datasets demonstrate that AGD-Net can improve the reconstruction quality by
more than 1.0 dB on average while saving 67$\times$ parameters and 32$\times$
FLOPs, compared with state-of-the-art methods. The code will be publicly
available at https://github.com/zbzhzhy/GD-Net.
","Zhiyu Zhu, Hui Liu, Junhui Hou, Sen Jia, Qingfu Zhang",Qingfu Zhang,2021-08-12T05:54:09Z
"Semantic-embedded Unsupervised Spectral Reconstruction from Single RGB
  Images in the Wild","  This paper investigates the problem of reconstructing hyperspectral (HS)
images from single RGB images captured by commercial cameras, \textbf{without}
using paired HS and RGB images during training. To tackle this challenge, we
propose a new lightweight and end-to-end learning-based framework.
Specifically, on the basis of the intrinsic imaging degradation model of RGB
images from HS images, we progressively spread the differences between input
RGB images and re-projected RGB images from recovered HS images via effective
unsupervised camera spectral response function estimation. To enable the
learning without paired ground-truth HS images as supervision, we adopt the
adversarial learning manner and boost it with a simple yet effective
$\mathcal{L}_1$ gradient clipping scheme. Besides, we embed the semantic
information of input RGB images to locally regularize the unsupervised
learning, which is expected to promote pixels with identical semantics to have
consistent spectral signatures. In addition to conducting quantitative
experiments over two widely-used datasets for HS image reconstruction from
synthetic RGB images, we also evaluate our method by applying recovered HS
images from real RGB images to HS-based visual tracking. Extensive results show
that our method significantly outperforms state-of-the-art unsupervised methods
and even exceeds the latest supervised method under some settings. The source
code is public available at
https://github.com/zbzhzhy/Unsupervised-Spectral-Reconstruction.
","Zhiyu Zhu, Hui Liu, Junhui Hou, Huanqiang Zeng, Qingfu Zhang",Qingfu Zhang,2021-08-15T05:19:44Z
"Near-field Hyperspectral Imaging of Resonant Mie Modes in a Dielectric
  Island","  All-dielectric, sub-micrometric particles have been successfully exploited
for light management in a plethora of applications at visible and near-infrared
frequency. However, the investigation of the intricacies of the Mie resonances
at the sub-wavelength scale has been hampered by the limitation of conventional
near-field methods. Here we address spatial and spectral mapping of multi-polar
modes of a Si island by hyper-spectral imaging. The simultaneous detection of
several resonant modes allows to clarify the role of substrate and incidence
angle of the impinging light, highlighting spectral splitting of the
quadrupolar mode and resulting in different spatial features of the field
intensity. We explore theoretically and experimentally such spatial features.
Details as small as 200 nm can be detected and are in agreement with
simulations based on a Finite Difference Time Domain method. Our results are
relevant to near-field imaging of dielectric structures, to the comprehension
of the photophysics of resonant Mie structures, to beam steering and to the
resonant coupling with light emitters. Our analysis paves the way for a novel
approach to control the spatial overlap of a single emitter with localized
electric field maxima.
","Nicoletta Granchi, Michele Montanari, Andrea Ristori, Mario Khoury, Mohammed Bouabdellaui, Chiara Barri, Luca Fagiani, Massimo Gurioli, Monica Bollani, Marco Abbarchi, Francesca Intonti",Francesca Intonti,2021-08-31T09:01:38Z
"Low-threshold exciton transport and control in atomically thin
  semiconductors","  Understanding and controlling the nanoscale transport of excitonic
quasiparticles in atomically thin 2D semiconductors is crucial to produce
highly efficient nano-excitonic devices. Here, we present a nano-gap device to
selectively confine excitons or trions of 2D transition metal dichalcogenides
at the nanoscale, facilitated by the drift-dominant exciton funnelling into the
strain-induced local spot. We investigate the spatio-spectral characteristics
of the funnelled excitons in a WSe2 monolayer (ML) and converted trions in a
MoS2 ML using hyperspectral tip-enhanced photoluminescence (TEPL) imaging with
<15 nm spatial resolution. In addition, we dynamically control the exciton
funnelling and trion conversion rate by the GPa scale tip pressure engineering.
Through a drift-diffusion model, we confirm an exciton funnelling efficiency of
~25 % with a significantly low strain threshold (~0.1 %) which sufficiently
exceeds the efficiency of ~3 % in previous studies. This work provides a new
strategy to facilitate efficient exciton transport and trion conversion of 2D
semiconductor devices.
","Hyeongwoo Lee, Yeonjeong Koo, Jinseong Choi, Shailabh Kumar, Hyoung-Taek Lee, Gangseon Ji, Soo Ho Choi, Mingu Kang, Ki Kang Kim, Hyeong-Ryeol Park, Hyuck Choo, Kyoung-Duck Park",Kyoung-Duck Park,2021-09-15T07:28:20Z
"Terahertz nanospectroscopy of plasmon polaritons for the evaluation of
  doping in quantum devices","  Terahertz (THz) waves are a highly sensitive probe of free carrier
concentrations in semiconducting materials. However, most experiments operate
in the far-field, which precludes the observation of nanoscale features that
affect the material response. Here, we demonstrate the use of nanoscale THz
plasmon polaritons as an indicator of surface quality in prototypical quantum
devices properties. Using THz near-field hyperspectral measurements, we observe
polaritonic features in doped silicon near a metal-semiconductor interface. The
presence of the THz surface plasmon polariton indicates the existence of a thin
film doped layer on the device. Using a multilayer extraction procedure
utilising vector calibration, we quantitatively probe the doped surface layer
and determine its thickness and complex permittivity. The recovered multilayer
characteristics match the dielectric conditions necessary to support the THz
surface plasmon polariton. Applying these findings to superconducting
resonators, we show that etching of this doped layer leads to an increase of
the quality factor as determined by cryogenic measurements. This study
demonstrates that THz scattering-type scanning near-field optical microscopy
(s-SNOM) is a promising diagnostic tool for characterization of surface
dielectric properties of quantum devices.
","Xiao Guo, Xin He, Zach Degnan, Chun-Ching Chiu, Bogdan C Donose, Karl Bertling, Arkady Fedorov, Aleksandar D Rakic, Peter Jacobson",Peter Jacobson,2021-10-12T07:07:39Z
Nonlinear Transform Induced Tensor Nuclear Norm for Tensor Completion,"  The linear transform-based tensor nuclear norm (TNN) methods have recently
obtained promising results for tensor completion. The main idea of this type of
methods is exploiting the low-rank structure of frontal slices of the targeted
tensor under the linear transform along the third mode. However, the
low-rankness of frontal slices is not significant under linear transforms
family. To better pursue the low-rank approximation, we propose a nonlinear
transform-based TNN (NTTNN). More concretely, the proposed nonlinear transform
is a composite transform consisting of the linear semi-orthogonal transform
along the third mode and the element-wise nonlinear transform on frontal slices
of the tensor under the linear semi-orthogonal transform, which are
indispensable and complementary in the composite transform to fully exploit the
underlying low-rankness. Based on the suggested low-rankness metric, i.e.,
NTTNN, we propose a low-rank tensor completion (LRTC) model. To tackle the
resulting nonlinear and nonconvex optimization model, we elaborately design the
proximal alternating minimization (PAM) algorithm and establish the theoretical
convergence guarantee of the PAM algorithm. Extensive experimental results on
hyperspectral images, multispectral images, and videos show that the our method
outperforms linear transform-based state-of-the-art LRTC methods qualitatively
and quantitatively.
","Ben-Zheng Li, Xi-Le Zhao, Teng-Yu Ji, Xiong-Jun Zhang, Ting-Zhu Huang",Ting-Zhu Huang,2021-10-17T09:25:37Z
"Robust Semi-Supervised Classification using GANs with Self-Organizing
  Maps","  Generative adversarial networks (GANs) have shown tremendous promise in
learning to generate data and effective at aiding semi-supervised
classification. However, to this point, semi-supervised GAN methods make the
assumption that the unlabeled data set contains only samples of the joint
distribution of the classes of interest, referred to as inliers. Consequently,
when presented with a sample from other distributions, referred to as outliers,
GANs perform poorly at determining that it is not qualified to make a decision
on the sample. The problem of discriminating outliers from inliers while
maintaining classification accuracy is referred to here as the DOIC problem. In
this work, we describe an architecture that combines self-organizing maps
(SOMs) with SS-GANS with the goal of mitigating the DOIC problem and
experimental results indicating that the architecture achieves the goal.
Multiple experiments were conducted on hyperspectral image data sets. The
SS-GANS performed slightly better than supervised GANS on classification
problems with and without the SOM. Incorporating the SOMs into the SS-GANs and
the supervised GANS led to substantially mitigation of the DOIC problem when
compared to SS-GANS and GANs without the SOMs. Furthermore, the SS-GANS
performed much better than GANS on the DOIC problem, even without the SOMs.
","Ronald Fick, Paul Gader, Alina Zare",Alina Zare,2021-10-19T22:07:45Z
"Freeze-frame approach for robust single-molecule tip-enhnaced Raman
  spectroscopy at room temperature","  A quantitative single-molecule tip-enhanced Raman spectroscopy (TERS) study
at room temperature remained a challenge due to the rapid structural dynamics
of molecules exposed to air. Here, we demonstrate the single-molecule level
hyperspectral TERS imaging of brilliant cresyl blue (BCB) at room temperature
for the first time, along with quantitative spectral analyses. Freeze-frame
approach using a thin Al2O3 capping layer, which suppresses spectral diffusions
and inhibits chemical reactions and contaminations in air, enabled reliable and
robust chemical imaging. For the molecules resolved spatially in the TERS
image, a clear Raman peak variation up to 7.5 cm-1 is observed, which cannot be
found in molecular ensembles. From density functional theory-based quantitative
analyses of the varied TERS peaks, we reveal the conformational heterogeneity
at the single-molecule level. This work provides a facile way to investigate
the single-molecule properties in interacting media, expanding the scope of
single-molecule vibrational spectroscopy.
","Mingu Kang, Hyunwoo Kim, Elham Oleiki, Yeonjeong Koo, Hyeongwoo Lee, Jinseong Choi, Taeyong Eom, Geunsik Lee, Yung Doug Suh, Kyoung-Duck Park",Kyoung-Duck Park,2021-10-25T04:52:10Z
"Technical note: On the use of polychromatic cameras for high spatial
  resolution spectral dose measurements","  Despite the demonstrated benefits of hyperspectral formalism for stem effect
corrections in the context of fiber dose measurements, this approach has not
been yet translated into volumetric measurements where cameras are typically
used for their distinguishing spatial resolution. This work investigates
demosaicing algorithms for polychromatic cameras based spectral imaging. The
scintillation and Cherenkov signals produced in a radioluminescent phantom are
imaged by a polychromatic camera and isolated using the spectral formalism. To
do so, five demosaicing algorithms are investigated from calibration to
measurements: a clustering method and four interpolation algorithms. The
resulting accuracy of scintillation and Cherenkov images is evaluated with
measurements of the differences (mean $\pm$ standard deviation) between the
obtained and expected signals from profiles drawn across a scintillation spot.
Signal-to-noise ratio and signal-to-background ratio are further measured and
compared in the resulting scintillation images. Clustering, OpenCV, bilinear,
Malvar and Menon demosaicing algorithms respectively yielded differences of
$3\pm6\%$, $0.1\pm0.5\%$, $0.5\pm0.5\%$, $1\pm3\%$ and $1\pm4\%$ in the
resulting scintillation images. For the Cherenkov images, all algorithms
provided differences below 1\%. All methods enabled measurements over the
detectability (SBR>2) and sensitivity (SNR>5) thresholds with the bilinear
algorithm providing the best SNR value. Hence, radioluminescent signals can
accurately be isolated using a single polychromatic camera. Moreover,
demosaicing using a bilinear kernel provided the best results and enabled stem
effect subtraction while preserving the full spatial resolution of the camera.
","Emily Cloutier, Luc Beaulieu, Louis Archambault",Louis Archambault,2021-11-30T20:22:14Z
"Spectral Compressive Imaging Reconstruction Using Convolution and
  Contextual Transformer","  Spectral compressive imaging (SCI) is able to encode the high-dimensional
hyperspectral image to a 2D measurement, and then uses algorithms to
reconstruct the spatio-spectral data-cube. At present, the main bottleneck of
SCI is the reconstruction algorithm, and the state-of-the-art (SOTA)
reconstruction methods generally face the problem of long reconstruction time
and/or poor detail recovery. In this paper, we propose a novel hybrid network
module, namely CCoT (Convolution and Contextual Transformer) block, which can
acquire the inductive bias ability of convolution and the powerful modeling
ability of transformer simultaneously,and is conducive to improving the quality
of reconstruction to restore fine details. We integrate the proposed CCoT block
into deep unfolding framework based on the generalized alternating projection
algorithm, and further propose the GAP-CCoT network. Through the experiments of
extensive synthetic and real data, our proposed model achieves higher
reconstruction quality ($>$2dB in PSNR on simulated benchmark datasets) and
shorter running time than existing SOTA algorithms by a large margin. The code
and models are publicly available at https://github.com/ucaswangls/GAP-CCoT.
","Lishun Wang, Zongliang Wu, Yong Zhong, Xin Yuan",Xin Yuan,2022-01-15T06:30:03Z
"An achromatic metafiber for focusing and imaging across the entire
  telecommunication range","  Dispersion engineering is essential to the performance of most modern optical
systems including fiber-optic devices. Even though the chromatic dispersion of
a meter-scale single-mode fiber used for endoscopic applications is negligible,
optical lenses located on the fiber end face for optical focusing and imaging
suffer from strong chromatic aberration. Here we present the design and
nanoprinting of a 3D achromatic diffractive metalens on the end face of a
single-mode fiber, capable of performing achromatic and
polarization-insensitive focusing across the entire near-infrared
telecommunication wavelength band ranging from 1.25 to 1.65 um. This represents
the whole single-mode domain of commercially used fibers. The unlocked height
degree of freedom in a 3D nanopillar meta-atom largely increases the upper
bound of the time-bandwidth product of an achromatic metalens up to 21.34,
leading to a wide group delay modulation range spanning from -8 to 14 fs.
Furthermore, we demonstrate the use of our compact and flexible achromatic
metafiber for fiber-optic confocal imaging, capable of creating in-focus sharp
images under broadband light illumination. These results may unleash the full
potential of fiber meta-optics for widespread applications including
hyperspectral endoscopic imaging, femtosecond laser-assisted treatment, deep
tissue imaging, wavelength-multiplexing fiber-optic communications, fiber
sensing, and fiber lasers.
","Haoran Ren, Jaehyuck Jang, Chenhao Li, Andreas Aigner, Malte Plidschun, Jisoo Kim, Junsuk Rho, Markus A. Schmidt, Stefan A. Maier",Stefan A. Maier,2022-01-18T18:03:40Z
"Exact Decomposition of Joint Low Rankness and Local Smoothness Plus
  Sparse Matrices","  It is known that the decomposition in low-rank and sparse matrices
(\textbf{L+S} for short) can be achieved by several Robust PCA techniques.
Besides the low rankness, the local smoothness (\textbf{LSS}) is a vitally
essential prior for many real-world matrix data such as hyperspectral images
and surveillance videos, which makes such matrices have low-rankness and local
smoothness properties at the same time. This poses an interesting question: Can
we make a matrix decomposition in terms of \textbf{L\&LSS +S } form exactly? To
address this issue, we propose in this paper a new RPCA model based on
three-dimensional correlated total variation regularization (3DCTV-RPCA for
short) by fully exploiting and encoding the prior expression underlying such
joint low-rank and local smoothness matrices. Specifically, using a
modification of Golfing scheme, we prove that under some mild assumptions, the
proposed 3DCTV-RPCA model can decompose both components exactly, which should
be the first theoretical guarantee among all such related methods combining low
rankness and local smoothness. In addition, by utilizing Fast Fourier Transform
(FFT), we propose an efficient ADMM algorithm with a solid convergence
guarantee for solving the resulting optimization problem. Finally, a series of
experiments on both simulations and real applications are carried out to
demonstrate the general validity of the proposed 3DCTV-RPCA model.
","Jiangjun Peng, Yao Wang, Hongying Zhang, Jianjun Wang, Deyu Meng",Deyu Meng,2022-01-29T13:58:03Z
"High-Performance Mid-IR to Deep-UV van der Waals Photodetectors Capable
  of Local Spectroscopy at Room Temperature","  The ability to perform broadband optical spectroscopy with
sub-diffraction-limit resolution is highly sought-after for a wide range of
critical applications. However, sophisticated tip-enhanced techniques are
currently required to achieve this goal. We bypass this challenge by
demonstrating an extremely broadband photodetector based on a two-dimensional
(2D) van der Waals heterostructure that is sensitive to light across over a
decade in energy from the mid-infrared (MIR) to deep-ultraviolet (DUV) at room
temperature. The devices feature high detectivity (> 10^9 cm Hz^1/2 W^-1)
together with high bandwidth (2.1 MHz). The active area can be further
miniaturized to submicron dimensions, far below the diffraction limit for the
longest detectable wavelength of 4.1 um, enabling such devices for facile
measurements of local optical properties on atomic-layer-thickness samples
placed in close proximity. This work can lead to the development of low-cost
and high-throughput photosensors for hyperspectral imaging at the nanoscale.
","Daozhi Shen, HeeBong Yang, Christian Spudat, Tarun Patel, Shazhou Zhong, Fangchu Chen, Jian Yan, Xuan Luo, Meixin Cheng, German Sciaini, Yuping Sun, Daniel A. Rhodes, Thomas Timusk, Y. Norman Zhou, Na Young Kim, Adam W. Tsen",Adam W. Tsen,2022-01-31T19:20:42Z
"Europa's Surface Water-ice Crystallinity and Correlations between Lineae
  and Hydrate Composition","  Europa's surface composition and evidence for cryovolcanic activity can
provide insight into the properties and composition of the subsurface ocean,
allowing the evaluation of its potential habitability. One promising avenue for
revealing the surface processing and subsurface activity are the relative
fractions of crystalline and amorphous water-ice observed on the surface, which
are influenced by temperature, charged particle bombardment, vapor deposition,
and cryovolcanic activity. The crystallinity observed on Europa's leading
hemisphere cannot be reproduced by thermophysical and particle flux modeling
alone, indicating that there may be additional processes influencing the
surface. We performed a spectral mixture analysis on hyperspectral image cubes
from the Galileo Near-Infrared Mapping Spectrometer (NIMS) to identify how
surface crystallinity is influenced by physical processing at a high spatial
resolution scale. We focus specifically on two image cubes, 15e015 closer to
the equator and 17e009 closer to the south pole, both on the leading
hemisphere. We performed a nonnegative least-squares spectral mixture analysis
to reveal both the non-ice composition and the water-ice crystallinity of the
surface. We found that amorphous water-ice dominates the spectrum at the
equator and the south pole. We estimated a mean crystallinity of ~35% within
the 15e015 NIMS cube and a mean crystallinity of ~15% within the 17e009 NIMS
cube, which is consistent with ground-based spectroscopically derived
crystallinities. We also identified a correlation of magnesium sulfate,
magnesium chloride, and hydrated sulfuric acid with lineae and ridges, which
may provide evidence for surface processing by upwelling subsurface material.
","Jodi R. Berdis, James R. Murphy, Nancy J. Chanover",Nancy J. Chanover,2022-02-15T14:16:28Z
Multiple multi-sample testing under arbitrary covariance dependency,"  Modern high-throughput biomedical devices routinely produce data on a large
scale, and the analysis of high-dimensional datasets has become commonplace in
biomedical studies. However, given thousands or tens of thousands of measured
variables in these datasets, extracting meaningful features poses a challenge.
In this article, we propose a procedure to evaluate the strength of the
associations between a nominal (categorical) response variable and multiple
features simultaneously. Specifically, we propose a framework of large-scale
multiple testing under arbitrary correlation dependency among test statistics.
First, marginal multinomial regressions are performed for each feature
individually. Second, we use an approach of multiple marginal models for each
baseline-category pair to establish asymptotic joint normality of the stacked
vector of the marginal multinomial regression coefficients. Third, we estimate
the (limiting) covariance matrix between the estimated coefficients from all
marginal models. Finally, our approach approximates the realized false
discovery proportion of a thresholding procedure for the marginal p-values, for
each baseline-category pair. The proposed approach offers a sensible trade-off
between the expected numbers of true and false rejections. Furthermore, we
demonstrate a practical application of the method on hyperspectral imaging
data. This dataset is obtained by a matrix-assisted laser desorption/ionization
(MALDI) instrument. MALDI demonstrates tremendous potential for clinical
diagnosis, particularly for cancer research. In our application, the nominal
response categories represent cancer subtypes.
","Vladimir Vutov, Thorsten Dickhaus",Thorsten Dickhaus,2022-02-24T20:17:04Z
"HDNet: High-resolution Dual-domain Learning for Spectral Compressive
  Imaging","  The rapid development of deep learning provides a better solution for the
end-to-end reconstruction of hyperspectral image (HSI). However, existing
learning-based methods have two major defects. Firstly, networks with
self-attention usually sacrifice internal resolution to balance model
performance against complexity, losing fine-grained high-resolution (HR)
features. Secondly, even if the optimization focusing on spatial-spectral
domain learning (SDL) converges to the ideal solution, there is still a
significant visual difference between the reconstructed HSI and the truth.
Therefore, we propose a high-resolution dual-domain learning network (HDNet)
for HSI reconstruction. On the one hand, the proposed HR spatial-spectral
attention module with its efficient feature fusion provides continuous and fine
pixel-level features. On the other hand, frequency domain learning (FDL) is
introduced for HSI reconstruction to narrow the frequency domain discrepancy.
Dynamic FDL supervision forces the model to reconstruct fine-grained
frequencies and compensate for excessive smoothing and distortion caused by
pixel-level losses. The HR pixel-level attention and frequency-level refinement
in our HDNet mutually promote HSI perceptual quality. Extensive quantitative
and qualitative evaluation experiments show that our method achieves SOTA
performance on simulated and real HSI datasets. Code and models will be
released at https://github.com/caiyuanhao1998/MST
","Xiaowan Hu, Yuanhao Cai, Jing Lin, Haoqian Wang, Xin Yuan, Yulun Zhang, Radu Timofte, Luc Van Gool",Luc Van Gool,2022-03-04T06:37:45Z
"HyperTransformer: A Textural and Spectral Feature Fusion Transformer for
  Pansharpening","  Pansharpening aims to fuse a registered high-resolution panchromatic image
(PAN) with a low-resolution hyperspectral image (LR-HSI) to generate an
enhanced HSI with high spectral and spatial resolution. Existing pansharpening
approaches neglect using an attention mechanism to transfer HR texture features
from PAN to LR-HSI features, resulting in spatial and spectral distortions. In
this paper, we present a novel attention mechanism for pansharpening called
HyperTransformer, in which features of LR-HSI and PAN are formulated as queries
and keys in a transformer, respectively. HyperTransformer consists of three
main modules, namely two separate feature extractors for PAN and HSI, a
multi-head feature soft attention module, and a spatial-spectral feature fusion
module. Such a network improves both spatial and spectral quality measures of
the pansharpened HSI by learning cross-feature space dependencies and
long-range details of PAN and LR-HSI. Furthermore, HyperTransformer can be
utilized across multiple spatial scales at the backbone for obtaining improved
performance. Extensive experiments conducted on three widely used datasets
demonstrate that HyperTransformer achieves significant improvement over the
state-of-the-art methods on both spatial and spectral quality measures.
Implementation code and pre-trained weights can be accessed at
https://github.com/wgcban/HyperTransformer.
","Wele Gedara Chaminda Bandara, Vishal M. Patel",Vishal M. Patel,2022-03-04T18:59:08Z
Multimodal Fusion Transformer for Remote Sensing Image Classification,"  Vision transformers (ViTs) have been trending in image classification tasks
due to their promising performance when compared to convolutional neural
networks (CNNs). As a result, many researchers have tried to incorporate ViTs
in hyperspectral image (HSI) classification tasks. To achieve satisfactory
performance, close to that of CNNs, transformers need fewer parameters. ViTs
and other similar transformers use an external classification (CLS) token which
is randomly initialized and often fails to generalize well, whereas other
sources of multimodal datasets, such as light detection and ranging (LiDAR)
offer the potential to improve these models by means of a CLS. In this paper,
we introduce a new multimodal fusion transformer (MFT) network which comprises
a multihead cross patch attention (mCrossPA) for HSI land-cover classification.
Our mCrossPA utilizes other sources of complementary information in addition to
the HSI in the transformer encoder to achieve better generalization. The
concept of tokenization is used to generate CLS and HSI patch tokens, helping
to learn a {distinctive representation} in a reduced and hierarchical feature
space. Extensive experiments are carried out on {widely used benchmark}
datasets {i.e.,} the University of Houston, Trento, University of Southern
Mississippi Gulfpark (MUUFL), and Augsburg. We compare the results of the
proposed MFT model with other state-of-the-art transformers, classical CNNs,
and conventional classifiers models. The superior performance achieved by the
proposed model is due to the use of multihead cross patch attention. The source
code will be made available publicly at
\url{https://github.com/AnkurDeria/MFT}.}
","Swalpa Kumar Roy, Ankur Deria, Danfeng Hong, Behnood Rasti, Antonio Plaza, Jocelyn Chanussot",Jocelyn Chanussot,2022-03-31T11:18:41Z
"Degradation-Aware Unfolding Half-Shuffle Transformer for Spectral
  Compressive Imaging","  In coded aperture snapshot spectral compressive imaging (CASSI) systems,
hyperspectral image (HSI) reconstruction methods are employed to recover the
spatial-spectral signal from a compressed measurement. Among these algorithms,
deep unfolding methods demonstrate promising performance but suffer from two
issues. Firstly, they do not estimate the degradation patterns and
ill-posedness degree from the highly related CASSI to guide the iterative
learning. Secondly, they are mainly CNN-based, showing limitations in capturing
long-range dependencies. In this paper, we propose a principled
Degradation-Aware Unfolding Framework (DAUF) that estimates parameters from the
compressed image and physical mask, and then uses these parameters to control
each iteration. Moreover, we customize a novel Half-Shuffle Transformer (HST)
that simultaneously captures local contents and non-local dependencies. By
plugging HST into DAUF, we establish the first Transformer-based deep unfolding
method, Degradation-Aware Unfolding Half-Shuffle Transformer (DAUHST), for HSI
reconstruction. Experiments show that DAUHST significantly surpasses
state-of-the-art methods while requiring cheaper computational and memory
costs. Code and models will be released at
https://github.com/caiyuanhao1998/MST
","Yuanhao Cai, Jing Lin, Haoqian Wang, Xin Yuan, Henghui Ding, Yulun Zhang, Radu Timofte, Luc Van Gool",Luc Van Gool,2022-05-20T11:37:44Z
Fast Multilevel Algorithms for Compressive Principle Component Pursuit,"  Recovering a low-rank matrix from highly corrupted measurements arises in
compressed sensing of structured high-dimensional signals (e.g., videos and
hyperspectral images among others). Robust principal component analysis (RPCA),
solved via principal component pursuit (PCP), recovers a low-rank matrix from
sparse corruptions that are of unknown value and support by decomposing the
observation matrix into two terms: a low-rank matrix and a sparse one,
accounting for sparse noise and outliers. In the more general setting, where
only a fraction of the data matrix has been observed, low-rank matrix recovery
is achieved by solving the compressive principle component pursuit (CPCP). Both
PCP and CPCP are well-studied convex programs, and numerous iterative
algorithms have been proposed for their optimisation. Nevertheless, these
algorithms involve singular value decomposition (SVD) at each iteration, which
renders their applicability challenging in the case of massive data. In this
paper, we propose a multilevel approach for the solution of PCP and CPCP
problems. The core principle behind our algorithm is to apply SVD in models of
lower-dimensionality than the original one and then lift its solution to the
original problem dimension. We show that the proposed algorithms are easy to
implement, converge at the same rate but with much lower iteration cost.
Numerical experiments on numerous synthetic and real problems indicate that the
proposed multilevel algorithms are several times faster than their original
counterparts, namely PCP and CPCP.
","Vahan Hovhannisyan, Yannis Panagakis, Panos Parpas, Stefanos Zafeiriou",Stefanos Zafeiriou,2022-06-27T15:30:22Z
"Multispectral large-area X-ray imaging enabled by stacked multilayer
  scintillators","  Conventional energy-integration black-white X-ray imaging lacks spectral
information of X-ray photons. Although X-ray spectra (energy) can be
distinguished by photon-counting technique typically with CdZnTe detectors, it
is very challenging to be applied to large-area flat-panel X-ray imaging
(FPXI). Herein, we design multi-layer stacked scintillators of different X-ray
absorption capabilities and scintillation spectrums, in this scenario, the
X-ray energy can be discriminated by detecting the emission spectra of each
scintillator, therefore the multispectral X-ray imaging can be easily obtained
by color or multispectral visible-light camera in one single shot of X-ray. To
verify this idea, stacked multilayer scintillators based on several emerging
metal halides were fabricated in the cost-effective and scalable solution
process, and proof-of-concept multi-energy FPXI were experimentally
demonstrated. The dual-energy X-ray image of a bone-muscle model clearly showed
the details that were invisible in conventional energy-integration FPXI. By
stacking four layers of specifically designed multilayer scintillators with
appropriate thicknesses, a prototype FPXI with four energy channels was
realized, proving its extendibility to multispectral or even hyperspectral
X-ray imaging. This study provides a facile and effective strategy to realize
energy-resolved flat-panel X-ray imaging.
","Peng Ran, Lurong Yang, Tingming Jiang, Xuehui Xu, Juan Hui, Yirong Su, Cuifang Kuang, Xu Liu,  Yang,  Yang", Yang,2022-06-23T15:19:14Z
"Majorization-minimization for Sparse Nonnegative Matrix Factorization
  with the $β$-divergence","  This article introduces new multiplicative updates for nonnegative matrix
factorization with the $\beta$-divergence and sparse regularization of one of
the two factors (say, the activation matrix). It is well known that the norm of
the other factor (the dictionary matrix) needs to be controlled in order to
avoid an ill-posed formulation. Standard practice consists in constraining the
columns of the dictionary to have unit norm, which leads to a nontrivial
optimization problem. Our approach leverages a reparametrization of the
original problem into the optimization of an equivalent scale-invariant
objective function. From there, we derive block-descent
majorization-minimization algorithms that result in simple multiplicative
updates for either $\ell_{1}$-regularization or the more ""aggressive""
log-regularization. In contrast with other state-of-the-art methods, our
algorithms are universal in the sense that they can be applied to any
$\beta$-divergence (i.e., any value of $\beta$) and that they come with
convergence guarantees. We report numerical comparisons with existing heuristic
and Lagrangian methods using various datasets: face images, an audio
spectrogram, hyperspectral data, and song play counts. We show that our methods
obtain solutions of similar quality at convergence (similar objective values)
but with significantly reduced CPU times.
","Arthur Marmin, José Henrique de Morais Goulart, Cédric Févotte",Cédric Févotte,2022-07-13T16:09:29Z
"Neural Network Learning of Chemical Bond Representations in Spectral
  Indices and Features","  In this paper we investigate neural networks for classification in
hyperspectral imaging with a focus on connecting the architecture of the
network with the physics of the sensing and materials present. Spectroscopy is
the process of measuring light reflected or emitted by a material as a function
wavelength. Molecular bonds present in the material have vibrational
frequencies which affect the amount of light measured at each wavelength. Thus
the measured spectrum contains information about the particular chemical
constituents and types of bonds. For example, chlorophyll reflects more light
in the near-IR rage (800-900nm) than in the red (625-675nm) range, and this
difference can be measured using a normalized vegetation difference index
(NDVI), which is commonly used to detect vegetation presence, health, and type
in imagery collected at these wavelengths. In this paper we show that the
weights in a Neural Network trained on different vegetation classes learn to
measure this difference in reflectance. We then show that a Neural Network
trained on a more complex set of ten different polymer materials will learn
spectral 'features' evident in the weights for the network, and these features
can be used to reliably distinguish between the different types of polymers.
Examination of the weights provides a human-interpretable understanding of the
network.
",Bill Basener,Bill Basener,2022-07-21T15:11:51Z
"Target Identification and Bayesian Model Averaging with Probabilistic
  Hierarchical Factor Probabilities","  Target detection in hyperspectral imagery is the process of locating pixels
from an image which are likely to contain target, typically done by comparing
one or more spectra for the desired target material to each pixel in the image.
Target identification is the process of target detection incorporating an
additional process to identify more specifically the material that is present
in each pixel that scored high in detection. Detection is generally a 2-class
problem of target vs. background, and identification is a many class problem
including target, background, and additional know materials. The identification
process we present is probabilistic and hierarchical which provides
transparency to the process and produces trustworthy output. In this paper we
show that target identification has a much lower false alarm rate than
detection alone, and provide a detailed explanation of a robust identification
method using probabilistic hierarchical classification that handles the vague
categories of materials that depend on users which are different than the
specific physical categories of chemical constituents. Identification is often
done by comparing mixtures of materials including the target spectra to
mixtures of materials that do not include the target spectra, possibly with
other steps. (band combinations, feature checking, background removal, etc.)
Standard linear regression does not handle these problems well because the
number of regressors (identification spectra) is greater than the number of
feature variables (bands), and there are multiple correlated spectra. Our
proposed method handles these challenges efficiently and provides additional
important practical information in the form of hierarchical probabilities
computed from Bayesian model averaging.
",William Basener,William Basener,2022-07-21T13:38:39Z
"Hyperspectral imaging of excitons within a moiré unit-cell with a
  sub-nanometer electron probe","  Electronic and optical excitations in two-dimensional moir\'e systems are
uniquely sensitive to local atomic registries, leading to materials- and
twist-angle specific correlated electronic ground states with varied degree of
localization. However, there has been no direct experimental correlation
between the sub-nanometer structure and emergent excitonic transitions,
comprising tightly-bound pairs of photoexcited electrons and holes. Here, we
use cryogenic transmission electron microscopy and spectroscopy to
simultaneously image the structural reconstruction and associated localization
of the lowest-energy intralayer exciton in a rotationally aligned
heterostructure of WS2 and WSe2 monolayers. In conjunction with optical
spectroscopy and ab initio calculations, we determine that the exciton
center-of-mass wavefunction is strongly modulated in space, confined to a
radius of ~ 2 nm around the highest-energy stacking site in the moir\'e
unit-cell, forming a triangular lattice. Our results provide direct evidence
that atomic reconstructions lead to the strongly confining moir\'e potentials
and that engineering strain at the nanoscale will enable new types of excitonic
lattices.
","Sandhya Susarla, Mit H. Naik, Daria D. Blach, Jonas Zipfel, Takashi Taniguchi, Kenji Watanabe, Libai Huang, Ramamoorthy Ramesh, Felipe H. da Jornada, Steven G. Louie, Peter Ercius, Archana Raja",Archana Raja,2022-07-27T23:24:12Z
"Graph Neural Networks Extract High-Resolution Cultivated Land Maps from
  Sentinel-2 Image Series","  Maintaining farm sustainability through optimizing the agricultural
management practices helps build more planet-friendly environment. The emerging
satellite missions can acquire multi- and hyperspectral imagery which captures
more detailed spectral information concerning the scanned area, hence allows us
to benefit from subtle spectral features during the analysis process in
agricultural applications. We introduce an approach for extracting 2.5 m
cultivated land maps from 10 m Sentinel-2 multispectral image series which
benefits from a compact graph convolutional neural network. The experiments
indicate that our models not only outperform classical and deep machine
learning techniques through delivering higher-quality segmentation maps, but
also dramatically reduce the memory footprint when compared to U-Nets (almost
8k trainable parameters of our models, with up to 31M parameters of U-Nets).
Such memory frugality is pivotal in the missions which allow us to uplink a
model to the AI-powered satellite once it is in orbit, as sending large nets is
impossible due to the time constraints.
","Lukasz Tulczyjew, Michal Kawulok, Nicolas Longépé, Bertrand Le Saux, Jakub Nalepa",Jakub Nalepa,2022-08-03T21:19:06Z
"Massively Parallel Universal Linear Transformations using a
  Wavelength-Multiplexed Diffractive Optical Network","  We report deep learning-based design of a massively parallel broadband
diffractive neural network for all-optically performing a large group of
arbitrarily-selected, complex-valued linear transformations between an input
and output field-of-view, each with N_i and N_o pixels, respectively. This
broadband diffractive processor is composed of N_w wavelength channels, each of
which is uniquely assigned to a distinct target transformation. A large set of
arbitrarily-selected linear transformations can be individually performed
through the same diffractive network at different illumination wavelengths,
either simultaneously or sequentially (wavelength scanning). We demonstrate
that such a broadband diffractive network, regardless of its material
dispersion, can successfully approximate N_w unique complex-valued linear
transforms with a negligible error when the number of diffractive neurons (N)
in its design matches or exceeds 2 x N_w x N_i x N_o. We further report that
the spectral multiplexing capability (N_w) can be increased by increasing N;
our numerical analyses confirm these conclusions for N_w > 180, which can be
further increased to e.g., ~2000 depending on the upper bound of the
approximation error. Massively parallel, wavelength-multiplexed diffractive
networks will be useful for designing high-throughput intelligent machine
vision systems and hyperspectral processors that can perform statistical
inference and analyze objects/scenes with unique spectral properties.
","Jingxi Li, Bijie Bai, Yi Luo, Aydogan Ozcan",Aydogan Ozcan,2022-08-13T07:59:39Z
"Nonlinear optical signal generation mediated by a plasmonic azimuthally
  chirped grating","  The deployment of plasmonic nanostructures to enhance nonlinear signal
generation requires effective far-to-near field coupling and phase matching for
frequency conversion. While the latter can be easily achieved at plasmonic
hotspots, the former is an antenna problem that requires dedicated structural
design and optimization. Plasmonic gratings are a simple but effective platform
for nonlinear signal generation since they provide a well-defined momentum for
photon-plasmon coupling and local hotspots for frequency conversion. In this
work, a plasmonic azimuthally chirped grating (ACG), which provides spatially
resolved broadband momentum for photon-plasmon coupling, was exploited to
investigate the plasmonic enhancement effect in two nonlinear optical
processes, namely two-photon photoluminescence (TPPL) and second-harmonic
generation (SHG). The spatial distributions of the nonlinear signals were
determined experimentally by hyperspectral mapping with ultrashort pulsed
excitation. The experimental spatial distributions of nonlinear signals agree
very well with the analytical prediction based solely on photon-plasmon
coupling with the momentum of the ACG, revealing the antenna function of the
grating in plasmonic nonlinear signal generation. This work highlights the
importance of the antenna effect of the gratings for nonlinear signal
generation and provides insight into the enhancement mechanism of plasmonic
gratings in addition to local hotspot engineering.
","Parijat Barman, Abhik Chakraborty, Denis Akimov, Ankit Kumar Singh, Tobias Meyer-Zedler, Xiaofei Wu, Carsten Ronning, Michael Schmitt, Jürgen Popp, Jer-Shing Huang",Jer-Shing Huang,2022-08-24T12:11:02Z
Transformers in Remote Sensing: A Survey,"  Deep learning-based algorithms have seen a massive popularity in different
areas of remote sensing image analysis over the past decade. Recently,
transformers-based architectures, originally introduced in natural language
processing, have pervaded computer vision field where the self-attention
mechanism has been utilized as a replacement to the popular convolution
operator for capturing long-range dependencies. Inspired by recent advances in
computer vision, remote sensing community has also witnessed an increased
exploration of vision transformers for a diverse set of tasks. Although a
number of surveys have focused on transformers in computer vision in general,
to the best of our knowledge we are the first to present a systematic review of
recent advances based on transformers in remote sensing. Our survey covers more
than 60 recent transformers-based methods for different remote sensing problems
in sub-areas of remote sensing: very high-resolution (VHR), hyperspectral (HSI)
and synthetic aperture radar (SAR) imagery. We conclude the survey by
discussing different challenges and open issues of transformers in remote
sensing. Additionally, we intend to frequently update and maintain the latest
transformers in remote sensing papers with their respective code at:
https://github.com/VIROBO-15/Transformer-in-Remote-Sensing
","Abdulaziz Amer Aleissaee, Amandeep Kumar, Rao Muhammad Anwer, Salman Khan, Hisham Cholakkal, Gui-Song Xia, Fahad Shahbaz khan",Fahad Shahbaz khan,2022-09-02T17:57:05Z
"Library transfer between distinct Laser-Induced Breakdown Spectroscopy
  systems with shared standards","  The mutual incompatibility of distinct spectroscopic systems is among the
most limiting factors in Laser-Induced Breakdown Spectroscopy (LIBS). The cost
related to setting up a new LIBS system is increased, as its extensive
calibration is required. Solving the problem would enable inter-laboratory
reference measurements and shared spectral libraries, which are fundamental for
other spectroscopic techniques. In this work, we study a simplified version of
this challenge where LIBS systems differ only in used spectrometers and
collection optics but share all other parts of the apparatus, and collect
spectra simultaneously from the same plasma plume. Extensive datasets measured
as hyperspectral images of heterogeneous specimens are used to train machine
learning models that can transfer spectra between systems. The transfer is
realized by a pipeline that consists of a variational autoencoder (VAE) and a
fully-connected artificial neural network (ANN). In the first step, we obtain a
latent representation of the spectra which were measured on the Primary system
(by using the VAE). In the second step, we map spectra from the Secondary
system to corresponding locations in the latent space (by the ANN). Finally,
Secondary system spectra are reconstructed from the latent space to the space
of the Primary system. The transfer is evaluated by several figures of merit
(Euclidean and cosine distances, both spatially resolved; k-means clustering of
transferred spectra). The methodology is compared to several baseline
approaches.
","J. Vrábel, E. Képeš, P. Nedělník, J. Buday, J. Cempírek, P. Pořízka, J. Kaiser",J. Kaiser,2022-08-31T16:15:55Z
"Quantifying and correcting geolocation error in spaceborne LiDAR forest
  canopy observations using high spatial accuracy ALS: A Bayesian model
  approach","  Geolocation error in spaceborne sampling light detection and ranging (LiDAR)
measurements of forest structure can compromise forest attribute estimates and
degrade integration with georeferenced field measurements or other remotely
sensed data. Data integration is especially problematic when geolocation error
is not well quantified. We propose a general model that uses airborne laser
scanning (ALS) data to quantify and correct geolocation error in spaceborne
sampling LiDAR. To illustrate the model, LiDAR data from NASA Goddard's LiDAR
Hyperspectral & Thermal Imager (G-LiHT) was used with a subset of LiDAR data
from NASA's Global Ecosystem Dynamics Investigation (GEDI). The model
accommodates multiple canopy height metrics derived from a simulated GEDI
footprint kernel using spatially coincident G-LiHT, and incorporates both
additive and multiplicative mapping between the canopy height metrics generated
from both datasets. A Bayesian implementation provides probabilistic
uncertainty quantification in both parameter and geolocation error estimates.
Results show a systematic geolocation error of 9.62 m in the southwest
direction. In addition, estimated geolocation errors within GEDI footprints
were highly variable, with results showing a ~0.45 probability the true
footprint center is within 20 m. Estimating and correcting geolocation error
via the model outlined here can help inform subsequent efforts to integrate
spaceborne LiDAR data, like GEDI, with other georeferenced data.
","Elliot S. Shannon, Andrew O. Finley, Daniel J. Hayes, Sylvia N. Noralez, Aaron R. Weiskittel, Bruce D. Cook, Chad Babcock",Chad Babcock,2022-09-23T18:32:59Z
Upconversion time-stretch infrared spectroscopy,"  High-speed measurement confronts the extreme speed limit when the signal
becomes comparable to the noise level. In the context of broadband mid-infrared
spectroscopy, state-of-the-art ultrafast Fourier-transform infrared
spectrometers, in particular dual-comb spectrometers, have improved the
measurement rate up to a few Mspectra/s, which is limited by the
signal-to-noise ratio. Time-stretch infrared spectroscopy, an emerging
ultrafast frequency-swept mid-infrared spectroscopy technique, has shown a
record-high rate of 80 Mspectra/s with an intrinsically higher signal-to-noise
ratio than Fourier-transform spectroscopy by more than the square-root of the
number of spectral elements. However, it can measure no more than ~30 spectral
elements with a low resolution of several cm-1. Here, we significantly increase
the measurable number of spectral elements to more than 1,000 by incorporating
a nonlinear upconversion process. The one-to-one mapping of a broadband
spectrum from the mid-infrared to the near-infrared telecommunication region
enables low-loss time-stretching with a single-mode optical fiber and low-noise
signal detection with a high-bandwidth photoreceiver. We demonstrate
high-resolution mid-infrared spectroscopy of gas-phase methane molecules with a
high resolution of 0.017 cm-1. This unprecedentedly high-speed vibrational
spectroscopy technique would satisfy various unmet needs in experimental
molecular science, e.g., measuring ultrafast dynamics of irreversible
phenomena, statistically analyzing a large amount of heterogeneous spectral
data, or taking broadband hyperspectral images at a high frame rate.
","Kazuki Hashimoto, Takuma Nakamura, Takahiro Kageyama, Venkata Ramaiah Badarla, Hiroyuki Shimada, Ryoich Horisaki, Takuro Ideguchi",Takuro Ideguchi,2022-09-26T02:02:46Z
"Ethylenediamine Addition Improves Performance and Suppresses Phase
  Instabilities in Mixed-Halide Perovskites","  We show that adding ethylenediamine (EDA) to perovskite precursor solution
improves the photovoltaic device performance and material stability of
high-bromide-content, methylammonium-free, formamidinium cesium lead halide
perovskites FA1-xCsxPb(I1-yBry)3 which are currently of interest for
perovskite-on-Si tandem solar cells. Using spectroscopy and hyperspectral
microscopy, we show that the additive improves film homogeneity and suppresses
the phase instability that is ubiquitous in high-Br perovskite formulations,
producing films that remain stable for over 100 days in ambient conditions.
With the addition of 1 mol% EDA we demonstrate 1.69 eV-gap perovskite
single-junction p-i-n devices with a VOC of 1.22 V, and a champion maximum
power point tracked power conversion efficiency of 18.8%, comparable to the
best reported methylammonium-free perovskites. Using nuclear magnetic resonance
(NMR) spectroscopy and X-ray diffraction techniques, we show that EDA reacts
with FA+ in solution, rapidly and quantitatively forming imidazolinium cations.
It is the presence of imidazolinium during crystallization which drives the
improved perovskite thin-film properties.
","Margherita Taddei, Joel A. Smith, Benjamin M. Gallant, Suer Zhou, Robert J. E. Westbrook, Yangwei Shi, Jian Wang, James N. Drysdale, Declan P. McCarthy, Stephen Barlow, Seth R. Marder, Henry J. Snaith, David S. Ginger",David S. Ginger,2022-09-29T21:08:32Z
"A roadmap for edge computing enabled automated multidimensional
  transmission electron microscopy","  The advent of modern, high-speed electron detectors has made the collection
of multidimensional hyperspectral transmission electron microscopy datasets,
such as 4D-STEM, a routine. However, many microscopists find such experiments
daunting since such datasets' analysis, collection, long-term storage, and
networking remain challenging. Some common issues are the large and unwieldy
size of the said datasets, often running into several gigabytes,
non-standardized data analysis routines, and a lack of clarity about the
computing and network resources needed to utilize the electron microscope
fully. However, the existing computing and networking bottlenecks introduce
significant penalties in each step of these experiments, and thus, real-time
analysis-driven automated experimentation for multidimensional TEM is
exceptionally challenging. One solution is integrating microscopy with edge
computing, where moderately powerful computational hardware performs the
preliminary analysis before handing off the heavier computation to HPC systems.
In this perspective, we trace the roots of computation in modern electron
microscopy, demonstrate deep learning experiments running on an edge system,
and discuss the networking requirements for tying together microscopes, edge
computers, and HPC systems.
","Debangshu Mukherjee, Kevin M. Roccapriore, Anees Al-Najjar, Ayana Ghosh, Jacob D. Hinkle, Andrew R. Lupini, Rama K. Vasudevan, Sergei V. Kalinin, Olga S. Ovchinnikova, Maxim A. Ziatdinov, Nageswara S. Rao",Nageswara S. Rao,2022-10-05T20:13:58Z
"Guided Nonlocal Patch Regularization and Efficient Filtering-Based
  Inversion for Multiband Fusion","  In multiband fusion, an image with a high spatial and low spectral resolution
is combined with an image with a low spatial but high spectral resolution to
produce a single multiband image having high spatial and spectral resolutions.
This comes up in remote sensing applications such as pansharpening~(MS+PAN),
hyperspectral sharpening~(HS+PAN), and HS-MS fusion~(HS+MS). Remote sensing
images are textured and have repetitive structures. Motivated by nonlocal
patch-based methods for image restoration, we propose a convex regularizer that
(i) takes into account long-distance correlations, (ii) penalizes patch
variation, which is more effective than pixel variation for capturing texture
information, and (iii) uses the higher spatial resolution image as a guide
image for weight computation. We come up with an efficient ADMM algorithm for
optimizing the regularizer along with a standard least-squares loss function
derived from the imaging model. The novelty of our algorithm is that by
expressing patch variation as filtering operations and by judiciously splitting
the original variables and introducing latent variables, we are able to solve
the ADMM subproblems efficiently using FFT-based convolution and
soft-thresholding. As far as the reconstruction quality is concerned, our
method is shown to outperform state-of-the-art variational and deep learning
techniques.
","Unni V. S., Pravin Nair, Kunal N. Chaudhury",Kunal N. Chaudhury,2022-10-09T06:32:51Z
"Experimental Design for Multi-Channel Imaging via Task-Driven Feature
  Selection","  This paper presents a data-driven, task-specific paradigm for experimental
design, to shorten acquisition time, reduce costs, and accelerate the
deployment of imaging devices. Current approaches in experimental design focus
on model-parameter estimation and require specification of a particular model,
whereas in imaging, other tasks may drive the design. Furthermore, such
approaches often lead to intractable optimization problems in real-world
imaging applications. Here we present a new paradigm for experimental design
that simultaneously optimizes the design (set of image channels) and trains a
machine-learning model to execute a user-specified image-analysis task. The
approach obtains data densely-sampled over the measurement space (many image
channels) for a small number of acquisitions, then identifies a subset of
channels of prespecified size that best supports the task. We propose a method:
TADRED for TAsk-DRiven Experimental Design in imaging, to identify the most
informative channel-subset whilst simultaneously training a network to execute
the task given the subset. Experiments demonstrate the potential of TADRED in
diverse imaging applications: several clinically-relevant tasks in magnetic
resonance imaging; and remote sensing and physiological applications of
hyperspectral imaging. Results show substantial improvement over classical
experimental design, two recent application-specific methods within the new
paradigm, and state-of-the-art approaches in supervised feature selection. We
anticipate further applications of our approach. Code is available:
https://github.com/sbb-gh/experimental-design-multichannel
","Stefano B. Blumberg, Paddy J. Slator, Daniel C. Alexander",Daniel C. Alexander,2022-10-13T10:36:24Z
"Bayesian Layer Graph Convolutioanl Network for Hyperspetral Image
  Classification","  In recent years, research on hyperspectral image (HSI) classification has
continuous progress on introducing deep network models, and recently the graph
convolutional network (GCN) based models have shown impressive performance.
However, these deep learning frameworks based on point estimation suffer from
low generalization and inability to quantify the classification results
uncertainty. On the other hand, simply applying the Bayesian Neural Network
(BNN) based on distribution estimation to classify the HSI is unable to achieve
high classification accuracy due to the large amount of parameters. In this
paper, we design a Bayesian layer with Bayesian idea as an insertion layer into
point estimation based neural networks, and propose a Bayesian Layer Graph
Convolutional Network (BLGCN) model by combining graph convolution operations,
which can effectively extract graph information and estimate the uncertainty of
classification results. Moreover, a Generative Adversarial Network (GAN) is
built to solve the sample imbalance problem of HSI dataset. Finally, we design
a dynamic control training strategy based on the confidence interval of the
classification results, which will terminate the training early when the
confidence interval reaches the preseted threshold. The experimental results
show that our model achieves a balance between high classification accuracy and
strong generalization. In addition, it can quantifies the uncertainty of the
classification results.
","Mingyang Zhang, Ziqi Di, Maoguo Gong, Yue Wu, Hao Li, Xiangming Jiang",Xiangming Jiang,2022-11-14T12:56:56Z
"U2Net: A General Framework with Spatial-Spectral-Integrated Double U-Net
  for Image Fusion","  In image fusion tasks, images obtained from different sources exhibit
distinct properties. Consequently, treating them uniformly with a single-branch
network can lead to inadequate feature extraction. Additionally, numerous works
have demonstrated that multi-scaled networks capture information more
sufficiently than single-scaled models in pixel-level computer vision problems.
Considering these factors, we propose U2Net, a spatial-spectral-integrated
double U-shape network for image fusion. The U2Net utilizes a spatial U-Net and
a spectral U-Net to extract spatial details and spectral characteristics, which
allows for the discriminative and hierarchical learning of features from
diverse images. In contrast to most previous works that merely employ
concatenation to merge spatial and spectral information, this paper introduces
a novel spatial-spectral integration structure called S2Block, which combines
feature maps from different sources in a logical and effective way. We conduct
a series of experiments on two image fusion tasks, including remote sensing
pansharpening and hyperspectral image super-resolution (HISR). The U2Net
outperforms representative state-of-the-art (SOTA) approaches in both
quantitative and qualitative evaluations, demonstrating the superiority of our
method. The code is available at https://github.com/PSRben/U2Net.
","Siran Peng, Chenhao Guo, Xiao Wu, Liang-Jian Deng",Liang-Jian Deng,2022-12-13T10:34:16Z
Tensor Denoising via Amplification and Stable Rank Methods,"  Tensors in the form of multilinear arrays are ubiquitous in data science
applications. Captured real-world data, including video, hyperspectral images,
and discretized physical systems, naturally occur as tensors and often come
with attendant noise. Under the additive noise model and with the assumption
that the underlying clean tensor has low rank, many denoising methods have been
created that utilize tensor decomposition to effect denoising through low rank
tensor approximation. However, all such decomposition methods require
estimating the tensor rank, or related measures such as the tensor spectral and
nuclear norms, all of which are NP-hard problems.
  In this work we leverage our previously developed framework of
$\textit{tensor amplification}$, which provides good approximations of the
spectral and nuclear tensor norms, to denoising synthetic tensors of various
sizes, ranks, and noise levels, along with real-world tensors derived from
physiological signals. We also introduce two new notions of tensor rank --
$\textit{stable slice rank}$ and $\textit{stable }$$X$$\textit{-rank}$ -- and
new denoising methods based on their estimation. The experimental results show
that in the low rank context, tensor-based amplification provides comparable
denoising performance in high signal-to-noise ratio (SNR) settings and superior
performance in noisy (i.e., low SNR) settings, while the stable $X$-rank method
achieves superior denoising performance on the physiological signal data.
","Jonathan Gryak, Kayvan Najarian, Harm Derksen",Harm Derksen,2023-01-10T02:46:09Z
Metasurface-enhanced mid-infrared spectrochemical imaging of tissues,"  Label-free and nondestructive mid-infrared vibrational hyperspectral imaging
is emerging as an important ex-vivo tissue analysis tool, providing spatially
resolved biochemical information critical to understanding physiological and
pathological processes. However, the chemically complex and spatially
heterogeneous composition of tissue specimens and the inherently weak
interaction of infrared light with biomolecules limit the analytical
performance of infrared absorption spectroscopy. Here, we introduce an advanced
mid-infrared spectrochemical tissue imaging modality using metasurfaces that
support strong surface-localized electromagnetic fields to capture quantitative
molecular maps of large-area murine brain-tissue sections. Our approach
leverages polarization-multiplexed multi-resonance plasmonic metasurfaces to
simultaneously detect many different functional biomolecules. The resulting
surface-enhanced mid-infrared spectral imaging (SE-MIRSI) method eliminates the
non-specific effects of bulk tissue morphology on the quantitative analysis of
fingerprint spectra and improves the chemical selectivity. We show that the
metasurface enhancement increases the retrieval of amide I and II absorption
bands associated with secondary structures of proteins. Moreover, we
demonstrate that plasmonic metasurfaces enhance the chemical contrast in
infrared images and enable the detection of ultrathin tissue regions that are
not otherwise visible to conventional mid-infrared spectral imaging. While we
tested our approach on murine brain tissue sections, this chemical imaging
method is well-suited for any tissue type, which significantly broadens the
potential impacts of our method for both translational research and clinical
histopathology.
","S. Rosas, K. A. Schoeller, E. Chang, H. Mei, M. A. Kats, K. W. Eliceiri, X. Zhao, F. Yesilkoy",F. Yesilkoy,2023-01-14T10:37:49Z
Quantum-inspired tensor network for Earth science,"  Deep Learning (DL) is one of many successful methodologies to extract
informative patterns and insights from ever increasing noisy large-scale
datasets (in our case, satellite images). However, DL models consist of a few
thousand to millions of training parameters, and these training parameters
require tremendous amount of electrical power for extracting informative
patterns from noisy large-scale datasets (e.g., computationally expensive).
Hence, we employ a quantum-inspired tensor network for compressing trainable
parameters of physics-informed neural networks (PINNs) in Earth science. PINNs
are DL models penalized by enforcing the law of physics; in particular, the law
of physics is embedded in DL models. In addition, we apply tensor decomposition
to HyperSpectral Images (HSIs) to improve their spectral resolution. A
quantum-inspired tensor network is also the native formulation to efficiently
represent and train quantum machine learning models on big datasets on GPU
tensor cores. Furthermore, the key contribution of this paper is twofold: (I)
we reduced a number of trainable parameters of PINNs by using a
quantum-inspired tensor network, and (II) we improved the spectral resolution
of remotely-sensed images by employing tensor decomposition. As a benchmark
PDE, we solved Burger's equation. As practical satellite data, we employed HSIs
of Indian Pine, USA and of Pavia University, Italy.
","Soronzonbold Otgonbaatar, Dieter Kranzlmüller",Dieter Kranzlmüller,2023-01-15T08:35:37Z
In-situ Water quality monitoring in Oil and Gas operations,"  From agriculture to mining, to energy, surface water quality monitoring is an
essential task. As oil and gas operators work to reduce the consumption of
freshwater, it is increasingly important to actively manage fresh and non-fresh
water resources over the long term. For large-scale monitoring, manual sampling
at many sites has become too time-consuming and unsustainable, given the sheer
number of dispersed ponds, small lakes, playas, and wetlands over a large area.
Therefore, satellite-based environmental monitoring presents great potential.
Many existing satellite-based monitoring studies utilize index-based methods to
monitor large water bodies such as rivers and oceans. However, these existing
methods fail when monitoring small ponds-the reflectance signal received from
small water bodies is too weak to detect. To address this challenge, we propose
a new Water Quality Enhanced Index (WQEI) Model, which is designed to enable
users to determine contamination levels in water bodies with weak reflectance
patterns. Our results show that 1) WQEI is a good indicator of water turbidity
validated with 1200 water samples measured in the laboratory, and 2) by
applying our method to commonly available satellite data (e.g. LandSat8), one
can achieve high accuracy water quality monitoring efficiently in large
regions. This provides a tool for operators to optimize the quality of water
stored within surface storage ponds and increasing the readiness and
availability of non-fresh water.
","Satish Kumar, Rui Kou, Henry Hill, Jake Lempges, Eric Qian, Vikram Jayaram",Vikram Jayaram,2023-01-20T20:56:52Z
"Bibliometric and social network analysis on the use of satellite imagery
  in agriculture: an entropy-based approach","  Satellite imagery is gaining popularity as a valuable tool to lower the
impact on natural resources and increase profits for farmers. The purpose of
this study is twofold: to mine the scientific literature to reveal the
structure of this research domain, and to investigate to what extent scientific
results can reach a wider public audience. To meet these two objectives, a Web
of Science and a Twitter dataset were retrieved and analysed, respectively. For
the academic literature, different performances of various countries were
observed: the USA and China resulted as the leading actors, both in terms of
published papers and employed researchers. Among the categorised keywords,
""resolution"", ""Landsat"", ""yield"", ""wheat"" and ""multispectral"" are the most
used. Then, analysing the semantic network of the words used in the various
abstracts, the different facets of the research in satellite remote sensing
were detected. The importance of retrieving meteorological parameters through
remote sensing and the broad use of vegetation indexes emerged from these
analyses. As emerging topics, classification tasks for land use assessment and
crop recognition stand out, alongside the use of hyperspectral sensors.
Regarding the interaction of academia with the public, the analysis showed that
it is practically absent on Twitter: most of the activity therein stems from
private companies advertising their business. This shows that there is still a
communication gap between academia and actors from other societal sectors.
","Riccardo Dainelli, Fabio Saracco",Fabio Saracco,2023-02-01T10:46:32Z
"Apple scab detection in orchards using deep learning on colour and
  multispectral images","  Apple scab is a fungal disease caused by Venturia inaequalis. Disease is of
particular concern for growers, as it causes significant damage to fruit and
leaves, leading to loss of fruit and yield. This article examines the ability
of deep learning and hyperspectral imaging to accurately identify an apple
symptom infection in apple trees. In total, 168 image scenes were collected
using conventional RGB and Visible to Near-infrared (VIS-NIR) spectral imaging
(8 channels) in infected orchards. Spectral data were preprocessed with an
Artificial Neural Network (ANN) trained in segmentation to detect scab pixels
based on spectral information. Linear Discriminant Analysis (LDA) was used to
find the most discriminating channels in spectral data based on the healthy
leaf and scab infested leaf spectra. Five combinations of false-colour images
were created from the spectral data and the segmentation net results. The
images were trained and evaluated with a modified version of the YOLOv5
network. Despite the promising results of deep learning using RGB images
(P=0.8, mAP@50=0.73), the detection of apple scab in apple trees using
multispectral imaging proved to be a difficult task. The high-light environment
of the open field made it difficult to collect a balanced spectrum from the
multispectral camera, since the infrared channel and the visible channels
needed to be constantly balanced so that they did not overexpose in the images.
","Robert Rouš, Joseph Peller, Gerrit Polder, Selwin Hageraats, Thijs Ruigrok, Pieter M. Blok",Pieter M. Blok,2023-02-17T11:33:17Z
MorphGANFormer: Transformer-based Face Morphing and De-Morphing,"  Semantic face image manipulation has received increasing attention in recent
years. StyleGAN-based approaches to face morphing are among the leading
techniques; however, they often suffer from noticeable blurring and artifacts
as a result of the uniform attention in the latent feature space. In this
paper, we propose to develop a transformer-based alternative to face morphing
and demonstrate its superiority to StyleGAN-based methods. Our contributions
are threefold. First, inspired by GANformer, we introduce a bipartite structure
to exploit long-range interactions in face images for iterative propagation of
information from latent variables to salient facial features. Special loss
functions are designed to support the optimization of face morphing. Second, we
extend the study of transformer-based face morphing to demorphing by presenting
an effective defense strategy with access to a reference image using the same
generator of MorphGANFormer. Such demorphing is conceptually similar to
unmixing of hyperspectral images but operates in the latent (instead of pixel)
space. Third, for the first time, we address a fundamental issue of
vulnerability-detectability trade-off for face morphing studies. It is argued
that neither doppelganger norrandom pair selection is optimal, and a Lagrangian
multiplier-based approach should be used to achieve an improved trade-off
between recognition vulnerability and attack detectability.
","Na Zhang, Xudong Liu, Xin Li, Guo-Jun Qi",Guo-Jun Qi,2023-02-18T19:09:11Z
"Near-field Imaging of Optical Resonances in Silicon Metasurfaces Using
  Photoelectron Microscopy","  Precise control of light-matter interactions at the nanoscale lies at the
heart of nanophotonics. Experimental examination at this length scale is
challenging, however, since the corresponding electromagnetic near-field is
often confined within volumes below the resolution of conventional optical
microscopy. In semiconductor nanophotonics electromagnetic fields are further
restricted within the confines of individual subwavelength resonators, limiting
access to critical light-matter interactions in these structures. In this work,
we demonstrate that photoelectron emission microscopy (PEEM) can be used for
polarization resolved near-field spectroscopy and imaging of electromagnetic
resonances supported by broken-symmetry silicon metasurfaces. We find that the
photoemission results, enabled through an in-situ potassium surface layer, are
consistent with full-wave simulations and far-field reflectance measurements
across visible and near-infrared wavelengths. In addition, we uncover a
polarization dependent evolution of collective resonances near the metasurface
array edge taking advantage of the far-field excitation and full-field imaging
of PEEM. Here, we deduce that coupling between eight resonators or more
establishes the collective excitations of this metasurface. All told, we
demonstrate that the high-spatial resolution hyperspectral imaging and
far-field illumination of PEEM can be leveraged for the metrology of
collective, non-local, optical resonances in semiconductor nanophotonic
structures.
","Alex Boehm, Sylvain D. Gennaro, Chloe F. Doiron, Thomas E. Beechem, Michael B. Sinclair, Igal Brener, Raktim Sarma, Taisuke Ohta",Taisuke Ohta,2023-02-24T18:58:55Z
Hybrid Spectral Denoising Transformer with Guided Attention,"  In this paper, we present a Hybrid Spectral Denoising Transformer (HSDT) for
hyperspectral image denoising. Challenges in adapting transformer for HSI arise
from the capabilities to tackle existing limitations of CNN-based methods in
capturing the global and local spatial-spectral correlations while maintaining
efficiency and flexibility. To address these issues, we introduce a hybrid
approach that combines the advantages of both models with a Spatial-Spectral
Separable Convolution (S3Conv), Guided Spectral Self-Attention (GSSA), and
Self-Modulated Feed-Forward Network (SM-FFN). Our S3Conv works as a lightweight
alternative to 3D convolution, which extracts more spatial-spectral correlated
features while keeping the flexibility to tackle HSIs with an arbitrary number
of bands. These features are then adaptively processed by GSSA which per-forms
3D self-attention across the spectral bands, guided by a set of learnable
queries that encode the spectral signatures. This not only enriches our model
with powerful capabilities for identifying global spectral correlations but
also maintains linear complexity. Moreover, our SM-FFN proposes the
self-modulation that intensifies the activations of more informative regions,
which further strengthens the aggregated features. Extensive experiments are
conducted on various datasets under both simulated and real-world noise, and it
shows that our HSDT significantly outperforms the existing state-of-the-art
methods while maintaining low computational overhead. Code is at https:
//github.com/Zeqiang-Lai/HSDT.
","Zeqiang Lai, Chenggang Yan, Ying Fu",Ying Fu,2023-03-16T02:24:31Z
Unsupervised Domain Transfer with Conditional Invertible Neural Networks,"  Synthetic medical image generation has evolved as a key technique for neural
network training and validation. A core challenge, however, remains in the
domain gap between simulations and real data. While deep learning-based domain
transfer using Cycle Generative Adversarial Networks and similar architectures
has led to substantial progress in the field, there are use cases in which
state-of-the-art approaches still fail to generate training images that produce
convincing results on relevant downstream tasks. Here, we address this issue
with a domain transfer approach based on conditional invertible neural networks
(cINNs). As a particular advantage, our method inherently guarantees cycle
consistency through its invertible architecture, and network training can
efficiently be conducted with maximum likelihood training. To showcase our
method's generic applicability, we apply it to two spectral imaging modalities
at different scales, namely hyperspectral imaging (pixel-level) and
photoacoustic tomography (image-level). According to comprehensive experiments,
our method enables the generation of realistic spectral data and outperforms
the state of the art on two downstream classification tasks (binary and
multi-class). cINN-based domain transfer could thus evolve as an important
method for realistic synthetic data generation in the field of spectral imaging
and beyond.
","Kris K. Dreher, Leonardo Ayala, Melanie Schellenberg, Marco Hübner, Jan-Hinrich Nölke, Tim J. Adler, Silvia Seidlitz, Jan Sellner, Alexander Studier-Fischer, Janek Gröhl, Felix Nickel, Ullrich Köthe, Alexander Seitel, Lena Maier-Hein",Lena Maier-Hein,2023-03-17T18:00:27Z
"Visibility Constrained Wide-band Illumination Spectrum Design for
  Seeing-in-the-Dark","  Seeing-in-the-dark is one of the most important and challenging computer
vision tasks due to its wide applications and extreme complexities of
in-the-wild scenarios. Existing arts can be mainly divided into two threads: 1)
RGB-dependent methods restore information using degraded RGB inputs only (\eg,
low-light enhancement), 2) RGB-independent methods translate images captured
under auxiliary near-infrared (NIR) illuminants into RGB domain (\eg, NIR2RGB
translation). The latter is very attractive since it works in complete darkness
and the illuminants are visually friendly to naked eyes, but tends to be
unstable due to its intrinsic ambiguities. In this paper, we try to robustify
NIR2RGB translation by designing the optimal spectrum of auxiliary illumination
in the wide-band VIS-NIR range, while keeping visual friendliness. Our core
idea is to quantify the visibility constraint implied by the human vision
system and incorporate it into the design pipeline. By modeling the formation
process of images in the VIS-NIR range, the optimal multiplexing of a wide
range of LEDs is automatically designed in a fully differentiable manner,
within the feasible region defined by the visibility constraint. We also
collect a substantially expanded VIS-NIR hyperspectral image dataset for
experiments by using a customized 50-band filter wheel. Experimental results
show that the task can be significantly improved by using the optimized
wide-band illumination than using NIR only. Codes Available:
https://github.com/MyNiuuu/VCSD.
","Muyao Niu, Zhuoxiao Li, Zhihang Zhong, Yinqiang Zheng",Yinqiang Zheng,2023-03-21T07:27:37Z
Hybrid bound states in the continuum in terahertz metasurfaces,"  Bound states in the continuum (BICs) have exhibited extraordinary properties
in photonics for enhanced light-matter interactions that enable appealing
applications in nonlinear optics, biosensors, and ultrafast optical switches.
The most common strategy to apply BICs in a metasurface is by breaking symmetry
of resonators in the uniform array that leaks the otherwise uncoupled mode to
free space and exhibits an inverse quadratic relationship between quality
factor (Q) and asymmetry. Here, we propose a scheme to further reduce
scattering losses and improve the robustness of symmetry-protected BICs by
decreasing the radiation density with a hybrid BIC lattice.We observe
significant increase of radiative Q in the hybrid lattice compared to uniform
lattice with a factor larger than 14.6. In the hybrid BIC lattice, modes are
transferred to Gamma point inherited from high symmetric X, Y and M points in
the Brillouin zone that reveal as multiple Fano resonances in the far field and
would find applications in hyperspectral sensing. This work initiates a novel
and generalized path toward reducing scattering losses and improving the
robustness of BICs in terms of lattice engineering that would release the rigid
requirements of fabrication accuracy and benefit applications of photonics and
optoelectronic devices.
","Junxing Fan, Zhanqiang Xue, Hongyang Xing, Dan Lu, Guizhen Xu, Jianqiang Gu, Jiaguang Han, Longqing Cong",Longqing Cong,2023-03-22T02:18:32Z
"MethaneMapper: Spectral Absorption aware Hyperspectral Transformer for
  Methane Detection","  Methane (CH$_4$) is the chief contributor to global climate change. Recent
Airborne Visible-Infrared Imaging Spectrometer-Next Generation (AVIRIS-NG) has
been very useful in quantitative mapping of methane emissions. Existing methods
for analyzing this data are sensitive to local terrain conditions, often
require manual inspection from domain experts, prone to significant error and
hence are not scalable. To address these challenges, we propose a novel
end-to-end spectral absorption wavelength aware transformer network,
MethaneMapper, to detect and quantify the emissions. MethaneMapper introduces
two novel modules that help to locate the most relevant methane plume regions
in the spectral domain and uses them to localize these accurately. Thorough
evaluation shows that MethaneMapper achieves 0.63 mAP in detection and reduces
the model size (by 5x) compared to the current state of the art. In addition,
we also introduce a large-scale dataset of methane plume segmentation mask for
over 1200 AVIRIS-NG flight lines from 2015-2022. It contains over 4000 methane
plume sites. Our dataset will provide researchers the opportunity to develop
and advance new methods for tackling this challenging green-house gas detection
problem with significant broader social impact. Dataset and source code are
public
","Satish Kumar, Ivan Arevalo, ASM Iftekhar, B S Manjunath",B S Manjunath,2023-04-05T22:15:18Z
"Quantifying colors at micrometer scale by colorimetric microscopy
  (C-Microscopy) approach","  The color is the primal property of the objects around us and is direct
manifestation of light-matter interactions. The color information is used in
many different fields of science, technology and industry to investigate
material properties or for identification of concentrations of substances.
Usually the color information is used as a global parameter in a macro scale.
To quantitatively measure color information in micro scale one needs to use
dedicated microscope spectrophotometers or specialized micro-reflectance
setups. Here, the Colorimetric Microscopy (C-Microscopy) approach based on
digital optical microscopy and a free software is presented. The C-Microscopy
approach uses color calibrated image and colorimetric calculations to obtain
physically meaningful quantities i.e., dominant wavelength and excitation
purity maps at micro level scale. This allows for the discovery of the local
color details of samples surfaces. Later, to fully characterize the optical
properties, the hyperspectral reflectance data at micro scale (reflectance as a
function of wavelength for a each point) are colorimetrically recovered. The
C-Microscopy approach was successfully applied to various types of samples
i.e., two metamorphic rocks unakite and lapis lazuli, which are mixtures of
different minerals; and to the surface of gold 99.999 % pellet, which exhibits
different types of surface features. The C-Microscopy approach could be used to
quantify the local optical properties changes of various materials at
microscale in an accessible way. The approach is freely available as a set of
python jupyter notebooks.
",Benedykt R. Jany,Benedykt R. Jany,2023-04-10T23:16:30Z
"SST-ReversibleNet: Reversible-prior-based Spectral-Spatial Transformer
  for Efficient Hyperspectral Image Reconstruction","  Spectral image reconstruction is an important task in snapshot compressed
imaging. This paper aims to propose a new end-to-end framework with iterative
capabilities similar to a deep unfolding network to improve reconstruction
accuracy, independent of optimization conditions, and to reduce the number of
parameters. A novel framework called the reversible-prior-based method is
proposed. Inspired by the reversibility of the optical path, the
reversible-prior-based framework projects the reconstructions back into the
measurement space, and then the residuals between the projected data and the
real measurements are fed into the network for iteration. The reconstruction
subnet in the network then learns the mapping of the residuals to the true
values to improve reconstruction accuracy. In addition, a novel
spectral-spatial transformer is proposed to account for the global correlation
of spectral data in both spatial and spectral dimensions while balancing
network depth and computational complexity, in response to the shortcomings of
existing transformer-based denoising modules that ignore spatial texture
features or learn local spatial features at the expense of global spatial
features. Extensive experiments show that our SST-ReversibleNet significantly
outperforms state-of-the-art methods on simulated and real HSI datasets, while
requiring lower computational and storage costs.
https://github.com/caizeyu1992/SST
","Zeyu Cai, Jian Yu, Ziyu Zhang, Chengqian Jin, Feipeng Da",Feipeng Da,2023-05-06T14:01:02Z
"Frequency combs induced by optical feedback and harmonic order
  tunability in quantum cascade lasers","  This study investigates the interaction between frequency combs and optical
feedback effects in Quantum Cascade Lasers (QCLs). The theoretical analysis
reveals new phenomena arising from the interplay between comb generation and
feedback. By considering the bias current corresponding to free-running single
mode emission, the introduction of optical feedback can trigger the generation
of frequency combs, including both fundamental and harmonic combs. This
presents opportunities to extend the comb region and generate harmonic
frequency combs with different orders through optimization of external cavity
parameters such as losses and length. Furthermore, the study demonstrates that
optical feedback can selectively tune the harmonic order of a pre-existing
free-running comb by adjusting the external cavity length, particularly for
feedback ratios around 1%, which are readily achievable in experimental setups.
Under strong feedback conditions (Acket parameter C>4.6), mixed states emerge,
displaying the features of both laser and external cavity dynamics. While the
study is predominantly centered on Terahertz QCLs, we have also confirmed that
the described phenomena occur when utilizing mid-infrared QCL parameters. This
work establishes a connection between comb technology and the utilization of
optical feedback, providing new avenues for exploration and advancement in the
field. In fact, the novel reported phenomena open a pathway towards new
methodologies across various domains, such as design of tunable comb sources,
hyperspectral imaging, multimode coherent sensing, and multi-channel
communication.
","Carlo Silvestri, Xiaoqiong Qi, Thomas Taimre, Aleksandar D. Rakić",Aleksandar D. Rakić,2023-05-08T04:21:24Z
"Tinto: Multisensor Benchmark for 3D Hyperspectral Point Cloud
  Segmentation in the Geosciences","  The increasing use of deep learning techniques has reduced interpretation
time and, ideally, reduced interpreter bias by automatically deriving
geological maps from digital outcrop models. However, accurate validation of
these automated mapping approaches is a significant challenge due to the
subjective nature of geological mapping and the difficulty in collecting
quantitative validation data. Additionally, many state-of-the-art deep learning
methods are limited to 2D image data, which is insufficient for 3D digital
outcrops, such as hyperclouds. To address these challenges, we present Tinto, a
multi-sensor benchmark digital outcrop dataset designed to facilitate the
development and validation of deep learning approaches for geological mapping,
especially for non-structured 3D data like point clouds. Tinto comprises two
complementary sets: 1) a real digital outcrop model from Corta Atalaya (Spain),
with spectral attributes and ground-truth data, and 2) a synthetic twin that
uses latent features in the original datasets to reconstruct realistic spectral
data (including sensor noise and processing artifacts) from the ground-truth.
The point cloud is dense and contains 3,242,964 labeled points. We used these
datasets to explore the abilities of different deep learning approaches for
automated geological mapping. By making Tinto publicly available, we hope to
foster the development and adaptation of new deep learning tools for 3D
applications in Earth sciences. The dataset can be accessed through this link:
https://doi.org/10.14278/rodare.2256.
","Ahmed J. Afifi, Samuel T. Thiele, Aldino Rizaldy, Sandra Lorenz, Pedram Ghamisi, Raimon Tolosana-Delgado, Moritz Kirsch, Richard Gloaguen, Michael Heizmann",Michael Heizmann,2023-05-17T03:24:08Z
Binarized Spectral Compressive Imaging,"  Existing deep learning models for hyperspectral image (HSI) reconstruction
achieve good performance but require powerful hardwares with enormous memory
and computational resources. Consequently, these methods can hardly be deployed
on resource-limited mobile devices. In this paper, we propose a novel method,
Binarized Spectral-Redistribution Network (BiSRNet), for efficient and
practical HSI restoration from compressed measurement in snapshot compressive
imaging (SCI) systems. Firstly, we redesign a compact and easy-to-deploy base
model to be binarized. Then we present the basic unit, Binarized
Spectral-Redistribution Convolution (BiSR-Conv). BiSR-Conv can adaptively
redistribute the HSI representations before binarizing activation and uses a
scalable hyperbolic tangent function to closer approximate the Sign function in
backpropagation. Based on our BiSR-Conv, we customize four binarized
convolutional modules to address the dimension mismatch and propagate
full-precision information throughout the whole network. Finally, our BiSRNet
is derived by using the proposed techniques to binarize the base model.
Comprehensive quantitative and qualitative experiments manifest that our
proposed BiSRNet outperforms state-of-the-art binarization methods and achieves
comparable performance with full-precision algorithms. Code and models are
publicly available at https://github.com/caiyuanhao1998/BiSCI and
https://github.com/caiyuanhao1998/MST
","Yuanhao Cai, Yuxin Zheng, Jing Lin, Xin Yuan, Yulun Zhang, Haoqian Wang",Haoqian Wang,2023-05-17T15:36:08Z
"Programmable Nanowrinkle-Induced Room-Temperature Exciton Localization
  in Monolayer WSe2","  Localized states in two-dimensional (2D) transition metal dichalcogenides
(TMDCs) have been the subject of intense study, driven by potential
applications in quantum information science. Despite the rapidly growing
knowledge surrounding these emitters, their microscopic nature is still not
fully understood, limiting their production and application. Motivated by this
challenge, and by recent theoretical and experimental evidence showing that
nanowrinkles generate localized room-temperature emitters, we demonstrate a
method to intentionally induce wrinkles with collections of stressors, showing
that long-range wrinkle direction and position are controllable with patterned
array design. Nano-photoluminescence (nano-PL) imaging combined with detailed
strain modeling based on measured wrinkle topography establishes a correlation
between wrinkle properties, particularly shear strain, and localized exciton
emission. Beyond the array-induced super-wrinkles, nano-PL spatial maps further
reveal that the strain environment around individual stressors is heterogeneous
due to the presence of fine wrinkles that are less deterministic. Detailed
nanoscale hyperspectral images uncover a wide range of low-energy emission
peaks originating from these fine wrinkles, and show that the states can be
tightly confined to regions < 10 nm, even in ambient conditions. These results
establish a promising potential route towards realizing room temperature
quantum emission in 2D TMDC systems.
","Emanuil S. Yanev, Thomas P. Darlington, Sophia A. Ladyzhets, Matthew C. Strasbourg, Song Liu, Daniel A. Rhodes, Kobi Hall, Aditya Sinha, Nicholas J. Borys, James C. Hone, P. James Schuck",P. James Schuck,2023-05-24T18:53:49Z
"Spectrally dispersed kernel phase interferometry with SCExAO/CHARIS:
  proof of concept and calibration strategies","  Kernel phase interferometry (KPI) is a data processing technique that allows
for the detection of asymmetries (such as companions or disks) in high-Strehl
images, close to and within the classical diffraction limit. We show that KPI
can successfully be applied to hyperspectral image cubes generated from
integral field spectrographs (IFSs). We demonstrate this technique of
spectrally-dispersed kernel phase by recovering a known binary with the
SCExAO/CHARIS IFS in high-resolution K-band mode. We also explore a spectral
differential imaging (SDI) calibration strategy that takes advantage of the
information available in images from multiple wavelength bins. Such
calibrations have the potential to mitigate high-order, residual systematic
kernel phase errors, which currently limit the achievable contrast of KPI. The
SDI calibration presented here is applicable to searches for line emission or
sharp absorption features, and is a promising avenue toward achieving
photon-noise-limited kernel phase observations. The high angular resolution and
spectral coverage provided by dispersed kernel phase offers novel opportunities
for science observations which would have been challenging to achieve
otherwise.
","Alexander Chaushev, Steph Sallum, Julien Lozi, Frantz Martinache, Jeffrey Chilcote, Tyler Groff, Olivier Guyon, N. Jeremy Kasdin, Barnaby Norris, Andy Skemer",Andy Skemer,2023-05-26T16:21:20Z
"Deep imaging inside scattering media through virtual spatiotemporal
  wavefront shaping","  The multiple scattering of light makes materials opaque and obstructs
imaging. Wavefront shaping can reverse the scattering process, but imaging with
physical wavefront shaping has limitations such as requiring physical
guidestars, being restricted within a small isoplanatic volume, and relying on
slow wavefront updates, with some approaches only working for planar targets
outside the scattering media. Here, we introduce scattering matrix tomography
(SMT): measure the hyperspectral scattering matrix of the sample, use it to
digitally scan a synthesized confocal spatiotemporal focus and construct a
volumetric image of the sample, and then use the tomograms as virtual
guidestars in a nonconvex optimization to find the pulse shape, input
wavefront, and output wavefront that can compensate for aberrations and
scattering. SMT combines the strengths of wavefront shaping, spatiotemporal
gating, and computational adaptive optics, eliminating physical guidestars and
enabling digital double-path wavefront corrections tailored for every
isoplanatic volume. We demonstrate sub-micron lateral resolution and one-micron
axial resolution at one millimeter beneath ex vivo mouse brain tissue and over
three transport mean free paths inside an opaque colloid, where existing
imaging methods all fail due to the overwhelming multiple scattering. As a
noninvasive and label-free method that works both inside and outside the
scattering media, SMT may be applied broadly across medical imaging, biological
science, device inspection, and colloidal physics.
","Yiwen Zhang, Minh Dinh, Zeyu Wang, Tianhao Zhang, Tianhang Chen, Chia Wei Hsu",Chia Wei Hsu,2023-06-15T00:31:06Z
"Infrastructure Strategy to Enable Optical Communications for
  Next-Generation Heliophysics Missions","  To expand frontiers and achieve measurable progress, instruments such as
hyperspectral imagers are increased in resolution, field of view, and spectral
resolution and range, leading to dramatically higher data volumes.
Increasingly, data need to be returned from greater distances, ranging from the
Sun-earth L1/ L2 points at 1.5 million km, to L4/L5 halo orbits at 1 AU, to
several AU in the case of planetary probes. Optical communications can
significantly reduce resource competition, requiring significantly fewer passes
per day and/or shorter overall passes, and thereby enable far greater,
transformative science return from individual missions and the capacity to
support multiple such missions within a smaller ground network. Optical
communications also provides superior performance and increased ranges for
Inter-satellite Links (ISL) from 2,000 to 10,000 km for Swarms and DSMs.
Lastly, the only way to guarantee timely space weather warnings (with a target
of 15 minutes latency) is through space relays in MEO or GEO orbits, a strategy
which also includes optical communications.
","Marta Shelton, Hongbo Li, Daniel Motto, Antti Pulkkinen, Errol Summerlin, Doug Rabin, Ryan Rogalin, Abraham Douglas, Stephen Lichten, Mark Storm, Brian Mathason, Amir Caspi",Amir Caspi,2023-06-20T04:18:55Z
Cross Spectral Image Reconstruction Using a Deep Guided Neural Network,"  Cross spectral camera arrays, where each camera records different spectral
content, are becoming increasingly popular for RGB, multispectral and
hyperspectral imaging, since they are capable of a high resolution in every
dimension using off-the-shelf hardware. For these, it is necessary to build an
image processing pipeline to calculate a consistent image data cube, i.e., it
should look like as if every camera records the scene from the center camera.
Since the cameras record the scene from a different angle, this pipeline needs
a reconstruction component for pixels that are not visible to peripheral
cameras. For that, a novel deep guided neural network (DGNet) is presented.
Since only little cross spectral data is available for training, this neural
network is highly regularized. Furthermore, a new data augmentation process is
introduced to generate the cross spectral content. On synthetic and real
multispectral camera array data, the proposed network outperforms the state of
the art by up to 2 dB in terms of PSNR on average. Besides, DGNet also tops its
best competitor in terms of SSIM as well as in runtime by a factor of nearly
12. Moreover, a qualitative evaluation reveals visually more appealing results
for real camera array data.
","Frank Sippel, Jürgen Seiler, André Kaup",André Kaup,2023-06-27T06:31:23Z
"AE-RED: A Hyperspectral Unmixing Framework Powered by Deep Autoencoder
  and Regularization by Denoising","  Spectral unmixing has been extensively studied with a variety of methods and
used in many applications. Recently, data-driven techniques with deep learning
methods have obtained great attention to spectral unmixing for its superior
learning ability to automatically learn the structure information. In
particular, autoencoder based architectures are elaborately designed to solve
blind unmixing and model complex nonlinear mixtures. Nevertheless, these
methods perform unmixing task as blackboxes and lack of interpretability. On
the other hand, conventional unmixing methods carefully design the regularizer
to add explicit information, in which algorithms such as plug-and-play (PnP)
strategies utilize off-the-shelf denoisers to plug powerful priors. In this
paper, we propose a generic unmixing framework to integrate the autoencoder
network with regularization by denoising (RED), named AE-RED. More specially,
we decompose the unmixing optimized problem into two subproblems. The first one
is solved using deep autoencoders to implicitly regularize the estimates and
model the mixture mechanism. The second one leverages the denoiser to bring in
the explicit information. In this way, both the characteristics of the deep
autoencoder based unmixing methods and priors provided by denoisers are merged
into our well-designed framework to enhance the unmixing performance.
Experiment results on both synthetic and real data sets show the superiority of
our proposed framework compared with state-of-the-art unmixing approaches.
","Min Zhao, Jie Chen, Nicolas Dobigeon",Nicolas Dobigeon,2023-07-01T08:20:36Z
"General-Purpose Multimodal Transformer meets Remote Sensing Semantic
  Segmentation","  The advent of high-resolution multispectral/hyperspectral sensors, LiDAR DSM
(Digital Surface Model) information and many others has provided us with an
unprecedented wealth of data for Earth Observation. Multimodal AI seeks to
exploit those complementary data sources, particularly for complex tasks like
semantic segmentation. While specialized architectures have been developed,
they are highly complicated via significant effort in model design, and require
considerable re-engineering whenever a new modality emerges. Recent trends in
general-purpose multimodal networks have shown great potential to achieve
state-of-the-art performance across multiple multimodal tasks with one unified
architecture. In this work, we investigate the performance of PerceiverIO, one
in the general-purpose multimodal family, in the remote sensing semantic
segmentation domain. Our experiments reveal that this ostensibly universal
network struggles with object scale variation in remote sensing images and
fails to detect the presence of cars from a top-down view. To address these
issues, even with extreme class imbalance issues, we propose a spatial and
volumetric learning component. Specifically, we design a UNet-inspired module
that employs 3D convolution to encode vital local information and learn
cross-modal features simultaneously, while reducing network computational
burden via the cross-attention mechanism of PerceiverIO. The effectiveness of
the proposed component is validated through extensive experiments comparing it
with other methods such as 2D convolution, and dual local module (\ie the
combination of Conv2D 1x1 and Conv2D 3x3 inspired by UNetFormer). The proposed
method achieves competitive results with specialized architectures like
UNetFormer and SwinUNet, showing its potential to minimize network architecture
engineering with a minimal compromise on the performance.
","Nhi Kieu, Kien Nguyen, Sridha Sridharan, Clinton Fookes",Clinton Fookes,2023-07-07T04:58:34Z
Meta-Transformer: A Unified Framework for Multimodal Learning,"  Multimodal learning aims to build models that can process and relate
information from multiple modalities. Despite years of development in this
field, it still remains challenging to design a unified network for processing
various modalities ($\textit{e.g.}$ natural language, 2D images, 3D point
clouds, audio, video, time series, tabular data) due to the inherent gaps among
them. In this work, we propose a framework, named Meta-Transformer, that
leverages a $\textbf{frozen}$ encoder to perform multimodal perception without
any paired multimodal training data. In Meta-Transformer, the raw input data
from various modalities are mapped into a shared token space, allowing a
subsequent encoder with frozen parameters to extract high-level semantic
features of the input data. Composed of three main components: a unified data
tokenizer, a modality-shared encoder, and task-specific heads for downstream
tasks, Meta-Transformer is the first framework to perform unified learning
across 12 modalities with unpaired data. Experiments on different benchmarks
reveal that Meta-Transformer can handle a wide range of tasks including
fundamental perception (text, image, point cloud, audio, video), practical
application (X-Ray, infrared, hyperspectral, and IMU), and data mining (graph,
tabular, and time-series). Meta-Transformer indicates a promising future for
developing unified multimodal intelligence with transformers. Code will be
available at https://github.com/invictus717/MetaTransformer
","Yiyuan Zhang, Kaixiong Gong, Kaipeng Zhang, Hongsheng Li, Yu Qiao, Wanli Ouyang, Xiangyu Yue",Xiangyu Yue,2023-07-20T12:10:29Z
Quantitative and dark field ghost imaging with ultraviolet light,"  Ultraviolet (UV) imaging enables a diverse array of applications, such as
material composition analysis, biological fluorescence imaging, and detecting
defects in semiconductor manufacturing. However, scientific-grade UV cameras
with high quantum efficiency are expensive and include a complex thermoelectric
cooling system. Here, we demonstrate a UV computational ghost imaging (UV-CGI)
method to provide a cost-effective UV imaging and detection strategy. By
applying spatial-temporal illumination patterns and using a 325 nm laser
source, a single-pixel detector is enough to reconstruct the images of objects.
To demonstrate its capability for quantitative detection, we use UV-CGI to
distinguish four UV-sensitive sunscreen areas with different densities on a
sample. Furthermore, we demonstrate dark field UV-CGI in both transmission and
reflection schemes. By only collecting the scattered light from objects, we can
detect the edges of pure phase objects and small scratches on a compact disc.
Our results showcase a feasible low-cost solution for non-destructive UV
imaging and detection. By combining it with other imaging techniques, such as
hyperspectral imaging or time-resolved imaging, a compact and versatile UV
computational imaging platform may be realized for future applications.
","Jiaqi Song, Baolei Liu, Yao Wang, Chaohao Chen, Xuchen Shan, Xiaolan Zhong, Ling-An Wu, Fan Wang",Fan Wang,2023-08-02T14:14:43Z
"Comparing the quality of neural network uncertainty estimates for
  classification problems","  Traditional deep learning (DL) models are powerful classifiers, but many
approaches do not provide uncertainties for their estimates. Uncertainty
quantification (UQ) methods for DL models have received increased attention in
the literature due to their usefulness in decision making, particularly for
high-consequence decisions. However, there has been little research done on how
to evaluate the quality of such methods. We use statistical methods of
frequentist interval coverage and interval width to evaluate the quality of
credible intervals, and expected calibration error to evaluate classification
predicted confidence. These metrics are evaluated on Bayesian neural networks
(BNN) fit using Markov Chain Monte Carlo (MCMC) and variational inference (VI),
bootstrapped neural networks (NN), Deep Ensembles (DE), and Monte Carlo (MC)
dropout. We apply these different UQ for DL methods to a hyperspectral image
target detection problem and show the inconsistency of the different methods'
results and the necessity of a UQ quality metric. To reconcile these
differences and choose a UQ method that appropriately quantifies the
uncertainty, we create a simulated data set with fully parameterized
probability distribution for a two-class classification problem. The gold
standard MCMC performs the best overall, and the bootstrapped NN is a close
second, requiring the same computational expense as DE. Through this
comparison, we demonstrate that, for a given data set, different models can
produce uncertainty estimates of markedly different quality. This in turn
points to a great need for principled assessment methods of UQ quality in DL
applications.
","Daniel Ries, Joshua Michalenko, Tyler Ganter, Rashad Imad-Fayez Baiyasi, Jason Adams",Jason Adams,2023-08-11T01:55:14Z
"Exploiting the Quantum Advantage for Satellite Image Processing: Review
  and Assessment","  This article examines the current status of quantum computing in Earth
observation (EO) and satellite imagery. We analyze the potential limitations
and applications of quantum learning models when dealing with satellite data,
considering the persistent challenges of profiting from quantum advantage and
finding the optimal sharing between high-performance computing (HPC) and
quantum computing (QC). We then assess some parameterized quantum circuit
models transpiled into a Clifford+T universal gate set. The T-gates shed light
on the quantum resources required to deploy quantum models, either on an HPC
system or several QC systems. In particular, if the T-gates cannot be simulated
efficiently on an HPC system, we can apply a quantum computer and its
computational power over conventional techniques. Our quantum resource
estimation showed that quantum machine learning (QML) models, with a sufficient
number of T-gates, provide the quantum advantage if and only if they generalize
on unseen data points better than their classical counterparts deployed on the
HPC system and they break the symmetry in their weights at each learning
iteration like in conventional deep neural networks. We also estimated the
quantum resources required for some QML models as an initial innovation.
Lastly, we defined the optimal sharing between an HPC+QC system for executing
QML models for hyperspectral satellite images. These are a unique dataset
compared to other satellite images since they have a limited number of input
qubits and a small number of labeled benchmark images, making them less
challenging to deploy on quantum computers.
","Soronzonbold Otgonbaatar, Dieter Kranzlmüller",Dieter Kranzlmüller,2023-08-18T10:34:34Z
"Bayesian sparsity and class sparsity priors for dictionary learning and
  coding","  Dictionary learning methods continue to gain popularity for the solution of
challenging inverse problems. In the dictionary learning approach, the
computational forward model is replaced by a large dictionary of possible
outcomes, and the problem is to identify the dictionary entries that best match
the data, akin to traditional query matching in search engines. Sparse coding
techniques are used to guarantee that the dictionary matching identifies only
few of the dictionary entries, and dictionary compression methods are used to
reduce the complexity of the matching problem. In this article, we propose a
work flow to facilitate the dictionary matching process. First, the full
dictionary is divided into subdictionaries that are separately compressed. The
error introduced by the dictionary compression is handled in the Bayesian
framework as a modeling error. Furthermore, we propose a new Bayesian
data-driven group sparsity coding method to help identify subdictionaries that
are not relevant for the dictionary matching. After discarding irrelevant
subdictionaries, the dictionary matching is addressed as a deflated problem
using sparse coding. The compression and deflation steps can lead to
substantial decreases of the computational complexity. The effectiveness of
compensating for the dictionary compression error and using the novel group
sparsity promotion to deflate the original dictionary are illustrated by
applying the methodology to real world problems, the glitch detection in the
LIGO experiment and hyperspectral remote sensing.
","Alberto Bocchinfuso, Daniela Calvetti, Erkki Somersalo",Erkki Somersalo,2023-09-02T17:54:23Z
"Giant ultra-broadband photoconductivity in twisted graphene
  heterostructures","  The requirements for broadband photodetection are becoming exceedingly
demanding in hyperspectral imaging. Whilst intrinsic photoconductor arrays
based on mercury cadmium telluride represent the most sensitive and suitable
technology, their optical spectrum imposes a narrow spectral range with a sharp
absorption edge that cuts their operation to < 25 um. Here, we demonstrate a
giant ultra-broadband photoconductivity in twisted double bilayer graphene
heterostructures spanning a spectral range of 2 - 100 um with internal quantum
efficiencies ~ 40 % at speeds of 100 kHz. The giant response originates from
unique properties of twist-decoupled heterostructures including pristine,
crystal field induced terahertz band gaps, parallel photoactive channels, and
strong photoconductivity enhancements caused by interlayer screening of
electronic interactions by respective layers acting as sub-atomic spaced
proximity screening gates. Our work demonstrates a rare instance of an
intrinsic infrared-terahertz photoconductor that is complementary
metal-oxide-semiconductor compatible and array integratable, and introduces
twist-decoupled graphene heterostructures as a viable route for engineering
gapped graphene photodetectors with 3D scalability.
","Hitesh Agarwal, Krystian Nowakowski, Andres Forrer, Alessandro Principi, Riccardo Bertini, Sergi Batlle-Porro, Antoine Reserbat-Plantey, Parmeshwar Prasad, Lorenzo Vistoli, Kenji Watanabe, Takashi Taniguchi, Adrian Bachtold, Giacomo Scalari, Roshan Krishna Kumar, Frank H. L. Koppens",Frank H. L. Koppens,2023-09-04T12:13:04Z
"Infrared Nanoimaging of Hydrogenated Perovskite Nickelate Synaptic
  Devices","  Solid-state devices made from correlated oxides such as perovskite nickelates
are promising for neuromorphic computing by mimicking biological synaptic
function. However, comprehending dopant action at the nanoscale poses a
formidable challenge to understanding the elementary mechanisms involved. Here,
we perform operando infrared nanoimaging of hydrogen-doped correlated
perovskite, neodymium nickel oxide (H-NdNiO3) devices and reveal how an applied
field perturbs dopant distribution at the nanoscale. This perturbation leads to
stripe phases of varying conductivity perpendicular to the applied field, which
define the macroscale electrical characteristics of the devices. Hyperspectral
nano-FTIR imaging in conjunction with density functional theory calculations
unveil a real-space map of multiple vibrational states of H-NNO associated with
OH stretching modes and their dependence on the dopant concentration. Moreover,
the localization of excess charges induces an out-of-plane lattice expansion in
NNO which was confirmed by in-situ - x-ray diffraction and creates a strain
that acts as a barrier against further diffusion. Our results and the
techniques presented here hold great potential to the rapidly growing field of
memristors and neuromorphic devices wherein nanoscale ion motion is
fundamentally responsible for function.
","Sampath Gamage, Sukriti Manna, Marc Zajac, Steven Hancock, Qi Wang, Sarabpreet Singh, Mahdi Ghafariasl, Kun Yao, Tom Tiwald, Tae Joon Park, David P. Landau, Haidan Wen, Subramanian Sankaranarayanan, Pierre Darancet, Shriram Ramanathan, Yohannes Abate",Yohannes Abate,2023-08-29T14:08:00Z
"Bridging Sensor Gaps via Attention Gated Tuning for Hyperspectral Image
  Classification","  Data-hungry HSI classification methods require high-quality labeled HSIs,
which are often costly to obtain. This characteristic limits the performance
potential of data-driven methods when dealing with limited annotated samples.
Bridging the domain gap between data acquired from different sensors allows us
to utilize abundant labeled data across sensors to break this bottleneck. In
this paper, we propose a novel Attention-Gated Tuning (AGT) strategy and a
triplet-structured transformer model, Tri-Former, to address this issue. The
AGT strategy serves as a bridge, allowing us to leverage existing labeled HSI
datasets, even RGB datasets to enhance the performance on new HSI datasets with
limited samples. Instead of inserting additional parameters inside the basic
model, we train a lightweight auxiliary branch that takes intermediate features
as input from the basic model and makes predictions. The proposed AGT resolves
conflicts between heterogeneous and even cross-modal data by suppressing the
disturbing information and enhances the useful information through a soft gate.
Additionally, we introduce Tri-Former, a triplet-structured transformer with a
spectral-spatial separation design that enhances parameter utilization and
computational efficiency, enabling easier and flexible fine-tuning. Comparison
experiments conducted on three representative HSI datasets captured by
different sensors demonstrate the proposed Tri-Former achieves better
performance compared to several state-of-the-art methods. Homologous,
heterologous and cross-modal tuning experiments verified the effectiveness of
the proposed AGT. Code has been released at:
\href{https://github.com/Cecilia-xue/AGT}{https://github.com/Cecilia-xue/AGT}.
","Xizhe Xue, Haokui Zhang, Zongwen Bai, Ying Li",Ying Li,2023-09-22T13:39:24Z
"Bidirectional recurrent imputation and abundance estimation of LULC
  classes with MODIS multispectral time series and geo-topographic and climatic
  data","  Remotely sensed data are dominated by mixed Land Use and Land Cover (LULC)
types. Spectral unmixing (SU) is a key technique that disentangles mixed pixels
into constituent LULC types and their abundance fractions. While existing
studies on Deep Learning (DL) for SU typically focus on single time-step
hyperspectral (HS) or multispectral (MS) data, our work pioneers SU using MODIS
MS time series, addressing missing data with end-to-end DL models. Our approach
enhances a Long-Short Term Memory (LSTM)-based model by incorporating
geographic, topographic (geo-topographic), and climatic ancillary information.
Notably, our method eliminates the need for explicit endmember extraction,
instead learning the input-output relationship between mixed spectra and LULC
abundances through supervised learning. Experimental results demonstrate that
integrating spectral-temporal input data with geo-topographic and climatic
information significantly improves the estimation of LULC abundances in mixed
pixels. To facilitate this study, we curated a novel labeled dataset for
Andalusia (Spain) with monthly MODIS multispectral time series at 460m
resolution for 2013. Named Andalusia MultiSpectral MultiTemporal Unmixing
(Andalusia-MSMTU), this dataset provides pixel-level annotations of LULC
abundances along with ancillary information. The dataset
(https://zenodo.org/records/7752348) and code
(https://github.com/jrodriguezortega/MSMTU) are available to the public.
","José Rodríguez-Ortega, Rohaifa Khaldi, Domingo Alcaraz-Segura, Siham Tabik",Siham Tabik,2023-10-11T06:13:50Z
Learning a Cross-modality Anomaly Detector for Remote Sensing Imagery,"  Remote sensing anomaly detector can find the objects deviating from the
background as potential targets for Earth monitoring. Given the diversity in
earth anomaly types, designing a transferring model with cross-modality
detection ability should be cost-effective and flexible to new earth
observation sources and anomaly types. However, the current anomaly detectors
aim to learn the certain background distribution, the trained model cannot be
transferred to unseen images. Inspired by the fact that the deviation metric
for score ranking is consistent and independent from the image distribution,
this study exploits the learning target conversion from the varying background
distribution to the consistent deviation metric. We theoretically prove that
the large-margin condition in labeled samples ensures the transferring ability
of learned deviation metric. To satisfy this condition, two large margin losses
for pixel-level and feature-level deviation ranking are proposed respectively.
Since the real anomalies are difficult to acquire, anomaly simulation
strategies are designed to compute the model loss. With the large-margin
learning for deviation metric, the trained model achieves cross-modality
detection ability in five modalities including hyperspectral, visible light,
synthetic aperture radar (SAR), infrared and low-light in zero-shot manner.
","Jingtao Li, Xinyu Wang, Hengwei Zhao, Liangpei Zhang, Yanfei Zhong",Yanfei Zhong,2023-10-11T14:07:05Z
"MLP-AMDC: An MLP Architecture for Adaptive-Mask-based Dual-Camera
  snapshot hyperspectral imaging","  Coded Aperture Snapshot Spectral Imaging (CASSI) system has great advantages
over traditional methods in dynamically acquiring Hyper-Spectral Image (HSI),
but there are the following problems. 1) Traditional mask relies on random
patterns or analytical design, both of which limit the performance improvement
of CASSI. 2) Existing high-quality reconstruction algorithms are slow in
reconstruction and can only reconstruct scene information offline. To address
the above two problems, this paper designs the AMDC-CASSI system, introducing
RGB camera with CASSI based on Adaptive-Mask as multimodal input to improve the
reconstruction quality. The existing SOTA reconstruction schemes are based on
transformer, but the operation of self-attention pulls down the operation
efficiency of the network. In order to improve the inference speed of the
reconstruction network, this paper proposes An MLP Architecture for
Adaptive-Mask-based Dual-Camera (MLP-AMDC) to replace the transformer structure
of the network. Numerous experiments have shown that MLP performs no less well
than transformer-based structures for HSI reconstruction, while MLP greatly
improves the network inference speed and has less number of parameters and
operations, our method has a 8 db improvement over SOTA and at least a 5-fold
improvement in reconstruction speed. (https://github.com/caizeyu1992/MLP-AMDC.)
","Zeyu Cai, Can Zhang, Xunhao Chen, Shanghuan Liu, Chengqian Jin, Feipeng Da",Feipeng Da,2023-10-12T03:14:02Z
Gromov-Wasserstein-like Distances in the Gaussian Mixture Models Space,"  The Gromov-Wasserstein (GW) distance is frequently used in machine learning
to compare distributions across distinct metric spaces. Despite its utility, it
remains computationally intensive, especially for large-scale problems.
Recently, a novel Wasserstein distance specifically tailored for Gaussian
mixture models (GMMs) and known as MW2 (mixture Wasserstein) has been
introduced by several authors. In scenarios where data exhibit clustering, this
approach simplifies to a small-scale discrete optimal transport problem, which
complexity depends solely on the number of Gaussian components in the GMMs.
This paper aims to incorporate invariance properties into MW2. This is done by
introducing new Gromov-type distances, designed to be isometry-invariant in
Euclidean spaces and applicable for comparing GMMs across different dimensional
spaces. Our first contribution is the Mixture Gromov Wasserstein distance
(MGW2), which can be viewed as a ""Gromovized"" version of MW2. This new distance
has a straightforward discrete formulation, making it highly efficient for
estimating distances between GMMs in practical applications. To facilitate the
derivation of a transport plan between GMMs, we present a second distance, the
Embedded Wasserstein distance (EW2). This distance turns out to be closely
related to several recent alternatives to Gromov-Wasserstein. We show that EW2
can be adapted to derive a distance as well as optimal transportation plans
between GMMs. We demonstrate the efficiency of these newly proposed distances
on medium to large-scale problems, including shape matching and hyperspectral
image color transfer.
","Antoine Salmona, Julie Delon, Agnès Desolneux",Agnès Desolneux,2023-10-17T13:22:36Z
Low-Multi-Rank High-Order Bayesian Robust Tensor Factorization,"  The recently proposed tensor robust principal component analysis (TRPCA)
methods based on tensor singular value decomposition (t-SVD) have achieved
numerous successes in many fields. However, most of these methods are only
applicable to third-order tensors, whereas the data obtained in practice are
often of higher order, such as fourth-order color videos, fourth-order
hyperspectral videos, and fifth-order light-field images. Additionally, in the
t-SVD framework, the multi-rank of a tensor can describe more fine-grained
low-rank structure in the tensor compared with the tubal rank. However,
determining the multi-rank of a tensor is a much more difficult problem than
determining the tubal rank. Moreover, most of the existing TRPCA methods do not
explicitly model the noises except the sparse noise, which may compromise the
accuracy of estimating the low-rank tensor. In this work, we propose a novel
high-order TRPCA method, named as Low-Multi-rank High-order Bayesian Robust
Tensor Factorization (LMH-BRTF), within the Bayesian framework. Specifically,
we decompose the observed corrupted tensor into three parts, i.e., the low-rank
component, the sparse component, and the noise component. By constructing a
low-rank model for the low-rank component based on the order-$d$ t-SVD and
introducing a proper prior for the model, LMH-BRTF can automatically determine
the tensor multi-rank. Meanwhile, benefiting from the explicit modeling of both
the sparse and noise components, the proposed method can leverage information
from the noises more effectivly, leading to an improved performance of TRPCA.
Then, an efficient variational inference algorithm is established for
parameters estimation. Empirical studies on synthetic and real-world datasets
demonstrate the effectiveness of the proposed method in terms of both
qualitative and quantitative results.
","Jianan Liu, Chunguang Li",Chunguang Li,2023-11-10T06:15:38Z
"Degradation Estimation Recurrent Neural Network with Local and Non-Local
  Priors for Compressive Spectral Imaging","  In the Coded Aperture Snapshot Spectral Imaging (CASSI) system, deep
unfolding networks (DUNs) have demonstrated excellent performance in recovering
3D hyperspectral images (HSIs) from 2D measurements. However, some noticeable
gaps exist between the imaging model used in DUNs and the real CASSI imaging
process, such as the sensing error as well as photon and dark current noise,
compromising the accuracy of solving the data subproblem and the prior
subproblem in DUNs. To address this issue, we propose a Degradation Estimation
Network (DEN) to correct the imaging model used in DUNs by simultaneously
estimating the sensing error and the noise level, thereby improving the
performance of DUNs. Additionally, we propose an efficient Local and Non-local
Transformer (LNLT) to solve the prior subproblem, which not only effectively
models local and non-local similarities but also reduces the computational cost
of the window-based global Multi-head Self-attention (MSA). Furthermore, we
transform the DUN into a Recurrent Neural Network (RNN) by sharing parameters
of DNNs across stages, which not only allows DNN to be trained more adequately
but also significantly reduces the number of parameters. The proposed
DERNN-LNLT achieves state-of-the-art (SOTA) performance with fewer parameters
on both simulation and real datasets.
","Yubo Dong, Dahua Gao, Yuyan Li, Guangming Shi, Danhua Liu",Danhua Liu,2023-11-15T09:23:42Z
"Learning transformer-based heterogeneously salient graph representation
  for multimodal remote sensing image classification","  Data collected by different modalities can provide a wealth of complementary
information, such as hyperspectral image (HSI) to offer rich spectral-spatial
properties, synthetic aperture radar (SAR) to provide structural information
about the Earth's surface, and light detection and ranging (LiDAR) to cover
altitude information about ground elevation. Therefore, a natural idea is to
combine multimodal images for refined and accurate land-cover interpretation.
Although many efforts have been attempted to achieve multi-source remote
sensing image classification, there are still three issues as follows: 1)
indiscriminate feature representation without sufficiently considering modal
heterogeneity, 2) abundant features and complex computations associated with
modeling long-range dependencies, and 3) overfitting phenomenon caused by
sparsely labeled samples. To overcome the above barriers, a transformer-based
heterogeneously salient graph representation (THSGR) approach is proposed in
this paper. First, a multimodal heterogeneous graph encoder is presented to
encode distinctively non-Euclidean structural features from heterogeneous data.
Then, a self-attention-free multi-convolutional modulator is designed for
effective and efficient long-term dependency modeling. Finally, a mean forward
is put forward in order to avoid overfitting. Based on the above structures,
the proposed model is able to break through modal gaps to obtain differentiated
graph representation with competitive time cost, even for a small fraction of
training samples. Experiments and analyses on three benchmark datasets with
various state-of-the-art (SOTA) methods show the performance of the proposed
approach.
","Jiaqi Yang, Bo Du, Liangpei Zhang",Liangpei Zhang,2023-11-17T04:06:20Z
"Unmixing Optical Signals from Undersampled Volumetric Measurements by
  Filtering the Pixel Latent Variables","  The development of signal unmixing algorithms is essential for leveraging
multimodal datasets acquired through a wide array of scientific imaging
technologies, including hyperspectral or time-resolved acquisitions. In
experimental physics, enhancing the spatio-temporal resolution or expanding the
number of detection channels often leads to diminished sampling rate and
signal-to-noise ratio (SNR), significantly affecting the efficacy of signal
unmixing algorithms. We propose Latent Unmixing, a new approach which applies
band-pass filters to the latent space of a multi-dimensional convolutional
neural network to disentangle overlapping signal components. It enables better
isolation and quantification of individual signal contributions, especially in
the context of undersampled distributions. Using multi-dimensional convolution
kernels to process all dimensions simultaneously enhances the network's ability
to extract information from adjacent pixels, and time- or spectral-bins. This
approach enables more effective separation of components in cases where
individual pixels do not provide clear, well-resolved information. We showcase
the method's practical use in experimental physics through two test cases that
highlight the versatility of our approach: fluorescence lifetime microscopy and
mode decomposition in optical fibers. The latent unmixing method extracts
valuable information from complex signals that cannot be resolved by standard
methods. It opens new possibilities in optics and photonics for multichannel
separations at an increased sampling rate.
","Catherine Bouchard, Andréanne Deschênes, Vincent Boulanger, Jean-Michel Bellavance, Julia Chabbert, Alexy Pelletier-Rioux, Flavie Lavoie-Cardinal, Christian Gagné",Christian Gagné,2023-12-08T20:34:37Z
Spectro-photometric properties of CoPhyLab's dust mixtures,"  Objective: In the framework of the Cometary Physics Laboratory (CoPhyLab) and
its sublimation experiments of cometary surface analogues under simulated space
conditions, we characterize the properties of intimate mixtures of juniper
charcoal and SiO$_2$ chosen as a dust analogue \citep{Lethuillier_2022}. We
present the details of these investigations for the spectrophotometric
properties of the samples.
  Methods: We measured these properties using a hyperspectral imager and a
radio-goniometer. From the samples' spectra, we evaluated reflectance ratios
and spectral slopes. From the measured phase curves, we inverted a photometric
model for all samples. Complementary characterizations were obtained using a
pycnometer, a scanning electron microscope and an organic elemental analyser.
  Results: We report the first values for the apparent porosity, elemental
composition, and VIS-NIR spectrophotometric properties for juniper charcoal, as
well as for intimate mixtures of this charcoal with the SiO$_2$. We find that
the juniper charcoal drives the spectrophotometric properties of the intimate
mixtures and that its strong absorbance is consistent with its elemental
composition. We find that SiO$_2$ particles form large and compact agglomerates
in every mixture imaged with the electron microscope, and its
spectrophotometric properties are affected by such features and their
particle-size distribution. We compare our results to the current literature on
comets and other small Solar System bodies and find that most of the
characterized properties of the dust analogue are comparable to some extent
with the spacecraft-visited cometary nucleii, as well as to Centaurs, Trojans
and the bluest TNOs.
","C. Feller, A. Pommerol, A. Lethuillier, N. Hänni, S. Schürch, C. Bühr, B. Gundlach, B. Haenni, N. Jäggi, M. Kaminek, the CoPhyLab Team",the CoPhyLab Team,2023-12-13T17:30:20Z
"Artificial intelligence optical hardware empowers high-resolution
  hyperspectral video understanding at 1.2 Tb/s","  Foundation models, exemplified by GPT technology, are discovering new
horizons in artificial intelligence by executing tasks beyond their designers'
expectations. While the present generation provides fundamental advances in
understanding language and images, the next frontier is video comprehension.
Progress in this area must overcome the 1 Tb/s data rate demanded to grasp
real-time multidimensional video information. This speed limit lies well beyond
the capabilities of the existing generation of hardware, imposing a roadblock
to further advances. This work introduces a hardware-accelerated integrated
optoelectronic platform for multidimensional video understanding in real-time.
The technology platform combines artificial intelligence hardware, processing
information optically, with state-of-the-art machine vision networks, resulting
in a data processing speed of 1.2 Tb/s with hundreds of frequency bands and
megapixel spatial resolution at video rates. Such performance, validated in the
AI tasks of video semantic segmentation and object understanding in indoor and
aerial applications, surpasses the speed of the closest technologies with
similar spectral resolution by three to four orders of magnitude. This platform
opens up new avenues for research in real-time AI video understanding of
multidimensional visual information, helping the empowerment of future
human-machine interactions and cognitive processing developments.
","Maksim Makarenko, Qizhou Wang, Arturo Burguete-Lopez, Silvio Giancola, Bernard Ghanem, Luca Passone, Andrea Fratalocchi",Andrea Fratalocchi,2023-12-17T07:51:38Z
"Learning Exhaustive Correlation for Spectral Super-Resolution: Where
  Spatial-Spectral Attention Meets Linear Dependence","  Spectral super-resolution that aims to recover hyperspectral image (HSI) from
easily obtainable RGB image has drawn increasing interest in the field of
computational photography. The crucial aspect of spectral super-resolution lies
in exploiting the correlation within HSIs. However, two types of bottlenecks in
existing Transformers limit performance improvement and practical applications.
First, existing Transformers often separately emphasize either spatial-wise or
spectral-wise correlation, disrupting the 3D features of HSI and hindering the
exploitation of unified spatial-spectral correlation. Second, existing
self-attention mechanism always establishes full-rank correlation matrix by
learning the correlation between pairs of tokens, leading to its inability to
describe linear dependence widely existing in HSI among multiple tokens. To
address these issues, we propose a novel Exhaustive Correlation Transformer
(ECT) for spectral super-resolution. First, we propose a Spectral-wise
Discontinuous 3D (SD3D) splitting strategy, which models unified
spatial-spectral correlation by integrating spatial-wise continuous splitting
strategy and spectral-wise discontinuous splitting strategy. Second, we propose
a Dynamic Low-Rank Mapping (DLRM) model, which captures linear dependence among
multiple tokens through a dynamically calculated low-rank dependence map. By
integrating unified spatial-spectral attention and linear dependence, our ECT
can model exhaustive correlation within HSI. The experimental results on both
simulated and real data indicate that our method achieves state-of-the-art
performance. Codes and pretrained models will be available later.
","Hongyuan Wang, Lizhi Wang, Jiang Xu, Chang Chen, Xue Hu, Fenglong Song, Youliang Yan",Youliang Yan,2023-12-20T08:30:07Z
"FedDiff: Diffusion Model Driven Federated Learning for Multi-Modal and
  Multi-Clients","  With the rapid development of imaging sensor technology in the field of
remote sensing, multi-modal remote sensing data fusion has emerged as a crucial
research direction for land cover classification tasks. While diffusion models
have made great progress in generative models and image classification tasks,
existing models primarily focus on single-modality and single-client control,
that is, the diffusion process is driven by a single modal in a single
computing node. To facilitate the secure fusion of heterogeneous data from
clients, it is necessary to enable distributed multi-modal control, such as
merging the hyperspectral data of organization A and the LiDAR data of
organization B privately on each base station client. In this study, we propose
a multi-modal collaborative diffusion federated learning framework called
FedDiff. Our framework establishes a dual-branch diffusion model feature
extraction setup, where the two modal data are inputted into separate branches
of the encoder. Our key insight is that diffusion models driven by different
modalities are inherently complementary in terms of potential denoising steps
on which bilateral connections can be built. Considering the challenge of
private and efficient communication between multiple clients, we embed the
diffusion model into the federated learning communication structure, and
introduce a lightweight communication module. Qualitative and quantitative
experiments validate the superiority of our framework in terms of image quality
and conditional consistency.
","DaiXun Li, Weiying Xie, ZiXuan Wang, YiBing Lu, Yunsong Li, Leyuan Fang",Leyuan Fang,2023-11-16T02:29:37Z
"Multimodal Informative ViT: Information Aggregation and Distribution for
  Hyperspectral and LiDAR Classification","  In multimodal land cover classification (MLCC), a common challenge is the
redundancy in data distribution, where irrelevant information from multiple
modalities can hinder the effective integration of their unique features. To
tackle this, we introduce the Multimodal Informative Vit (MIVit), a system with
an innovative information aggregate-distributing mechanism. This approach
redefines redundancy levels and integrates performance-aware elements into the
fused representation, facilitating the learning of semantics in both forward
and backward directions. MIVit stands out by significantly reducing redundancy
in the empirical distribution of each modality's separate and fused features.
It employs oriented attention fusion (OAF) for extracting shallow local
features across modalities in horizontal and vertical dimensions, and a
Transformer feature extractor for extracting deep global features through
long-range attention. We also propose an information aggregation constraint
(IAC) based on mutual information, designed to remove redundant information and
preserve complementary information within embedded features. Additionally, the
information distribution flow (IDF) in MIVit enhances performance-awareness by
distributing global classification information across different modalities'
feature maps. This architecture also addresses missing modality challenges with
lightweight independent modality classifiers, reducing the computational load
typically associated with Transformers. Our results show that MIVit's
bidirectional aggregate-distributing mechanism between modalities is highly
effective, achieving an average overall accuracy of 95.56% across three
multimodal datasets. This performance surpasses current state-of-the-art
methods in MLCC. The code for MIVit is accessible at
https://github.com/icey-zhang/MIViT.
","Jiaqing Zhang, Jie Lei, Weiying Xie, Geng Yang, Daixun Li, Yunsong Li",Yunsong Li,2024-01-06T09:53:33Z
"Limitations of Data-Driven Spectral Reconstruction -- Optics-Aware
  Analysis and Mitigation","  Hyperspectral imaging empowers machine vision systems with the distinct
capability of identifying materials through recording their spectral
signatures. Recent efforts in data-driven spectral reconstruction aim at
extracting spectral information from RGB images captured by cost-effective RGB
cameras, instead of dedicated hardware.
  In this paper we systematically analyze the performance of such methods,
evaluating both the practical limitations with respect to current datasets and
overfitting, as well as fundamental limitations with respect to the nature of
the information encoded in the RGB images, and the dependency of this
information on the optical system of the camera.
  We find that, the current models are not robust under slight variations,
e.g., in noise level or compression of the RGB file. Without modeling
underrepresented spectral content, existing datasets and the models trained on
them are limited in their ability to cope with challenging metameric colors. To
mitigate this issue, we propose to exploit the combination of metameric data
augmentation and optical lens aberrations to improve the encoding of the
metameric information into the RGB image, which paves the road towards higher
performing spectral imaging and reconstruction approaches.
","Qiang Fu, Matheus Souza, Eunsue Choi, Suhyun Shin, Seung-Hwan Baek, Wolfgang Heidrich",Wolfgang Heidrich,2024-01-08T11:46:45Z
"StarCraftImage: A Dataset For Prototyping Spatial Reasoning Methods For
  Multi-Agent Environments","  Spatial reasoning tasks in multi-agent environments such as event prediction,
agent type identification, or missing data imputation are important for
multiple applications (e.g., autonomous surveillance over sensor networks and
subtasks for reinforcement learning (RL)). StarCraft II game replays encode
intelligent (and adversarial) multi-agent behavior and could provide a testbed
for these tasks; however, extracting simple and standardized representations
for prototyping these tasks is laborious and hinders reproducibility. In
contrast, MNIST and CIFAR10, despite their extreme simplicity, have enabled
rapid prototyping and reproducibility of ML methods. Following the simplicity
of these datasets, we construct a benchmark spatial reasoning dataset based on
StarCraft II replays that exhibit complex multi-agent behaviors, while still
being as easy to use as MNIST and CIFAR10. Specifically, we carefully summarize
a window of 255 consecutive game states to create 3.6 million summary images
from 60,000 replays, including all relevant metadata such as game outcome and
player races. We develop three formats of decreasing complexity: Hyperspectral
images that include one channel for every unit type (similar to multispectral
geospatial images), RGB images that mimic CIFAR10, and grayscale images that
mimic MNIST. We show how this dataset can be used for prototyping spatial
reasoning methods. All datasets, code for extraction, and code for dataset
loading can be found at https://starcraftdata.davidinouye.com
","Sean Kulinski, Nicholas R. Waytowich, James Z. Hare, David I. Inouye",David I. Inouye,2024-01-09T00:05:56Z
"Unlocking the Potential: Multi-task Deep Learning for Spaceborne
  Quantitative Monitoring of Fugitive Methane Plumes","  As global warming intensifies, increased attention is being paid to
monitoring fugitive methane emissions and detecting gas plumes from landfills.
We have divided methane emission monitoring into three subtasks: methane
concentration inversion, plume segmentation, and emission rate estimation.
Traditional algorithms face certain limitations: methane concentration
inversion typically employs the matched filter, which is sensitive to the
global spectrum distribution and prone to significant noise. There is scant
research on plume segmentation, with many studies depending on manual
segmentation, which can be subjective. The estimation of methane emission rate
frequently uses the IME algorithm, which necessitates meteorological
measurement data. Utilizing the WENT landfill site in Hong Kong along with
PRISMA hyperspectral satellite imagery, we introduce a novel deep
learning-based framework for quantitative methane emission monitoring from
remote sensing images that is grounded in physical simulation. We create
simulated methane plumes using large eddy simulation (LES) and various
concentration maps of fugitive emissions using the radiative transfer equation
(RTE), while applying augmentation techniques to construct a simulated PRISMA
dataset. We train a U-Net network for methane concentration inversion, a Mask
R-CNN network for methane plume segmentation, and a ResNet-50 network for
methane emission rate estimation. All three deep networks yield higher
validation accuracy compared to traditional algorithms. Furthermore, we combine
the first two subtasks and the last two subtasks to design multi-task learning
models, MTL-01 and MTL-02, both of which outperform single-task models in terms
of accuracy. Our research exemplifies the application of multi-task deep
learning to quantitative methane monitoring and can be generalized to a wide
array of methane monitoring tasks.
","Guoxin Si, Shiliang Fu, Wei Yao",Wei Yao,2024-01-23T16:04:19Z
"Label-free discrimination of actin and myosin muscle networks using
  nonresonant contribution of Multiplex-Coherent anti-Stokes Raman Scattering
  (M-CARS)","  We propose an original experimental strategy providing evidence for the first
label-free disclosure of muscle actin network based on the nonresonant
contribution of a multiplex CARS (M-CARS) microscopy setup. Thin actin
filaments are known for being located between thick myosin filaments that can
be detected in Second Harmonic Generation (SHG) with our M-CARS setup. The
first step of our strategy consists in defining spatial regions where thick
myosin filaments or thin actin filaments are expected. Then we present an
analysis based on two M-CARS spectra corresponding to these regions, which
outcome highlights differences in their relative nonresonant contribution. The
final step of the presented strategy is their exploitation on each pixel of the
M-CARS hyperspectral image, enabling label-free revelation of thin actin
filaments. This qualitative imaging represents a proof of principle for
highlighting and discriminating purposes in biological microscopy thanks to a
difference in the nonlinear properties of the related proteins. Besides, this
peculiar imaging technique results from a competition between several four-wave
mixing schemes. This paves the way for considering label-free imaging through a
competition involving several light-matter interaction effects, rather than
considering several of them singularly.
","Malik Nafa, Tigran Mansuryan, Vincent Couderc, Laetitia Magnol, Véronique Blanquet, Fabienne Baraige, Claire Carrion, Jean-René Duclère, Claire Lefort",Claire Lefort,2024-02-28T18:39:27Z
"Programming the scalable optical learning operator with spatial-spectral
  optimization","  Electronic computers have evolved drastically over the past years with an
ever-growing demand for improved performance. However, the transfer of
information from memory and high energy consumption have emerged as issues that
require solutions. Optical techniques are considered promising solutions to
these problems with higher speed than their electronic counterparts and with
reduced energy consumption. Here, we use the optical reservoir computing
framework we have previously described (Scalable Optical Learning Operator or
SOLO) to program the spatial-spectral output of the light after nonlinear
propagation in a multimode fiber. The novelty in the current paper is that the
system is programmed through an output sampling scheme, similar to that used in
hyperspectral imaging in astronomy. Linear and nonlinear computations are
performed by light in the multimode fiber and the high dimensional
spatial-spectral information at the fiber output is optically programmed before
it reaches the camera. We then used a digital computer to classify the
programmed output of the multi-mode fiber using a simple, single layer network.
When combining front-end programming and the proposed spatial-spectral
programming, we were able to achieve 89.9% classification accuracy on the
dataset consisting of chest X-ray images from COVID-19 patients. At the same
time, we obtained a decrease of 99% in the number of tunable parameters
compared to an equivalently performing digital neural network. These results
show that the performance of programmed SOLO is comparable with cutting-edge
electronic computing platforms, albeit with a much-reduced number of electronic
operations.
","Yi Zhou, Jih-Liang Hsieh, Ilker Oguz, Mustafa Yildirim, Niyazi Ulas Dinc, Carlo Gigli, Kenneth K. Y. Wong, Christophe Moser, Demetri Psaltis",Demetri Psaltis,2024-03-04T20:09:56Z
"Optical Screening of Citrus Leaf Diseases Using Label-Free Spectroscopic
  Tools: A Review","  Citrus diseases pose threats to citrus farming and result in economic losses
worldwide. Nucleic acid and serology-based methods of detection and,
immunochromatographic assays are commonly used but these laboratory tests are
laborious, expensive and might be subjected to cross-reaction and
contamination. Modern optical spectroscopic techniques offer a promising
alternative as they are label-free, sensitive, rapid, non-destructive, and
demonstrate the potential for incorporation into an autonomous system for
disease detection in citrus orchards. Nevertheless, the majority of optical
spectroscopic methods for citrus disease detection are still in the trial
phases and, require additional efforts to be established as efficient and
commercially viable methods. The review presents an overview of fundamental
working principles, the state of the art, and explains the applications and
limitations of the optical spectroscopy technique including the spectroscopic
imaging approach (hyperspectral imaging) in the identification of diseases in
citrus plants. The review highlights (1) the technical specifications of
optical spectroscopic tools that can potentially be utilized in field
measurements, (2) their applications in screening citrus diseases through leaf
spectroscopy, and (3) discusses their benefits and limitations, including
future insights into label-free identification of citrus diseases. Moreover,
the role of artificial intelligence is reviewed as potential effective tools
for spectral analysis, enabling more accurate detection of infected citrus
leaves even before the appearance of visual symptoms by leveraging
compositional, morphological, and chemometric characteristics of the plant
leaves. The review aims to encourage stakeholders to enhance the development
and commercialization of field-based, label-free optical tools for the rapid
and early-stage screening of citrus diseases in plants.
","Saurav Bharadwaj, Akshita Midha, Shikha Sharma, Gurupkar Singh Sidhu, Rajesh Kumar",Rajesh Kumar,2024-03-07T14:00:39Z
SCINeRF: Neural Radiance Fields from a Snapshot Compressive Image,"  In this paper, we explore the potential of Snapshot Compressive Imaging (SCI)
technique for recovering the underlying 3D scene representation from a single
temporal compressed image. SCI is a cost-effective method that enables the
recording of high-dimensional data, such as hyperspectral or temporal
information, into a single image using low-cost 2D imaging sensors. To achieve
this, a series of specially designed 2D masks are usually employed, which not
only reduces storage requirements but also offers potential privacy protection.
Inspired by this, to take one step further, our approach builds upon the
powerful 3D scene representation capabilities of neural radiance fields (NeRF).
Specifically, we formulate the physical imaging process of SCI as part of the
training of NeRF, allowing us to exploit its impressive performance in
capturing complex scene structures. To assess the effectiveness of our method,
we conduct extensive evaluations using both synthetic data and real data
captured by our SCI system. Extensive experimental results demonstrate that our
proposed approach surpasses the state-of-the-art methods in terms of image
reconstruction and novel view image synthesis. Moreover, our method also
exhibits the ability to restore high frame-rate multi-view consistent images by
leveraging SCI and the rendering capabilities of NeRF. The code is available at
https://github.com/WU-CVGL/SCINeRF.
","Yunhao Li, Xiaodong Wang, Ping Wang, Xin Yuan, Peidong Liu",Peidong Liu,2024-03-29T07:14:14Z
"Multiscale structure-property discovery via active learning in scanning
  tunneling microscopy","  Atomic arrangements and local sub-structures fundamentally influence emergent
material functionalities. The local structures are conventionally probed using
spatially resolved studies and the property correlations are usually deciphered
by a researcher based on sequential explorations and auxiliary information,
thus limiting the throughput efficiency. Here we demonstrate a Bayesian deep
learning based framework that automatically correlates material structure with
its electronic properties using scanning tunneling microscopy (STM)
measurements in real-time. Its predictions are used to autonomously direct
exploration toward regions of the sample that optimize a given material
property. This autonomous method is deployed on the low-temperature ultra-high
vacuum STM to understand the structure-property relationship in a
europium-based semimetal, EuZn2As2, one of the promising candidates for
studying the magnetism-driven topological properties. The framework employs a
sparse sampling approach to efficiently construct the scalar-property space
using a minimal number of measurements, about 1 - 10 % of the data required in
standard hyperspectral imaging methods. We further demonstrate a
target-property-guided active learning of structures within a multiscale
framework. This is implemented across length scales in a hierarchical fashion
for the autonomous discovery of structural origins for an observed material
property. This framework offers the choice to select and derive a suitable
scalar property from the spectroscopic data to steer exploration across the
sample space. Our findings reveal correlations of the electronic properties
unique to surface terminations, local defect density, and point defects.
","Ganesh Narasimha, Dejia Kong, Paras Regmi, Rongying Jin, Zheng Gai, Rama Vasudevan, Maxim Ziatdinov",Maxim Ziatdinov,2024-04-10T15:03:48Z
"A Novel State Space Model with Local Enhancement and State Sharing for
  Image Fusion","  In image fusion tasks, images from different sources possess distinct
characteristics. This has driven the development of numerous methods to explore
better ways of fusing them while preserving their respective
characteristics.Mamba, as a state space model, has emerged in the field of
natural language processing. Recently, many studies have attempted to extend
Mamba to vision tasks. However, due to the nature of images different from
causal language sequences, the limited state capacity of Mamba weakens its
ability to model image information. Additionally, the sequence modeling ability
of Mamba is only capable of spatial information and cannot effectively capture
the rich spectral information in images. Motivated by these challenges, we
customize and improve the vision Mamba network designed for the image fusion
task. Specifically, we propose the local-enhanced vision Mamba block, dubbed as
LEVM. The LEVM block can improve local information perception of the network
and simultaneously learn local and global spatial information. Furthermore, we
propose the state sharing technique to enhance spatial details and integrate
spatial and spectral information. Finally, the overall network is a multi-scale
structure based on vision Mamba, called LE-Mamba. Extensive experiments show
the proposed methods achieve state-of-the-art results on multispectral
pansharpening and multispectral and hyperspectral image fusion datasets, and
demonstrate the effectiveness of the proposed approach. Codes can be accessed
at \url{https://github.com/294coder/Efficient-MIF}.
","Zihan Cao, Xiao Wu, Liang-Jian Deng, Yu Zhong",Yu Zhong,2024-04-14T16:09:33Z
Dual-comb correlation spectroscopy of thermal light,"  The detection of light of thermal origin is the principal means by which
humanity has learned about our world and the cosmos. In optical astronomy, in
particular, direct detection of thermal photons and the resolution of their
spectra have enabled discoveries of the broadest scope and impact. Such
measurements, however, do not capture the phase of the thermal fields--a
parameter that has proven crucial to transformative techniques in radio
astronomy such as synthetic aperture imaging. Over the last 25 years,
tremendous progress has occurred in laser science, notably in the
phase-sensitive, broad bandwidth, high resolution, and traceable spectroscopy
enabled by the optical frequency comb. In this work, we directly connect the
fields of frequency comb laser spectroscopy and passive optical sensing as
applied to astronomy, remote sensing, and atmospheric science. We provide
fundamental sensitivity analysis of dual-comb correlation spectroscopy (DCCS),
whereby broadband thermal light is measured via interferometry with two optical
frequency combs. We define and experimentally verify the sensitivity scaling of
DCCS at black body temperatures relevant for astrophysical observations.
Moreover, we provide comparison with direct detection techniques and more
conventional laser heterodyne radiometry. Our work provides the foundation for
future exploration of comb-based broadband synthetic aperture hyperspectral
imaging across the infrared and optical spectrum.
","Eugene J. Tsao, Alexander J. Lind, Connor Fredrick, Ryan K. Cole, Peter Chang, Kristina F. Chang, Dahyeon Lee, Matthew Heyrich, Nazanin Hoghooghi, Franklyn Quinlan, Scott A. Diddams",Scott A. Diddams,2024-05-23T17:55:51Z
Spectral Image Data Fusion for Multisource Data Augmentation,"  Multispectral and hyperspectral images are increasingly popular in different
research fields, such as remote sensing, astronomical imaging, or precision
agriculture. However, the amount of free data available to perform machine
learning tasks is relatively small. Moreover, artificial intelligence models
developed in the area of spectral imaging require input images with a fixed
spectral signature, expecting the data to have the same number of spectral
bands or the same spectral resolution. This requirement significantly reduces
the number of usable sources that can be used for a given model. The scope of
this study is to introduce a methodology for spectral image data fusion, in
order to allow machine learning models to be trained and/or used on data from a
larger number of sources, thus providing better generalization. For this
purpose, we propose different interpolation techniques, in order to make
multisource spectral data compatible with each other. The interpolation
outcomes are evaluated through various approaches. This includes direct
assessments using surface plots and metrics such as a Custom Mean Squared Error
(CMSE) and the Normalized Difference Vegetation Index (NDVI). Additionally,
indirect evaluation is done by estimating their impact on machine learning
model training, particularly for semantic segmentation.
","Roberta Iuliana Luca, Alexandra Baicoianu, Ioana Cristina Plajer",Ioana Cristina Plajer,2024-04-05T13:40:18Z
"Computational toolkit for predicting thickness of 2D materials using
  machine learning and autogenerated dataset by large language model","  The thickness of 2D materials not only plays a crucial role in determining
the performance of nanoelectronic and optoelectronic devices but also
introduces complexities in predicting volume-dependent properties such as
energy storage capacity, due to the intrinsic vacuum within these materials.
Although a plethora of experimental techniques, including but not limited to
optical contrast, Raman spectroscopy, nonlinear optical spectroscopy,
near-field optical imaging, and hyperspectral imaging, facilitate the
measurement of 2D material thickness, comprehensive data for many materials
remains elusive. Over the last decade, the exponential proliferation of 2D
materials and their heterostructures has outstripped the capabilities of
conventional experimental and computational approaches. In this evolving
landscape, machine learning (ML) has emerged as an indispensable tool, offering
novel avenues to augment these traditional methodologies. Addressing the
critical gap, we introduce THICK2D - Thickness Hierarchy Inference and
Calculation Kit for 2D Materials. This Python-based computational framework
harnesses an autogenerated thickness database, developed using large language
models (LLMs), and advanced ML algorithms to facilitate the rapid and scalable
estimation of material thickness, relying solely on crystallographic data. To
demonstrate the utility and robustness of THICK2D, we successfully employed the
toolkit to predict the thickness of more than 8000 2D-based materials, sourced
from two extensive 2D material databases. THICK2D is disseminated as an
open-source utility, accessible on GitHub https://github.com/gmp007/THICK2D,
and archived on Zenodo at
https://doi.org/10.5281/zenodo.11216648}{10.5281/zenodo.11216648.
",Chinedu Ekuma,Chinedu Ekuma,2024-05-24T01:05:47Z
NeurTV: Total Variation on the Neural Domain,"  Recently, we have witnessed the success of total variation (TV) for many
imaging applications. However, traditional TV is defined on the original pixel
domain, which limits its potential. In this work, we suggest a new TV
regularization defined on the neural domain. Concretely, the discrete data is
continuously and implicitly represented by a deep neural network (DNN), and we
use the derivatives of DNN outputs w.r.t. input coordinates to capture local
correlations of data. As compared with classical TV on the original domain, the
proposed TV on the neural domain (termed NeurTV) enjoys two advantages. First,
NeurTV is not limited to meshgrid but is suitable for both meshgrid and
non-meshgrid data. Second, NeurTV can more exactly capture local correlations
across data for any direction and any order of derivatives attributed to the
implicit and continuous nature of neural domain. We theoretically reinterpret
NeurTV under the variational approximation framework, which allows us to build
the connection between classical TV and NeurTV and inspires us to develop
variants (e.g., NeurTV with arbitrary resolution and space-variant NeurTV).
Extensive numerical experiments with meshgrid data (e.g., color and
hyperspectral images) and non-meshgrid data (e.g., point clouds and spatial
transcriptomics) showcase the effectiveness of the proposed methods.
","Yisi Luo, Xile Zhao, Kai Ye, Deyu Meng",Deyu Meng,2024-05-27T14:57:58Z
"Untrained Neural Nets for Snapshot Compressive Imaging: Theory and
  Algorithms","  Snapshot compressive imaging (SCI) recovers high-dimensional (3D) data cubes
from a single 2D measurement, enabling diverse applications like video and
hyperspectral imaging to go beyond standard techniques in terms of acquisition
speed and efficiency. In this paper, we focus on SCI recovery algorithms that
employ untrained neural networks (UNNs), such as deep image prior (DIP), to
model source structure. Such UNN-based methods are appealing as they have the
potential of avoiding the computationally intensive retraining required for
different source models and different measurement scenarios. We first develop a
theoretical framework for characterizing the performance of such UNN-based
methods. The theoretical framework, on the one hand, enables us to optimize the
parameters of data-modulating masks, and on the other hand, provides a
fundamental connection between the number of data frames that can be recovered
from a single measurement to the parameters of the untrained NN. We also employ
the recently proposed bagged-deep-image-prior (bagged-DIP) idea to develop SCI
Bagged Deep Video Prior (SCI-BDVP) algorithms that address the common
challenges faced by standard UNN solutions. Our experimental results show that
in video SCI our proposed solution achieves state-of-the-art among UNN methods,
and in the case of noisy measurements, it even outperforms supervised
solutions.
","Mengyu Zhao, Xi Chen, Xin Yuan, Shirin Jalali",Shirin Jalali,2024-06-06T02:22:43Z
"Local-to-Global Cross-Modal Attention-Aware Fusion for HSI-X Semantic
  Segmentation","  Hyperspectral image (HSI) classification has recently reached its performance
bottleneck. Multimodal data fusion is emerging as a promising approach to
overcome this bottleneck by providing rich complementary information from the
supplementary modality (X-modality). However, achieving comprehensive
cross-modal interaction and fusion that can be generalized across different
sensing modalities is challenging due to the disparity in imaging sensors,
resolution, and content of different modalities. In this study, we propose a
Local-to-Global Cross-modal Attention-aware Fusion (LoGoCAF) framework for
HSI-X classification that jointly considers efficiency, accuracy, and
generalizability. LoGoCAF adopts a pixel-to-pixel two-branch semantic
segmentation architecture to learn information from HSI and X modalities. The
pipeline of LoGoCAF consists of a local-to-global encoder and a lightweight
multilayer perceptron (MLP) decoder. In the encoder, convolutions are used to
encode local and high-resolution fine details in shallow layers, while
transformers are used to integrate global and low-resolution coarse features in
deeper layers. The MLP decoder aggregates information from the encoder for
feature fusion and prediction. In particular, two cross-modality modules, the
feature enhancement module (FEM) and the feature interaction and fusion module
(FIFM), are introduced in each encoder stage. The FEM is used to enhance
complementary information by combining the feature from the other modality
across direction-aware, position-sensitive, and channel-wise dimensions. With
the enhanced features, the FIFM is designed to promote cross-modality
information interaction and fusion for the final semantic prediction. Extensive
experiments demonstrate that our LoGoCAF achieves superior performance and
generalizes well. The code will be made publicly available.
","Xuming Zhang, Naoto Yokoya, Xingfa Gu, Qingjiu Tian, Lorenzo Bruzzone",Lorenzo Bruzzone,2024-06-25T16:12:20Z
"Fully invertible hyperbolic neural networks for segmenting large-scale
  surface and sub-surface data","  The large spatial/temporal/frequency scale of geoscience and remote-sensing
datasets causes memory issues when using convolutional neural networks for
(sub-) surface data segmentation. Recently developed fully reversible or fully
invertible networks can mostly avoid memory limitations by recomputing the
states during the backward pass through the network. This results in a low and
fixed memory requirement for storing network states, as opposed to the typical
linear memory growth with network depth. This work focuses on a fully
invertible network based on the telegraph equation. While reversibility saves
the major amount of memory used in deep networks by the data, the convolutional
kernels can take up most memory if fully invertible networks contain multiple
invertible pooling/coarsening layers. We address the explosion of the number of
convolutional kernels by combining fully invertible networks with layers that
contain the convolutional kernels in a compressed form directly. A second
challenge is that invertible networks output a tensor the same size as its
input. This property prevents the straightforward application of invertible
networks to applications that map between different input-output dimensions,
need to map to outputs with more channels than present in the input data, or
desire outputs that decrease/increase the resolution compared to the input
data. However, we show that by employing invertible networks in a non-standard
fashion, we can still use them for these tasks. Examples in hyperspectral
land-use classification, airborne geophysical surveying, and seismic imaging
illustrate that we can input large data volumes in one chunk and do not need to
work on small patches, use dimensionality reduction, or employ methods that
classify a patch to a single central pixel.
","Bas Peters, Eldad Haber, Keegan Lensink",Keegan Lensink,2024-06-30T05:35:12Z
Sum-of-norms regularized Nonnegative Matrix Factorization,"  When applying nonnegative matrix factorization (NMF), generally the rank
parameter is unknown. Such rank in NMF, called the nonnegative rank, is usually
estimated heuristically since computing the exact value of it is NP-hard. In
this work, we propose an approximation method to estimate such rank while
solving NMF on-the-fly. We use sum-of-norm (SON), a group-lasso structure that
encourages pairwise similarity, to reduce the rank of a factor matrix where the
rank is overestimated at the beginning. On various datasets, SON-NMF is able to
reveal the correct nonnegative rank of the data without any prior knowledge nor
tuning.
  SON-NMF is a nonconvx nonsmmoth non-separable non-proximable problem, solving
it is nontrivial. First, as rank estimation in NMF is NP-hard, the proposed
approach does not enjoy a lower computational complexity. Using a
graph-theoretic argument, we prove that the complexity of the SON-NMF is almost
irreducible. Second, the per-iteration cost of any algorithm solving SON-NMF is
possibly high, which motivated us to propose a first-order BCD algorithm to
approximately solve SON-NMF with a low per-iteration cost, in which we do so by
the proximal average operator. Lastly, we propose a simple greedy method for
post-processing.
  SON-NMF exhibits favourable features for applications. Beside the ability to
automatically estimate the rank from data, SON-NMF can deal with rank-deficient
data matrix, can detect weak component with small energy. Furthermore, on the
application of hyperspectral imaging, SON-NMF handle the issue of spectral
variability naturally.
","Andersen Ang, Waqas Bin Hamed, Hans De Sterck",Hans De Sterck,2024-06-30T14:16:27Z
"Orthogonal Constrained Minimization with Tensor $\ell_{2,p}$
  Regularization for HSI Denoising and Destriping","  Hyperspectral images (HSIs) are often contaminated by a mixture of noises
such as Gaussian noise, dead lines, stripes, and so on. In this paper, we
propose a novel approach for HSI denoising and destriping, called NLTL2p, which
consists of an orthogonal constrained minimization model and an iterative
algorithm with convergence guarantees. The model of the proposed NLTL2p
approach is built based on a new sparsity-enhanced Nonlocal Low-rank Tensor
regularization and a tensor $\ell_{2,p}$ norm with $p\in(0,1)$. The low-rank
constraints for HSI denoising utilize the spatial nonlocal self-similarity and
spectral correlation of HSIs and are formulated based on independent
higher-order singular value decomposition with sparsity enhancement on its core
tensor to prompt more low-rankness. The tensor $\ell_{2,p}$ norm for HSI
destriping is extended from the matrix $\ell_{2,p}$ norm. A proximal block
coordinate descent algorithm is proposed in the NLTL2p approach to solve the
resulting nonconvex nonsmooth minimization with orthogonal constraints. We show
any accumulation point of the sequence generated by the proposed algorithm
converges to a first-order stationary point, which is defined using three
equalities of substationarity, symmetry, and feasibility for orthogonal
constraints. In the numerical experiments, we compare the proposed method with
state-of-the-art methods including a deep learning based method, and test the
methods on both simulated and real HSI datasets. Our proposed NLTL2p method
demonstrates outperformance in terms of metrics such as mean peak
signal-to-noise ratio as well as visual quality.
","Xiaoxia Liu, Shijie Yu, Jian Lu, Xiaojun Chen",Xiaojun Chen,2024-07-04T03:33:19Z
"An Interpretable Neural Network for Vegetation Phenotyping with
  Visualization of Trait-Based Spectral Features","  Plant phenotyping is the assessment of a plant's traits and plant
identification is the process of determining the category such as genus and
species. In this paper we present an interpretable neural network trained on
the UPWINS spectral library which contains spectra with rich metadata across
variation in species, health, growth stage, annual variation, and environmental
conditions for 13 selected indicator species and natural common background
species. We show that the neurons in the network learn spectral indicators for
chemical and physiological traits through visualization of the network weights,
and we show how these traits are combined by the network for species
identification with an accuracy around 90% on a test set. While neural networks
are often perceived as `black box' classifiers, our work shows that they can be
in fact more explainable and informative than other machine learning methods.
We show that the neurons learn fundamental traits about the vegetation, for
example the composition of different types of chlorophyll present which
indicates species as well as response to illumination conditions. There is
clear excess training capacity in our network, and we expect that as the UPWINS
spectral library continues to grow the approach in this paper will provide
further foundational insights in understanding plant traits. This provides a
methodology for designing and interpreting neural networks on spectral data in
general, and provides a framework for using neural networks with hyperspectral
imagery for understanding vegetation that is extendable to other domains.
","William Basener, Abigail Basener, Michael Luegering",Michael Luegering,2024-07-14T21:20:37Z
HINER: Neural Representation for Hyperspectral Image,"  This paper introduces {HINER}, a novel neural representation for compressing
HSI and ensuring high-quality downstream tasks on compressed HSI. HINER fully
exploits inter-spectral correlations by explicitly encoding of spectral
wavelengths and achieves a compact representation of the input HSI sample
through joint optimization with a learnable decoder. By additionally
incorporating the Content Angle Mapper with the L1 loss, we can supervise the
global and local information within each spectral band, thereby enhancing the
overall reconstruction quality. For downstream classification on compressed
HSI, we theoretically demonstrate the task accuracy is not only related to the
classification loss but also to the reconstruction fidelity through a
first-order expansion of the accuracy degradation, and accordingly adapt the
reconstruction by introducing Adaptive Spectral Weighting. Owing to the
monotonic mapping of HINER between wavelengths and spectral bands, we propose
Implicit Spectral Interpolation for data augmentation by adding random
variables to input wavelengths during classification model training.
Experimental results on various HSI datasets demonstrate the superior
compression performance of our HINER compared to the existing learned methods
and also the traditional codecs. Our model is lightweight and computationally
efficient, which maintains high accuracy for downstream classification task
even on decoded HSIs at high compression ratios. Our materials will be released
at https://github.com/Eric-qi/HINER.
","Junqi Shi, Mingyi Jiang, Ming Lu, Tong Chen, Xun Cao, Zhan Ma",Zhan Ma,2024-07-31T07:35:15Z
"Empowering Snapshot Compressive Imaging: Spatial-Spectral State Space
  Model with Across-Scanning and Local Enhancement","  Snapshot Compressive Imaging (SCI) relies on decoding algorithms such as CNN
or Transformer to reconstruct the hyperspectral image (HSI) from its compressed
measurement. Although existing CNN and Transformer-based methods have proven
effective, CNNs are limited by their inadequate modeling of long-range
dependencies, while Transformer ones face high computational costs due to
quadratic complexity. Recent Mamba models have demonstrated superior
performance over CNN and Transformer-based architectures in some visual tasks,
but these models have not fully utilized the local similarities in both spatial
and spectral dimensions. Moreover, the long-sequence modeling capability of SSM
may offer an advantage in processing the numerous spectral bands for HSI
reconstruction, which has not yet been explored. In this paper, we introduce a
State Space Model with Across-Scanning and Local Enhancement, named ASLE-SSM,
that employs a Spatial-Spectral SSM for global-local balanced context encoding
and cross-channel interaction promoting. Specifically, we introduce local
scanning in the spatial dimension to balance the global and local receptive
fields, and then propose our across-scanning method based on spatial-spectral
local cubes to leverage local similarities between adjacent spectral bands and
pixels to guide the reconstruction process. These two scanning mechanisms
extract the HSI's local features while balancing the global perspective without
any additional costs. Experimental results illustrate ASLE-SSM's superiority
over existing state-of-the-art methods, with an inference speed 2.4 times
faster than Transformer-based MST and saving 0.12 (M) of parameters, achieving
the lowest computational cost and parameter count.
","Wenzhe Tian, Haijin Zeng, Yin-Ping Zhao, Yongyong Chen, Zhen Wang, Xuelong Li",Xuelong Li,2024-08-01T15:14:10Z
"New spectral imaging biomarkers for sepsis and mortality in intensive
  care","  With sepsis remaining a leading cause of mortality, early identification of
septic patients and those at high risk of death is a challenge of high
socioeconomic importance. The driving hypothesis of this study was that
hyperspectral imaging (HSI) could provide novel biomarkers for sepsis diagnosis
and treatment management due to its potential to monitor microcirculatory
alterations. We conducted a comprehensive study involving HSI data of the palm
and fingers from more than 480 patients on the day of their intensive care unit
(ICU) admission. The findings demonstrate that HSI measurements can predict
sepsis with an area under the receiver operating characteristic curve (AUROC)
of 0.80 (95 % confidence interval (CI) [0.76; 0.84]) and mortality with an
AUROC of 0.72 (95 % CI [0.65; 0.79]). The predictive performance improves
substantially when additional clinical data is incorporated, leading to an
AUROC of up to 0.94 (95 % CI [0.92; 0.96]) for sepsis and 0.84 (95 % CI [0.78;
0.89]) for mortality. We conclude that HSI presents novel imaging biomarkers
for the rapid, non-invasive prediction of sepsis and mortality, suggesting its
potential as an important modality for guiding diagnosis and treatment.
","Silvia Seidlitz, Katharina Hölzl, Ayca von Garrel, Jan Sellner, Stephan Katzenschlager, Tobias Hölle, Dania Fischer, Maik von der Forst, Felix C. F. Schmitt, Markus A. Weigand, Lena Maier-Hein, Maximilian Dietrich",Maximilian Dietrich,2024-08-19T10:24:57Z
"MSFMamba: Multi-Scale Feature Fusion State Space Model for Multi-Source
  Remote Sensing Image Classification","  In multi-source remote sensing image classification field, remarkable
progress has been made by convolutional neural network and Transformer.
However, existing methods are still limited due to the inherent local reductive
bias. Recently, Mamba-based methods built upon the State Space Model have shown
great potential for long-range dependency modeling with linear complexity, but
it has rarely been explored for the multi-source remote sensing image
classification task. To this end, we propose Multi-Scale Feature Fusion Mamba
(MSFMamba) network for hyperspectral image (HSI) and LiDAR/SAR data joint
classification. Specifically, MSFMamba mainly comprises three parts:
Multi-Scale Spatial Mamba (MSpa-Mamba) block, Spectral Mamba (Spe-Mamba) block,
and Fusion Mamba (Fus-Mamba) block. Specifically, to solve the feature
redundancy in multiple canning routes, the MSpa-Mamba block incorporates the
multi-scale strategy to minimize the computational redundancy and alleviate the
feature redundancy of SSM. In addition, Spe-Mamba is designed for spectral
feature exploration, which is essential for HSI feature modeling. Moreover, to
alleviate the heterogeneous gap between HSI and LiDAR/SAR data, we design
Fus-Mamba block for multi-source feature fusion. The original Mamba is extended
to accommodate dual inputs, and cross-modal feature interaction is enhanced.
Extensive experimental results on three multi-source remote sensing datasets
demonstrate the superiority performance of the proposed MSFMamba over the
state-of-the-art models. Source codes of MSFMamba will be made public available
at https://github.com/summitgao/MSFMamba .
","Feng Gao, Xuepeng Jin, Xiaowei Zhou, Junyu Dong, Qian Du",Qian Du,2024-08-26T13:18:16Z
"Multi-Head Attention Residual Unfolded Network for Model-Based
  Pansharpening","  The objective of pansharpening and hypersharpening is to accurately combine a
high-resolution panchromatic (PAN) image with a low-resolution multispectral
(MS) or hyperspectral (HS) image, respectively. Unfolding fusion methods
integrate the powerful representation capabilities of deep learning with the
robustness of model-based approaches. These techniques involve unrolling the
steps of the optimization scheme derived from the minimization of an energy
into a deep learning framework, resulting in efficient and highly interpretable
architectures. In this paper, we propose a model-based deep unfolded method for
satellite image fusion. Our approach is based on a variational formulation that
incorporates the classic observation model for MS/HS data, a high-frequency
injection constraint based on the PAN image, and an arbitrary convex prior. For
the unfolding stage, we introduce upsampling and downsampling layers that use
geometric information encoded in the PAN image through residual networks. The
backbone of our method is a multi-head attention residual network (MARNet),
which replaces the proximity operator in the optimization scheme and combines
multiple head attentions with residual learning to exploit image
self-similarities via nonlocal operators defined in terms of patches.
Additionally, we incorporate a post-processing module based on the MARNet
architecture to further enhance the quality of the fused images. Experimental
results on PRISMA, Quickbird, and WorldView2 datasets demonstrate the superior
performance of our method and its ability to generalize across different sensor
configurations and varying spatial and spectral resolutions. The source code
will be available at https://github.com/TAMI-UIB/MARNet.
","Ivan Pereira-Sánchez, Eloi Sans, Julia Navarro, Joan Duran",Joan Duran,2024-09-04T13:05:00Z
Moiré exciton polaron engineering via twisted hBN,"  Twisted hexagonal boron nitride (thBN) exhibits emergent ferroelectricity due
to the formation of moir\'e superlattices with alternating AB and BA domains.
These domains possess electric dipoles, leading to a periodic electrostatic
potential that can be imprinted onto other 2D materials placed in its
proximity. Here we demonstrate the remote imprinting of moir\'e patterns from
twisted hexagonal boron nitride (thBN) onto monolayer MoSe2 and investigate the
resulting changes in the exciton properties. We confirm the imprinting of
moir\'e patterns on monolayer MoSe2 via proximity using Kelvin probe force
microscopy (KPFM) and hyperspectral photoluminescence (PL) mapping. By
developing a technique to create large ferroelectric domain sizes ranging from
1 {\mu}m to 8.7 {\mu}m, we achieve unprecedented potential modulation of 387 +-
52 meV. We observe the formation of exciton polarons due to charge
redistribution caused by the antiferroelectric moir\'e domains and investigate
the optical property changes induced by the moir\'e pattern in monolayer MoSe2
by varying the moir\'e pattern size down to 110 nm. Our findings highlight the
potential of twisted hBN as a platform for controlling the optical and
electronic properties of 2D materials for optoelectronic and valleytronic
applications.
","Minhyun Cho, Biswajit Datta, Kwanghee Han, Saroj B. Chand, Pratap Chandra Adak, Sichao Yu, Fengping Li, Kenji Watanabe, Takashi Taniguchi, James Hone, Jeil Jung, Gabriele Grosso, Young Duck Kim, Vinod M. Menon",Vinod M. Menon,2024-09-11T04:18:06Z
"Neural Network Architecture Search Enabled Wide-Deep Learning (NAS-WD)
  for Spatially Heterogenous Property Awared Chicken Woody Breast
  Classification and Hardness Regression","  Due to intensive genetic selection for rapid growth rates and high broiler
yields in recent years, the global poultry industry has faced a challenging
problem in the form of woody breast (WB) conditions. This condition has caused
significant economic losses as high as $200 million annually, and the root
cause of WB has yet to be identified. Human palpation is the most common method
of distinguishing a WB from others. However, this method is time-consuming and
subjective. Hyperspectral imaging (HSI) combined with machine learning
algorithms can evaluate the WB conditions of fillets in a non-invasive,
objective, and high-throughput manner. In this study, 250 raw chicken breast
fillet samples (normal, mild, severe) were taken, and spatially heterogeneous
hardness distribution was first considered when designing HSI processing
models. The study not only classified the WB levels from HSI but also built a
regression model to correlate the spectral information with sample hardness
data. To achieve a satisfactory classification and regression model, a neural
network architecture search (NAS) enabled a wide-deep neural network model
named NAS-WD, which was developed. In NAS-WD, NAS was first used to
automatically optimize the network architecture and hyperparameters. The
classification results show that NAS-WD can classify the three WB levels with
an overall accuracy of 95%, outperforming the traditional machine learning
model, and the regression correlation between the spectral data and hardness
was 0.75, which performs significantly better than traditional regression
models.
","Chaitanya Pallerla, Yihong Feng, Casey M. Owens, Ramesh Bahadur Bist, Siavash Mahmoudi, Pouya Sohrabipour, Amirreza Davar, Dongyi Wang",Dongyi Wang,2024-09-25T16:57:09Z
"Projected Tensor-Tensor Products for Efficient Computation of Optimal
  Multiway Data Representations","  Tensor decompositions have become essential tools for feature extraction and
compression of multiway data. Recent advances in tensor operators have enabled
desirable properties of standard matrix algebra to be retained for multilinear
factorizations. Behind this matrix-mimetic tensor operation is an invertible
matrix whose size depends quadratically on certain dimensions of the data. As a
result, for large-scale multiway data, the invertible matrix can be
computationally demanding to apply and invert and can lead to inefficient
tensor representations in terms of construction and storage costs. In this
work, we propose a new projected tensor-tensor product that relaxes the
invertibility restriction to reduce computational overhead and still preserves
fundamental linear algebraic properties. The transformation behind the
projected product is a tall-and-skinny matrix with unitary columns, which
depends only linearly on certain dimensions of the data, thereby reducing
computational complexity by an order of magnitude. We provide extensive theory
to prove the matrix mimeticity and the optimality of compressed representations
within the projected product framework. We further prove that
projected-product-based approximations outperform a comparable,
non-matrix-mimetic tensor factorization. We support the theoretical findings
and demonstrate the practical benefits of projected products through numerical
experiments on video and hyperspectral imaging data.
","Katherine Keegan, Elizabeth Newman",Elizabeth Newman,2024-09-28T16:29:54Z
Synthetic gain for electron-beam spectroscopy,"  Electron-beam microscopy and spectroscopy featuring atomic-scale spatial
resolution have become essential tools used daily in almost all branches of
nanoscale science and technology. As a natural supercontinuum source of light,
free electrons couple with phonons, plasmons, electron-hole pairs, inter- and
intra-band transitions, and inner-shell ionization. The multiple excitations,
intertwined with the intricate nature of nanostructured samples, present
significant challenges in isolating specific spectral characteristics amidst
complex experimental backgrounds. Here we introduce the approach of synthetic
complex frequency waves to mitigate these challenges in free-electron--light
interaction. The complex frequency waves, created through causality-informed
coherent superposition of real-frequency waves induced by free electrons, offer
virtual gain to offset material losses. This amplifies and enhances spectral
features, as confirmed by our electron energy loss and cathodoluminescence
measurements on multi-layer membranes, suspended nanoparticles, and
film-coupled nanostructures. Strikingly, we reveal that our approach can
retrieve resonance excitation completed buried underneath the zero-loss peak,
substantially enhance the quality of hyperspectral imaging, and resolve
entangled multiple-photon--electron events in their quantum interaction. Our
findings indicate the versatile utility of complex frequency waves in various
electron-beam spectroscopy and their promising diagnostic capabilities in
free-electron quantum optics.
","Yongliang Chen, Kebo Zeng, Zetao Xie, Yixin Sha, Zeling Chen, Xudong Zhang, Shu Yang, Shimeng Gong, Yiqin Chen, Huigao Duan, Shuang Zhang, Yi Yang",Yi Yang,2024-10-22T13:11:17Z
Integration of Communication and Computational Imaging,"  Communication enables the expansion of human visual perception beyond the
limitations of time and distance, while computational imaging overcomes the
constraints of depth and breadth. Although impressive achievements have been
witnessed with the two types of technologies, the occlusive information flow
between the two domains is a bottleneck hindering their ulterior progression.
Herein, we propose a novel framework that integrates communication and
computational imaging (ICCI) to break through the inherent isolation between
communication and computational imaging for remote perception. By jointly
considering the sensing and transmitting of remote visual information, the ICCI
framework performs a full-link information transfer optimization, aiming to
minimize information loss from the generation of the information source to the
execution of the final vision tasks. We conduct numerical analysis and
experiments to demonstrate the ICCI framework by integrating communication
systems and snapshot compressive imaging systems. Compared with straightforward
combination schemes, which sequentially execute sensing and transmitting, the
ICCI scheme shows greater robustness against channel noise and impairments
while achieving higher data compression. Moreover, an 80 km 27-band
hyperspectral video perception with a rate of 30 fps is experimentally
achieved. This new ICCI remote perception paradigm offers a highefficiency
solution for various real-time computer vision tasks.
","Zhenming Yu, Liming Cheng, Hongyu Huang, Wei Zhang, Liang Lin, Kun Xu",Kun Xu,2024-10-25T09:19:59Z
"Xeno-learning: knowledge transfer across species in deep learning-based
  spectral image analysis","  Novel optical imaging techniques, such as hyperspectral imaging (HSI)
combined with machine learning-based (ML) analysis, have the potential to
revolutionize clinical surgical imaging. However, these novel modalities face a
shortage of large-scale, representative clinical data for training ML
algorithms, while preclinical animal data is abundantly available through
standardized experiments and allows for controlled induction of pathological
tissue states, which is not ethically possible in patients. To leverage this
situation, we propose a novel concept called ""xeno-learning"", a cross-species
knowledge transfer paradigm inspired by xeno-transplantation, where organs from
a donor species are transplanted into a recipient species. Using a total of
11,268 HSI images from humans as well as porcine and rat models, we show that
although spectral signatures of organs differ across species, shared
pathophysiological mechanisms manifest as comparable relative spectral changes
across species. Such changes learnt in one species can thus be transferred to a
new species via a novel ""physiology-based data augmentation"" method, enabling
the large-scale secondary use of preclinical animal data for humans. The
resulting ethical, monetary, and performance benefits of the proposed knowledge
transfer paradigm promise a high impact of the methodology on future
developments in the field.
","Jan Sellner, Alexander Studier-Fischer, Ahmad Bin Qasim, Silvia Seidlitz, Nicholas Schreck, Minu Tizabi, Manuel Wiesenfarth, Annette Kopp-Schneider, Samuel Knödler, Caelan Max Haney, Gabriel Salg, Berkin Özdemir, Maximilian Dietrich, Maurice Stephan Michel, Felix Nickel, Karl-Friedrich Kowalewski, Lena Maier-Hein",Lena Maier-Hein,2024-10-15T16:25:16Z
"Multiple-beam Interference Spectroscopy: Instrument Analysis and
  Spectrum Reconstruction","  Hyperspectral imaging systems based on multiple-beam interference (MBI), such
as Fabry-Perot interferometry, are attracting interest due to their compact
design, high throughput, and fine resolution. Unlike dispersive devices, which
measure spectra directly, the desired spectra in interferometric systems are
reconstructed from measured interferograms. Although the response of MBI
devices is modeled by the Airy function, existing reconstruction techniques are
often limited to Fourier-transform spectroscopy, which is tailored for two-beam
interference (TBI). These methods impose limitations for MBI and are
susceptible to non-idealities like irregular sampling and noise, highlighting
the need for an in-depth numerical framework. To fill this gap, we propose a
rigorous taxonomy of the TBI and MBI instrument description and propose a
unified Bayesian formulation which both embeds the description of existing
literature works and adds some of the real-world non-idealities of the
acquisition process. Under this framework, we provide a comprehensive review of
spectroscopy forward and inverse models. In the forward model, we propose a
thorough analysis of the discretization of the continuous model and the
ill-posedness of the problem. In the inverse model, we extend the range of
existing solutions for spectrum reconstruction, framing them as an optimization
problem. Specifically, we provide a progressive comparative analysis of
reconstruction methods from more specific to more general scenarios, up to
employing the proposed Bayesian framework with prior knowledge, such as
sparsity constraints. Experiments on simulated and real data demonstrate the
framework's flexibility and noise robustness. The code is available at
https://github.com/mhmdjouni/inverspyctrometry.
","Mohamad Jouni, Daniele Picone, Mauro Dalla Mura",Mauro Dalla Mura,2024-10-28T22:40:39Z
"Unsupervised Multimodal Fusion of In-process Sensor Data for Advanced
  Manufacturing Process Monitoring","  Effective monitoring of manufacturing processes is crucial for maintaining
product quality and operational efficiency. Modern manufacturing environments
generate vast amounts of multimodal data, including visual imagery from various
perspectives and resolutions, hyperspectral data, and machine health monitoring
information such as actuator positions, accelerometer readings, and temperature
measurements. However, interpreting this complex, high-dimensional data
presents significant challenges, particularly when labeled datasets are
unavailable. This paper presents a novel approach to multimodal sensor data
fusion in manufacturing processes, inspired by the Contrastive Language-Image
Pre-training (CLIP) model. We leverage contrastive learning techniques to
correlate different data modalities without the need for labeled data,
developing encoders for five distinct modalities: visual imagery, audio
signals, laser position (x and y coordinates), and laser power measurements. By
compressing these high-dimensional datasets into low-dimensional
representational spaces, our approach facilitates downstream tasks such as
process control, anomaly detection, and quality assurance. We evaluate the
effectiveness of our approach through experiments, demonstrating its potential
to enhance process monitoring capabilities in advanced manufacturing systems.
This research contributes to smart manufacturing by providing a flexible,
scalable framework for multimodal data fusion that can adapt to diverse
manufacturing environments and sensor configurations.
","Matthew McKinney, Anthony Garland, Dale Cillessen, Jesse Adamczyk, Dan Bolintineanu, Michael Heiden, Elliott Fowler, Brad L. Boyce",Brad L. Boyce,2024-10-29T21:52:04Z
"Investigating the Applicability of a Snapshot Computed Tomography
  Imaging Spectrometer for the Prediction of Brix and pH of Grapes","  In this paper, a recently developed snapshot hyperspectral imaging (HSI)
system based on Computed Tomography Imaging Spectroscopy (CTIS) is utilized to
determine Brix and pH values in Sheegene 20 table grapes through Partial Least
Squares Regression (PLSR) modeling. The performance of the CTIS system is
compared with that of a state-of-the-art line scan HSI system by imaging 100
grapes across both platforms. Reference measurements of Brix and pH values are
obtained directly using a refractometer and a pH meter, as these parameters are
essential for assessing the quality of table and wine grapes. The findings
indicate that the spectra captured by the CTIS camera correlate well with the
reference measurements, despite the system's narrower spectral range. The CTIS
camera's advantages, including its lower cost, portability, and reduced
susceptibility to motion errors, highlight its potential for promising in-field
applications in grape quality assessment.
","Mads Svanborg Peters, Mads Juul Ahlebæk, Mads Toudal Frandsen, Bjarke Jørgensen, Christian Hald Jessen, Andreas Krogh Carlsen, Wei-Chih Huang, René Lynge Eriksen",René Lynge Eriksen,2024-11-05T14:03:36Z
"An improvement to the volcano-scan algorithm for atmospheric correction
  of CRISM and OMEGA spectral data","  The observations of Mars by the CRISM and OMEGA hyperspectral imaging
spectrometers require correction for photometric, atmospheric and thermal
effects prior to the interpretation of possible mineralogical features in the
spectra. Here, we report on a simple, yet non-trivial, adaptation to the
commonly-used volcano-scan correction technique for atmospheric CO_2, which
allows for the improved detection of minerals with intrinsic absorption bands
at wavelengths between 1.9-2.1 $\mu$m. This volcano-scan technique removes the
absorption bands of CO_2 by ensuring that the Lambert albedo is the same at two
wavelengths: 1.890 $\mu$m and 2.011 $\mu$m, with the first wavelength outside
the CO_2 gas bands and the second wavelength deep inside the CO_2 gas bands.
Our adaptation to the volcano-scan technique moves the first wavelength from
1.890 $\mu$m to be instead within the gas bands at 1.980 $\mu$m, and for CRISM
data, our adaptation shifts the second wavelength slightly, to 2.007 $\mu$m. We
also report on our efforts to account for a slight ~0.001 $\mu$m shift in
wavelengths due to thermal effects in the CRISM instrument.
","Patrick C. McGuire, Janice L. Bishop, Adrian J. Brown, Abigail A. Fraeman, Giuseppe A. Marzo, M. Frank Morgan, Scott L. Murchie, John F. Mustard, Mario Parente, Shannon M. Pelkey, Ted L. Roush, Frank P. Seelos, Michael D. Smith, Lorenz Wendt, Michael J. Wolff",Michael J. Wolff,2009-03-21T15:55:15Z
"Properties of the giant HII regions and bar in the nearby spiral galaxy
  NGC5430","  In order to better understand the impact of the bar on the evolution of
spiral galaxies, we measure the properties of giant HII regions and the bar in
the SB(s)b galaxy NGC5430. We use two complementary data sets, both obtained at
the Observatoire du Mont-M\'egantic: a hyperspectral data cube from the imaging
Fourier transform spectrograph SpIOMM, and high-resolution spectra across the
bar from a long-slit spectrograph. We flux-calibrate SpIOMM spectra for the
first time, and produce H{\alpha} and [NII]{\lambda}6584\r{A} intensity maps
from which we identify 51 giant HII regions in the spiral arms and bar. We
evaluate the type of activity, the oxygen abundance and the age of the young
populations contained in these giant HII regions and in the bar. Thus, we
confirm that NGC5430 does not harbour a strong AGN, and that its Wolf-Rayet
knot shows a pure HII region nature. We find no variation in abundance or age
between the bar and spiral arms, nor as a function of galactocentric radius.
These results are consistent with the hypothesis that a chemical mixing
mechanism is at work in the galaxy's disc to flatten the oxygen abundance
gradient. Using the starburst99 model, we estimate the ages of the young
populations, and again find no variations in age between the bar and the arms
or as a function of radius. Instead, we find evidence for two galaxy-wide waves
of star formation, about 7.1 Myr and 10.5 Myr ago. While the bar in NGC5430 is
an obvious candidate to trigger these two episodes, it is not clear how the bar
could induce widespread star formation on such a short time-scale.
","É. Brière, S. Cantin, K. Spekkens",K. Spekkens,2012-06-08T03:20:20Z
"Retrieving Atmospheric Dust Opacity on Mars by Imaging Spectroscopy at
  Large Angles","  We propose a new method to retrieve the optical depth of Martian aerosols
(AOD) from OMEGA and CRISM hyperspectral imagery at a reference wavelength of 1
{\mu}m. Our method works even if the underlying surface is completely made of
minerals, corresponding to a low contrast between surface and atmospheric dust,
while being observed at a fixed geometry. Minimizing the effect of the surface
reflectance properties on the AOD retrieval is the second principal asset of
our method. The method is based on the parametrization of the radiative
coupling between particles and gas determining, with local altimetry,
acquisition geometry, and the meteorological situation, the absorption band
depth of gaseous CO2. Because the last three factors can be predicted to some
extent, we can define a new parameter {\beta} that expresses specifically the
strength of the gas-aerosols coupling while directly depending on the AOD.
Combining estimations of {\beta} and top of the atmosphere radiance values
extracted from the observed spectra within the CO2 gas band at 2 {\mu}m, we
evaluate the AOD and the surface reflectance by radiative transfer inversion.
One should note that practically {\beta} can be estimated for a large variety
of mineral or icy surfaces with the exception of CO2 ice when its 2 {\mu}m
solid band is not sufficiently saturated. Validation of the proposed method
shows that it is reliable if two conditions are fulfilled: (i) the observation
conditions provide large incidence or/and emergence angles (ii) the aerosol are
vertically well mixed in the atmosphere. Experiments conducted on OMEGA nadir
looking observations as well as CRISM EPF acquisitions with incidence angles
higher than 65{\deg} and 33{\deg} respectively produce very satisfactory
results. Finally in a companion paper the method is applied to monitoring
atmospheric dust spring activity at high southern latitudes on Mars using
OMEGA.
","S. Douté, X. Ceamanos, T. Appéré",T. Appéré,2013-02-04T14:01:13Z
"A Multiple Hypothesis Testing Approach to Low-Complexity Subspace
  Unmixing","  Subspace-based signal processing traditionally focuses on problems involving
a few subspaces. Recently, a number of problems in different application areas
have emerged that involve a significantly larger number of subspaces relative
to the ambient dimension. It becomes imperative in such settings to first
identify a smaller set of active subspaces that contribute to the observation
before further processing can be carried out. This problem of identification of
a small set of active subspaces among a huge collection of subspaces from a
single (noisy) observation in the ambient space is termed subspace unmixing.
This paper formally poses the subspace unmixing problem under the parsimonious
subspace-sum (PS3) model, discusses connections of the PS3 model to problems in
wireless communications, hyperspectral imaging, high-dimensional statistics and
compressed sensing, and proposes a low-complexity algorithm, termed marginal
subspace detection (MSD), for subspace unmixing. The MSD algorithm turns the
subspace unmixing problem for the PS3 model into a multiple hypothesis testing
(MHT) problem and its analysis in the paper helps control the family-wise error
rate of this MHT problem at any level $\alpha \in [0,1]$ under two random
signal generation models. Some other highlights of the analysis of the MSD
algorithm include: (i) it is applicable to an arbitrary collection of subspaces
on the Grassmann manifold; (ii) it relies on properties of the collection of
subspaces that are computable in polynomial time; and ($iii$) it allows for
linear scaling of the number of active subspaces as a function of the ambient
dimension. Finally, numerical results are presented in the paper to better
understand the performance of the MSD algorithm.
","Waheed U. Bajwa, Dustin G. Mixon",Dustin G. Mixon,2014-08-07T02:44:24Z
"Spectrophotometric analysis of cometary nuclei from in situ observations
  (PhD thesis)","  Topic of this work are comets, small and elusive objects that may hold great
secrets about the origin of the Solar System and life on Earth, being among the
most primitive objects. The method of investigation addressed in this work is
the visible and infrared spectrophotometry by imaging spectrometers, designed
for the observation of remote planetary atmospheres and surfaces, capable to
acquire hyperspectral data with high spatial and spectral resolution. The
context under which this mission moves its steps is described in the first
chapter. In the second chapter the performances of the VIRTS instrument,
onboard Rosetta spacecraft, are analyzed in detail. In particular the modeling
of the signal to noise ratio is the main argument of this chapter. The third
chapter shows simulations of possible spectra of the comet's nucleus, which are
useful for both a comparison with real spectra, and for a planning of the
observations. Hapke's radiative transfer model is used to invert acquired data
to infer physical properties. The fourth chapter introduces a method for
spectral modeling. It includes the information on the instrumental noise,
permitting the analysis of the goodness of the models, and an estimation of the
error of the retrieved parameters. The fifth chapter presents the spectral
analysis of Tempel 1 and Hartley 2 whose data are coming from Deep Impact space
mission and its extended investigation. The sixth chapter shows the photometric
analysis of Lutetia asteroid, which was encountered by Rosetta during its
cruise phase. This work have paved the way to the analysis of the final target
of Rosetta: comet 67P/Churyumov-Gerasimenko. The tools presented are currently
used by the VIRTIS Team to produce works on the comet, that are recommended to
the reader. Since a complete analysis on the comet is outside the scope of this
work, just preliminary results are shown here.
",Andrea Raponi,Andrea Raponi,2015-03-27T18:23:57Z
"A Critical Survey of Deconvolution Methods for Separating cell-types in
  Complex Tissues","  Identifying concentrations of components from an observed mixture is a
fundamental problem in signal processing. It has diverse applications in fields
ranging from hyperspectral imaging to denoising biomedical sensors. This paper
focuses on in-silico deconvolution of signals associated with complex tissues
into their constitutive cell-type specific components, along with a
quantitative characterization of the cell-types. Deconvolving mixed
tissues/cell-types is useful in the removal of contaminants (e.g., surrounding
cells) from tumor biopsies, as well as in monitoring changes in the cell
population in response to treatment or infection. In these contexts, the
observed signal from the mixture of cell-types is assumed to be a linear
combination of the expression levels of genes in constitutive cell-types. The
goal is to use known signals corresponding to individual cell-types along with
a model of the mixing process to cast the deconvolution problem as a suitable
optimization problem.
  In this paper, we present a survey of models, methods, and assumptions
underlying deconvolution techniques. We investigate the choice of the different
loss functions for evaluating estimation error, constraints on solutions,
preprocessing and data filtering, feature selection, and regularization to
enhance the quality of solutions, along with the impact of these choices on the
performance of regression-based methods for deconvolution. We assess different
combinations of these factors and use detailed statistical measures to evaluate
their effectiveness. We identify shortcomings of current methods and avenues
for further investigation. For many of the identified shortcomings, such as
normalization issues and data filtering, we provide new solutions. We summarize
our findings in a prescriptive step-by-step process, which can be applied to a
wide range of deconvolution problems.
","Shahin Mohammadi, Neta Zuckerman, Andrea Goldsmith, Ananth Grama",Ananth Grama,2015-10-15T15:28:02Z
"The temporal evolution of exposed water ice-rich areas on the surface of
  67P/Churyumov-Gerasimenko: spectral analysis","  Water ice-rich patches have been detected on the surface of comet
67P/Churyumov-Gerasimenko by the VIRTIS hyperspectral imager on-board the
Rosetta spacecraft, since the orbital insertion in late August 2014. Among
those, three icy patches have been selected, and VIRTIS data are used to
analyse their properties and their temporal evolution while the comet was
moving towards the Sun. We performed an extensive analysis of the spectral
parameters, and we applied the Hapke radiative transfer model to retrieve the
abundance and grain size of water ice, as well as the mixing modalities of
water ice and dark terrains on the three selected water ice rich areas. Study
of the spatial distribution of the spectral parameters within the ice-rich
patches has revealed that water ice follows different patterns associated to a
bimodal distribution of the grains: ~50 {\mu}m sized and ~2000 {\mu}m sized. In
all three cases, after the first detections at about 3.5 AU heliocentric
distance, the spatial extension and intensity of the water ice spectral
features increased, it reached a maximum after 60-100 days at about 3.0 AU, and
was followed by an approximately equally timed decrease and disappearanceat
about ~2.2 AU, before perihelion. The behaviour of the analysed patches can be
assimilated to a seasonal cycle. In addition we found evidence of short-term
variability associated to a diurnal water cycle. The similar lifecycle of the
three icy regions indicates that water ice is uniformly distributed in the
subsurface layers, and no large water ice reservoirs are present.
","A. Raponi, M. Ciarniello, F. Capaccioni, G. Filacchione, F. Tosi, M. C. De Sanctis, M. T. Capria, M. A. Barucci, A. Longobardo, E. Palomba, D. Kappel, G. Arnold, S. Mottola, B. Rousseau, E. Quirico, G. Rinaldi, S. Erard, D. Bockelee-Morvan, C. Leyrat",C. Leyrat,2016-12-07T12:52:57Z
"Mapping polar atmospheric features on Titan with VIMS: from the
  dissipation of the northern cloud to the onset of a southern polar vortex","  We have analyzed the complete archive of the Visual and Infrared Mapping
Spectrometer (VIMS) data in order to monitor and analyze the evolution of the
clouds and haze coverage at both poles of Titan during the entire Cassini
mission. Our objective is to give a cartographic synopsis from a VIMS
perspective, to provide a global view of the seasonal evolution of Titan's
atmosphere over the poles. We leave the detailed comparison with the Imaging
Science Subsystem (ISS) and the Composite Infrared Spectrometer (CIRS) data
sets to further studies. We have computed global hyperspectral mosaics for each
of the 127 targeted flybys of Titan to produce synthetic color maps emphasizing
the main atmospheric features. The north pole appears fully covered by a huge
cloud as soon as the first observations in 2004 and up to the equinox in 2009
(Le Mou\'elic et al. 2012). The northern skies then became progressively
clearer, after the circulation turnover in 2009, revealing the underlying lakes
and seas to the optical instruments up to 2017. The reverse situation is
observed over the south pole, which was mostly clear of such a high obscuring
cloud during the first years of the mission, but started to develop a polar
cloud in 2012. This feature grew up month after month until the end of the
mission in 2017, with a poleward latitudinal extent of 75$^\circ$S in 2013 up
to 58$^\circ$S in April 2017. Thanks to the spectral capabilities of VIMS, we
have detected HCN spectral signatures over the north pole in almost all flybys
between 2004 and 2008. These HCN signatures started then to show up over the
south pole in almost all flybys between 2012 and 2017, so perfectly matching
the timing and spatial extent of the northern and southern polar atmospheric
features.
","Stéphane Le Mouélic, Sébastien Rodriguez, Rozen Robidel, Baptiste Rousseau, Benoît Seignovert, Christophe Sotin, Jason W. Barnes, Robert H. Brown, Kevin H. Baines, Bonnie J. Buratti, Roger N. Clark, Philip D. Nicholson, Pascal Rannou, Thomas Cornet",Thomas Cornet,2018-05-02T20:58:09Z
"Correlated nanoscale analysis of the emission from wurtzite versus
  zincblende (In,Ga)As/GaAs nanowire core-shell quantum wells","  While the properties of wurtzite GaAs have been extensively studied during
the past decade, little is known about the influence of the crystal polytype on
ternary (In,Ga)As quantum well structures. We address this question with a
unique combination of correlated, spatially-resolved measurement techniques on
core-shell nanowires that contain extended segments of both the zincblende and
wurtzite polytypes. Cathodoluminescence hyperspectral imaging reveals a
blueshift of the quantum well emission energy by $75\pm15$ meV in the wurtzite
polytype segment. Nanoprobe x-ray diffraction and atom probe tomography enable
$\mathbf{k}\cdot\mathbf{p}$ calculations for the specific sample geometry to
reveal two comparable contributions to this shift. First, there is a 30% drop
in In mole fraction going from the zincblende to the wurtzite segment. Second,
the quantum well is under compressive strain, which has a much stronger impact
on the hole ground state in the wurtzite than in the zincblende segment. Our
results highlight the role of the crystal structure in tuning the emission of
(In,Ga)As quantum wells and pave the way to exploit the possibilities of
three-dimensional bandgap engineering in core-shell nanowire heterostructures.
At the same time, we have demonstrated an advanced characterization toolkit for
the investigation of semiconductor nanostructures.
","Jonas Lähnemann, Megan O. Hill, Jesús Herranz, Oliver Marquardt, Guanhui Gao, Ali Al Hassan, Arman Davtyan, Stephan O. Hruszkewycz, Martin V. Holt, Chunyi Huang, Irene Calvo-Almazán, Uwe Jahn, Ullrich Pietsch, Lincoln J. Lauhon, Lutz Geelhaar",Lutz Geelhaar,2019-03-18T11:30:20Z
"Intelligent Measurement Analysis on Single Cell Raman Images for the
  Diagnosis of Follicular Thyroid Carcinoma","  Inter-observer variability and cancer over-diagnosis are emerging clinical
problems, and there is a strong necessity to support the standards histological
and cytological evaluations by biochemical composition information. Over the
past decades, there has been a very active research in the development of Raman
spectroscopy techniques for oncological applications and large scale clinical
diagnosis. A major issue that has received a lot of attention in the Raman
literature is the fact that variations in instrumental responses and intrinsic
spectral backgrounds over different days of measurements or devices creates
strong inconsistency of Raman intensity spectra over the various experimental
condition, thus making the use of Raman spectroscopy on a large scale and
reproductive basis difficult. We explore different methods to tackle this
inconsistency and show that regular preprocessing methods such as baseline
correction, normalization or wavelet transformation are inefficient on our
datasets. We find that subtracting the mean background spectrum estimated by
identifying non-cell regions in Raman images makes the data more consistent. As
a proof of concept, we employ our single-cell Raman Imaging protocol to
diagnosis challenging follicular lesions, that is known to be particularly
difficult due to the lack of obvious morphological and cytological criteria for
malignancy. We explore dimensionality reduction with both PCA and feature
selection methods, and classification is then performed at the single cell
level with standard classifiers such as k Nearest Neighbors or Random Forest.
We investigate Raman hyperspectral images from FTC133, RO82W-1 and NthyOri 3-1
cell lines and show that the chemical information for the diagnosis is mostly
contained in the cytoplasm. We also reveal some important wavenumber for
malignancy, that can be associated mainly to lipids, cytochrome and
phenylalanine.
",Aurelien Pelissier,Aurelien Pelissier,2019-04-11T13:12:56Z
"A data-driven approach to sampling matrix selection for compressive
  sensing","  Sampling is a fundamental aspect of any implementation of compressive
sensing. Typically, the choice of sampling method is guided by the
reconstruction basis. However, this approach can be problematic with respect to
certain hardware constraints and is not responsive to domain-specific context.
We propose a method for defining an order for a sampling basis that is optimal
with respect to capturing variance in data, thus allowing for meaningful
sensing at any desired level of compression. We focus on the Walsh-Hadamard
sampling basis for its relevance to hardware constraints, but our approach
applies to any sampling basis of interest. We illustrate the effectiveness of
our method on the Physical Sciences Inc. Fabry-P\'{e}rot interferometer sensor
multispectral dataset, the Johns Hopkins Applied Physics Lab FTIR-based
longwave infrared sensor hyperspectral dataset, and a Colorado State University
Swiss Ranger depth image dataset. The spectral datasets consist of simulant
experiments, including releases of chemicals such as GAA and SF6. We combine
our sampling and reconstruction with the adaptive coherence estimator (ACE) and
bulk coherence for chemical detection and we incorporate an algorithmic
threshold for ACE values to determine the presence or absence of a chemical. We
compare results across sampling methods in this context. We have successful
chemical detection at a compression rate of 90%. For all three datasets, we
compare our sampling approach to standard orderings of sampling basis such as
random, sequency, and an analog of sequency that we term `frequency.' In one
instance, the peak signal to noise ratio was improved by over 30% across a test
set of depth images.
","Elin Farnell, Henry Kvinge, John P. Dixon, Julia R. Dupuis, Michael Kirby, Chris Peterson, Elizabeth C. Schundler, Christian W. Smith",Christian W. Smith,2019-06-20T21:25:18Z
Velocity dispersion in the interstellar medium of early galaxies,"  We study the structure of spatially resolved, line-of-sight velocity
dispersion for galaxies in the Epoch of Reionization (EoR) traced by [CII]
$158\mu\rm{m}$ line emission. Our laboratory is a simulated prototypical
Lyman-break galaxy, ""Freesia"", part of the SERRA suite. The analysis
encompasses the redshift range 6 < z < 8, when Freesia is in a very active
assembling phase. We build velocity dispersion maps for three dynamically
distinct evolutionary stages (Spiral Disk at z=7.4, Merger at z=8.0, and
Disturbed Disk at z=6.5) using [CII] hyperspectral data cubes. We find that, at
a high spatial resolution of 0.005"" ($\simeq 30 pc$), the luminosity-weighted
average velocity dispersion is $\sigma_{\rm{CII}}$~23-38 km/s with the highest
value belonging to the highly-structured Disturbed Disk stage. Low resolution
observations tend to overestimate $\sigma_{\rm CII}$ values due to beam
smearing effects that depend on the specific galaxy structure. For an angular
resolution of 0.02"" (0.1""), the average velocity dispersion is 16-34% (52-115%)
larger than the actual one. The [CII] emitting gas in Freesia has a Toomre
parameter $\mathcal{Q}$~0.2 and a rotational-to-dispersion ratio of $v_{\rm
c}/\sigma$~ 7 similar to that observed in z=2-3 galaxies. The primary energy
source for the velocity dispersion is due to gravitational processes, such as
merging/accretion events; energy input from stellar feedback is generally
subdominant (< 10%). Finally, we find that the resolved $\sigma_{\rm{CII}} -
{\Sigma}_{\rm SFR}$ relation is relatively flat for $0.02<{\Sigma}_{\rm
SFR}/{{\rm M}_{\odot}} \mathrm{yr}^{-1} {\mathrm kpc}^{-2} < 30$, with the
majority of data lying on the derived analytical relation $\sigma \propto
\Sigma_{\rm SFR}^{5/7}$. At high SFR, the increased contribution from stellar
feedback steepens the relation, and $\sigma_{\rm{CII}}$ rises slightly.
","M. Kohandel, A. Pallottini, A. Ferrara, S. Carniani, S. Gallerani, L. Vallini, A. Zanella, C. Behrens",C. Behrens,2020-09-10T18:00:01Z
"Carrier diffusion in GaN -- a cathodoluminescence study. III: Nature of
  nonradiative recombination at threading dislocations","  We investigate the impact of threading dislocations with an edge component (a
or a+c-type) on carrier recombination and diffusion in GaN(0001) layers close
to the surface as well as in the bulk. To this end, we utilize
cathodoluminescence imaging of the top surface of a GaN(0001) layer with a
deeply buried (In,Ga)N quantum well. Varying the acceleration voltage of the
primary electrons and comparing the signal from the layer and the quantum well
enables us to probe carrier recombination at depths ranging from the close
vicinity of the surface to the position of the quantum well. Our experiments
are accompanied by fully three-dimensional Monte Carlo simulations of carrier
drift, diffusion, and recombination in the presence of the surface, the quantum
well, and the dislocation, taking into account the dislocation strain field and
the resulting piezoelectric field at the dislocation outcrop. Near the surface,
this field establishes an exciton dead zone around the dislocation, the extent
of which is not related to the carrier diffusion length. However, reliable
values of the carrier diffusion length can be extracted from the dipole-like
energy shift observed in hyperspectral cathodoluminescence maps recorded around
the dislocation outcrop at low acceleration voltages. For high acceleration
voltages, allowing us to probe a depth where carrier recombination is
unaffected by surface effects, we observe a much stronger contrast than
expected from the piezoelectric field alone. This finding provides unambiguous
experimental evidence for the strong nonradiative activity of edge threading
dislocations in bulk GaN and hence also in buried heterostructures.
","Jonas Lähnemann, Vladimir M. Kaganer, Karl K. Sabelfeld, Anastasya E. Kireeva, Uwe Jahn, Caroline Chèze, Raffaella Calarco, Oliver Brandt",Oliver Brandt,2020-09-30T12:47:17Z
"Comparative optic and dosimetric characterization of the HYPERSCINT
  scintillation dosimetry research platform for multipoint applications","  This study introduces the HYPERSCINT research platform, the first
commercially available scintillation dosimetry platform capable of multi-point
dosimetry through the hyperspectral approach. Optic and dosimetric performances
of the system were investigated through comparison with another commercially
available solution, the Ocean Optics QE65Pro spectrometer. The optical
characterization was accomplished by measuring the linearity of the signal as a
function of integration time, photon detection efficiency and spectral
resolution for both systems. Dosimetric performances were then evaluated with a
3-point plastic scintillator detector (mPSD) in terms of signal to noise ratio
(SNR) and signal to background ratio (SBR) associated with each scintillator.
The latter were subsequently compared with those found in the literature for
the Exradin W1, a single-point plastic scintillator detector. Finally, various
beam measurements were realized with the HYPERSCINT platform to evaluate its
ability to perform clinical photon beam dosimetry. Both systems were found to
be comparable in terms of linearity of the signal as a function of the
intensity. Although the QE65Pro possesses a higher spectral resolution, the
detection efficency of the HYPERSCINT is up to 1000 time greater. Dosimetric
measurements shows that the latter also offers a better SNR and SBR, surpassing
even the SNR of the Exradin W1 single-point PSD. While the doses ranging from 1
cGy to 600 cGy were accurately measured within 2.1% of the predicted dose using
the HYPERSCINT platform coupled to the mPSD, the Ocean optics spectrometer
shows discrepencies up to 86% under 50cGy. Similarly, depth dose, full width at
half maximum region of the beam profile and output factors were all accurately
measured within 2.3% of the predicted dose using the HYPERSCINT platform and
exhibit an average difference of 0.5%, 1.6% and 0.6%, respectively.
","Emilie Jean, Francois Therriault-Proulx, Luc Beaulieu",Luc Beaulieu,2020-10-30T18:12:07Z
Matrix-wise $\ell_0$-constrained Sparse Nonnegative Least Squares,"  Nonnegative least squares problems with multiple right-hand sides (MNNLS)
arise in models that rely on additive linear combinations. In particular, they
are at the core of most nonnegative matrix factorization algorithms and have
many applications. The nonnegativity constraint is known to naturally favor
sparsity, that is, solutions with few non-zero entries. However, it is often
useful to further enhance this sparsity, as it improves the interpretability of
the results and helps reducing noise, which leads to the sparse MNNLS problem.
In this paper, as opposed to most previous works that enforce sparsity column-
or row-wise, we first introduce a novel formulation for sparse MNNLS, with a
matrix-wise sparsity constraint. Then, we present a two-step algorithm to
tackle this problem. The first step divides sparse MNNLS in subproblems, one
per column of the original problem. It then uses different algorithms to
produce, either exactly or approximately, a Pareto front for each subproblem,
that is, to produce a set of solutions representing different tradeoffs between
reconstruction error and sparsity. The second step selects solutions among
these Pareto fronts in order to build a sparsity-constrained matrix that
minimizes the reconstruction error. We perform experiments on facial and
hyperspectral images, and we show that our proposed two-step approach provides
more accurate results than state-of-the-art sparse coding heuristics applied
both column-wise and globally.
","Nicolas Nadisic, Jeremy E Cohen, Arnaud Vandaele, Nicolas Gillis",Nicolas Gillis,2020-11-22T17:21:16Z
"What Does TERRA-REF's High Resolution, Multi Sensor Plant Sensing Public
  Domain Data Offer the Computer Vision Community?","  A core objective of the TERRA-REF project was to generate an open-access
reference dataset for the evaluation of sensing technologies to study plants
under field conditions. The TERRA-REF program deployed a suite of
high-resolution, cutting edge technology sensors on a gantry system with the
aim of scanning 1 hectare (10$^4$) at around 1 mm$^2$ spatial resolution
multiple times per week. The system contains co-located sensors including a
stereo-pair RGB camera, a thermal imager, a laser scanner to capture 3D
structure, and two hyperspectral cameras covering wavelengths of 300-2500nm.
This sensor data is provided alongside over sixty types of traditional plant
phenotype measurements that can be used to train new machine learning models.
Associated weather and environmental measurements, information about agronomic
management and experimental design, and the genomic sequences of hundreds of
plant varieties have been collected and are available alongside the sensor and
plant phenotype data.
  Over the course of four years and ten growing seasons, the TERRA-REF system
generated over 1 PB of sensor data and almost 45 million files. The subset that
has been released to the public domain accounts for two seasons and about half
of the total data volume. This provides an unprecedented opportunity for
investigations far beyond the core biological scope of the project.
  The focus of this paper is to provide the Computer Vision and Machine
Learning communities an overview of the available data and some potential
applications of this one of a kind data.
","David LeBauer, Max Burnette, Noah Fahlgren, Rob Kooper, Kenton McHenry, Abby Stylianou",Abby Stylianou,2021-07-29T15:01:29Z
From Google Maps to a Fine-Grained Catalog of Street trees,"  Up-to-date catalogs of the urban tree population are important for
municipalities to monitor and improve quality of life in cities. Despite much
research on automation of tree mapping, mainly relying on dedicated airborne
LiDAR or hyperspectral campaigns, trees are still mostly mapped manually in
practice. We present a fully automated tree detection and species recognition
pipeline to process thousands of trees within a few hours using publicly
available aerial and street view images of Google MapsTM. These data provide
rich information (viewpoints, scales) from global tree shapes to bark textures.
Our work-flow is built around a supervised classification that automatically
learns the most discriminative features from thousands of trees and
corresponding, public tree inventory data. In addition, we introduce a change
tracker to keep urban tree inventories up-to-date. Changes of individual trees
are recognized at city-scale by comparing street-level images of the same tree
location at two different times. Drawing on recent advances in computer vision
and machine learning, we apply convolutional neural networks (CNN) for all
classification tasks. We propose the following pipeline: download all available
panoramas and overhead images of an area of interest, detect trees per image
and combine multi-view detections in a probabilistic framework, adding prior
knowledge; recognize fine-grained species of detected trees. In a later,
separate module, track trees over time and identify the type of change. We
believe this is the first work to exploit publicly available image data for
fine-grained tree mapping at city-scale, respectively over many thousands of
trees. Experiments in the city of Pasadena, California, USA show that we can
detect > 70% of the street trees, assign correct species to > 80% for 40
different species, and correctly detect and classify changes in > 90% of the
cases.
","Steve Branson, Jan Dirk Wegner, David Hall, Nico Lang, Konrad Schindler, Pietro Perona",Pietro Perona,2019-10-07T08:52:50Z
"Learning mid-IR emission spectra of polycyclic aromatic hydrocarbon
  populations from observations","  The JWST will deliver large data sets of high-quality spectral data over the
0.6-28 $\mu$m range. It will combine sensitivity, spectral and spatial
resolution. Specific tools are required to provide efficient scientific
analysis of such large data sets. Our aim is to illustrate the potential of
unsupervised learning methods to get insights into chemical variations in the
populations that carry the aromatic infrared bands (AIBs), more specifically
PAH species and carbonaceous very small grains (VSGs). We present a method
based on linear fitting and blind signal separation (BSS) for extracting
representative spectra for a spectral data set. The method is fast and robust,
which ensures its applicability to JWST spectral cubes. We tested this method
on a sample of ISO-SWS data, which resemble most closely the JWST spectra in
terms of spectral resolution and coverage. Four representative spectra were
extracted. Their main characteristics appear consistent with previous studies
with populations dominated by cationic PAHs, neutral PAHs, evaporating VSGs,
and large ionized PAHs, known as the PAH$^x$ population. In addition, the 3
$\mu$m range, which is considered here for the first time in a BSS method,
reveals the presence of aliphatics connected to neutral PAHs. Each
representative spectrum is found to carry second-order spectral signatures
(e.g. small bands), which are connected with the underlying chemical diversity
of populations. However, the precise attribution of theses signatures remains
limited by the combined small size and heterogeneity of the sample of
astronomical spectra available in this study. The upcoming JWST data will allow
us to overcome this limitation. The large data sets of hyperspectral images
provided by JWST analysed with the proposed method, which is fast and robust,
will open promising perspectives for our understanding of the chemical
evolution of the AIB carriers.
","Sacha Foschino, Olivier Berné, Christine Joblin",Christine Joblin,2019-10-23T10:34:56Z
"AdaptiveWeighted Attention Network with Camera Spectral Sensitivity
  Prior for Spectral Reconstruction from RGB Images","  Recent promising effort for spectral reconstruction (SR) focuses on learning
a complicated mapping through using a deeper and wider convolutional neural
networks (CNNs). Nevertheless, most CNN-based SR algorithms neglect to explore
the camera spectral sensitivity (CSS) prior and interdependencies among
intermediate features, thus limiting the representation ability of the network
and performance of SR. To conquer these issues, we propose a novel adaptive
weighted attention network (AWAN) for SR, whose backbone is stacked with
multiple dual residual attention blocks (DRAB) decorating with long and short
skip connections to form the dual residual learning. Concretely, we investigate
an adaptive weighted channel attention (AWCA) module to reallocate channel-wise
feature responses via integrating correlations between channels. Furthermore, a
patch-level second-order non-local (PSNL) module is developed to capture
long-range spatial contextual information by second-order non-local operations
for more powerful feature representations. Based on the fact that the recovered
RGB images can be projected by the reconstructed hyperspectral image (HSI) and
the given CSS function, we incorporate the discrepancies of the RGB images and
HSIs as a finer constraint for more accurate reconstruction. Experimental
results demonstrate the effectiveness of our proposed AWAN network in terms of
quantitative comparison and perceptual quality over other state-of-the-art SR
methods. In the NTIRE 2020 Spectral Reconstruction Challenge, our entries
obtain the 1st ranking on the Clean track and the 3rd place on the Real World
track. Codes are available at https://github.com/Deep-imagelab/AWAN.
","Jiaojiao Li, Chaoxiong Wu, Rui Song, Yunsong Li, Fei Liu",Fei Liu,2020-05-19T09:21:01Z
"Improving the estimation of directional area scattering factor (DASF)
  from canopy reflectance: theoretical basis and validation","  Directional area scattering factor (DASF) is a critical canopy structural
parameter for vegetation monitoring. It provides an efficient tool for
decoupling of canopy structure and leaf optics from canopy reflectance. Current
standard approach to estimate DASF from canopy bidirectional reflectance factor
(BRF) is based on the assumption that in the weakly absorbing 710 to 790 nm
spectral interval, leaf scattering does not change much with the concentration
of dry matter and thus its variation can be neglected. This results in biased
estimates of DASF and consequently leads to uncertainty in DASF-related
applications. This study proposes a new approach to account for variations in
concentrations of this biochemical constituent, which additionally uses the
canopy BRF at 2260 nm. In silico analysis of the proposed approach suggests
significant increase in accuracy over the standard technique by a relative root
mean square error (rRMSE) of 49% and 34% for one- and three dimensional scenes,
respectively. When compared with indoor multi-angular hyperspectral
measurements reported in literature, the mean absolute error has reduced by 68%
for needle leaf and 20% for broadleaf canopies. Thus, the proposed DASF
estimation approach outperforms the current one and can be used more reliably
in DASF-related applications, such as vegetation monitoring of functional
traits, dynamics, and radiation budget.
","Yi Lin, Siyuan Liu, Lei Yan, Kai Yan, Yelu Zeng, Bin Yang",Bin Yang,2022-04-28T02:54:24Z
"A Variable Density Sampling Scheme for Compressive Fourier Transform
  Interferometry","  Fourier Transform Interferometry (FTI) is an appealing Hyperspectral (HS)
imaging modality for many applications demanding high spectral resolution,
e.g., in fluorescence microscopy. However, the effective resolution of FTI is
limited by the durability of biological elements when exposed to illuminating
light. Overexposed elements are subject to photo-bleaching and become unable to
fluoresce. In this context, the acquisition of biological HS volumes based on
sampling the Optical Path Difference (OPD) axis at Nyquist rate leads to
unpleasant trade-offs between spectral resolution, quality of the HS volume,
and light exposure intensity. We propose two variants of the FTI imager, i.e.,
Coded Illumination-FTI (CI-FTI) and Structured Illumination FTI (SI-FTI), based
on the theory of compressive sensing (CS). These schemes efficiently modulate
light exposure temporally (in CI-FTI) or spatiotemporally (in SI-FTI).
Leveraging a variable density sampling strategy recently introduced in CS, we
provide near-optimal illumination strategies, so that the light exposure
imposed on a biological specimen is minimized while the spectral resolution is
preserved. Our analysis focuses on two criteria: (i) a trade-off between
exposure intensity and the quality of the reconstructed HS volume for a given
spectral resolution; (ii) maximizing HS volume quality for a fixed spectral
resolution and constrained exposure budget. Our contributions can be adapted to
an FTI imager without hardware modifications. The reconstruction of HS volumes
from CS-FTI measurements relies on an $l_1$-norm minimization problem promoting
a spatiospectral sparsity prior. Numerically, we support the proposed methods
on synthetic data and simulated CS measurements (from actual FTI measurements)
under various scenarios. In particular, the biological HS volumes can be
reconstructed with a three-to-ten-fold reduction in the light exposure.
","A. Moshtaghpour, L. Jacques, V. Cambareri, P. Antoine, M. Roblin",M. Roblin,2018-01-31T13:00:34Z
"Ice state evolution during spring in Richardson crater, Mars","  The Martian climate is governed by an annual cycle, that results in the
condensation of CO$_{2}$ ice during winter, up to a meter thick at the pole and
thousands of kilometers in extension. Water and dust may be trapped during the
condensation and freed during the sublimation. In addition, ice may be
translucent or granular depending on the deposition process (snow vs direct
condensation), annealing efficiency, and dust sinking process. The
determination of ice translucency is of particular interest to confirm or
reject the cold jet model (also known as Kieffer model).
  This work is focused on the dune field of Richardson Crater in which strong
interactions between the water, dust and CO$_{2}$ cycles are observed. We
analyzed CRISM hyperspectral images in the near IR using radiative transfer
model inversion. We demonstrate that among the states of CO$_{2}$ ice, the
translucent state is observed most frequently. The monitoring of surface
characteristics shows a decrease in the thickness of the ice during the spring
consistently with climate models simulations. We estimate a very low dust
content of a few ppmv into the CO$_{2}$ ice, consistent with the formation
scenario of cold jets. The water impurities is around 0.1\%v, almost stable
during the spring, suggesting a water escape from the surface of subliming
CO$_{2}$ ice layer. The water ice grain size varies in a range 1 to 50 microns.
From these results, we propose the following new mechanism of small water ice
grain suspension: as a cold jet occurs, water ice grains of various sizes are
lifted from the surface. These jets happen during daytime, when the general
upward gas flux from the subliming CO$_{2}$ ice layer is strong enough to carry
the smaller grains, while the bigger fall back on the CO$_{2}$ ice layer. The
smaller water grains are carried away and integrated to the general atmospheric
circulation.
","François Andrieu, Frédéric Schmidt, Sylvain Douté, Eric Chassefière",Eric Chassefière,2018-06-19T10:02:39Z
"Multi-temporal and multi-source remote sensing image classification by
  nonlinear relative normalization","  Remote sensing image classification exploiting multiple sensors is a very
challenging problem: data from different modalities are affected by spectral
distortions and mis-alignments of all kinds, and this hampers re-using models
built for one image to be used successfully in other scenes. In order to adapt
and transfer models across image acquisitions, one must be able to cope with
datasets that are not co-registered, acquired under different illumination and
atmospheric conditions, by different sensors, and with scarce ground
references. Traditionally, methods based on histogram matching have been used.
However, they fail when densities have very different shapes or when there is
no corresponding band to be matched between the images. An alternative builds
upon \emph{manifold alignment}. Manifold alignment performs a multidimensional
relative normalization of the data prior to product generation that can cope
with data of different dimensionality (e.g. different number of bands) and
possibly unpaired examples. Aligning data distributions is an appealing
strategy, since it allows to provide data spaces that are more similar to each
other, regardless of the subsequent use of the transformed data. In this paper,
we study a methodology that aligns data from different domains in a nonlinear
way through {\em kernelization}. We introduce the Kernel Manifold Alignment
(KEMA) method, which provides a flexible and discriminative projection map,
exploits only a few labeled samples (or semantic ties) in each domain, and
reduces to solving a generalized eigenvalue problem. We successfully test KEMA
in multi-temporal and multi-source very high resolution classification tasks,
as well as on the task of making a model invariant to shadowing for
hyperspectral imaging.
","Devis Tuia, Diego Marcos, Gustau Camps-Valls",Gustau Camps-Valls,2020-12-07T08:46:11Z
"3D mapping of the Crab Nebula with SITELLE. I. Deconvolution and
  kinematic reconstruction","  We present a hyperspectral cube of the Crab Nebula obtained with the imaging
Fourier transform spectrometer SITELLE on the Canada-France-Hawaii telescope.
We describe our techniques used to deconvolve the 310 000 individual spectra (R
= 9 600) containing Halpha, [NII]6548,6583, and [SII]6716,6731 emission lines
and create a detailed three-dimensional reconstruction of the supernova remnant
assuming uniform global expansion. We find that the general boundaries of the
3D volume occupied by the Crab are not strictly ellipsoidal as commonly
assumed, and instead appear to follow a ""heart-shaped"" distribution that is
symmetrical about the plane of the pulsar wind torus. Conspicuous restrictions
in the bulk distribution of gas consistent with constrained expansion coincide
with positions of the dark bays and east-west band of He-rich filaments, which
may be associated with interaction with a pre-existing circumstellar disk. The
distribution of filaments follows an intricate honeycomb-like arrangement with
straight and rounded boundaries at large and small scales that are
anti-correlated with distance from the center of expansion. The distribution is
not unlike the large-scale rings observed in supernova remnants 3C 58 and
Cassiopeia A, where it has been attributed to turbulent mixing processes that
encouraged outwardly expanding plumes of radioactive 56Ni-rich ejecta. These
characteristics reflect critical details of the original supernova of 1054 CE
and its progenitor star, and may favour a low-energy explosion of an iron-core
progenitor. We demonstrate that our main findings are robust despite regions of
non-homologous expansion driven by acceleration of material by the pulsar wind
nebula.
","Thomas Martin, Danny Milisavljevic, Laurent Drissen",Laurent Drissen,2021-01-07T19:00:00Z
The PIXL Instrument on the Mars 2020 Perseverance Rover,"  The Planetary Instrument for X-ray Lithochemistry (PIXL) is a micro-focus
X-ray fluorescence spectrometer mounted on the robotic arm of NASA's
Perseverance rover. PIXL will acquire high spatial resolution observations of
rock and soil chemistry, rapidly analyzing the elemental chemistry of a target
surface. In 10 seconds, PIXL can use its powerful 120 micrometer diameter X-ray
beam to analyze a single, sand-sized grain with enough sensitivity to detect
major and minor rock-forming elements, as well as many trace elements. Over a
period of several hours, PIXL can autonomously scan an area of the rock surface
and acquire a hyperspectral map comprised of several thousand individual
measured points.
","Abigail C. Allwood, Joel A. Hurowitz, Benton C. Clark, Luca Cinquini, Scott Davidoff, Robert W. Denise, W. Timothy Elam, Marc C. Foote, David T. Flannery, James H. Gerhard, John P. Grotzinger, Christopher M. Heirwegh, Christina Hernandez, Robert P. Hodyss, Michael W. Jones, John Leif Jorgensen, Jesper Henneke, Peter R. Lawson, Yang Liu, Haley MacDonald, Scott M. McLennan, Kelsey R. Moore, Marion Nachon, Peter Nemere, Lauren O'Neil, David A. K. Pedersen, Kimberly P. Sinclair, Michael E. Sondheim, Eugenie Song, Nicholas R. Tallarida, Michael M. Tice, Alan Treiman, Kyle Uckert, Lawrence A. Wade, Jimmie D. Young, Payam Zamani",Payam Zamani,2021-03-11T23:22:46Z
"A General Destriping Framework for Remote Sensing Images Using Flatness
  Constraint","  Removing stripe noise, i.e., destriping, from remote sensing images is an
essential task in terms of visual quality and subsequent processing. Most
existing destriping methods are designed by combining a particular image
regularization with a stripe noise characterization that cooperates with the
regularization, which precludes us to examine and activate different
regularizations to adapt to various target images. To resolve this, two
requirements need to be considered: a general framework that can handle a
variety of image regularizations in destriping, and a strong stripe noise
characterization that can consistently capture the nature of stripe noise,
regardless of the choice of image regularization. To this end, this paper
proposes a general destriping framework using a newly-introduced stripe noise
characterization, named flatness constraint, where we can handle various
regularization functions in a unified manner. Specifically, we formulate the
destriping problem as a nonsmooth convex optimization problem involving a
general form of image regularization and the flatness constraint. The
constraint mathematically models that the intensity of each stripe is constant
along one direction, resulting in a strong characterization of stripe noise.
For solving the optimization problem, we also develop an efficient algorithm
based on a diagonally preconditioned primal-dual splitting algorithm (DP-PDS),
which can automatically adjust the stepsizes. The effectiveness of our
framework is demonstrated through destriping experiments, where we
comprehensively compare combinations of a variety of image regularizations and
stripe noise characterizations using hyperspectral images (HSI) and infrared
(IR) videos.
","Kazuki Naganuma, Shunsuke Ono",Shunsuke Ono,2021-04-07T01:08:55Z
The Galaxy Evolution Probe,"  The Galaxy Evolution Probe (GEP) is a concept for a mid- and far-infrared
space observatory to measure key properties of large samples of galaxies with
large and unbiased surveys. GEP will attempt to achieve zodiacal light and
Galactic dust emission photon background-limited observations by utilizing a 6
Kelvin, 2.0 meter primary mirror and sensitive arrays of kinetic inductance
detectors. It will have two instrument modules: a 10 - 400 micron hyperspectral
imager with spectral resolution R = 8 (GEP-I) and a 24 - 193 micron, R = 200
grating spectrometer (GEP-S). GEP-I surveys will identify star-forming galaxies
via their thermal dust emission and simultaneously measure redshifts using
polycyclic aromatic hydrocarbon emission lines. Galaxy luminosities derived
from star formation and nuclear supermassive black hole accretion will be
measured for each source, enabling the cosmic star formation history to be
measured to much greater precision than previously possible. Using optically
thin far-infrared fine-structure lines, surveys with GEP-S will measure the
growth of metallicity in the hearts of galaxies over cosmic time and
extraplanar gas will be mapped in spiral galaxies in the local universe to
investigate feedback processes. The science case and mission architecture
designed to meet the science requirements are described, and the kinetic
inductance detector and readout electronics state of the art and needed
developments are described. This paper supersedes the GEP concept study report
cited in it by providing new content, including: a summary of recent
mid-infrared KID development, a discussion of microlens array fabrication for
mid-infrared KIDs, and additional context for galaxy surveys. The reader
interested in more technical details may want to consult the concept study
report.
","Jason Glenn, Charles M. Bradford, Erik Rosolowsky, Rashied Amini, Katherine Alatalo, Lee Armus, Andrew J. Benson, Tzu-Ching Chang, Jeremy Darling, Peter K. Day, Jeanette Domber, Duncan Farrah, Brandon Hensley, Sarah Lipscy, Bradley Moore, Seb Oliver, Joanna Perido, David Redding, Michael Rodgers, Raphael Shirley, Howard A. Smith, John B. Steeves, Carole Tucker, Jonas Zmuidzinas",Jonas Zmuidzinas,2021-09-01T21:04:58Z
"Single-target mineral detection with site-specific endmember extraction
  for survey points identification: A case study of Jaffna, Sri Lanka","  As field surveys used for manual lithological mapping are costly and
time-consuming, digital lithological mapping (DLM) that utilizes remotely
sensed spectral imaging provides a viable and economical alternative.
Generally, DLM has been performed using spectral imaging with the use of
laboratory-generated generic endmember signatures. To that end, this paper
proposes generating a single-target abundance mineral map for DLM, where the
generated map can further be used as a guide for the selection or avoidance of
a field survey. For that, a stochastic cancellation-based methodology was used
to generate a site-specific endemic signature for the mineral in concern to
reduce the inclusive nature otherwise present in DLM. Furthermore, a soil pixel
alignment strategy to visualize the relative purity level of the target mineral
has been introduced in the proposed work. Then, for the method validation,
mapping of limestone deposits in the Jaffna peninsula of Sri Lanka was
conducted as the case study using satellite-based spectral imaging as the
input. It was observed that despite the low signal-to-noise ratio of the input
hyperspectral data the proposed methodology was able to robustly extract the
rich information contained in the input data. Further, a field survey was
conducted to collect soil samples of four sites chosen by the proposed DLM from
the Jaffna peninsula as an algorithm validation and to demonstrate the
application of the proposed solution. The proposed abundance threshold of 0.1
coincided with the industrial standard X-ray diffraction (XRD) threshold of 5%
for the mineral presence. The results of the XRD test validated the use of the
algorithm in the selection of sites to be surveyed, hence could avoid
conducting a costly field survey on the assumption of the existence of a
mineral.
","D. Y. L. Ranasinghe, H. M. H. K. Weerasooriya, S. Herath, H. M. V. R. Herath, G. M. R. I. Godaliyadda, M. P. B. Ekanayake, A. Senaratne, S. L. P. Yasakethu",S. L. P. Yasakethu,2021-09-06T16:29:52Z
"External beam irradiation angle measurement using Cerenkov emission I:
  Signal dependencies consideration","  This study introduces a novel hybrid Cerenkov-scintillation dosimeter which
is intended to be used for irradiation angle measurements based on the Cerenkov
angular dependency. First measurements aimed at validating the ability to
account for the Cerenkov electron energy spectrum dependency by simultaneously
measuring the deposited dose, thus isolating signal variations resulting from
the angular dependency. The Cerenkov probe is composed of a 10-mm long
sensitive volume of clear PMMA optical fiber separated by an absorptive filter
from a 1-mm diameter transport fiber. Filtered and raw Cerenkov signals from
the sensitive volume and transport fiber, respectively, were collected using
the Hyperscint RP-200 scintillation dosimetry platform. The total signal was
unmixed using a hyperspectral approach. Dose calibration of the detector signal
was accomplished with photon and electron beams. Using a solid-water phantom,
measurements at fixed incident angles covering a wide range of doses and output
factors were realized. For fixed incident angle, signal characterization of the
Cerenkov detector displays a linear dose-light relationship. As expected, the
sensitive volume signal was found to be energy dependent. Output factors were
accurately measured within 0.8 % for field size up to 25 cm x 25 cm with both
photons and electrons. First validation of the Cerenkov angular dependency
shows a linear dose-light relationship for the whole range of angles tested. As
expected, the Cerenkov signal intensity per dose unit varies based on the
irradiation angle due to the angular dependency. Results showed that using
calibration conditions where the electron energy spectrum is similar to the
measurement conditions allows to rely on deposited dose to account for this
dependency. These preliminary results constitute a first step toward
experimental irradiation angle measurements.
","Emilie Jean, Simon Lambert-Girard, Francois Therriault-Proulx, Luc Beaulieu",Luc Beaulieu,2021-11-22T15:57:49Z
"HyperPCA: a Powerful Tool to Extract Elemental Maps from Noisy Data
  Obtained in LIBS Mapping of Materials","  Laser-induced breakdown spectroscopy is a preferred technique for fast and
direct multi-elemental mapping of samples under ambient pressure, without any
limitation on the targeted element. However, LIBS mapping data have two
peculiarities: an intrinsically low signal-to-noise ratio due to single-shot
measurements, and a high dimensionality due to the high number of spectra
acquired for imaging. This is all the truer as lateral resolution gets higher:
in this case, the ablation spot diameter is reduced, as well as the ablated
mass and the emission signal, while the number of spectra for a given surface
increases. Therefore, efficient extraction of physico-chemical information from
a noisy and large dataset is a major issue. Multivariate approaches were
introduced by several authors as a means to cope with such data, particularly
Principal Component Analysis. This technique is useful to analyse correlations
between different elements, but it is limited to low signal-to-noise ratios. In
this paper, we introduce HyperPCA, a new analysis tool for hyperspectral images
based on a sparse representation of the data using Discrete Wavelet Transform
and kernel-based sparse PCA to reduce the impact of noise on the data and to
consistently extract the spectroscopic signal, with a particular emphasis on
LIBS data. The method is first illustrated using simulated LIBS mapping
datasets to emphasise its performances with an extremely low shot-to-shot
signal-to-noise ratio, and with a variable degree of spectral interference.
Comparisons to standard PCA and to traditional univariate data analyses are
provided. Finally, it is used to process real data in two cases that clearly
illustrate the potential of the proposed algorithm. We show that the method
presents advantages both in quantity and quality of the information recovered,
thus improving the physico-chemical characterization of analysed surfaces.
","Riccardo Finotello, Mohamed Tamaazousti, Jean-Baptiste Sirven",Jean-Baptiste Sirven,2021-11-30T07:52:44Z
"Planetary Terrestrial Analogues Library Project: 3. Characterization of
  Samples with MicrOmega","  The PTAL (Planetary Terrestrial Analogues Library) project aims at building
and exploiting a database involving several analytical techniques, to help
characterizing the mineralogical evolution of terrestrial bodies, starting with
Mars. Around 100 natural Earth rock samples have been collected from selected
locations to gather a variety of analogues for Martian geology, from volcanic
to sedimentary origin with different levels of alteration. All samples are to
be characterized within the PTAL project with different mineralogical and
elemental analysis techniques, including techniques brought on actual and
future instruments at the surface of Mars (Near InfraRed spectroscopy, Raman
spectroscopy and Laser Induced Breakdown Spectroscopy). This paper presents the
NIR measurements and interpretations acquired with the ExoMars MicrOmega spare
instrument. MicrOmega is a NIR hyperspectral microscope, mounted in the
analytical laboratory of the ExoMars rover Rosalind Franklin. All PTAL samples
have been observed at least once with MicrOmega using a dedicated setup. For
all PTAL samples data description and interpretation are presented. For some
chosen examples, RGB images and spectra are presented a well. A comparison with
characterizations by NIR and Raman spectrometry is discussed for some of the
samples. In particular, the spectral imaging capacity of MicrOmega allows
detections of mineral components and potential organic molecules that were not
possible with other one-spot techniques. Additionally, it enables to estimate
heterogeneities in the spatial distribution of various mineral species. The
MicrOmega/PTAL data shall support the future observations and analyses
performed by MicrOmega/Rosalind Franklin instrument.
","Loizeau Damien, Pilorget Cédric, Poulet François, Lantz Cateline, Bibring Jean-Pierre, Hamm Vincent, Royer Clément, Dypvik Henning, Krzesińska Agata M., Rull Fernando, Werner Stephanie C",Werner Stephanie C,2022-01-03T17:49:41Z
Martian meteorites reflectance and implications for rover missions,"  In the next decade, two rovers will characterize in situ the mineralogy of
rocks on Mars, using for the first time near-infrared reflectance
spectrometers: SuperCam onboard the Mars 2020 rover and MicrOmega onboard the
ExoMars rover, although this technique is predominantly used in orbit for
mineralogical investigations. Until successful completion of sample-return
missions from Mars, Martian meteorites are currently the only samples of the
red planet available for study in terrestrial laboratories and comparison with
in situ data. However, the current spectral database available for these
samples does not represent their diversity and consists primarily of spectra
acquired on finely crushed samples, albeit grain size is known to greatly
affect spectral features. We measured the reflected light of a broad Martian
meteorite suite as a means to catalogue and characterize their spectra between
0.4 and 3 microns. These measurements are achieved using a point spectrometer
acquiring data comparable to SuperCam, and an imaging spectrometer producing
hyperspectral cubes similarly to MicrOmega. Our results indicate that point
spectrometry is sufficient to discriminate the different Martian meteorites
families, to identify their primary petrology based on band parameters, and to
detect their low content in alteration minerals. However, significant spectral
mixing occurs in the point measurements, even at spot sizes down to a few
millimeters, and imaging spectroscopy is needed to correctly identify the
various mineral phases in the meteorites. Bidirectional spectral measurements
confirm their non-Lambertian behavior, with backward and suspected forward
scattering peaks. With changing observation geometry, the main absorption
strengths show variations up to 10-15 percents. All the spectra presented are
provided in the supplementary data for further comparison with in situ and
orbital measurements.
","Lucia Mandon, Pierre Beck, Cathy Quantin-Nataf, Erwin Dehouck, Antoine Pommerol, Zurine Yoldi, Romain Cerubini, Lu Pan, Melissa Martinot, Violaine Sautter",Violaine Sautter,2022-03-18T16:52:47Z
"DiverGet: A Search-Based Software Testing Approach for Deep Neural
  Network Quantization Assessment","  Quantization is one of the most applied Deep Neural Network (DNN) compression
strategies, when deploying a trained DNN model on an embedded system or a cell
phone. This is owing to its simplicity and adaptability to a wide range of
applications and circumstances, as opposed to specific Artificial Intelligence
(AI) accelerators and compilers that are often designed only for certain
specific hardware (e.g., Google Coral Edge TPU). With the growing demand for
quantization, ensuring the reliability of this strategy is becoming a critical
challenge. Traditional testing methods, which gather more and more genuine data
for better assessment, are often not practical because of the large size of the
input space and the high similarity between the original DNN and its quantized
counterpart. As a result, advanced assessment strategies have become of
paramount importance. In this paper, we present DiverGet, a search-based
testing framework for quantization assessment. DiverGet defines a space of
metamorphic relations that simulate naturally-occurring distortions on the
inputs. Then, it optimally explores these relations to reveal the disagreements
among DNNs of different arithmetic precision. We evaluate the performance of
DiverGet on state-of-the-art DNNs applied to hyperspectral remote sensing
images. We chose the remote sensing DNNs as they're being increasingly deployed
at the edge (e.g., high-lift drones) in critical domains like climate change
research and astronomy. Our results show that DiverGet successfully challenges
the robustness of established quantization techniques against
naturally-occurring shifted data, and outperforms its most recent concurrent,
DiffChaser, with a success rate that is (on average) four times higher.
","Ahmed Haj Yahmed, Houssem Ben Braiek, Foutse Khomh, Sonia Bouzidi, Rania Zaatour",Rania Zaatour,2022-07-13T15:27:51Z
The AEROS ocean observation mission and its CubeSat pathfinder,"  AEROS aims to develop a nanosatellite as a precursor of a future system of
systems, which will include assets and capabilities of both new and existing
platforms operating in the Ocean and Space, equipped with state-of-the-art
sensors and technologies, all connected through a communication network linked
to a data gathering, processing and dissemination system. This constellation
leverages scientific and economic synergies emerging from New Space and the
opportunities in prospecting, monitoring, and valuing the Ocean in a
sustainable manner, addressing the demand for improved spatial, temporal, and
spectral coverage in areas such as coastal ecosystems management and climate
change assessment and mitigation. Currently, novel sensors and systems,
including a miniaturized hyperspectral imager and a flexible software-defined
communication system, are being developed and integrated into a new versatile
satellite structure, supported by an innovative on-board software. Additional
sensors, like the LoRaWAN protocol and a wider field of view RGB camera, are
under study. To cope with data needs, a Data Analysis Centre, including a
cloud-based data and telemetry dashboard and a back-end layer, to receive and
process acquired and ingested data, is being implemented to provide
tailored-to-use remote sensing products for a wide range of applications for
private and institutional stakeholders.
","Rute Santos, Orfeu Bertolami, E. Castanho, P. Silva, Alexander Costa, André G. C. Guerra, Miguel Arantes, Miguel Martin, Paulo Figueiredo, Catarina M. Cecilio, Inês Castelão, L. Filipe Azevedo, João Faria, H. Silva, Jorge Fontes, Sophie Prendergast, Marcos Tieppo, Eduardo Pereira, Tiago Miranda, Tiago Hormigo, Kerri Cahoy, Christian Haughwout, Miles Lifson, Cadence Payne",Cadence Payne,2022-11-09T16:38:49Z
"Plasmonic photoconductive terahertz focal-plane array with pixel
  super-resolution","  Imaging systems operating in the terahertz part of the electromagnetic
spectrum are in great demand because of the distinct characteristics of
terahertz waves in penetrating many optically-opaque materials and providing
unique spectral signatures of various chemicals. However, the use of terahertz
imagers in real-world applications has been limited by the slow speed, large
size, high cost, and complexity of the existing imaging systems. These
limitations are mainly imposed due to the lack of terahertz focal-plane arrays
(THz-FPAs) that can directly provide the frequency-resolved and/or
time-resolved spatial information of the imaged objects. Here, we report the
first THz-FPA that can directly provide the spatial amplitude and phase
distributions, along with the ultrafast temporal and spectral information of an
imaged object. It consists of a two-dimensional array of ~0.3 million plasmonic
photoconductive nanoantennas optimized to rapidly detect broadband terahertz
radiation with a high signal-to-noise ratio. As the first proof-of-concept, we
utilized the multispectral nature of the amplitude and phase data captured by
these plasmonic nanoantennas to realize pixel super-resolution imaging of
objects. We successfully imaged and super-resolved etched patterns in a silicon
substrate and reconstructed both the shape and depth of these structures with
an effective number of pixels that exceeds 1-kilo pixels. By eliminating the
need for raster scanning and spatial terahertz modulation, our THz-FPA offers
more than a 1000-fold increase in the imaging speed compared to the
state-of-the-art. Beyond this proof-of-concept super-resolution demonstration,
the unique capabilities enabled by our plasmonic photoconductive THz-FPA offer
transformative advances in a broad range of applications that use hyperspectral
and three-dimensional terahertz images of objects for a wide range of
applications.
","Xurong Li, Deniz Mengu, Aydogan Ozcan, Mona Jarrahi",Mona Jarrahi,2023-05-16T07:03:37Z
"Comparing Transmission- and Epi-BCARS: A Transnational Round Robin on
  Solid State Materials","  Broadband coherent anti-Stokes Raman scattering (BCARS) is an advanced Raman
spectroscopy method that combines the spectral sensitivity of spontaneous Raman
scattering (SR) with the increased signal intensity of single-frequency
coherent Raman techniques. These two features make BCARS particularly suitable
for ultra-fast imaging of heterogeneous samples, as already shown in
biomedicine. Recent studies demonstrated that BCARS also shows exceptional
spectroscopic capabilities when inspecting crystalline materials like lithium
niobate and lithium tantalate, and can be used for fast imaging of
ferroelectric domain walls. These results strongly suggest the extension of
BCARS towards new imaging applications like mapping defects, strain, or dopant
levels, similar to standard SR imaging. Despite these advantages, BCARS suffers
from a spurious and chemically unspecific non-resonant background (NRB) that
distorts and shifts the Raman peaks. Post-processing numerical algorithms are
then used to remove the NRB and to obtain spectra comparable to SR results.
Here, we show the reproducibility of BCARS by conducting an internal Round
Robin with two different BCARS experimental setups, comparing the results on
different crystalline materials of increasing structural complexity: diamond,
6H-SiC, KDP, and KTP. First, we compare the detected and phase-retrieved
signals, the setup-specific NRB-removal steps, and the mode assignment.
Subsequently, we demonstrate the versatility of BCARS by showcasing how the
selection of pump wavelength, pulse width, and detection geometry can be
tailored to suit the specific objectives of the experiment. Finally, we compare
and optimize measurement parameters for the high-speed, hyperspectral imaging
of ferroelectric domain walls in lithium niobate.
","Franz Hempel, Federico Vernuccio, Lukas König, Robin Buschbeck, Michael Rüsing, Giulio Cerullo, Dario Polli, Lukas M. Eng",Lukas M. Eng,2023-06-16T09:08:00Z
"Cross-City Matters: A Multimodal Remote Sensing Benchmark Dataset for
  Cross-City Semantic Segmentation using High-Resolution Domain Adaptation
  Networks","  Artificial intelligence (AI) approaches nowadays have gained remarkable
success in single-modality-dominated remote sensing (RS) applications,
especially with an emphasis on individual urban environments (e.g., single
cities or regions). Yet these AI models tend to meet the performance bottleneck
in the case studies across cities or regions, due to the lack of diverse RS
information and cutting-edge solutions with high generalization ability. To
this end, we build a new set of multimodal remote sensing benchmark datasets
(including hyperspectral, multispectral, SAR) for the study purpose of the
cross-city semantic segmentation task (called C2Seg dataset), which consists of
two cross-city scenes, i.e., Berlin-Augsburg (in Germany) and Beijing-Wuhan (in
China). Beyond the single city, we propose a high-resolution domain adaptation
network, HighDAN for short, to promote the AI model's generalization ability
from the multi-city environments. HighDAN is capable of retaining the spatially
topological structure of the studied urban scene well in a parallel high-to-low
resolution fusion fashion but also closing the gap derived from enormous
differences of RS image representations between different cities by means of
adversarial learning. In addition, the Dice loss is considered in HighDAN to
alleviate the class imbalance issue caused by factors across cities. Extensive
experiments conducted on the C2Seg dataset show the superiority of our HighDAN
in terms of segmentation performance and generalization ability, compared to
state-of-the-art competitors. The C2Seg dataset and the semantic segmentation
toolbox (involving the proposed HighDAN) will be available publicly at
https://github.com/danfenghong.
","Danfeng Hong, Bing Zhang, Hao Li, Yuxuan Li, Jing Yao, Chenyu Li, Martin Werner, Jocelyn Chanussot, Alexander Zipf, Xiao Xiang Zhu",Xiao Xiang Zhu,2023-09-26T23:55:39Z
"Learnable real-time inference of molecular composition from diffuse
  spectroscopy of brain tissue","  Diffuse optical modalities such as broadband near-infrared spectroscopy
(bNIRS) and hyperspectral imaging (HSI) represent a promising alternative for
low-cost, non-invasive, and fast monitoring of functional and structural
properties of living tissue. Particularly, the possibility of extracting the
molecular composition of the tissue from the optical spectra in real-time deems
the spectroscopy techniques as a unique diagnostic tool. However, no
established method exists to streamline the inference of the biochemical
composition from the optical spectrum for real-time applications such as
surgical monitoring. In this paper, we analyse a machine learning technique for
fast and accurate inference of changes in the molecular composition of brain
tissue. We reconsider and propose modifications to the existing learnable
methodology based on the Beer-Lambert law, which analytically connects the
spectra with concentrations. We evaluate the method's applicability to linear
and non-linear formulations of the Beer-Lambert law. The approach is tested on
real data obtained from the bNIRS- and HSI-based optical monitoring of brain
tissue. The results demonstrate that the proposed method enables real-time
molecular composition inference while maintaining the accuracy of traditional
linear and non-linear optimization solvers. Preliminary findings show that
Beer-Lambert law-based spectral unmixing allows to contrast brain anatomy
semantics such as the vessel tree and tumor area.
","Ivan Ezhov, Kevin Scibilia, Luca Giannoni, Florian Kofler, Ivan Iliash, Felix Hsieh, Suprosanna Shit, Charly Caredda, Fred Lange, Ilias Tachtsidis, Daniel Rueckert",Daniel Rueckert,2023-09-27T20:54:41Z
A case study of early galaxy cluster with the Athena X-IFU,"  Context: Observations of the hot gas in distant clusters of galaxies, though
challenging, are key to understand the role of intense galaxy activity,
super-massive black hole feedback and chemical enrichment in the process of
massive halos assembly. Aims: We assess the feasibility to retrieve, using
X-ray hyperspectral data only, the thermodymamical hot gas properties and
chemical abundances of a $z=2$ galaxy cluster of mass M500=7 x $10^{13}
M_{\odot}$, extracted from the Hydrangea hydrodynamical simulation. Methods: We
create mock X-ray observations of the future X-ray Integral Field Unit (X-IFU)
onboard the Athena mission. By forward-modeling the measured 0.4-1 keV surface
brightness, the projected gas temperature and abundance profiles, we
reconstruct the three-dimensional distribution for the gas density, pressure,
temperature and entropy. Results: Thanks to its large field-of-view, high
throughput and exquisite spectral resolution, one X-IFU exposure lasting 100ks
enables reconstructing density and pressure profiles with 20% precision out to
a characteristic radius of R500, accounting for each quantity's intrinsic
dispersion in the Hydrangea simulations. Reconstruction of abundance profiles
requires both higher signal-to-noise ratios and specific binning schemes. We
assess the enhancement brought by longer exposures and by observing the same
object at later evolutionary stages ($z=1-1.5$). Conclusions: Our analysis
highlights the importance of scatter in the radially binned gas properties,
which induces significant effects on the observed projected quantities. The
fidelity of the reconstruction of gas profiles is sensitive to the degree of
gas components mixing along the line-of-sight. Future analyses should aim at
involving dedicated hyper-spectral models and fitting methods that are able to
grasp the complexity of such three-dimensional, multi-phase, diffuse gas
structures.
","F. Castellani, N. Clerc, E. Pointecouteau, Y. M. Bahé, J. Schaye, F. Pajot",F. Pajot,2023-10-19T14:06:55Z
"AllSpark: A Multimodal Spatio-Temporal General Intelligence Model with
  Thirteen Modalities","  For a long time, due to the high heterogeneity in structure and semantics
among various spatiotemporal modal data, the joint interpretation of multimodal
spatiotemporal data has been an extremely challenging problem. The primary
challenge resides in striking a trade-off between the cohesion and autonomy of
diverse modalities, and this trade-off exhibits a progressively nonlinear
nature as the number of modalities expands. We introduce the Language as
Reference Framework (LaRF), a fundamental principle for constructing a
multimodal unified model, aiming to strike a trade-off between the cohesion and
autonomy among different modalities. We propose a multimodal spatiotemporal
general artificial intelligence model, called AllSpark. Our model integrates
thirteen different modalities into a unified framework, including 1D (text,
code), 2D (RGB, infrared, SAR, multispectral, hyperspectral, tables, graphs,
trajectory, oblique photography), and 3D (point clouds, videos) modalities. To
achieve modal cohesion, AllSpark uniformly maps diverse modal features to the
language modality. In addition, we design modality-specific prompts to guide
multi-modal large language models in accurately perceiving multimodal data. To
maintain modality autonomy, AllSpark introduces modality-specific encoders to
extract the tokens of various spatiotemporal modalities. And modal bridge is
employed to achieve dimensional projection from each modality to the language
modality. Finally, observing a gap between the model's interpretation and
downstream tasks, we designed task heads to enhance the model's generalization
capability on specific downstream tasks. Experiments indicate that AllSpark
achieves competitive accuracy in modalities such as RGB and trajectory compared
to state-of-the-art models.
","Run Shao, Cheng Yang, Qiujun Li, Qing Zhu, Yongjun Zhang, YanSheng Li, Yu Liu, Yong Tang, Dapeng Liu, Shizhong Yang, Haifeng Li",Haifeng Li,2023-12-31T17:21:02Z
"Convolutional Neural Network Ensemble Learning for Hyperspectral
  Imaging-based Blackberry Fruit Ripeness Detection in Uncontrolled Farm
  Environment","  Fruit ripeness estimation models have for decades depended on spectral index
features or colour-based features, such as mean, standard deviation, skewness,
colour moments, and/or histograms for learning traits of fruit ripeness.
Recently, few studies have explored the use of deep learning techniques to
extract features from images of fruits with visible ripeness cues. However, the
blackberry (Rubus fruticosus) fruit does not show obvious and reliable visible
traits of ripeness when mature and therefore poses great difficulty to fruit
pickers. The mature blackberry, to the human eye, is black before, during, and
post-ripening. To address this engineering application challenge, this paper
proposes a novel multi-input convolutional neural network (CNN) ensemble
classifier for detecting subtle traits of ripeness in blackberry fruits. The
multi-input CNN was created from a pre-trained visual geometry group 16-layer
deep convolutional network (VGG16) model trained on the ImageNet dataset. The
fully connected layers were optimized for learning traits of ripeness of mature
blackberry fruits. The resulting model served as the base for building
homogeneous ensemble learners that were ensemble using the stack generalization
ensemble (SGE) framework. The input to the network is images acquired with a
stereo sensor using visible and near-infrared (VIS-NIR) spectral filters at
wavelengths of 700 nm and 770 nm. Through experiments, the proposed model
achieved 95.1% accuracy on unseen sets and 90.2% accuracy with in-field
conditions. Further experiments reveal that machine sensory is highly and
positively correlated to human sensory over blackberry fruit skin texture.
","Chollette C. Olisah, Ben Trewhella, Bo Li, Melvyn L. Smith, Benjamin Winstone, E. Charles Whitfield, Felicidad Fernández Fernández, Harriet Duncalfe",Harriet Duncalfe,2024-01-09T12:00:17Z
Jitter Characterization of the HyTI Satellite,"  The Hyperspectral Thermal Imager (HyTI) is a technology demonstration mission
that will obtain high spatial, spectral, and temporal resolution long-wave
infrared images of Earth's surface from a 6U cubesat. HyTI science requires
that the pointing accuracy of the optical axis shall not exceed 2.89 arcsec
over the 0.5 ms integration time due to microvibration effects (known as
jitter). Two sources of vibration are a cryocooler that is added to maintain
the detector at 68 K and three orthogonally placed reaction wheels that are a
part of the attitude control system. Both of these parts will introduce
vibrations that are propagated through to the satellite structure while
imaging. Typical methods of characterizing and measuring jitter involve complex
finite element methods and specialized equipment and setups. In this paper, we
describe a novel method of characterizing jitter for small satellite systems
that is low-cost and minimally modifies the subject's mass distribution. The
metrology instrument is comprised of a laser source, a small mirror mounted via
a 3D printed clamp to a jig, and a lateral effect position-sensing detector.
The position-sensing detector samples 1000 Hz and can measure displacements as
little as 0.15 arcsec at distances of one meter. This paper provides an
experimental procedure that incrementally analyzes vibratory sources to
establish causal relationships between sources and the vibratory modes they
create. We demonstrate the capabilities of this metrology system and testing
procedure on HyTI in the Hawaii Space Flight Lab's clean room. Results include
power spectral density plots that show fundamental and higher-order vibratory
modal frequencies. Results from metrology show that jitter from reaction wheels
meets HyTI system requirements within 3$\sigma$.
","Chase Urasaki, Frances Zhu, Michael Bottom, Miguel Nunes, Aidan Walk",Aidan Walk,2024-04-24T00:26:40Z
"From STEM-EDXS data to phase separation and quantification using
  physics-guided NMF","  We present the development of a new algorithm which combines state-of-the-art
energy-dispersive X-ray (EDX) spectroscopy theory and a suitable machine
learning formulation for the hyperspectral unmixing of scanning transmission
electron microscope EDX spectrum images. The algorithm is based on non-negative
matrix factorization (NMF) incorporating a physics-guided factorization model.
It optimizes a Poisson likelihood, under additional simplex constraint together
with user-chosen sparsity-inducing and smoothing regularizations, and is based
on iterative multiplicative updates. The fluorescence of X-rays is fully
modeled thanks to state-of-the-art theoretical work. It is shown that the
output of the algorithm can be used for a direct chemical quantification. With
this approach, it is straightforward to include a priori knowledge on the
specimen such as the presence or absence of certain chemical elements in some
of its phases. This work is implemented within two open-source Python packages,
espm and emtables, which are used here for data simulation, data analysis and
quantification. Using simulated data, we demonstrate that incorporating
physical modeling in the decomposition helps retrieve meaningful components
from spatially and spectrally mixed phases, even when the data are very noisy.
For synthetic data with a higher signal, the regularizations yield a tenfold
increase in the quality of the reconstructed abundance maps compared to
standard NMF. Our approach is further validated on experimental data with a
known ground truth, where state-of-the art results are achieved by using prior
knowledge about the sample. Our model can be generalized to any other scanning
spectroscopy techniques where underlying physical modeling can be linearized.
","Adrien Teurtrie, Nathanaël Perraudin, Thomas Holvoet, Hui Chen, Duncan T. L. Alexander, Guillaume Obozinski, Cécile Hébert",Cécile Hébert,2024-04-26T15:51:33Z
"Spectral similarities in galaxies through an unsupervised classification
  of spaxels","  We present the first unsupervised classification of spaxels in hyperspectral
images of individual galaxies. Classes identify regions by spectral similarity
and thus take all the information into account that is contained in the data
cubes (spatial and spectral).We used Gaussian mixture models in a latent
discriminant subspace to find clusters of spaxels. The spectra were corrected
for small-scale motions within the galaxy based on emission lines with an
automatic algorithm. Our data consist of two MUSE/VLT data cubes of JKB 18 and
NGC 1068 and one NIRSpec/JWST data cube of NGC 4151.Our classes identify many
regions that are most often easily interpreted. Most of the 11 classes that we
find for JKB 18 are identified as photoionised by stars. Some of them are known
HII regions, but we mapped them as extended, with gradients of ionisation
intensities. One compact structure has not been reported before, and according
to diagnostic diagrams, it might be a planetary nebula or a denser HII region.
For NGC 1068, our 16 classes are of active galactic nucleus-type (AGN) or
star-forming regions. Their spatial distribution corresponds perfectly to
well-known structures such as spiral arms and a ring with giant molecular
clouds. A subclassification in the nuclear region reveals several structures
and gradients in the AGN spectra. Our unsupervised classification of the MUSE
data of NGC 1068 helps visualise the complex interaction of the AGN and the jet
with the interstellar medium in a single map. The centre of NGC 4151 is very
complex, but our classes can easily be related to ionisation cones, the jet, or
H2 emission. We find a new elongated structure that is ionised by the AGN along
the N-S axis perpendicular to the jet direction. It is rotated counterclockwise
with respect to the axis of the H2 emission. Our work shows that the
unsupervised classification of spaxels takes full advantage of the richness of
the information in the data cubes by presenting the spectral and spatial
information in a combined and synthetic way.
","Hugo Chambon, Didier Fraix-Burnet",Didier Fraix-Burnet,2024-05-27T08:40:43Z
"Large-amplitude transverse MHD waves prevailing in the H$α$
  chromosphere of a solar quiet region revealed by MiHI integrated field
  spectral observations","  The investigation of plasma motions in the solar chromosphere is crucial for
understanding the transport of mechanical energy from the interior of the Sun
to the outer atmosphere and into interplanetary space. We report the finding of
large-amplitude oscillatory transverse motions prevailing in the non-spicular
Halpha chromosphere of a small quiet region near the solar disk center. The
observation was carried out on 2018 August 25 with the Microlensed
Hyperspectral Imager (MiHI) installed as an extension to the spectrograph at
the Swedish Solar Telescope (SST). MiHi produced high-resolution Stokes spectra
of the Halpha line over a two-dimensional array of points (sampled every 0.066
arcsec on the image plane) every 1.33 s for about 17 min. We extracted the
Dopple-shift-insensitive intensity data of the line core by applying a bisector
fit to Stoke I line profiles. From our time-distance analysis of the intensity
data, we find a variety of transverse motions with velocity amplitudes of up to
40 km/s in fan fibrils and tiny filaments. In particular, in the fan fibrils,
large-amplitude transverse MHD waves were seen to occur with a mean velocity
amplitude of 25 km/s and a mean period of 5.8 min, propagating at a speed of 40
km/s. These waves are nonlinear and display group behavior. We estimate the
wave energy flux in the upper chromosphere at 3 x 10^6 erg cm^-2 s^-1. Our
results contribute to the advancement of our understanding of the properties of
transverse MHD waves in the solar chromosphere.
","Jongchul Chae, Michiel van Noort, Maria S. Madjarska, Kyeore Lee, Juhyung Kang, Kyuhyoun Cho",Kyuhyoun Cho,2024-05-27T12:10:08Z
"On the Peril of Inferring Phytoplankton Properties from Remote-Sensing
  Observations","  Since 1978, sensors on remote-sensing satellites have provided global,
multi-band images at optical wavelengths to assess ocean color. In parallel,
sophisticated radiative transfer models account for attenuation and emission by
the Earth's atmosphere and ocean, thereby estimating the water-leaving radiance
or and remote-sensing reflectance Rrs. From these Rrs measurements, estimates
of the absorption and scattering by seawater are inferred. We emphasize an
inherent, physical degeneracy in the radiative transfer equation that relates
Rrs to the absorption and backscattering coefficients a and b_b, aka inherent
optical properties (IOPs). Because Rrs depends solely on the ratio of b_b to a,
meaning one cannot retrieve independent functions for the non-water IOPs, a_nw
and b_bnw, without a priori knowledge. Moreover, water generally dominates
scattering at blue wavelengths and absorption at red wavelengths, further
limiting retrievals of IOPs in the presence of noise. We demonstrate that all
previous and current multi-spectral satellite observations lack the statistical
power to measure more than 3 parameters total to describe a_nw and b_bnw. Due
to the ubiquitous exponential-like absorption by color dissolved organic matter
at short wavelengths (l<500nm), multi-spectral Rrs do not permit the detection
of phytoplankton absorption a_ph without very strict priors. Furthermore, such
priors lead to biased and uncertain retrievals of a_ph. Hyperspectral
observations may recover a 4th and possibly 5th parameter describing only one
or two aspects of the complexity of a_ph. These results cast doubt on decades
of literature on IOP retrievals, including estimates of phytoplankton growth
and biomass. We further conclude that NASA/PACE will greatly enhance our
ability to measure the phytoplankton biomass of Earth, but challenges remain in
resolving the IOPs.
","J. Xavier Prochaska, Robert J. Frouin",Robert J. Frouin,2024-08-12T13:43:41Z
"Hydrodynamic thinning of a coating film induced by a small solid defect:
  evidence of a time-minimum thickness","  During coating processes, dust deposition can lead to an uneven thickness in
the resulting film, posing significant problems in industrial processes. Our
study explores the effects of solid defects using a vertical cylindrical fiber
deposited on a silicone oil film coating a horizontal solid substrate. We use a
hyperspectral camera to measure the film thickness by interferometry in the
vicinity of the defect. As predicted and observed in many studies in various
geometries, a circular groove appears around the fiber because of the capillary
suction induced by the meniscus that grows at the bottom of the fiber. We
measure the evolution of the thickness of the film at the groove over time. The
thickness decreases before increasing again leading to the healing of the
perturbation at long time. We propose that healing is due to the arrest of the
suction when the meniscus reaches its equilibrium shape. By combining geometric
analysis with the thin film equation, we have developed scaling laws that
predict both the minimum thickness of the groove, that we call the time-minimum
thickness, and the time required to reach this minimum. If the time-minimum
thickness reaches the thickness at which intermolecular forces begin to play a
role prior to healing, the thickness of the groove will stop decreasing and
saturate due to the competition between drainage and repulsive intermolecular
forces. Based on the previous scaling law, we developed a scaling law
accounting for the critical initial thickness of the film below which the
intermolecular repulsion will start to have an effect, which is in good
agreement with our experiments. These results thus offer valuable insights into
predicting and preventing defects in coating processes, thereby improving the
quality and reliability of coated products in various industries.
","Alice Etienne-Simonetti, Frédéric Restagno, Isabelle Cantat, Emmanuelle Rio",Emmanuelle Rio,2024-09-06T13:16:21Z
"SANE: Strategic Autonomous Non-Smooth Exploration for Multiple Optima
  Discovery in Multi-modal and Non-differentiable Black-box Functions","  Both computational and experimental material discovery bring forth the
challenge of exploring multidimensional and multimodal parameter spaces, such
as phase diagrams of Hamiltonians with multiple interactions, composition
spaces of combinatorial libraries, material structure image spaces, and
molecular embedding spaces. Often these systems are black-box and
time-consuming to evaluate, which resulted in strong interest towards active
learning methods such as Bayesian optimization (BO). However, these systems are
often noisy which make the black box function severely multi-modal and
non-differentiable, where a vanilla BO can get overly focused near a single or
faux optimum, deviating from the broader goal of scientific discovery. To
address these limitations, here we developed Strategic Autonomous Non-Smooth
Exploration (SANE) to facilitate an intelligent Bayesian optimized navigation
with a proposed cost-driven probabilistic acquisition function to find multiple
global and local optimal regions, avoiding the tendency to becoming trapped in
a single optimum. To distinguish between a true and false optimal region due to
noisy experimental measurements, a human (domain) knowledge driven dynamic
surrogate gate is integrated with SANE. We implemented the gate-SANE into a
pre-acquired Piezoresponse spectroscopy data of a ferroelectric combinatorial
library with high noise levels in specific regions, and a piezoresponse force
microscopy (PFM) hyperspectral data. SANE demonstrated better performance than
classical BO to facilitate the exploration of multiple optimal regions and
thereby prioritized learning with higher coverage of scientific values in
autonomous experiments. Our work showcases the potential application of this
method to real-world experiment, where such combined strategic and human
intervening approaches can be critical to unlocking new discoveries in
autonomous research.
","Arpan Biswas, Rama Vasudevan, Rohit Pant, Ichiro Takeuchi, Hiroshi Funakubo, Yongtao Liu",Yongtao Liu,2024-09-18T20:04:51Z
Electrical Spectroscopy of Polaritonic Nanoresonators,"  One of the most captivating properties of polaritons is their capacity to
confine light at the nanoscale. This confinement is even more extreme in
two-dimensional (2D) materials. 2D polaritons have been investigated by optical
measurements using an external photodetector. However, their effective
spectrally resolved electrical detection via far-field excitation remains
unexplored. This fact hinders their potential exploitation in crucial
applications such as sensing molecules and gases, hyperspectral imaging and
optical spectrometry, banking on their potential for integration with silicon
technologies. Herein, we present the first electrical spectroscopy of
polaritonic nanoresonators based on a high-quality 2D-material heterostructure,
which serves at the same time as the photodetector and the polaritonic
platform. We employ metallic nanorods to create hybrid nanoresonators within
the hybrid plasmon-phonon polaritonic medium in the mid and long-wave infrared
ranges. Subsequently, we electrically detect these resonators by near-field
coupling to a graphene pn-junction. The nanoresonators simultaneously present a
record of lateral confinement and high-quality factors of up to 200, exhibiting
prominent peaks in the photocurrent spectrum, particularly at the underexplored
lower reststrahlen band of hBN. We exploit the geometrical and gate tunability
of these nanoresonators to investigate their impact on the photocurrent
spectrum and the polaritonic's waveguided modes. This work opens a venue for
studying this highly tunable and complex hybrid system, as well as for using it
in compact platforms for sensing and photodetection applications.
","Sebastián Castilla, Hitesh Agarwal, Ioannis Vangelidis, Yuliy Bludov, David Alcaraz Iranzo, Adrià Grabulosa, Matteo Ceccanti, Mikhail I. Vasilevskiy, Roshan Krishna Kumar, Eli Janzen, James H. Edgar, Kenji Watanabe, Takashi Taniguchi, Nuno M. R. Peres, Elefterios Lidorikis, Frank H. L. Koppens",Frank H. L. Koppens,2024-09-27T16:24:30Z
"The global surface composition of 67P/CG nucleus by Rosetta/VIRTIS. I)
  Prelanding mission phase","  From August to November 2014 the Rosetta orbiter has performed an extensive
observation campaign aimed at the characterization of 67P/CG nucleus properties
and to the selection of the Philae landing site. The campaign led to the
production of a global map of the illuminated portion of 67P/CG nucleus. During
this prelanding phase the comet's heliocentric distance decreased from 3.62 to
2.93 AU while Rosetta was orbiting around the nucleus at distances between 100
to 10 km. VIRTIS-M, the Visible and InfraRed Thermal Imaging Spectrometer -
Mapping channel (Coradini et al. 2007) onboard the orbiter, has acquired
0.25-5.1 micron hyperspectral data of the entire illuminated surface, e.g. the
north hemisphere and the equatorial regions, with spatial resolution between
2.5 and 25 m/pixel. I/F spectra have been corrected for thermal emission
removal in the 3.5-5.1 micron range and for surface's photometric response. The
resulting reflectance spectra have been used to compute several Cometary
Spectral Indicators (CSI): single scattering albedo at 0.55 micron, 0.5-0.8
micron and 1.0-2.5 micron spectral slopes, 3.2 micron organic material and 2.0
micron water ice band parameters (center, depth) with the aim to map their
spatial distribution on the surface and to study their temporal variability as
the nucleus moved towards the Sun. Indeed, throughout the investigated period,
the nucleus surface shows a significant increase of the single scattering
albedo along with a decrease of the 0.5-0.8 and 1.0-2.5 micron spectral slopes,
indicating a flattening of the reflectance. We attribute the origin of this
effect to the partial removal of the dust layer caused by the increased
contribution of water sublimation to the gaseous activity as comet crossed the
frost-line.
","Gianrico Filacchione, Fabrizio Capaccioni, Mauro Ciarniello, Andrea Raponi, Federico Tosi, Maria Cristina De Sanctis, Stephane Erard, Dominique Bockelee Morvan, Cedric Leyrat, Gabriele Arnold, Bernard Schmitt, Eric Quirico, Giuseppe Piccioni, Alessandra Migliorini, Maria Teresa Capria, Ernesto Palomba, Priscilla Cerroni, Andrea Longobardo, Antonella Barucci, Sonia Fornasier, Robert W. Carlson, Ralf Jaumann, Katrin Stephan, Lyuba V. Moroz, David Kappel, Batiste Rousseau, Sergio Fonti, Francesca Mancarella, Daniela Despan, Mathilde Faure",Mathilde Faure,2016-02-29T19:00:04Z
"Project 1640 Observations of Brown Dwarf GJ 758 B: Near-Infrared
  Spectrum and Atmospheric Modeling","  The nearby Sun-like star GJ 758 hosts a cold substellar companion, GJ 758 B,
at a projected separation of $\lesssim$30 AU, previously detected in
high-contrast multi-band photometric observations. In order to better constrain
the companion's physical characteristics, we acquired the first low-resolution
($R \sim 50$) near-infrared spectrum of it using the high-contrast
hyperspectral imaging instrument Project 1640 on Palomar Observatory's 5-m Hale
telescope. We obtained simultaneous images in 32 wavelength channels covering
the $Y$, $J$, and $H$ bands ($\sim$952-1770 nm), and used data processing
techniques based on principal component analysis to efficiently subtract
chromatic background speckle-noise. GJ 758 B was detected in four epochs during
2013 and 2014. Basic astrometric measurements confirm its apparent northwest
trajectory relative to the primary star, with no clear signs of orbital
curvature. Spectra of SpeX/IRTF observed T dwarfs were compared to the combined
spectrum of GJ 758 B, with ${\chi}^2$ minimization suggesting a best fit for
spectral type T7.0$\pm$1.0, but with a shallow minimum over T5-T8. Fitting of
synthetic spectra from the BT-Settl13 model atmospheres gives an effective
temperature $T_{\text{eff}}=741 \pm 25$ K and surface gravity $\log g = 4.3 \pm
0.5$ dex (cgs). Our derived best-fit spectral type and effective temperature
from modeling of the low-resolution spectrum suggest a slightly earlier and
hotter companion than previous findings from photometric data, but do not rule
out current results, and confirm GJ 758 B as one of the coolest sub-stellar
companions to a Sun-like star to date.
","R. Nilsson, A. Veicht, P. A. Giorla Godfrey, E. L. Rice, J. Aguilar, L. Pueyo, L. C. Roberts Jr., R. Oppenheimer, D. Brenner, S. H. Luszcz-Cook, E. Bacchus, C. Beichman, R. Burruss, E. Cady, R. Dekany, R. Fergus, L. Hillenbrand, S. Hinkley, D. King, T. Lockhart, I. R. Parry, A. Sivaramakrishnan, R. Soummer, G. Vasisht, C. Zhai, N. T. Zimmerman",N. T. Zimmerman,2017-03-03T03:14:17Z
"Quantitative inference of the $H_2$ column densities from 3 mm molecular
  emission: A case study towards Orion B","  Molecular hydrogen being unobservable in cold molecular clouds, the column
density measurements of molecular gas currently rely either on dust emission
observation in the far-IR or on star counting. (Sub-)millimeter observations of
numerous trace molecules are effective from ground based telescopes, but the
relationships between the emission of one molecular line and the H2 column
density (NH2) is non-linear and sensitive to excitation conditions, optical
depths, abundance variations due to the underlying physico-chemistry. We aim to
use multi-molecule line emission to infer NH2 from radio observations. We
propose a data-driven approach to determine NH2 from radio molecular line
observations. We use supervised machine learning methods (Random Forests) on
wide-field hyperspectral IRAM-30m observations of the Orion B molecular cloud
to train a predictor of NH2, using a limited set of molecular lines as input,
and the Herschel-based dust-derived NH2 as ground truth output. For conditions
similar to the Orion B molecular cloud, we obtain predictions of NH2 within a
typical factor of 1.2 from the Herschel-based estimates. An analysis of the
contributions of the different lines to the predictions show that the most
important lines are $^{13}$CO(1-0), $^{12}$CO(1-0), C$^{18}$O(1-0), and
HCO$^+$(1-0). A detailed analysis distinguishing between diffuse, translucent,
filamentary, and dense core conditions show that the importance of these four
lines depends on the regime, and that it is recommended to add the
N$_2$H$^+$(1-0) and CH$_3$OH(20-10) lines for the prediction of NH2 in dense
core conditions. This article opens a promising avenue to directly infer
important physical parameters from the molecular line emission in the
millimeter domain. The next step will be to try to infer several parameters
simultaneously (e.g., NH2 and far-UV illumination field) to further test the
method. [Abridged]
","Pierre Gratier, Jérôme Pety, Emeric Bron, Antoine Roueff, Jan H. Orkisz, Maryvonne Gerin, Victor de Souza Magalhaes, Mathilde Gaudel, Maxime Vono, Sébastien Bardeau, Jocelyn Chanussot, Pierre Chainais, Javier R. Goicoechea, Viviana V. Guzmán, Annie Hughes, Jouni Kainulainen, David Languignon, Jacques Le Bourlot, Franck Le Petit, François Levrier, Harvey Liszt, Nicolas Peretto, Evelyne Roueff, Albrecht Sievers",Albrecht Sievers,2020-08-31T08:15:22Z
"Tracers of the ionization fraction in dense and translucent gas: I.
  Automated exploitation of massive astrochemical model grids","  The ionization fraction plays a key role in the physics and chemistry of the
neutral interstellar medium, from controlling the coupling of the gas to the
magnetic field to allowing fast ion-neutral reactions that drive interstellar
chemistry. Most estimations of the ionization fraction have relied on
deuterated species such as DCO+, whose detection is limited to dense cores
representing an extremely small fraction of the volume of the giant molecular
clouds they are part of. As large field-of-view hyperspectral maps become
available, new tracers may be found. We search for the best observable tracers
of the ionization fraction based on a grid of astrochemical models. We build
grids of models that sample randomly a large space of physical conditions
(unobservable quantities such as gas density, temperature, etc.) and compute
the corresponding observables (line intensities, column densities) and the
ionization fraction. We estimate the predictive power of each potential tracer
by training a Random Forest model to predict the ionization fraction from that
tracer, based on these model grids. In both translucent medium and cold dense
medium conditions, several observable tracers with very good predictive power
for the ionization fraction are found. Several tracers in cold dense medium
conditions are found to be better and more widely applicable than the
traditional DCO+/HCO+ ratio. We also provide simpler analytical fits for
estimating the ionization fraction from the best tracers, and for estimating
the associated uncertainties. We discuss the limitations of the present study
and select a few recommended tracers in both types of conditions. The method
presented here is very general and can be applied to the measurement of any
other quantity of interest (cosmic ray flux, elemental abundances, etc.) from
any type of model (PDR models, time-dependent chemical models, etc.).
(abridged)
","Emeric Bron, Evelyne Roueff, Maryvonne Gerin, Jérôme Pety, Pierre Gratier, Franck Le Petit, Viviana Guzman, Jan H. Orkisz, Victor de Souza Magalhaes, Mathilde Gaudel, Maxime Vono, Sébastien Bardeau, Pierre Chainais, Javier R. Goicoechea, Annie Hughes, Jouni Kainulainen, David Languignon, Jacques Le Bourlot, François Levrier, Harvey Liszt, Karin Öberg, Nicolas Peretto, Antoine Roueff, Albrecht Sievers",Albrecht Sievers,2020-07-27T14:19:56Z
